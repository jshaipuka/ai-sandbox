{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Homework for AI-For-Beginners course: 03-Perceptron](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/3-NeuralNetworks/03-Perceptron/lab/PerceptronMultiClass.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# %pip install datasets\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all outputs from Jupyter notebook cells, not just last.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# pick the seed for reproducability - change it to explore the effects of random variations\n",
    "np.random.seed(1)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"mnist\", split=\"train[:10%]\")\n",
    "dataset_label = dataset_train.features['label']\n",
    "dataset_label_as_num = [dataset_label.str2int(label_name) for label_name in dataset_label.names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMultiClassMNIST:\n",
    "  num_iterations = 1000\n",
    "  learning_rate = 0.01\n",
    "\n",
    "  # Labels are the numbers from 0 to 9.\n",
    "  # For each label, split the dataset into two parts: one with the current label and one with all other labels.\n",
    "  def set_mnist_one_vs_other(dataset_train, label):\n",
    "    current_images = dataset_train.filter(lambda example: example[\"label\"] == label)\n",
    "    other_images = dataset_train.filter(lambda example: example[\"label\"] != label)\n",
    "    return current_images, other_images\n",
    "\n",
    "  # Train a perceptron to distinguish between the current label and all other labels.\n",
    "  def train(positive_examples, negative_examples):\n",
    "    weights = np.zeros((28,28))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = np.asarray(random.choice(positive_examples)['image'])\n",
    "        neg = np.asarray(random.choice(negative_examples)['image'])\n",
    "\n",
    "        if np.sum(np.dot(pos, weights)) <= 0:\n",
    "            weights += pos\n",
    "\n",
    "        if np.sum(np.dot(neg, weights)) >= 0:\n",
    "            weights -= neg\n",
    "\n",
    "    return weights\n",
    "  \n",
    "  # Same but with learning rate\n",
    "  def train_lr(positive_examples, negative_examples):\n",
    "    weights = np.zeros((28,28))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = np.asarray(random.choice(positive_examples)['image'])\n",
    "        neg = np.asarray(random.choice(negative_examples)['image'])\n",
    "\n",
    "        if np.sum(np.dot(pos, weights)) <= 0:\n",
    "            weights += PerceptronMultiClassMNIST.learning_rate * pos\n",
    "\n",
    "        if np.sum(np.dot(neg, weights)) >= 0:\n",
    "            weights -= PerceptronMultiClassMNIST.learning_rate * neg\n",
    "\n",
    "    return weights\n",
    "\n",
    "  def sigmoid(x):\n",
    "      return 1 / (1 + np.exp(-x))\n",
    "\n",
    "  def normalize(image):\n",
    "      return (image - np.mean(image)) / np.std(image)\n",
    "\n",
    "  # Same but with sigmoid\n",
    "  def train_lr_sigmoid(positive_examples, negative_examples):\n",
    "    weights = np.zeros((28,28))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = PerceptronMultiClassMNIST.normalize(np.asarray(random.choice(positive_examples)['image']))\n",
    "        neg = PerceptronMultiClassMNIST.normalize(np.asarray(random.choice(negative_examples)['image']))\n",
    "\n",
    "        pos_error = 1 - PerceptronMultiClassMNIST.sigmoid(np.sum(np.dot(pos, weights)))\n",
    "        neg_error = PerceptronMultiClassMNIST.sigmoid(np.sum(np.dot(neg, weights)))\n",
    "\n",
    "        weights += PerceptronMultiClassMNIST.learning_rate * pos_error * pos\n",
    "        weights -= PerceptronMultiClassMNIST.learning_rate * neg_error * neg\n",
    "\n",
    "    return weights\n",
    "\n",
    "  # Train a perceptron for each label.\n",
    "  def train_perceptrons(dataset_train, dataset_label_as_num, train_fn):\n",
    "    perceptrons = np.zeros(10, dtype=object)\n",
    "    for label_number in dataset_label_as_num:\n",
    "      positive_label, other_labels = PerceptronMultiClassMNIST.set_mnist_one_vs_other(dataset_train, label_number)\n",
    "      perceptrons[label_number] = train_fn(positive_label, other_labels)\n",
    "    return perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptrons = PerceptronMultiClassMNIST.train_perceptrons(dataset_train, dataset_label_as_num, PerceptronMultiClassMNIST.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, weights):\n",
    "    z = np.sum(np.dot(image, weights))\n",
    "    return 1 if z > 0.9 else 0\n",
    "\n",
    "def classify(perceptrons, image):\n",
    "    predictions = [predict(image, weights) for weights in perceptrons]\n",
    "    return np.argmax(predictions), predictions\n",
    "\n",
    "def accuracy(dataset, perceptrons):\n",
    "    correct = 0\n",
    "    for example in dataset:\n",
    "        label = example['label']\n",
    "        prediction, _ = classify(perceptrons, example['image'])\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "    return correct / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+t3w94N1/xTKF0rTZpYt217hl2wx+pZzwMVd8V+ANY8IWtteXktldWVyxSO6spvNj3gZKk4GD1/I+lcrRXuGlRr8UfhjZ+HtE1CSw1rSIkjksDN5cF1GOPMIHU9Mnsc8ciuP8aajYaD4ctvAWkXK3aW1wbrUrxfuy3ONu1P8AZUYGe5+lef0V9NeBfDp+GkNu82nZD2L32s6vImVgQKSsERB5IIyeD29Rj5svZlub+4nQELLKzgHqASTUFFaN1r+s39lHZXmr39xaRALHBNcu6IB0AUnA6Cs6iv/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4AWNgGNyAu/vK3/lhWN2oFHn67x8g8MKUNdzx6s+fHXkpF/4cx5CMf/nnzwYLoLDgq5/e6LJ3/m4yYwEJan/4bASRZIKrYWRiYmQE8thLebeeg4tCGSVAtzgD2dF/nmuhyzEo7PvzZ6caQ/mrP2YYcgwM/Bv//Nk8+83jcrDN6Aqk7v758/dPE7owlK/w9O//CUhyCNcCBZXY//87g0PSaYUAkgyQiWS58Co0OQaEsaaLBNbov0HVCudt/n9LIfbvnxC4ABIj8Mt7RYaiPxeRhBDM83/eus388EcBIYLEOg/0/58/l5BEkJi2n/7+WZHAgyRCMyYAfLhcsjJrmJoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = random.choice(dataset_train)\n",
    "actual_digit = digit['label']\n",
    "predicted_digit, all_predictions = classify(perceptrons, digit['image'])\n",
    "\n",
    "all_predictions\n",
    "actual_digit\n",
    "predicted_digit\n",
    "actual_digit == predicted_digit\n",
    "digit['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dataset_train, perceptrons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
