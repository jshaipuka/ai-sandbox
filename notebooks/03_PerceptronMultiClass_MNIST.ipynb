{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Homework for AI-For-Beginners course: 03-Perceptron](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/3-NeuralNetworks/03-Perceptron/lab/PerceptronMultiClass.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# %pip install datasets\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all outputs from Jupyter notebook cells, not just last.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# pick the seed for reproducability - change it to explore the effects of random variations\n",
    "np.random.seed(1)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"mnist\", split=\"train[:10%]\")\n",
    "dataset_label = dataset_train.features['label']\n",
    "dataset_label_as_num = [dataset_label.str2int(label_name) for label_name in dataset_label.names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6000, 784)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset_train['image']).shape # (6000, 28, 28)\n",
    "\n",
    "# When we train, we need to flatten the images. So (6000, 28, 28) -> (6000, 784)\n",
    "# 28*28 = 784 is the total number of features (pixels. a.k.a. a digit is represented as png file by those dimensions)\n",
    "np.array(dataset_train['image']).reshape(-1, 784).shape # (6000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMultiClassMNIST:\n",
    "  num_iterations = 1000\n",
    "  learning_rate = 0.01\n",
    "\n",
    "  # Labels are the numbers from 0 to 9.\n",
    "  # For each label, split the dataset into two parts: one with the current label and one with all other labels.\n",
    "  def set_mnist_one_vs_other(dataset_train, label):\n",
    "    current_images = dataset_train.filter(lambda example: example[\"label\"] == label)\n",
    "    other_images = dataset_train.filter(lambda example: example[\"label\"] != label)\n",
    "\n",
    "    current_images = np.array(current_images['image']).reshape(-1, 784)\n",
    "    other_images = np.array(other_images['image']).reshape(-1, 784)\n",
    "    return current_images, other_images\n",
    "\n",
    "  # Train a perceptron to distinguish between the current label and all other labels.\n",
    "  def train(positive_examples, negative_examples):\n",
    "    weights = np.zeros((784,))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = np.asarray(random.choice(positive_examples))\n",
    "        neg = np.asarray(random.choice(negative_examples))\n",
    "\n",
    "        if np.sum(np.dot(pos, weights)) <= 0:\n",
    "            weights += pos\n",
    "\n",
    "        if np.sum(np.dot(neg, weights)) >= 0:\n",
    "            weights -= neg\n",
    "\n",
    "    return weights\n",
    "  \n",
    "  # Same but with learning rate\n",
    "  def train_lr(positive_examples, negative_examples):\n",
    "    weights = np.zeros((784,))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = np.asarray(random.choice(positive_examples))\n",
    "        neg = np.asarray(random.choice(negative_examples))\n",
    "\n",
    "        if np.sum(np.dot(pos, weights)) <= 0:\n",
    "            weights += PerceptronMultiClassMNIST.learning_rate * pos\n",
    "\n",
    "        if np.sum(np.dot(neg, weights)) >= 0:\n",
    "            weights -= PerceptronMultiClassMNIST.learning_rate * neg\n",
    "\n",
    "    return weights\n",
    "\n",
    "  def sigmoid(x):\n",
    "      return 1 / (1 + np.exp(-x))\n",
    "\n",
    "  def normalize(image):\n",
    "      return (image - np.mean(image)) / np.std(image)\n",
    "\n",
    "  # Same but with sigmoid\n",
    "  def train_lr_sigmoid(positive_examples, negative_examples):\n",
    "    weights = np.zeros((784,))\n",
    "\n",
    "    for _ in range(PerceptronMultiClassMNIST.num_iterations):\n",
    "        pos = PerceptronMultiClassMNIST.normalize(np.asarray(random.choice(positive_examples)))\n",
    "        neg = PerceptronMultiClassMNIST.normalize(np.asarray(random.choice(negative_examples)))\n",
    "\n",
    "        pos_error = 1 - PerceptronMultiClassMNIST.sigmoid(np.sum(np.dot(pos, weights)))\n",
    "        neg_error = PerceptronMultiClassMNIST.sigmoid(np.sum(np.dot(neg, weights)))\n",
    "\n",
    "        weights += PerceptronMultiClassMNIST.learning_rate * pos_error * pos\n",
    "        weights -= PerceptronMultiClassMNIST.learning_rate * neg_error * neg\n",
    "\n",
    "    return weights\n",
    "\n",
    "  # Train a perceptron for each label.\n",
    "  def train_perceptrons(dataset_train, dataset_label_as_num, train_fn):\n",
    "    perceptrons = np.zeros(10, dtype=object)\n",
    "    for label_number in dataset_label_as_num:\n",
    "      positive_label, other_labels = PerceptronMultiClassMNIST.set_mnist_one_vs_other(dataset_train, label_number)\n",
    "      perceptrons[label_number] = train_fn(positive_label, other_labels)\n",
    "    return perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptrons = PerceptronMultiClassMNIST.train_perceptrons(dataset_train, dataset_label_as_num, PerceptronMultiClassMNIST.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, weights):\n",
    "    z = np.sum(np.dot(image, weights))\n",
    "    return 1 if z > 0.9 else 0\n",
    "\n",
    "def classify(perceptrons, image):\n",
    "    predictions = [predict(image, weights) for weights in perceptrons]\n",
    "    return np.argmax(predictions), predictions\n",
    "\n",
    "def accuracy(dataset, perceptrons):\n",
    "    correct = 0\n",
    "    for example in dataset:\n",
    "        label = example['label']\n",
    "        prediction, _ = classify(perceptrons, np.array(example['image']).reshape(-1, 784))\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "    return correct / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u88GfCTxL4zthe28cVnYE4FxdEqH/wB1QMsPfp71j+L/AATrHgzV57K/t5HhjICXiRMIZcgH5WI564PuDXN12nwq8N2Xirx/Y6dqG42qhpnRcfPsGdpz2Pf2rb8ffFLxLL4w1C10nVpbDTrKZ7W3isnKIURiAxx1Jx+HSt/4VePtf8V+IT4W8RznVdKvLWVJPOjXdGApOS4wcdsnJyRXjurRWtvrN9DYyGWzjuJEgdurRhiFJ+oxXQfDjxbH4K8ZW2rTQvLb7TDMqvtIRsZPQ5x1x3xXoOpfC/wt4svZ9c0Dxxp8NteXDStBcAKYtxyVGWB4z0IH1qrPq/hP4XeH9QsfDGqJrviHUEMD36LtS2jI52kE889mPIycYxXjlFFFFf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABKUlEQVR4AWNgoD9gRLXSXvv/ntuoQlCeQtHF1//+XsEqJ3vl79+///6+5+fGlM6+BpQDSv79e63CElWaddIvkBxY8u/fd6uFQNIwB1U1M/yZthskkmjCKcrAELAZxIYABaB9/TCOStvfvy8sYDwGtZt//zaywLlMvX//zoHzMoG2ycJ5DAwFv//+BXKZkIQQzAlfGJbDJRkZGS98QcgxWHAwHgVyIRb9/8+w4z2SpB/brZVwnRFIEkCmrB/D+3dwIaCD9vHBeSrAsLIG8eAOsueHS4aoMzxFsiT22d+/e7zkRBgYeOXUN3/9+xYRBEAtsudAAXu5rW0HiEaVY2DIBsv+/fsfKPcIRR/INpn0qyBN/24ct9aC2Q6LFSCfNxpIMK5E+AGmhq40AFxVg2Bx7OPYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = random.choice(dataset_train)\n",
    "actual_digit = digit['label']\n",
    "predicted_digit, all_predictions = classify(perceptrons, np.array(digit['image']).reshape(-1, 784))\n",
    "\n",
    "all_predictions\n",
    "actual_digit\n",
    "predicted_digit\n",
    "actual_digit == predicted_digit\n",
    "digit['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71%\n"
     ]
    }
   ],
   "source": [
    "trained_perceptrons_accuracy = accuracy(dataset_train, perceptrons)\n",
    "print(\"{:.0%}\".format(trained_perceptrons_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
