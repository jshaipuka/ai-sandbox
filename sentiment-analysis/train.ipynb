{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:12:47.243836Z",
     "start_time": "2025-06-29T17:12:47.239104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "id": "4a325cdc20fcea1b",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:12:47.750078Z",
     "start_time": "2025-06-29T17:12:47.743467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(messages):\n",
    "    tokens = set()\n",
    "    message_to_tokens = []\n",
    "    for message in messages:\n",
    "        doc = nlp(message)\n",
    "        message_tokens = {token.text.lower() for token in doc if\n",
    "                          token.pos_ in {'ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB'}}\n",
    "        tokens.update(message_tokens)\n",
    "        message_to_tokens.append(message_tokens)\n",
    "    return list(tokens), message_to_tokens"
   ],
   "id": "27ed57cb3ed045d1",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:12:48.814724Z",
     "start_time": "2025-06-29T17:12:48.809831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_x(vocabulary, tokens):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        index = vocabulary[token]\n",
    "        vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = [0] * 3\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "2a9cfd038183490b",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:09:34.468794Z",
     "start_time": "2025-06-29T18:08:40.099744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "corpus = concatenate_datasets([train_dataset, validation_dataset])['text']\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer() # TODO: try different max number of features\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "train_and_validation_xs = [list(row) for row in X] # TODO: what is the difference between this and X itself\n",
    "print(len(train_and_validation_xs))\n",
    "print(len(train_and_validation_xs[0]))\n",
    "\n",
    "# train_tokens, train_message_to_tokens = tokenize(train_dataset['text'])\n",
    "# validation_tokens, validation_message_to_tokens = tokenize(validation_dataset['text'])\n",
    "#\n",
    "# # the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "# tokens = sorted(set(train_tokens + validation_tokens))\n",
    "# print(tokens[:20])\n",
    "#\n",
    "# vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "# print(len(vocabulary))"
   ],
   "id": "ea90e1ea7dc93912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36437\n",
      "31804\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:09:47.405499Z",
     "start_time": "2025-06-29T18:09:47.313221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_xs = train_and_validation_xs[:len(train_dataset)]\n",
    "train_ys = [encode_y(label) for label in train_dataset['label']]\n",
    "validation_xs = train_and_validation_xs[len(train_dataset):]\n",
    "validation_ys = [encode_y(label) for label in validation_dataset['label']]\n",
    "print(f'Train xs length: {len(train_xs)}, train ys length: {len(train_ys)}')\n",
    "print(f'Validation xs length: {len(validation_xs)}, validation ys length: {len(validation_ys)}')"
   ],
   "id": "504721fc9f5288b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train xs length: 31232, train ys length: 31232\n",
      "Validation xs length: 5205, validation ys length: 5205\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:09:52.307109Z",
     "start_time": "2025-06-29T18:09:52.302428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return torch.tensor(np.stack([xs[index] for index in random_indices]), dtype=torch.float32), torch.tensor(\n",
    "        np.stack([ys[index] for index in random_indices]), dtype=torch.float32)"
   ],
   "id": "f47f64e9f3ef440f",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:12:15.838736Z",
     "start_time": "2025-06-29T18:12:15.834271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "e3c3d98029d56fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:12:16.375504Z",
     "start_time": "2025-06-29T18:12:16.270301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 512),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Linear(128, 3)\n",
    ").to(device)"
   ],
   "id": "2f29d5b2201dd917",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:12:26.756993Z",
     "start_time": "2025-06-29T18:12:26.754132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, iterations, validation_xs, validation_ys, batch_size):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "        validation_prediction = model(validation_x_batch.to(device))\n",
    "        validation_loss = F.cross_entropy(validation_prediction, validation_y_batch.to(device), reduction='mean')\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "480ba1bdf6ca83a5",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T18:13:01.648636Z",
     "start_time": "2025-06-29T18:12:27.332007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 128\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 1000\n",
    "for epoch in range(number_of_epoches):\n",
    "    if epoch % 100 == 0 or epoch == number_of_epoches - 1:\n",
    "        iterations = 10\n",
    "        model.eval()\n",
    "        loses = torch.zeros(iterations)\n",
    "        for i in range(iterations):\n",
    "            validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "            validation_prediction = model(validation_x_batch.to(device))\n",
    "            validation_loss = loss_fn(validation_prediction, validation_y_batch.to(device))\n",
    "            loses[i] = validation_loss.item()\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch}, validation loss {loses.mean().item()}')\n",
    "\n",
    "    x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "    if epoch % 100 == 0 or epoch == number_of_epoches - 1:\n",
    "        print(f'Epoch {epoch}, train loss {loss.item()}')\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch > 0 and (epoch % 100 == 0 or epoch == number_of_epoches - 1):\n",
    "        model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(\"Model has been saved as\", model_file_name)\n"
   ],
   "id": "cbea8f838038356e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, validation loss 1.1007750034332275\n",
      "Epoch 0, train loss 1.095632553100586\n",
      "Epoch 100, validation loss 0.8361845016479492\n",
      "Epoch 100, train loss 0.6235423684120178\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_100.pt\n",
      "Epoch 200, validation loss 0.8652393221855164\n",
      "Epoch 200, train loss 0.5559450387954712\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_200.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[175]\u001B[39m\u001B[32m, line 22\u001B[39m\n\u001B[32m     19\u001B[39m     model.train()\n\u001B[32m     20\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, validation loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloses.mean().item()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m x_batch, y_batch = \u001B[43mcreate_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_xs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_ys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m prediction = model(x_batch.to(device))\n\u001B[32m     24\u001B[39m loss = loss_fn(prediction, y_batch.to(device))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[166]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mcreate_batch\u001B[39m\u001B[34m(xs, ys, batch_size)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_batch\u001B[39m(xs, ys, batch_size):\n\u001B[32m      2\u001B[39m     random_indices = np.random.choice(\u001B[38;5;28mlen\u001B[39m(xs), batch_size)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch.tensor(\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mxs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrandom_indices\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, dtype=torch.float32), torch.tensor(\n\u001B[32m      4\u001B[39m         np.stack([ys[index] \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m random_indices]), dtype=torch.float32)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/numpy/_core/shape_base.py:442\u001B[39m, in \u001B[36mstack\u001B[39m\u001B[34m(arrays, axis, out, dtype, casting)\u001B[39m\n\u001B[32m    371\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_stack_dispatcher)\n\u001B[32m    372\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstack\u001B[39m(arrays, axis=\u001B[32m0\u001B[39m, out=\u001B[38;5;28;01mNone\u001B[39;00m, *, dtype=\u001B[38;5;28;01mNone\u001B[39;00m, casting=\u001B[33m\"\u001B[39m\u001B[33msame_kind\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    373\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    374\u001B[39m \u001B[33;03m    Join a sequence of arrays along a new axis.\u001B[39;00m\n\u001B[32m    375\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    440\u001B[39m \n\u001B[32m    441\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m442\u001B[39m     arrays = [\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[32m    443\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m arrays:\n\u001B[32m    444\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mneed at least one array to stack\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:24:06.448681Z",
     "start_time": "2025-06-29T17:24:06.341270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "torch.load(os.path.join(os.getcwd(), \"models\", 'model_999.pt'), map_location=torch.device(device)))"
   ],
   "id": "38e2afbf636e43fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:30:07.358486Z",
     "start_time": "2025-06-29T17:30:07.313546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "message_index = 201\n",
    "message = validation_dataset['text'][message_index]\n",
    "encoded_message = validation_xs[message_index]\n",
    "print(message)\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "print(f'Expected: {labels[torch.argmax(torch.tensor(validation_ys[message_index])).item()]}')\n",
    "# test_tokens, _ = tokenize([message])\n",
    "# x = encode_x(vocabulary, test_tokens)\n",
    "y = model(torch.tensor(encoded_message, dtype=torch.float32).to(device))\n",
    "#\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.argmax(distribution)\n",
    "print(['negative', 'neutral', 'positive'][answer])\n",
    "# model.train()"
   ],
   "id": "4e6ecc187750fda8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh dear! gareths b-day 2moro all my girlfriends are abroad  lucky niamh is coming home 2moro poor gareth has 2 listen 2 me talk all day\n",
      "Expected: neutral\n",
      "tensor([3.0862e-07, 9.9991e-01, 8.7616e-05], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "neutral\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "4fe4b1f7443a9b84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
