{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:51:44.059881Z",
     "start_time": "2025-06-30T05:51:41.663120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "id": "4a325cdc20fcea1b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:51:44.064717Z",
     "start_time": "2025-06-30T05:51:44.062852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_y(label):\n",
    "    vector = torch.zeros(3)\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "2a9cfd038183490b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:53:36.898276Z",
     "start_time": "2025-06-30T05:53:20.848762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "\n",
    "corpus = concatenate_datasets([train_dataset, validation_dataset])['text']\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # TODO: try different max number of features\n",
    "X = torch.tensor(vectorizer.fit_transform(corpus).toarray(), dtype=torch.float32)\n",
    "print(X.shape)"
   ],
   "id": "ea90e1ea7dc93912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36437, 268766])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:53:39.966828Z",
     "start_time": "2025-06-30T05:53:39.807579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_xs = X[:len(train_dataset)]\n",
    "train_ys = torch.stack([encode_y(label) for label in train_dataset['label']])\n",
    "validation_xs = X[len(train_dataset):]\n",
    "validation_ys = torch.stack([encode_y(label) for label in validation_dataset['label']])\n",
    "print(f'Train xs length: {len(train_xs)}, train ys length: {len(train_ys)}')\n",
    "print(f'Validation xs length: {len(validation_xs)}, validation ys length: {len(validation_ys)}')"
   ],
   "id": "504721fc9f5288b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train xs length: 31232, train ys length: 31232\n",
      "Validation xs length: 5205, validation ys length: 5205\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:53:42.023321Z",
     "start_time": "2025-06-30T05:53:42.020119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return xs[random_indices], ys[random_indices]"
   ],
   "id": "f47f64e9f3ef440f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:53:42.786753Z",
     "start_time": "2025-06-30T05:53:42.782793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "e3c3d98029d56fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T05:56:01.912557Z",
     "start_time": "2025-06-30T05:56:01.907788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, iterations, validation_xs, validation_ys, batch_size):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "        validation_prediction = model(validation_x_batch.to(device))\n",
    "        validation_loss = F.cross_entropy(validation_prediction, validation_y_batch.to(device), reduction='mean')\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "480ba1bdf6ca83a5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:00:07.941200Z",
     "start_time": "2025-06-30T06:00:07.701541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 128),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(128, 3)\n",
    ").to(device)"
   ],
   "id": "2f29d5b2201dd917",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:00:39.766076Z",
     "start_time": "2025-06-30T06:00:09.404784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 128\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 1000\n",
    "for epoch in range(number_of_epoches):\n",
    "    if epoch % 100 == 0 or epoch == number_of_epoches - 1:\n",
    "        iterations = 10\n",
    "        mean_loss = estimate_loss(model, iterations, validation_xs, validation_ys, batch_size)\n",
    "        print(f'Epoch {epoch}, validation loss {mean_loss.item()}')\n",
    "\n",
    "    x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "    if epoch % 100 == 0 or epoch == number_of_epoches - 1:\n",
    "        print(f'Epoch {epoch}, train loss {loss.item()}')\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch > 0 and (epoch % 100 == 0 or epoch == number_of_epoches - 1):\n",
    "        model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(\"Model has been saved as\", model_file_name)\n"
   ],
   "id": "cbea8f838038356e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, validation loss 1.1044849157333374\n",
      "Epoch 0, train loss 1.1006226539611816\n",
      "Epoch 100, validation loss 0.8304470181465149\n",
      "Epoch 100, train loss 0.5002315044403076\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_100.pt\n",
      "Epoch 200, validation loss 0.8196702003479004\n",
      "Epoch 200, train loss 0.43814992904663086\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_200.pt\n",
      "Epoch 300, validation loss 0.8260801434516907\n",
      "Epoch 300, train loss 0.27154871821403503\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_300.pt\n",
      "Epoch 400, validation loss 0.8721014261245728\n",
      "Epoch 400, train loss 0.19580766558647156\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_400.pt\n",
      "Epoch 500, validation loss 0.8616323471069336\n",
      "Epoch 500, train loss 0.19394882023334503\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_500.pt\n",
      "Epoch 600, validation loss 0.9115380048751831\n",
      "Epoch 600, train loss 0.22835923731327057\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_600.pt\n",
      "Epoch 700, validation loss 0.9760473966598511\n",
      "Epoch 700, train loss 0.03796270117163658\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_700.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, validation loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmean_loss.item()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m     15\u001B[39m x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m prediction = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m loss = loss_fn(prediction, y_batch.to(device))\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m epoch % \u001B[32m100\u001B[39m == \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m epoch == number_of_epoches - \u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1740\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1738\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1739\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1740\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1748\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1750\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1753\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1754\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    248\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    249\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1740\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1738\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1739\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1740\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1748\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1750\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1753\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1754\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:00:51.051491Z",
     "start_time": "2025-06-30T06:00:50.902184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(os.getcwd(), \"models\", 'model_200.pt'), map_location=torch.device(device)))"
   ],
   "id": "38e2afbf636e43fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:01:47.635242Z",
     "start_time": "2025-06-30T06:01:47.576705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "message_index = 207\n",
    "message = validation_dataset['text'][message_index]\n",
    "encoded_message = validation_xs[message_index]\n",
    "print(message)\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "print(f'Expected: {labels[torch.argmax(validation_ys[message_index]).item()]}')\n",
    "# test_tokens, _ = tokenize([message])\n",
    "# x = encode_x(vocabulary, test_tokens)\n",
    "y = model(encoded_message.to(device))\n",
    "#\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.argmax(distribution)\n",
    "print(['negative', 'neutral', 'positive'][answer])\n",
    "# model.train()"
   ],
   "id": "4e6ecc187750fda8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On my way to school not feeln this rainy day at all.... But I had lots of FUN this weekend  ....\n",
      "Expected: neutral\n",
      "tensor([0.1732, 0.6943, 0.1325], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "neutral\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "4fe4b1f7443a9b84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
