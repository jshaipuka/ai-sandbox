{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:25.316542Z",
     "start_time": "2025-06-28T21:24:23.454372Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset, Dataset\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:26.571497Z",
     "start_time": "2025-06-28T21:24:26.567158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(messages):\n",
    "    tokens = set()\n",
    "    message_to_tokens = []\n",
    "    for message in messages:\n",
    "        doc = nlp(message)\n",
    "        message_tokens = {token.text.lower() for token in doc if\n",
    "                          token.pos_ in {'ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB'}}\n",
    "        tokens.update(message_tokens)\n",
    "        message_to_tokens.append(message_tokens)\n",
    "    # the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "    return sorted(list(tokens)), message_to_tokens"
   ],
   "id": "ab5d7274b7e5c02b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:30.258515Z",
     "start_time": "2025-06-28T21:24:30.255691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_x(vocabulary, tokens):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        index = vocabulary[token]\n",
    "        vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = [0] * 3\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "ccdbb77242fc8586",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:46.611972Z",
     "start_time": "2025-06-28T21:24:32.578869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "\n",
    "tokens, message_to_tokens = tokenize(train_dataset['text'])\n",
    "print(tokens[:20])\n",
    "\n",
    "vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "print(len(vocabulary))"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"-', '#', '$', '%', \"'\", \"'-cholla`s\", \"'back\", \"'gummed\", \"'s\", '(:', '(=', '*', '****', '***kix', '*shuts', '*whispers', '+', '+1', '+1/2']\n",
      "29050\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:58.231893Z",
     "start_time": "2025-06-28T21:25:51.214442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xs = [encode_x(vocabulary, tokens) for tokens in message_to_tokens]\n",
    "ys = [encode_y(label) for label in train_dataset['label']]"
   ],
   "id": "70e9afa4b858fc22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:59.819510Z",
     "start_time": "2025-06-28T21:25:59.816120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return torch.tensor(np.stack([xs[index] for index in random_indices]), dtype=torch.float32), torch.tensor(\n",
    "        np.stack([ys[index] for index in random_indices]), dtype=torch.float32)"
   ],
   "id": "18c5705daf5e4493",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:26:01.200987Z",
     "start_time": "2025-06-28T21:26:01.196846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:26:03.801116Z",
     "start_time": "2025-06-28T21:26:03.545912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocabulary), 256),\n",
    "    nn.Linear(256, 3),\n",
    "    nn.Softmax(dim=-1)  # along which dimension the sum will be 1\n",
    ").to(device)"
   ],
   "id": "4b8c3318eccb5afb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:22:11.981094Z",
     "start_time": "2025-06-28T21:13:40.034582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 512\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 1300\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(xs, ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, loss.item())\n",
    "    if epoch > 0 and (epoch % 100 == 0 or epoch == number_of_epoches - 1):\n",
    "        model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(\"Model has been saved as\", model_file_name)\n"
   ],
   "id": "4f44062e1b42347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0984939336776733\n",
      "10 0.9625958800315857\n",
      "20 0.8951854705810547\n",
      "30 0.8292977213859558\n",
      "40 0.8181977272033691\n",
      "50 0.8018471002578735\n",
      "60 0.7799428701400757\n",
      "70 0.7932983636856079\n",
      "80 0.7879929542541504\n",
      "90 0.7697056531906128\n",
      "100 0.7825945019721985\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_100.pt\n",
      "110 0.743977427482605\n",
      "120 0.7197096943855286\n",
      "130 0.7389661073684692\n",
      "140 0.7244490385055542\n",
      "150 0.7258056402206421\n",
      "160 0.7150658369064331\n",
      "170 0.731610894203186\n",
      "180 0.7535115480422974\n",
      "190 0.7197318077087402\n",
      "200 0.740250825881958\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_200.pt\n",
      "210 0.7198085784912109\n",
      "220 0.7353278994560242\n",
      "230 0.691091775894165\n",
      "240 0.7065654993057251\n",
      "250 0.7149518728256226\n",
      "260 0.7192531824111938\n",
      "270 0.7050416469573975\n",
      "280 0.6831994652748108\n",
      "290 0.6705355644226074\n",
      "300 0.7140761017799377\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_300.pt\n",
      "310 0.6730180382728577\n",
      "320 0.6647689342498779\n",
      "330 0.6999655961990356\n",
      "340 0.6719528436660767\n",
      "350 0.6788133382797241\n",
      "360 0.6863399147987366\n",
      "370 0.6927505135536194\n",
      "380 0.6776487827301025\n",
      "390 0.7050332427024841\n",
      "400 0.7004280090332031\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_400.pt\n",
      "410 0.6724915504455566\n",
      "420 0.7009952664375305\n",
      "430 0.6892887353897095\n",
      "440 0.6820240616798401\n",
      "450 0.6913520693778992\n",
      "460 0.6666726469993591\n",
      "470 0.7006046772003174\n",
      "480 0.6607956886291504\n",
      "490 0.6997709274291992\n",
      "500 0.6767257452011108\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_500.pt\n",
      "510 0.6804311275482178\n",
      "520 0.6740821003913879\n",
      "530 0.6875536441802979\n",
      "540 0.6830805540084839\n",
      "550 0.6692428588867188\n",
      "560 0.6630392074584961\n",
      "570 0.6938391327857971\n",
      "580 0.6744682788848877\n",
      "590 0.6821123957633972\n",
      "600 0.6575753092765808\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_600.pt\n",
      "610 0.6912096738815308\n",
      "620 0.6966577768325806\n",
      "630 0.6858370900154114\n",
      "640 0.6832159757614136\n",
      "650 0.6956711411476135\n",
      "660 0.6562179327011108\n",
      "670 0.6949313879013062\n",
      "680 0.6918402910232544\n",
      "690 0.6335687637329102\n",
      "700 0.707924485206604\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_700.pt\n",
      "710 0.6886539459228516\n",
      "720 0.6798223257064819\n",
      "730 0.6827287077903748\n",
      "740 0.6881484985351562\n",
      "750 0.6671820282936096\n",
      "760 0.6580690741539001\n",
      "770 0.6642589569091797\n",
      "780 0.6673476696014404\n",
      "790 0.6704071760177612\n",
      "800 0.6719987392425537\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_800.pt\n",
      "810 0.6761307120323181\n",
      "820 0.6641855835914612\n",
      "830 0.6996922492980957\n",
      "840 0.6675180196762085\n",
      "850 0.6702898740768433\n",
      "860 0.6734938621520996\n",
      "870 0.6869027614593506\n",
      "880 0.683436393737793\n",
      "890 0.6677637100219727\n",
      "900 0.6743245124816895\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_900.pt\n",
      "910 0.6504344940185547\n",
      "920 0.6662143468856812\n",
      "930 0.6722172498703003\n",
      "940 0.695999264717102\n",
      "950 0.6779270172119141\n",
      "960 0.6802535057067871\n",
      "970 0.648482084274292\n",
      "980 0.6745708584785461\n",
      "990 0.6789515614509583\n",
      "1000 0.6702091693878174\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1000.pt\n",
      "1010 0.6853857636451721\n",
      "1020 0.6801196336746216\n",
      "1030 0.6592835187911987\n",
      "1040 0.6684601306915283\n",
      "1050 0.6589325666427612\n",
      "1060 0.6795766353607178\n",
      "1070 0.6629321575164795\n",
      "1080 0.660564124584198\n",
      "1090 0.6528737545013428\n",
      "1100 0.6599627137184143\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1100.pt\n",
      "1110 0.6938188076019287\n",
      "1120 0.666735053062439\n",
      "1130 0.6744412183761597\n",
      "1140 0.6631057262420654\n",
      "1150 0.6716185808181763\n",
      "1160 0.6589002013206482\n",
      "1170 0.6774452924728394\n",
      "1180 0.6458856463432312\n",
      "1190 0.6734843254089355\n",
      "1200 0.6611137390136719\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1200.pt\n",
      "1210 0.6911154389381409\n",
      "1220 0.6341685056686401\n",
      "1230 0.6642346978187561\n",
      "1240 0.6649180054664612\n",
      "1250 0.6852401494979858\n",
      "1260 0.6664875745773315\n",
      "1270 0.6706449389457703\n",
      "1280 0.6571624279022217\n",
      "1290 0.6529337167739868\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1299.pt\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:26:06.755135Z",
     "start_time": "2025-06-28T21:26:06.692711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(), \"models\", 'model_1299.pt'), map_location=torch.device(device)))\n",
    "model.eval()"
   ],
   "id": "f4c30589c091f035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=29050, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (2): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:27:53.390665Z",
     "start_time": "2025-06-28T21:27:53.345145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = \"My computer is totally broken\"\n",
    "tokens, message_to_tokens = tokenize([message])\n",
    "x = encode_x(vocabulary, tokens)\n",
    "y = model(torch.tensor(x, dtype=torch.float32).to(device))\n",
    "print(y)\n",
    "answer = torch.multinomial(y, 1, replacement=True)\n",
    "print(['negative', 'neutral', 'positive'][answer])"
   ],
   "id": "6c7160e407faace2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 1.1926e-18, 5.2388e-29], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "negative\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:22:59.649335Z",
     "start_time": "2025-06-28T21:22:59.491204Z"
    }
   },
   "cell_type": "code",
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "c630e4b125e46d91",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df6927473d2973f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
