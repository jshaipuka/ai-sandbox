{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:25.316542Z",
     "start_time": "2025-06-28T21:24:23.454372Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset, Dataset\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:26.571497Z",
     "start_time": "2025-06-28T21:24:26.567158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(messages):\n",
    "    tokens = set()\n",
    "    message_to_tokens = []\n",
    "    for message in messages:\n",
    "        doc = nlp(message)\n",
    "        message_tokens = {token.text.lower() for token in doc if\n",
    "                          token.pos_ in {'ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB'}}\n",
    "        tokens.update(message_tokens)\n",
    "        message_to_tokens.append(message_tokens)\n",
    "    # the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "    return sorted(list(tokens)), message_to_tokens"
   ],
   "id": "ab5d7274b7e5c02b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:24:30.258515Z",
     "start_time": "2025-06-28T21:24:30.255691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_x(vocabulary, tokens):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        index = vocabulary[token]\n",
    "        vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = [0] * 3\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "ccdbb77242fc8586",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:46.611972Z",
     "start_time": "2025-06-28T21:24:32.578869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "\n",
    "tokens, message_to_tokens = tokenize(train_dataset['text'])\n",
    "print(tokens[:20])\n",
    "\n",
    "vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "print(len(vocabulary))"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"-', '#', '$', '%', \"'\", \"'-cholla`s\", \"'back\", \"'gummed\", \"'s\", '(:', '(=', '*', '****', '***kix', '*shuts', '*whispers', '+', '+1', '+1/2']\n",
      "29050\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:58.231893Z",
     "start_time": "2025-06-28T21:25:51.214442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xs = [encode_x(vocabulary, tokens) for tokens in message_to_tokens]\n",
    "ys = [encode_y(label) for label in train_dataset['label']]"
   ],
   "id": "70e9afa4b858fc22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:25:59.819510Z",
     "start_time": "2025-06-28T21:25:59.816120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return torch.tensor(np.stack([xs[index] for index in random_indices]), dtype=torch.float32), torch.tensor(\n",
    "        np.stack([ys[index] for index in random_indices]), dtype=torch.float32)"
   ],
   "id": "18c5705daf5e4493",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:26:01.200987Z",
     "start_time": "2025-06-28T21:26:01.196846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:44:16.451847Z",
     "start_time": "2025-06-28T21:44:16.368145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocabulary), 512),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 3)\n",
    ").to(device)"
   ],
   "id": "4b8c3318eccb5afb",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:52:49.924310Z",
     "start_time": "2025-06-28T21:44:25.477835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 512\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 1300\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(xs, ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # TODO: evaluate against the test set as well\n",
    "        print(epoch, loss.item())\n",
    "    if epoch > 0 and (epoch % 100 == 0 or epoch == number_of_epoches - 1):\n",
    "        model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(\"Model has been saved as\", model_file_name)\n"
   ],
   "id": "4f44062e1b42347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0988504886627197\n",
      "10 1.0913362503051758\n",
      "20 1.0769563913345337\n",
      "30 1.0757659673690796\n",
      "40 1.033682107925415\n",
      "50 0.9479398727416992\n",
      "60 0.802152156829834\n",
      "70 0.8036815524101257\n",
      "80 0.7268104553222656\n",
      "90 0.7699982523918152\n",
      "100 0.756033182144165\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_100.pt\n",
      "110 0.6600620150566101\n",
      "120 0.6443519592285156\n",
      "130 0.6632018089294434\n",
      "140 0.702505350112915\n",
      "150 0.6174395084381104\n",
      "160 0.6248451471328735\n",
      "170 0.5867311954498291\n",
      "180 0.5470965504646301\n",
      "190 0.5937950015068054\n",
      "200 0.5384635329246521\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_200.pt\n",
      "210 0.5675145387649536\n",
      "220 0.5747131705284119\n",
      "230 0.4687992036342621\n",
      "240 0.5076034069061279\n",
      "250 0.46345430612564087\n",
      "260 0.4867647588253021\n",
      "270 0.4685673713684082\n",
      "280 0.4485918879508972\n",
      "290 0.471912145614624\n",
      "300 0.4138813614845276\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_300.pt\n",
      "310 0.41901320219039917\n",
      "320 0.4156564474105835\n",
      "330 0.3499963879585266\n",
      "340 0.4638604521751404\n",
      "350 0.40003520250320435\n",
      "360 0.41091495752334595\n",
      "370 0.37555038928985596\n",
      "380 0.3330247402191162\n",
      "390 0.275576651096344\n",
      "400 0.377447247505188\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_400.pt\n",
      "410 0.29948028922080994\n",
      "420 0.35588449239730835\n",
      "430 0.32459568977355957\n",
      "440 0.35659730434417725\n",
      "450 0.31442326307296753\n",
      "460 0.27638864517211914\n",
      "470 0.36057084798812866\n",
      "480 0.2923648953437805\n",
      "490 0.29991549253463745\n",
      "500 0.28613826632499695\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_500.pt\n",
      "510 0.3148738741874695\n",
      "520 0.2683204412460327\n",
      "530 0.3270254135131836\n",
      "540 0.2753145098686218\n",
      "550 0.32682502269744873\n",
      "560 0.23692820966243744\n",
      "570 0.22912195324897766\n",
      "580 0.28011393547058105\n",
      "590 0.29084837436676025\n",
      "600 0.26783287525177\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_600.pt\n",
      "610 0.26120278239250183\n",
      "620 0.3076983690261841\n",
      "630 0.2908191382884979\n",
      "640 0.30507224798202515\n",
      "650 0.2472001016139984\n",
      "660 0.23328089714050293\n",
      "670 0.25678902864456177\n",
      "680 0.20464660227298737\n",
      "690 0.2769838273525238\n",
      "700 0.20723363757133484\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_700.pt\n",
      "710 0.23436051607131958\n",
      "720 0.2570759654045105\n",
      "730 0.2527645230293274\n",
      "740 0.21049165725708008\n",
      "750 0.24354363977909088\n",
      "760 0.18512627482414246\n",
      "770 0.2829505205154419\n",
      "780 0.24744737148284912\n",
      "790 0.20306485891342163\n",
      "800 0.21613222360610962\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_800.pt\n",
      "810 0.25491654872894287\n",
      "820 0.21317750215530396\n",
      "830 0.22767877578735352\n",
      "840 0.24168069660663605\n",
      "850 0.24010513722896576\n",
      "860 0.16927699744701385\n",
      "870 0.21278871595859528\n",
      "880 0.2456757128238678\n",
      "890 0.19830523431301117\n",
      "900 0.1832621842622757\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_900.pt\n",
      "910 0.20889632403850555\n",
      "920 0.17387191951274872\n",
      "930 0.21209076046943665\n",
      "940 0.2354661524295807\n",
      "950 0.18784844875335693\n",
      "960 0.2536507844924927\n",
      "970 0.1720161736011505\n",
      "980 0.22948092222213745\n",
      "990 0.16976703703403473\n",
      "1000 0.219183087348938\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1000.pt\n",
      "1010 0.1483251452445984\n",
      "1020 0.1596420854330063\n",
      "1030 0.1946568489074707\n",
      "1040 0.15277454257011414\n",
      "1050 0.181155264377594\n",
      "1060 0.21557703614234924\n",
      "1070 0.1657562106847763\n",
      "1080 0.2059953510761261\n",
      "1090 0.16828852891921997\n",
      "1100 0.16793110966682434\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1100.pt\n",
      "1110 0.1253029704093933\n",
      "1120 0.2043188512325287\n",
      "1130 0.15525388717651367\n",
      "1140 0.19553439319133759\n",
      "1150 0.23529188334941864\n",
      "1160 0.1493472158908844\n",
      "1170 0.15469291806221008\n",
      "1180 0.17966561019420624\n",
      "1190 0.14018678665161133\n",
      "1200 0.13616740703582764\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1200.pt\n",
      "1210 0.1461515724658966\n",
      "1220 0.13425597548484802\n",
      "1230 0.17515817284584045\n",
      "1240 0.17465466260910034\n",
      "1250 0.20869290828704834\n",
      "1260 0.1347428262233734\n",
      "1270 0.19881072640419006\n",
      "1280 0.16173028945922852\n",
      "1290 0.15634581446647644\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1299.pt\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:53:04.871719Z",
     "start_time": "2025-06-28T21:53:04.773193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(), \"models\", 'model_1299.pt'), map_location=torch.device(device)))\n",
    "model.eval()"
   ],
   "id": "f4c30589c091f035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=29050, out_features=512, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Dropout(p=0.3, inplace=False)\n",
       "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (4): Sigmoid()\n",
       "  (5): Dropout(p=0.2, inplace=False)\n",
       "  (6): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:56:52.817524Z",
     "start_time": "2025-06-28T21:56:52.772011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = \"I don't like you\"\n",
    "tokens, message_to_tokens = tokenize([message])\n",
    "x = encode_x(vocabulary, tokens)\n",
    "y = model(torch.tensor(x, dtype=torch.float32).to(device))\n",
    "\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.multinomial(distribution, 1, replacement=True)\n",
    "print(['negative', 'neutral', 'positive'][answer])"
   ],
   "id": "6c7160e407faace2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1314, 0.5595, 0.3091], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "negative\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T21:40:57.361711Z",
     "start_time": "2025-06-28T21:40:57.111480Z"
    }
   },
   "cell_type": "code",
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "c630e4b125e46d91",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df6927473d2973f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
