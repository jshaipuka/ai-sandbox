{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-29T16:30:40.121040Z",
     "start_time": "2025-06-29T16:30:40.117356Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from datasets import load_dataset, Dataset\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:24:31.670225Z",
     "start_time": "2025-06-29T16:24:31.666662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(messages):\n",
    "    tokens = set()\n",
    "    message_to_tokens = []\n",
    "    for message in messages:\n",
    "        doc = nlp(message)\n",
    "        message_tokens = {token.text.lower() for token in doc if\n",
    "                          token.pos_ in {'ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB'}}\n",
    "        tokens.update(message_tokens)\n",
    "        message_to_tokens.append(message_tokens)\n",
    "    return list(tokens), message_to_tokens"
   ],
   "id": "ab5d7274b7e5c02b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:24:32.660526Z",
     "start_time": "2025-06-29T16:24:32.657318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_x(vocabulary, tokens):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        index = vocabulary[token]\n",
    "        vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = [0] * 3\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "ccdbb77242fc8586",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:25:59.492191Z",
     "start_time": "2025-06-29T16:24:35.275936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "\n",
    "train_tokens, train_message_to_tokens = tokenize(train_dataset['text'])\n",
    "validation_tokens, validation_message_to_tokens = tokenize(validation_dataset['text'])\n",
    "\n",
    "# the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "tokens = sorted(set(train_tokens + validation_tokens))\n",
    "print(tokens[:20])\n",
    "\n",
    "vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "print(len(vocabulary))"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"-', '#', '$', '%', '&', \"'\", \"'-cholla`s\", \"'back\", \"'calendar\", \"'gummed\", \"'not\", \"'peter\", \"'s\", '(:', '(=', '*', '****', '***kix', '*shuts']\n",
      "31839\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:26:09.308610Z",
     "start_time": "2025-06-29T16:26:01.930400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_xs = [encode_x(vocabulary, tokens) for tokens in train_message_to_tokens]\n",
    "train_ys = [encode_y(label) for label in train_dataset['label']]\n",
    "validation_xs = [encode_x(vocabulary, tokens) for tokens in validation_message_to_tokens]\n",
    "validation_ys = [encode_y(label) for label in validation_dataset['label']]"
   ],
   "id": "70e9afa4b858fc22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:26:11.021383Z",
     "start_time": "2025-06-29T16:26:11.019279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return torch.tensor(np.stack([xs[index] for index in random_indices]), dtype=torch.float32), torch.tensor(\n",
    "        np.stack([ys[index] for index in random_indices]), dtype=torch.float32)"
   ],
   "id": "18c5705daf5e4493",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:26:12.996389Z",
     "start_time": "2025-06-29T16:26:12.993104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:35:50.590505Z",
     "start_time": "2025-06-29T16:35:50.534024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocabulary), 256),\n",
    "    nn.Linear(256, 3)\n",
    ").to(device)"
   ],
   "id": "4b8c3318eccb5afb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:36:33.933884Z",
     "start_time": "2025-06-29T16:36:33.930266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, iterations, validation_xs, validation_ys, batch_size):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "        validation_prediction = model(validation_x_batch.to(device))\n",
    "        validation_loss = F.cross_entropy(validation_prediction, validation_y_batch.to(device), reduction='mean')\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "d3b92020a5546457",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T16:37:41.330190Z",
     "start_time": "2025-06-29T16:37:24.883640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 512\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 100\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == number_of_epoches - 1:\n",
    "        mean_loss = estimate_loss(model, 10, validation_xs, validation_ys, batch_size)\n",
    "        print(f'Epoch {epoch}, trail loss {loss.item()}, validation loss {mean_loss.item()}')\n",
    "    if epoch > 0 and (epoch % 10 == 0 or epoch == number_of_epoches - 1):\n",
    "        model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(\"Model has been saved as\", model_file_name)\n"
   ],
   "id": "4f44062e1b42347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, trail loss 1.0992399454116821, validation loss 1.076698899269104\n",
      "Epoch 10, trail loss 0.8647660613059998, validation loss 0.9031645655632019\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_10.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m number_of_epoches = \u001B[32m100\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(number_of_epoches):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     x_batch, y_batch = \u001B[43mcreate_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_xs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_ys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     prediction = model(x_batch.to(device))\n\u001B[32m     12\u001B[39m     loss = loss_fn(prediction, y_batch.to(device))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mcreate_batch\u001B[39m\u001B[34m(xs, ys, batch_size)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_batch\u001B[39m(xs, ys, batch_size):\n\u001B[32m      2\u001B[39m     random_indices = np.random.choice(\u001B[38;5;28mlen\u001B[39m(xs), batch_size)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch.tensor(\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mxs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrandom_indices\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, dtype=torch.float32), torch.tensor(\n\u001B[32m      4\u001B[39m         np.stack([ys[index] \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m random_indices]), dtype=torch.float32)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/numpy/_core/shape_base.py:442\u001B[39m, in \u001B[36mstack\u001B[39m\u001B[34m(arrays, axis, out, dtype, casting)\u001B[39m\n\u001B[32m    371\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_stack_dispatcher)\n\u001B[32m    372\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstack\u001B[39m(arrays, axis=\u001B[32m0\u001B[39m, out=\u001B[38;5;28;01mNone\u001B[39;00m, *, dtype=\u001B[38;5;28;01mNone\u001B[39;00m, casting=\u001B[33m\"\u001B[39m\u001B[33msame_kind\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    373\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    374\u001B[39m \u001B[33;03m    Join a sequence of arrays along a new axis.\u001B[39;00m\n\u001B[32m    375\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    440\u001B[39m \n\u001B[32m    441\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m442\u001B[39m     arrays = [\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[32m    443\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m arrays:\n\u001B[32m    444\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mneed at least one array to stack\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:46:47.507801Z",
     "start_time": "2025-06-28T22:46:47.424964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "torch.load(os.path.join(os.getcwd(), \"models\", 'model_99.pt'), map_location=torch.device(device)))"
   ],
   "id": "f4c30589c091f035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=31839, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T23:44:03.576994Z",
     "start_time": "2025-06-28T23:44:03.333477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "message = \"You're the worst\"\n",
    "test_tokens, _ = tokenize([message])\n",
    "x = encode_x(vocabulary, test_tokens)\n",
    "y = model(torch.tensor(x, dtype=torch.float32).to(device))\n",
    "\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.argmax(distribution)\n",
    "print(['negative', 'neutral', 'positive'][answer])\n",
    "model.train()"
   ],
   "id": "6c7160e407faace2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8409, 0.1492, 0.0099], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "negative\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:35:02.862627Z",
     "start_time": "2025-06-28T22:35:02.662960Z"
    }
   },
   "cell_type": "code",
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "c630e4b125e46d91",
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
