{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T19:16:40.773998Z",
     "start_time": "2025-06-30T19:16:40.769520Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:23:35.281552Z",
     "start_time": "2025-06-30T19:23:32.656135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from util import BucketBatchSampler, BucketDataset\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "test_dataset: Dataset = dataset['test']\n",
    "\n",
    "corpus = concatenate_datasets([train_dataset, validation_dataset])['text']\n",
    "vocabulary = sorted(set(''.join(corpus)))\n",
    "\n",
    "char_to_i = {u: i for i, u in enumerate(vocabulary)}\n",
    "\n",
    "\n",
    "def encode_x(char_to_i, message):\n",
    "    return np.array([char_to_i[char] for char in message])\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = torch.zeros(3)\n",
    "    vector[label] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "train_messages = [encode_x(char_to_i, message) for message in train_dataset['text']]\n",
    "train_labels = [encode_y(label) for label in train_dataset['label']]\n",
    "\n",
    "train_bucket_batch_sampler = BucketBatchSampler(train_messages, 128)  # <-- does not store X\n",
    "train_bucket_dataset = BucketDataset(train_messages, train_labels)\n",
    "train_dataloader = DataLoader(train_bucket_dataset, batch_size=1, batch_sampler=train_bucket_batch_sampler,\n",
    "                              shuffle=False, num_workers=8, drop_last=False)\n"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:27:27.015162Z",
     "start_time": "2025-06-30T19:27:27.009352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See https://docs.pytorch.org/docs/stable/generated/torch.nn.GRU.html.\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_dim, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, sequence, hidden):\n",
    "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
    "        embedded = self.embedding(sequence)\n",
    "        # (batch_size, sequence_length, embedding_dim)\n",
    "        # -> (batch_size, sequence_length, hidden_size), (num_layers, batch_size, hidden_size)\n",
    "        prediction, hidden = self.rnn(embedded, hidden)\n",
    "        # See https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#creating-the-network.\n",
    "        return self.linear(hidden[0]), hidden"
   ],
   "id": "74d00197ac7e8079",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:27:55.148661Z",
     "start_time": "2025-06-30T19:27:34.035189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim = 256\n",
    "hidden_size = 1024\n",
    "num_layers = 3\n",
    "model = Model(len(vocabulary), embedding_dim, hidden_size)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "# See https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop.\n",
    "for epoch, data in enumerate(train_dataloader):\n",
    "    x, y = data\n",
    "    batch_size = x.shape[0]\n",
    "    h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "    # See https://discuss.pytorch.org/t/gru-and-padded-sequences-tipps-and-tricks/90729.\n",
    "    prediction, _ = model.forward(x, h0)\n",
    "    print('prediction.shape', prediction.shape)\n",
    "    print('y.shape', y.shape)\n",
    "\n",
    "    loss = loss_fn(prediction, y)\n",
    "    loss.backward()\n",
    "    print(f'Epoch {epoch}, loss {loss.item()}')\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    break"
   ],
   "id": "4ab6bfa7cbf7355e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction.shape torch.Size([4, 3])\n",
      "y.shape torch.Size([4, 3])\n",
      "Epoch 0, loss 1.1266924142837524\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:13.495625Z",
     "start_time": "2025-06-29T20:10:09.997384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_xs = torch.stack([encode_x(vocabulary, tokens) for tokens in train_message_to_tokens])\n",
    "train_ys = torch.stack([encode_y(label) for label in train_dataset['label']])\n",
    "validation_xs = torch.stack([encode_x(vocabulary, tokens) for tokens in validation_message_to_tokens])\n",
    "validation_ys = torch.stack([encode_y(label) for label in validation_dataset['label']])\n",
    "print(train_xs.shape)\n",
    "print(train_ys.shape)\n",
    "print(validation_xs.shape)\n",
    "print(validation_ys.shape)"
   ],
   "id": "70e9afa4b858fc22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31232, 31839])\n",
      "torch.Size([31232, 3])\n",
      "torch.Size([5205, 31839])\n",
      "torch.Size([5205, 3])\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:16.171833Z",
     "start_time": "2025-06-29T20:10:16.166872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return xs[random_indices], ys[random_indices]"
   ],
   "id": "18c5705daf5e4493",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:18.744226Z",
     "start_time": "2025-06-29T20:10:18.739412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:12.914952Z",
     "start_time": "2025-06-29T20:11:12.907530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, iterations, validation_xs, validation_ys, batch_size):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "        validation_prediction = model(validation_x_batch.to(device))\n",
    "        validation_loss = F.cross_entropy(validation_prediction, validation_y_batch.to(device), reduction='mean')\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "d3b92020a5546457",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:13.419613Z",
     "start_time": "2025-06-29T20:11:13.190819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocabulary), 256),\n",
    "    nn.Linear(256, 3)\n",
    ").to(device)"
   ],
   "id": "4b8c3318eccb5afb",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:17.749951Z",
     "start_time": "2025-06-29T20:11:14.834904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 512\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 100\n",
    "min_validation_loss = float('inf')\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == number_of_epoches - 1:\n",
    "        mean_loss = estimate_loss(model, 10, validation_xs, validation_ys, batch_size)\n",
    "        print(f'Epoch {epoch}, trail loss {loss.item()}, validation loss {mean_loss.item()}')\n",
    "        if mean_loss < min_validation_loss:\n",
    "            model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print(\"Model has been saved as\", model_file_name)\n",
    "            min_validation_loss = mean_loss"
   ],
   "id": "4f44062e1b42347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, trail loss 1.102682113647461, validation loss 1.077303171157837\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.pt\n",
      "Epoch 10, trail loss 0.8979932069778442, validation loss 0.9276639819145203\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_10.pt\n",
      "Epoch 20, trail loss 0.7764990329742432, validation loss 0.8771727681159973\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_20.pt\n",
      "Epoch 30, trail loss 0.6884598135948181, validation loss 0.8671800494194031\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_30.pt\n",
      "Epoch 40, trail loss 0.7256267070770264, validation loss 0.9020015597343445\n",
      "Epoch 50, trail loss 0.6767445802688599, validation loss 0.8644858598709106\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_50.pt\n",
      "Epoch 60, trail loss 0.6512887477874756, validation loss 0.8933747410774231\n",
      "Epoch 70, trail loss 0.48553532361984253, validation loss 0.8906658887863159\n",
      "Epoch 80, trail loss 0.6025042533874512, validation loss 0.9102509617805481\n",
      "Epoch 90, trail loss 0.4578779935836792, validation loss 0.9364584684371948\n",
      "Epoch 99, trail loss 0.5630014538764954, validation loss 0.9557567834854126\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:47.164068Z",
     "start_time": "2025-06-29T20:11:46.942965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(os.getcwd(), \"models\", 'model_50.pt'), map_location=torch.device(device)))"
   ],
   "id": "f4c30589c091f035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:12:48.113589Z",
     "start_time": "2025-06-29T20:12:48.060756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "message = \"You're the best\"\n",
    "test_tokens, _ = tokenize([message])\n",
    "x = encode_x(vocabulary, test_tokens)\n",
    "y = model(x.to(device))\n",
    "\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.argmax(distribution)\n",
    "print(['negative', 'neutral', 'positive'][answer])\n",
    "model.train()"
   ],
   "id": "6c7160e407faace2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0780, 0.2832, 0.6388], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=31839, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:35:02.862627Z",
     "start_time": "2025-06-28T22:35:02.662960Z"
    }
   },
   "cell_type": "code",
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "c630e4b125e46d91",
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
