{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T21:41:25.602413Z",
     "start_time": "2025-06-30T21:41:22.881040Z"
    }
   },
   "source": [
    "import spacy\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:41:25.615296Z",
     "start_time": "2025-06-30T21:41:25.613227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:41:30.586500Z",
     "start_time": "2025-06-30T21:41:26.982580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "test_dataset: Dataset = dataset['test']\n",
    "\n",
    "corpus = concatenate_datasets([train_dataset, validation_dataset])['text']\n",
    "vocabulary = sorted(set(''.join(corpus)))\n",
    "\n",
    "# TODO: cleanup data to only have English letters\n",
    "char_to_i = {u: i for i, u in enumerate(vocabulary)}\n",
    "\n",
    "\n",
    "def encode_x(char_to_i, message):\n",
    "    return torch.tensor([char_to_i[char] for char in message])\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = torch.zeros(3)\n",
    "    vector[label] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "train_messages = [encode_x(char_to_i, message) for message in train_dataset['text']]\n",
    "train_labels = [encode_y(label) for label in train_dataset['label']]\n",
    "\n",
    "print(len(train_messages))\n",
    "print(len(train_labels))\n",
    "print(max([len(message) for message in train_messages]))\n",
    "print(len(vocabulary))\n"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31232\n",
      "31232\n",
      "2176\n",
      "591\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:41:31.315447Z",
     "start_time": "2025-06-30T21:41:31.313402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    # TODO: replace back to random once the data is cleaned up\n",
    "    random_indices = range(0, batch_size)\n",
    "    return nn.utils.rnn.pad_sequence([xs[i] for i in random_indices], batch_first=True), torch.stack([ys[i] for i in random_indices])"
   ],
   "id": "3f23bbdb9a1ce2ad",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:41:32.988829Z",
     "start_time": "2025-06-30T21:41:32.984861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See https://docs.pytorch.org/docs/stable/generated/torch.nn.GRU.html.\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_dim, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, sequence, hidden):\n",
    "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
    "        embedded = self.embedding(sequence)\n",
    "        # (batch_size, sequence_length, embedding_dim)\n",
    "        # -> (batch_size, sequence_length, hidden_size), (num_layers, batch_size, hidden_size)\n",
    "        prediction, hidden = self.rnn(embedded, hidden)\n",
    "        # See https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#creating-the-network.\n",
    "        return self.linear(hidden[0]), hidden"
   ],
   "id": "74d00197ac7e8079",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:47:59.017584Z",
     "start_time": "2025-06-30T21:47:15.353014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: try different batch sizes\n",
    "batch_size = 64\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "model = Model(len(vocabulary), embedding_dim, hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 100\n",
    "min_validation_loss = float('inf')\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(train_messages, train_labels, batch_size)\n",
    "    h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "    prediction, _ = model(x_batch.to(device), h0.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 1 == 0 or epoch == number_of_epoches - 1:\n",
    "        print(f'Epoch {epoch}, train loss {loss.item()}')"
   ],
   "id": "272aafaf0962bf85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 1.1091721057891846\n",
      "Epoch 1, train loss 9.116984367370605\n",
      "Epoch 2, train loss 1.900390386581421\n",
      "Epoch 3, train loss 5.665891170501709\n",
      "Epoch 4, train loss 2.328508138656616\n",
      "Epoch 5, train loss 2.052778482437134\n",
      "Epoch 6, train loss 1.8010810613632202\n",
      "Epoch 7, train loss 1.884670615196228\n",
      "Epoch 8, train loss 1.210036039352417\n",
      "Epoch 9, train loss 1.5176289081573486\n",
      "Epoch 10, train loss 1.455209493637085\n",
      "Epoch 11, train loss 1.4329092502593994\n",
      "Epoch 12, train loss 1.0979852676391602\n",
      "Epoch 13, train loss 1.1786409616470337\n",
      "Epoch 14, train loss 1.231377124786377\n",
      "Epoch 15, train loss 1.0844902992248535\n",
      "Epoch 16, train loss 0.9691324234008789\n",
      "Epoch 17, train loss 0.9969683885574341\n",
      "Epoch 18, train loss 0.9168793559074402\n",
      "Epoch 19, train loss 0.7745076417922974\n",
      "Epoch 20, train loss 0.7864413261413574\n",
      "Epoch 21, train loss 0.710435152053833\n",
      "Epoch 22, train loss 0.6658961772918701\n",
      "Epoch 23, train loss 0.5408737659454346\n",
      "Epoch 24, train loss 0.5052280426025391\n",
      "Epoch 25, train loss 0.4227439761161804\n",
      "Epoch 26, train loss 0.34364891052246094\n",
      "Epoch 27, train loss 0.30163607001304626\n",
      "Epoch 28, train loss 0.2552039921283722\n",
      "Epoch 29, train loss 0.19808727502822876\n",
      "Epoch 30, train loss 0.1436997801065445\n",
      "Epoch 31, train loss 0.10766707360744476\n",
      "Epoch 32, train loss 0.08124542236328125\n",
      "Epoch 33, train loss 0.061040766537189484\n",
      "Epoch 34, train loss 0.04361628741025925\n",
      "Epoch 35, train loss 0.03262120485305786\n",
      "Epoch 36, train loss 0.025099700316786766\n",
      "Epoch 37, train loss 0.019734632223844528\n",
      "Epoch 38, train loss 0.015764456242322922\n",
      "Epoch 39, train loss 0.012838619761168957\n",
      "Epoch 40, train loss 0.01061566174030304\n",
      "Epoch 41, train loss 0.008784716948866844\n",
      "Epoch 42, train loss 0.007365756202489138\n",
      "Epoch 43, train loss 0.006287515163421631\n",
      "Epoch 44, train loss 0.005428562872111797\n",
      "Epoch 45, train loss 0.004741658456623554\n",
      "Epoch 46, train loss 0.0041886428371071815\n",
      "Epoch 47, train loss 0.003735156264156103\n",
      "Epoch 48, train loss 0.0033554979600012302\n",
      "Epoch 49, train loss 0.003030186053365469\n",
      "Epoch 50, train loss 0.002752182073891163\n",
      "Epoch 51, train loss 0.0025194576010107994\n",
      "Epoch 52, train loss 0.0023256014101207256\n",
      "Epoch 53, train loss 0.002160202246159315\n",
      "Epoch 54, train loss 0.002016328740864992\n",
      "Epoch 55, train loss 0.0018906370969489217\n",
      "Epoch 56, train loss 0.0017764208605512977\n",
      "Epoch 57, train loss 0.0016710744239389896\n",
      "Epoch 58, train loss 0.0015781780239194632\n",
      "Epoch 59, train loss 0.0014972767094150186\n",
      "Epoch 60, train loss 0.0014269232051447034\n",
      "Epoch 61, train loss 0.0013651394983753562\n",
      "Epoch 62, train loss 0.0013097272021695971\n",
      "Epoch 63, train loss 0.001258857548236847\n",
      "Epoch 64, train loss 0.0012115135323256254\n",
      "Epoch 65, train loss 0.0011676326394081116\n",
      "Epoch 66, train loss 0.0011275408323854208\n",
      "Epoch 67, train loss 0.0010908255353569984\n",
      "Epoch 68, train loss 0.0010566611308604479\n",
      "Epoch 69, train loss 0.00102473353035748\n",
      "Epoch 70, train loss 0.0009951599640771747\n",
      "Epoch 71, train loss 0.000967940897680819\n",
      "Epoch 72, train loss 0.0009427359909750521\n",
      "Epoch 73, train loss 0.0009191268472932279\n",
      "Epoch 74, train loss 0.0008967990288510919\n",
      "Epoch 75, train loss 0.0008755424059927464\n",
      "Epoch 76, train loss 0.0008553423685953021\n",
      "Epoch 77, train loss 0.0008363216184079647\n",
      "Epoch 78, train loss 0.0008186570485122502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m x_batch, y_batch = create_batch(train_messages, train_labels, batch_size)\n\u001B[32m     14\u001B[39m h0 = torch.zeros(num_layers, batch_size, hidden_size)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m prediction, _ = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh0\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m loss = loss_fn(prediction, y_batch.to(device))\n\u001B[32m     18\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1740\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1738\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1739\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1740\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1748\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1750\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1753\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1754\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mModel.forward\u001B[39m\u001B[34m(self, sequence, hidden)\u001B[39m\n\u001B[32m     12\u001B[39m embedded = \u001B[38;5;28mself\u001B[39m.embedding(sequence)\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# (batch_size, sequence_length, embedding_dim)\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# -> (batch_size, sequence_length, hidden_size), (num_layers, batch_size, hidden_size)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m prediction, hidden = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# See https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#creating-the-network.\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.linear(hidden[\u001B[32m0\u001B[39m]), hidden\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1740\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1738\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1739\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1740\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1748\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1750\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1753\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1754\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1391\u001B[39m, in \u001B[36mGRU.forward\u001B[39m\u001B[34m(self, input, hx)\u001B[39m\n\u001B[32m   1389\u001B[39m \u001B[38;5;28mself\u001B[39m.check_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[32m   1390\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1391\u001B[39m     result = \u001B[43m_VF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1392\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1393\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1394\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1395\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1396\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1397\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1398\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1399\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1400\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1401\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1402\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1403\u001B[39m     result = _VF.gru(\n\u001B[32m   1404\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   1405\u001B[39m         batch_sizes,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1412\u001B[39m         \u001B[38;5;28mself\u001B[39m.bidirectional,\n\u001B[32m   1413\u001B[39m     )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2727732916a2a45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
