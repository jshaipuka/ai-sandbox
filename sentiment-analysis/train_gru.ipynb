{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T09:17:11.722140Z",
     "start_time": "2025-07-06T09:17:11.715813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ],
   "id": "a9dea8914236e91",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:40:25.163616Z",
     "start_time": "2025-07-05T08:40:25.159108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "cc76c8b605ea8925",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:44:04.811735Z",
     "start_time": "2025-07-05T08:44:04.806985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process(example):\n",
    "    example['text'] = example['text'].strip()\n",
    "    example['length'] = len(example['text'])\n",
    "    return example\n",
    "\n",
    "\n",
    "def tokenize_messages(messages):\n",
    "    tokens = set()\n",
    "    tokenized_messages = []\n",
    "    for message in tqdm(messages):\n",
    "        doc = nlp(message)\n",
    "        tokenized_message = [token.text.lower() for token in doc]\n",
    "        tokens.update(tokenized_message)\n",
    "        tokenized_messages.append(tokenized_message)\n",
    "    return list(tokens), tokenized_messages\n",
    "\n",
    "\n",
    "def encode_x(token_to_index, tokens):\n",
    "    return torch.tensor([token_to_index[token] for token in tokens if token in token_to_index])\n",
    "\n",
    "\n",
    "# Returns a scalar with the class index (0, 1 or 2).\n",
    "def encode_y(label):\n",
    "    return torch.tensor(label)"
   ],
   "id": "163dd410cddbc3f7",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:34:54.510626Z",
     "start_time": "2025-07-05T13:33:03.322192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "max_length = float('inf')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train'].filter(lambda it: len(it['text']) <= max_length).map(process).sort('length')\n",
    "validation_dataset: Dataset = dataset['validation'].filter(lambda it: len(it['text']) <= max_length).map(process).sort(\n",
    "    'length')\n",
    "test_dataset: Dataset = dataset['test'].filter(lambda it: it['text'] is not None and len(it['text']) <= max_length).map(\n",
    "    process).sort('length')\n",
    "\n",
    "train_tokens, train_tokenized_messages = tokenize_messages(train_dataset['text'])\n",
    "validation_tokens, validation_tokenized_messages = tokenize_messages(validation_dataset['text'])\n",
    "test_tokens, test_tokenized_messages = tokenize_messages(test_dataset['text'])"
   ],
   "id": "6f85cdf981c20f0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed unexpectedly!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/31232 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82d839b61dd144259577db7c93a4ae45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/31232 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "076b26209a7b441f9d658f18b414ffc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5205 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6dbb4308f2742db994f1263ae87156a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5205 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5e06e2fa0b24830a31395addbc3a41d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/5206 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d0b63e1b6da4ff3ac33b18ca044ebce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5205 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "626fa9ab2e0342cda7778a700a714a1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31232/31232 [01:19<00:00, 390.56it/s]\n",
      "100%|██████████| 5205/5205 [00:13<00:00, 393.82it/s]\n",
      "100%|██████████| 5205/5205 [00:12<00:00, 400.64it/s]\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:34:57.866930Z",
     "start_time": "2025-07-05T13:34:57.834797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "tokens = sorted(set(train_tokens + validation_tokens + test_tokens))\n",
    "print(tokens[:20])\n",
    "\n",
    "vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "print(len(vocabulary))\n",
    "\n",
    "token_to_index = {u: i for i, u in enumerate(vocabulary)}"
   ],
   "id": "83a48a58a92b318c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t ', '\\n', '\\n\\n', ' ', '  ', '   ', '    ', '     ', '      ', '       ', '        ', '             ', '              ', '               ', '                ', '                                           ', '                                                                                              ', '!', '\"', '\"-']\n",
      "36633\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:35:00.242057Z",
     "start_time": "2025-07-05T13:34:59.729965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_messages = [encode_x(token_to_index, tokens) for tokens in train_tokenized_messages]\n",
    "train_labels = [encode_y(label) for label in train_dataset['label']]\n",
    "validation_messages = [encode_x(token_to_index, tokens) for tokens in validation_tokenized_messages]\n",
    "validation_labels = [encode_y(label) for label in validation_dataset['label']]\n",
    "test_messages = [encode_x(token_to_index, tokens) for tokens in test_tokenized_messages]\n",
    "test_labels = [encode_y(label) for label in test_dataset['label']]\n",
    "print(len(train_messages))\n",
    "print(len(train_labels))\n",
    "print(len(validation_messages))\n",
    "print(len(validation_labels))\n",
    "print(len(test_messages))\n",
    "print(len(test_labels))"
   ],
   "id": "890b7a1117c53c76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31232\n",
      "31232\n",
      "5205\n",
      "5205\n",
      "5205\n",
      "5205\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:35:04.651658Z",
     "start_time": "2025-07-05T13:35:04.585908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index = 20000\n",
    "print(train_dataset['text'][index], train_tokenized_messages[index])"
   ],
   "id": "5377b20cad482166",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least he`s in breakthrough performance tho. I just wanted him nominated in his own category ['at', 'least', 'he`s', 'in', 'breakthrough', 'performance', 'tho', '.', 'i', 'just', 'wanted', 'him', 'nominated', 'in', 'his', 'own', 'category']\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:35:06.284457Z",
     "start_time": "2025-07-05T13:35:06.280159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size, padding_value):\n",
    "    index = np.random.choice(len(xs) - batch_size + 1)\n",
    "    indices = range(index, index + batch_size)\n",
    "    return nn.utils.rnn.pad_sequence([xs[i] for i in indices], batch_first=True,\n",
    "                                     padding_value=padding_value).int(), torch.stack(\n",
    "        [ys[i] for i in indices])"
   ],
   "id": "b3d48b570cd093b7",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:35:07.428421Z",
     "start_time": "2025-07-05T13:35:07.423622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, h0, iterations, validation_xs, validation_ys, batch_size, padding_value):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size, padding_value)\n",
    "        validation_prediction, _ = model(validation_x_batch.to(device), h0.to(device))\n",
    "        validation_loss = F.nll_loss(validation_prediction, validation_y_batch.to(device))\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "ae850c6100343752",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:41:34.458882Z",
     "start_time": "2025-07-06T06:41:34.454021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See https://docs.pytorch.org/docs/stable/generated/torch.nn.GRU.html.\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_dim, hidden_size, num_layers):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 3)\n",
    "        self.log_softmax = nn.LogSoftmax(\n",
    "            dim=1)  # The negative log likelihood loss expects log-probabilities of each class.\n",
    "\n",
    "    def forward(self, sequence, hidden):\n",
    "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
    "        embedded = self.embedding(sequence)\n",
    "        # (batch_size, sequence_length, embedding_dim)\n",
    "        # -> (batch_size, sequence_length, hidden_size), (num_layers, batch_size, hidden_size)\n",
    "        prediction, hidden = self.rnn(embedded, hidden)\n",
    "        # See https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#creating-the-network.\n",
    "        linear_prediction = self.linear(prediction[:, -1])\n",
    "        return self.log_softmax(linear_prediction), hidden"
   ],
   "id": "60774ac30b3db966",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T21:01:00.679299Z",
     "start_time": "2025-07-05T13:49:15.528589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 256\n",
    "# See https://discuss.pytorch.org/t/difference-between-cross-entropy-loss-or-log-likelihood-loss/38816/2.\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "patience = 30\n",
    "min_validation_loss = float('inf')\n",
    "for num_layers in range(1, 5):\n",
    "    for embedding_dim_power in range(12):\n",
    "        for hidden_size_power in range(12):\n",
    "            embedding_dim = 2 ** embedding_dim_power\n",
    "            hidden_size = 2 ** hidden_size_power\n",
    "            model = Model(len(vocabulary), embedding_dim, hidden_size, num_layers).to(device)\n",
    "            model_min_validation_loss = float('inf')\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "            number_of_epoches = 5000\n",
    "            model_validation_loses = []\n",
    "\n",
    "            current_patience = patience\n",
    "            for epoch in range(number_of_epoches):\n",
    "                x_batch, y_batch = create_batch(train_messages, train_labels, batch_size, len(vocabulary))\n",
    "                h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "                prediction, _ = model(x_batch.to(device), h0.to(device))\n",
    "                loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == number_of_epoches - 1:\n",
    "                    if current_patience == 0:\n",
    "                        break\n",
    "                    validation_loss = estimate_loss(model, torch.zeros(num_layers, batch_size, hidden_size), 32,\n",
    "                                                    validation_messages, validation_labels, batch_size, len(vocabulary))\n",
    "                    model_validation_loses.append(validation_loss.item())\n",
    "                    mean_validation_loss = torch.tensor(model_validation_loses[-8:]).mean()\n",
    "                    print(\n",
    "                        f'Epoch {epoch}, current patience {current_patience}, model mean validation loss {mean_validation_loss}, embedding dim {embedding_dim}, hidden size {hidden_size}, num layers {num_layers}, train loss {loss.item()}, validation loss {validation_loss.item()}')\n",
    "                    if validation_loss < min_validation_loss:\n",
    "                        model_file_name = os.path.join(model_dir,\n",
    "                                                       f\"model_{validation_loss}_{embedding_dim}_{hidden_size}_{num_layers}_{epoch}.pt\")\n",
    "                        torch.save(model.state_dict(), model_file_name)\n",
    "                        print(\"Model has been saved as\", model_file_name)\n",
    "                        min_validation_loss = validation_loss\n",
    "\n",
    "                    if mean_validation_loss < model_min_validation_loss:\n",
    "                        model_min_validation_loss = mean_validation_loss\n",
    "                        current_patience = patience\n",
    "                    else:\n",
    "                        current_patience -= 1\n",
    "\n"
   ],
   "id": "57891436daa9d9f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, current patience 30, model mean validation loss 1.1073980331420898, embedding dim 1, hidden size 1, num layers 1, train loss 1.1160489320755005, validation loss 1.1073980331420898\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.1073980331420898_1_1_1_0.pt\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1028841733932495, embedding dim 1, hidden size 1, num layers 1, train loss 1.0996456146240234, validation loss 1.0983703136444092\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0983703136444092_1_1_1_10.pt\n",
      "Epoch 20, current patience 30, model mean validation loss 1.100232720375061, embedding dim 1, hidden size 1, num layers 1, train loss 1.0947827100753784, validation loss 1.0949299335479736\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0949299335479736_1_1_1_20.pt\n",
      "Epoch 30, current patience 30, model mean validation loss 1.098907232284546, embedding dim 1, hidden size 1, num layers 1, train loss 1.092659592628479, validation loss 1.0949304103851318\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0975573062896729, embedding dim 1, hidden size 1, num layers 1, train loss 1.0909042358398438, validation loss 1.0921573638916016\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0921573638916016_1_1_1_40.pt\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0971026420593262, embedding dim 1, hidden size 1, num layers 1, train loss 1.0867607593536377, validation loss 1.0948293209075928\n",
      "Epoch 60, current patience 30, model mean validation loss 1.097010612487793, embedding dim 1, hidden size 1, num layers 1, train loss 1.0937453508377075, validation loss 1.0964584350585938\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0968914031982422, embedding dim 1, hidden size 1, num layers 1, train loss 1.1099836826324463, validation loss 1.0960566997528076\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0950534343719482, embedding dim 1, hidden size 1, num layers 1, train loss 1.094280481338501, validation loss 1.0926942825317383\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0945707559585571, embedding dim 1, hidden size 1, num layers 1, train loss 1.0886002779006958, validation loss 1.0945091247558594\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0945050716400146, embedding dim 1, hidden size 1, num layers 1, train loss 1.0954188108444214, validation loss 1.0944052934646606\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0947198867797852, embedding dim 1, hidden size 1, num layers 1, train loss 1.107729196548462, validation loss 1.096648931503296\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0953788757324219, embedding dim 1, hidden size 1, num layers 1, train loss 1.1039351224899292, validation loss 1.0974293947219849\n",
      "Epoch 130, current patience 28, model mean validation loss 1.0956995487213135, embedding dim 1, hidden size 1, num layers 1, train loss 1.0953474044799805, validation loss 1.097394347190857\n",
      "Epoch 140, current patience 27, model mean validation loss 1.0951948165893555, embedding dim 1, hidden size 1, num layers 1, train loss 1.1048290729522705, validation loss 1.0924204587936401\n",
      "Epoch 150, current patience 26, model mean validation loss 1.094616413116455, embedding dim 1, hidden size 1, num layers 1, train loss 1.0892102718353271, validation loss 1.091429352760315\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.091429352760315_1_1_1_150.pt\n",
      "Epoch 160, current patience 25, model mean validation loss 1.0947797298431396, embedding dim 1, hidden size 1, num layers 1, train loss 1.0840733051300049, validation loss 1.0940006971359253\n",
      "Epoch 170, current patience 24, model mean validation loss 1.094849944114685, embedding dim 1, hidden size 1, num layers 1, train loss 1.0756003856658936, validation loss 1.0950710773468018\n",
      "Epoch 180, current patience 23, model mean validation loss 1.0951762199401855, embedding dim 1, hidden size 1, num layers 1, train loss 1.090456247329712, validation loss 1.097015142440796\n",
      "Epoch 190, current patience 22, model mean validation loss 1.0955133438110352, embedding dim 1, hidden size 1, num layers 1, train loss 1.0887281894683838, validation loss 1.0993468761444092\n",
      "Epoch 200, current patience 21, model mean validation loss 1.0948095321655273, embedding dim 1, hidden size 1, num layers 1, train loss 1.096886396408081, validation loss 1.0917985439300537\n",
      "Epoch 210, current patience 20, model mean validation loss 1.0943093299865723, embedding dim 1, hidden size 1, num layers 1, train loss 1.0946905612945557, validation loss 1.093392014503479\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0945415496826172, embedding dim 1, hidden size 1, num layers 1, train loss 1.0882384777069092, validation loss 1.0942789316177368\n",
      "Epoch 230, current patience 29, model mean validation loss 1.0947703123092651, embedding dim 1, hidden size 1, num layers 1, train loss 1.1009875535964966, validation loss 1.0932589769363403\n",
      "Epoch 240, current patience 28, model mean validation loss 1.09459388256073, embedding dim 1, hidden size 1, num layers 1, train loss 1.1091972589492798, validation loss 1.092589020729065\n",
      "Epoch 250, current patience 27, model mean validation loss 1.0945203304290771, embedding dim 1, hidden size 1, num layers 1, train loss 1.1054491996765137, validation loss 1.0944825410842896\n",
      "Epoch 260, current patience 26, model mean validation loss 1.0942785739898682, embedding dim 1, hidden size 1, num layers 1, train loss 1.1084867715835571, validation loss 1.0950814485549927\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0934622287750244, embedding dim 1, hidden size 1, num layers 1, train loss 1.1012673377990723, validation loss 1.0928163528442383\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0936872959136963, embedding dim 1, hidden size 1, num layers 1, train loss 1.1018985509872437, validation loss 1.0935990810394287\n",
      "Epoch 290, current patience 29, model mean validation loss 1.0937180519104004, embedding dim 1, hidden size 1, num layers 1, train loss 1.0917534828186035, validation loss 1.0936379432678223\n",
      "Epoch 300, current patience 28, model mean validation loss 1.0930893421173096, embedding dim 1, hidden size 1, num layers 1, train loss 1.104726791381836, validation loss 1.0892499685287476\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0892499685287476_1_1_1_300.pt\n",
      "Epoch 310, current patience 30, model mean validation loss 1.092991590499878, embedding dim 1, hidden size 1, num layers 1, train loss 1.1009973287582397, validation loss 1.0924757719039917\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0931934118270874, embedding dim 1, hidden size 1, num layers 1, train loss 1.0896674394607544, validation loss 1.0942039489746094\n",
      "Epoch 330, current patience 29, model mean validation loss 1.0929230451583862, embedding dim 1, hidden size 1, num layers 1, train loss 1.0902984142303467, validation loss 1.0923200845718384\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0927343368530273, embedding dim 1, hidden size 1, num layers 1, train loss 1.0902522802352905, validation loss 1.0935711860656738\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0928966999053955, embedding dim 1, hidden size 1, num layers 1, train loss 1.0966887474060059, validation loss 1.094114899635315\n",
      "Epoch 360, current patience 29, model mean validation loss 1.0932319164276123, embedding dim 1, hidden size 1, num layers 1, train loss 1.092563271522522, validation loss 1.096281886100769\n",
      "Epoch 370, current patience 28, model mean validation loss 1.09295654296875, embedding dim 1, hidden size 1, num layers 1, train loss 1.0908129215240479, validation loss 1.0914348363876343\n",
      "Epoch 380, current patience 27, model mean validation loss 1.0930392742156982, embedding dim 1, hidden size 1, num layers 1, train loss 1.1060466766357422, validation loss 1.0899112224578857\n",
      "Epoch 390, current patience 26, model mean validation loss 1.09329092502594, embedding dim 1, hidden size 1, num layers 1, train loss 1.100473165512085, validation loss 1.094489574432373\n",
      "Epoch 400, current patience 25, model mean validation loss 1.093172550201416, embedding dim 1, hidden size 1, num layers 1, train loss 1.100067377090454, validation loss 1.0932564735412598\n",
      "Epoch 410, current patience 24, model mean validation loss 1.093788504600525, embedding dim 1, hidden size 1, num layers 1, train loss 1.077261209487915, validation loss 1.0972480773925781\n",
      "Epoch 420, current patience 23, model mean validation loss 1.093521237373352, embedding dim 1, hidden size 1, num layers 1, train loss 1.0698652267456055, validation loss 1.0914325714111328\n",
      "Epoch 430, current patience 22, model mean validation loss 1.0932202339172363, embedding dim 1, hidden size 1, num layers 1, train loss 1.0910859107971191, validation loss 1.0917062759399414\n",
      "Epoch 440, current patience 21, model mean validation loss 1.0928369760513306, embedding dim 1, hidden size 1, num layers 1, train loss 1.0857088565826416, validation loss 1.093217134475708\n",
      "Epoch 450, current patience 20, model mean validation loss 1.0930182933807373, embedding dim 1, hidden size 1, num layers 1, train loss 1.0852398872375488, validation loss 1.0928850173950195\n",
      "Epoch 460, current patience 19, model mean validation loss 1.093076229095459, embedding dim 1, hidden size 1, num layers 1, train loss 1.093069076538086, validation loss 1.09037446975708\n",
      "Epoch 470, current patience 18, model mean validation loss 1.0921077728271484, embedding dim 1, hidden size 1, num layers 1, train loss 1.0806443691253662, validation loss 1.0867424011230469\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0867424011230469_1_1_1_470.pt\n",
      "Epoch 480, current patience 30, model mean validation loss 1.091156244277954, embedding dim 1, hidden size 1, num layers 1, train loss 1.095327377319336, validation loss 1.0856444835662842\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0856444835662842_1_1_1_480.pt\n",
      "Epoch 490, current patience 30, model mean validation loss 1.0899138450622559, embedding dim 1, hidden size 1, num layers 1, train loss 1.0608257055282593, validation loss 1.0873088836669922\n",
      "Epoch 500, current patience 30, model mean validation loss 1.089544653892517, embedding dim 1, hidden size 1, num layers 1, train loss 1.072766661643982, validation loss 1.0884783267974854\n",
      "Epoch 510, current patience 30, model mean validation loss 1.0890586376190186, embedding dim 1, hidden size 1, num layers 1, train loss 1.09418785572052, validation loss 1.0878182649612427\n",
      "Epoch 520, current patience 30, model mean validation loss 1.088047742843628, embedding dim 1, hidden size 1, num layers 1, train loss 1.0831799507141113, validation loss 1.0851294994354248\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0851294994354248_1_1_1_520.pt\n",
      "Epoch 530, current patience 30, model mean validation loss 1.0872361660003662, embedding dim 1, hidden size 1, num layers 1, train loss 1.0791832208633423, validation loss 1.086392879486084\n",
      "Epoch 540, current patience 30, model mean validation loss 1.0862394571304321, embedding dim 1, hidden size 1, num layers 1, train loss 1.058333396911621, validation loss 1.0824010372161865\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0824010372161865_1_1_1_540.pt\n",
      "Epoch 550, current patience 30, model mean validation loss 1.086106300354004, embedding dim 1, hidden size 1, num layers 1, train loss 1.0627021789550781, validation loss 1.0856764316558838\n",
      "Epoch 560, current patience 30, model mean validation loss 1.0859570503234863, embedding dim 1, hidden size 1, num layers 1, train loss 1.051910400390625, validation loss 1.0844504833221436\n",
      "Epoch 570, current patience 30, model mean validation loss 1.0852442979812622, embedding dim 1, hidden size 1, num layers 1, train loss 1.0549218654632568, validation loss 1.0816073417663574\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0816073417663574_1_1_1_570.pt\n",
      "Epoch 580, current patience 30, model mean validation loss 1.0843669176101685, embedding dim 1, hidden size 1, num layers 1, train loss 1.0697124004364014, validation loss 1.0814591646194458\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0814591646194458_1_1_1_580.pt\n",
      "Epoch 590, current patience 30, model mean validation loss 1.0834516286849976, embedding dim 1, hidden size 1, num layers 1, train loss 1.053636074066162, validation loss 1.0804961919784546\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0804961919784546_1_1_1_590.pt\n",
      "Epoch 600, current patience 30, model mean validation loss 1.0828723907470703, embedding dim 1, hidden size 1, num layers 1, train loss 1.0704060792922974, validation loss 1.080494999885559\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.080494999885559_1_1_1_600.pt\n",
      "Epoch 610, current patience 30, model mean validation loss 1.0823094844818115, embedding dim 1, hidden size 1, num layers 1, train loss 1.102874517440796, validation loss 1.0818897485733032\n",
      "Epoch 620, current patience 30, model mean validation loss 1.0820412635803223, embedding dim 1, hidden size 1, num layers 1, train loss 1.0949903726577759, validation loss 1.0802561044692993\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0802561044692993_1_1_1_620.pt\n",
      "Epoch 630, current patience 30, model mean validation loss 1.081043004989624, embedding dim 1, hidden size 1, num layers 1, train loss 1.0741000175476074, validation loss 1.0776901245117188\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0776901245117188_1_1_1_630.pt\n",
      "Epoch 640, current patience 30, model mean validation loss 1.0798897743225098, embedding dim 1, hidden size 1, num layers 1, train loss 1.0953569412231445, validation loss 1.075223684310913\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.075223684310913_1_1_1_640.pt\n",
      "Epoch 650, current patience 30, model mean validation loss 1.079290509223938, embedding dim 1, hidden size 1, num layers 1, train loss 1.090590238571167, validation loss 1.0768139362335205\n",
      "Epoch 660, current patience 30, model mean validation loss 1.078432321548462, embedding dim 1, hidden size 1, num layers 1, train loss 1.0420430898666382, validation loss 1.074593186378479\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.074593186378479_1_1_1_660.pt\n",
      "Epoch 670, current patience 30, model mean validation loss 1.077260971069336, embedding dim 1, hidden size 1, num layers 1, train loss 1.0954945087432861, validation loss 1.0711263418197632\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0711263418197632_1_1_1_670.pt\n",
      "Epoch 680, current patience 30, model mean validation loss 1.0763943195343018, embedding dim 1, hidden size 1, num layers 1, train loss 1.1041220426559448, validation loss 1.073561668395996\n",
      "Epoch 690, current patience 30, model mean validation loss 1.0763487815856934, embedding dim 1, hidden size 1, num layers 1, train loss 1.068548321723938, validation loss 1.08152437210083\n",
      "Epoch 700, current patience 30, model mean validation loss 1.0755715370178223, embedding dim 1, hidden size 1, num layers 1, train loss 1.0763989686965942, validation loss 1.0740389823913574\n",
      "Epoch 710, current patience 30, model mean validation loss 1.0757174491882324, embedding dim 1, hidden size 1, num layers 1, train loss 1.0249748229980469, validation loss 1.0788570642471313\n",
      "Epoch 720, current patience 29, model mean validation loss 1.0751038789749146, embedding dim 1, hidden size 1, num layers 1, train loss 1.0540359020233154, validation loss 1.0703155994415283\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0703155994415283_1_1_1_720.pt\n",
      "Epoch 730, current patience 30, model mean validation loss 1.0742994546890259, embedding dim 1, hidden size 1, num layers 1, train loss 1.078701376914978, validation loss 1.0703787803649902\n",
      "Epoch 740, current patience 30, model mean validation loss 1.0729703903198242, embedding dim 1, hidden size 1, num layers 1, train loss 1.0450674295425415, validation loss 1.0639605522155762\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0639605522155762_1_1_1_740.pt\n",
      "Epoch 750, current patience 30, model mean validation loss 1.0731476545333862, embedding dim 1, hidden size 1, num layers 1, train loss 1.0842835903167725, validation loss 1.0725445747375488\n",
      "Epoch 760, current patience 29, model mean validation loss 1.0724868774414062, embedding dim 1, hidden size 1, num layers 1, train loss 1.0731680393218994, validation loss 1.0682752132415771\n",
      "Epoch 770, current patience 30, model mean validation loss 1.0704889297485352, embedding dim 1, hidden size 1, num layers 1, train loss 1.0081579685211182, validation loss 1.0655407905578613\n",
      "Epoch 780, current patience 30, model mean validation loss 1.0696213245391846, embedding dim 1, hidden size 1, num layers 1, train loss 1.0771300792694092, validation loss 1.0670983791351318\n",
      "Epoch 790, current patience 30, model mean validation loss 1.0684833526611328, embedding dim 1, hidden size 1, num layers 1, train loss 1.008650541305542, validation loss 1.0697531700134277\n",
      "Epoch 800, current patience 30, model mean validation loss 1.0675276517868042, embedding dim 1, hidden size 1, num layers 1, train loss 1.053921103477478, validation loss 1.0626702308654785\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0626702308654785_1_1_1_800.pt\n",
      "Epoch 810, current patience 30, model mean validation loss 1.0665392875671387, embedding dim 1, hidden size 1, num layers 1, train loss 1.038662075996399, validation loss 1.0624717473983765\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0624717473983765_1_1_1_810.pt\n",
      "Epoch 820, current patience 30, model mean validation loss 1.066657543182373, embedding dim 1, hidden size 1, num layers 1, train loss 1.0546953678131104, validation loss 1.0649058818817139\n",
      "Epoch 830, current patience 29, model mean validation loss 1.0662319660186768, embedding dim 1, hidden size 1, num layers 1, train loss 1.0805308818817139, validation loss 1.0691410303115845\n",
      "Epoch 840, current patience 30, model mean validation loss 1.0652623176574707, embedding dim 1, hidden size 1, num layers 1, train loss 1.0576364994049072, validation loss 1.0605167150497437\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0605167150497437_1_1_1_840.pt\n",
      "Epoch 850, current patience 30, model mean validation loss 1.0649446249008179, embedding dim 1, hidden size 1, num layers 1, train loss 1.0498993396759033, validation loss 1.0629997253417969\n",
      "Epoch 860, current patience 30, model mean validation loss 1.0645101070404053, embedding dim 1, hidden size 1, num layers 1, train loss 1.054394245147705, validation loss 1.063622236251831\n",
      "Epoch 870, current patience 30, model mean validation loss 1.0632089376449585, embedding dim 1, hidden size 1, num layers 1, train loss 1.0427727699279785, validation loss 1.0593435764312744\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0593435764312744_1_1_1_870.pt\n",
      "Epoch 880, current patience 30, model mean validation loss 1.0619440078735352, embedding dim 1, hidden size 1, num layers 1, train loss 1.0290181636810303, validation loss 1.052551031112671\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.052551031112671_1_1_1_880.pt\n",
      "Epoch 890, current patience 30, model mean validation loss 1.0615371465682983, embedding dim 1, hidden size 1, num layers 1, train loss 1.088221549987793, validation loss 1.059216856956482\n",
      "Epoch 900, current patience 30, model mean validation loss 1.0606648921966553, embedding dim 1, hidden size 1, num layers 1, train loss 1.0144636631011963, validation loss 1.0579272508621216\n",
      "Epoch 910, current patience 30, model mean validation loss 1.0597916841506958, embedding dim 1, hidden size 1, num layers 1, train loss 1.0296869277954102, validation loss 1.0621559619903564\n",
      "Epoch 920, current patience 30, model mean validation loss 1.0590815544128418, embedding dim 1, hidden size 1, num layers 1, train loss 1.0109608173370361, validation loss 1.0548356771469116\n",
      "Epoch 930, current patience 30, model mean validation loss 1.058340311050415, embedding dim 1, hidden size 1, num layers 1, train loss 1.0788402557373047, validation loss 1.0570694208145142\n",
      "Epoch 940, current patience 30, model mean validation loss 1.0570945739746094, embedding dim 1, hidden size 1, num layers 1, train loss 1.0610072612762451, validation loss 1.053657054901123\n",
      "Epoch 950, current patience 30, model mean validation loss 1.0569143295288086, embedding dim 1, hidden size 1, num layers 1, train loss 1.0999581813812256, validation loss 1.0579017400741577\n",
      "Epoch 960, current patience 30, model mean validation loss 1.0569093227386475, embedding dim 1, hidden size 1, num layers 1, train loss 1.0351693630218506, validation loss 1.0525104999542236\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0525104999542236_1_1_1_960.pt\n",
      "Epoch 970, current patience 30, model mean validation loss 1.0563533306121826, embedding dim 1, hidden size 1, num layers 1, train loss 1.0492300987243652, validation loss 1.0547688007354736\n",
      "Epoch 980, current patience 30, model mean validation loss 1.0554273128509521, embedding dim 1, hidden size 1, num layers 1, train loss 1.0074381828308105, validation loss 1.0505192279815674\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0505192279815674_1_1_1_980.pt\n",
      "Epoch 990, current patience 30, model mean validation loss 1.0536845922470093, embedding dim 1, hidden size 1, num layers 1, train loss 1.0695555210113525, validation loss 1.0482144355773926\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0482144355773926_1_1_1_990.pt\n",
      "Epoch 1000, current patience 30, model mean validation loss 1.0531028509140015, embedding dim 1, hidden size 1, num layers 1, train loss 0.9829179644584656, validation loss 1.050181269645691\n",
      "Epoch 1010, current patience 30, model mean validation loss 1.0517895221710205, embedding dim 1, hidden size 1, num layers 1, train loss 0.9793733954429626, validation loss 1.0465623140335083\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0465623140335083_1_1_1_1010.pt\n",
      "Epoch 1020, current patience 30, model mean validation loss 1.0507732629776, embedding dim 1, hidden size 1, num layers 1, train loss 0.9842450022697449, validation loss 1.045527458190918\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.045527458190918_1_1_1_1020.pt\n",
      "Epoch 1030, current patience 30, model mean validation loss 1.0499897003173828, embedding dim 1, hidden size 1, num layers 1, train loss 1.0752182006835938, validation loss 1.051633596420288\n",
      "Epoch 1040, current patience 30, model mean validation loss 1.0487629175186157, embedding dim 1, hidden size 1, num layers 1, train loss 0.9938067197799683, validation loss 1.0426959991455078\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0426959991455078_1_1_1_1040.pt\n",
      "Epoch 1050, current patience 30, model mean validation loss 1.0463967323303223, embedding dim 1, hidden size 1, num layers 1, train loss 1.017571210861206, validation loss 1.0358397960662842\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0358397960662842_1_1_1_1050.pt\n",
      "Epoch 1060, current patience 30, model mean validation loss 1.046163558959961, embedding dim 1, hidden size 1, num layers 1, train loss 0.9736478328704834, validation loss 1.048653483390808\n",
      "Epoch 1070, current patience 30, model mean validation loss 1.0454661846160889, embedding dim 1, hidden size 1, num layers 1, train loss 0.9776217937469482, validation loss 1.0426349639892578\n",
      "Epoch 1080, current patience 30, model mean validation loss 1.0438239574432373, embedding dim 1, hidden size 1, num layers 1, train loss 1.01092529296875, validation loss 1.0370441675186157\n",
      "Epoch 1090, current patience 30, model mean validation loss 1.0440435409545898, embedding dim 1, hidden size 1, num layers 1, train loss 0.9422621726989746, validation loss 1.0483181476593018\n",
      "Epoch 1100, current patience 29, model mean validation loss 1.0442272424697876, embedding dim 1, hidden size 1, num layers 1, train loss 0.9555476903915405, validation loss 1.0469982624053955\n",
      "Epoch 1110, current patience 28, model mean validation loss 1.0425785779953003, embedding dim 1, hidden size 1, num layers 1, train loss 1.021306037902832, validation loss 1.0384440422058105\n",
      "Epoch 1120, current patience 30, model mean validation loss 1.0412020683288574, embedding dim 1, hidden size 1, num layers 1, train loss 0.9669771790504456, validation loss 1.031684398651123\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.031684398651123_1_1_1_1120.pt\n",
      "Epoch 1130, current patience 30, model mean validation loss 1.0415687561035156, embedding dim 1, hidden size 1, num layers 1, train loss 0.9207190871238708, validation loss 1.0387732982635498\n",
      "Epoch 1140, current patience 29, model mean validation loss 1.0390576124191284, embedding dim 1, hidden size 1, num layers 1, train loss 1.0187292098999023, validation loss 1.0285637378692627\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0285637378692627_1_1_1_1140.pt\n",
      "Epoch 1150, current patience 30, model mean validation loss 1.0377540588378906, embedding dim 1, hidden size 1, num layers 1, train loss 0.9566752314567566, validation loss 1.0322071313858032\n",
      "Epoch 1160, current patience 30, model mean validation loss 1.0380864143371582, embedding dim 1, hidden size 1, num layers 1, train loss 1.118553876876831, validation loss 1.03970205783844\n",
      "Epoch 1170, current patience 29, model mean validation loss 1.036419153213501, embedding dim 1, hidden size 1, num layers 1, train loss 1.005161166191101, validation loss 1.0349807739257812\n",
      "Epoch 1180, current patience 30, model mean validation loss 1.0351970195770264, embedding dim 1, hidden size 1, num layers 1, train loss 1.0057330131530762, validation loss 1.0372202396392822\n",
      "Epoch 1190, current patience 30, model mean validation loss 1.033287763595581, embedding dim 1, hidden size 1, num layers 1, train loss 0.9454111456871033, validation loss 1.023169755935669\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.023169755935669_1_1_1_1190.pt\n",
      "Epoch 1200, current patience 30, model mean validation loss 1.031739592552185, embedding dim 1, hidden size 1, num layers 1, train loss 0.9466837048530579, validation loss 1.019300103187561\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.019300103187561_1_1_1_1200.pt\n",
      "Epoch 1210, current patience 30, model mean validation loss 1.0299928188323975, embedding dim 1, hidden size 1, num layers 1, train loss 1.0470653772354126, validation loss 1.0247986316680908\n",
      "Epoch 1220, current patience 30, model mean validation loss 1.030118465423584, embedding dim 1, hidden size 1, num layers 1, train loss 0.9569201469421387, validation loss 1.0295695066452026\n",
      "Epoch 1230, current patience 29, model mean validation loss 1.0311498641967773, embedding dim 1, hidden size 1, num layers 1, train loss 1.0678493976593018, validation loss 1.0404577255249023\n",
      "Epoch 1240, current patience 28, model mean validation loss 1.030069351196289, embedding dim 1, hidden size 1, num layers 1, train loss 1.0196486711502075, validation loss 1.03105890750885\n",
      "Epoch 1250, current patience 27, model mean validation loss 1.0272035598754883, embedding dim 1, hidden size 1, num layers 1, train loss 1.0006983280181885, validation loss 1.012054204940796\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.012054204940796_1_1_1_1250.pt\n",
      "Epoch 1260, current patience 30, model mean validation loss 1.0250765085220337, embedding dim 1, hidden size 1, num layers 1, train loss 0.9830589294433594, validation loss 1.0202033519744873\n",
      "Epoch 1270, current patience 30, model mean validation loss 1.024819016456604, embedding dim 1, hidden size 1, num layers 1, train loss 0.8933987021446228, validation loss 1.0211102962493896\n",
      "Epoch 1280, current patience 30, model mean validation loss 1.0248959064483643, embedding dim 1, hidden size 1, num layers 1, train loss 0.9068140983581543, validation loss 1.0199148654937744\n",
      "Epoch 1290, current patience 29, model mean validation loss 1.0234181880950928, embedding dim 1, hidden size 1, num layers 1, train loss 1.098044753074646, validation loss 1.0129766464233398\n",
      "Epoch 1300, current patience 30, model mean validation loss 1.0225082635879517, embedding dim 1, hidden size 1, num layers 1, train loss 0.9736802577972412, validation loss 1.022289514541626\n",
      "Epoch 1310, current patience 30, model mean validation loss 1.0197385549545288, embedding dim 1, hidden size 1, num layers 1, train loss 0.9966275691986084, validation loss 1.0183002948760986\n",
      "Epoch 1320, current patience 30, model mean validation loss 1.0167162418365479, embedding dim 1, hidden size 1, num layers 1, train loss 0.9412529468536377, validation loss 1.0068799257278442\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0068799257278442_1_1_1_1320.pt\n",
      "Epoch 1330, current patience 30, model mean validation loss 1.0176033973693848, embedding dim 1, hidden size 1, num layers 1, train loss 0.9296269416809082, validation loss 1.0191516876220703\n",
      "Epoch 1340, current patience 29, model mean validation loss 1.0171592235565186, embedding dim 1, hidden size 1, num layers 1, train loss 0.9661834836006165, validation loss 1.016650915145874\n",
      "Epoch 1350, current patience 28, model mean validation loss 1.015953779220581, embedding dim 1, hidden size 1, num layers 1, train loss 0.993813157081604, validation loss 1.0114666223526\n",
      "Epoch 1360, current patience 30, model mean validation loss 1.0134713649749756, embedding dim 1, hidden size 1, num layers 1, train loss 0.8935524821281433, validation loss 1.0000550746917725\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_1.0000550746917725_1_1_1_1360.pt\n",
      "Epoch 1370, current patience 30, model mean validation loss 1.0123391151428223, embedding dim 1, hidden size 1, num layers 1, train loss 0.9160333871841431, validation loss 1.0039186477661133\n",
      "Epoch 1380, current patience 30, model mean validation loss 1.0106313228607178, embedding dim 1, hidden size 1, num layers 1, train loss 0.9574744701385498, validation loss 1.0086268186569214\n",
      "Epoch 1390, current patience 30, model mean validation loss 1.010006070137024, embedding dim 1, hidden size 1, num layers 1, train loss 0.8998485803604126, validation loss 1.0132991075515747\n",
      "Epoch 1400, current patience 30, model mean validation loss 1.0108314752578735, embedding dim 1, hidden size 1, num layers 1, train loss 0.9012026786804199, validation loss 1.0134830474853516\n",
      "Epoch 1410, current patience 29, model mean validation loss 1.0095953941345215, embedding dim 1, hidden size 1, num layers 1, train loss 0.9738160967826843, validation loss 1.0092631578445435\n",
      "Epoch 1420, current patience 30, model mean validation loss 1.008127212524414, embedding dim 1, hidden size 1, num layers 1, train loss 0.904853105545044, validation loss 1.0049059391021729\n",
      "Epoch 1430, current patience 30, model mean validation loss 1.007275104522705, embedding dim 1, hidden size 1, num layers 1, train loss 1.03969144821167, validation loss 1.0046489238739014\n",
      "Epoch 1440, current patience 30, model mean validation loss 1.008424997329712, embedding dim 1, hidden size 1, num layers 1, train loss 0.9542657136917114, validation loss 1.0092538595199585\n",
      "Epoch 1450, current patience 29, model mean validation loss 1.0083975791931152, embedding dim 1, hidden size 1, num layers 1, train loss 0.8998708724975586, validation loss 1.003699779510498\n",
      "Epoch 1460, current patience 28, model mean validation loss 1.00730299949646, embedding dim 1, hidden size 1, num layers 1, train loss 0.9919871687889099, validation loss 0.9998705983161926\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9998705983161926_1_1_1_1460.pt\n",
      "Epoch 1470, current patience 27, model mean validation loss 1.0057508945465088, embedding dim 1, hidden size 1, num layers 1, train loss 0.9249494671821594, validation loss 1.000881314277649\n",
      "Epoch 1480, current patience 30, model mean validation loss 1.004486322402954, embedding dim 1, hidden size 1, num layers 1, train loss 0.9110684394836426, validation loss 1.003366470336914\n",
      "Epoch 1490, current patience 30, model mean validation loss 1.0046786069869995, embedding dim 1, hidden size 1, num layers 1, train loss 0.9502701759338379, validation loss 1.0108015537261963\n",
      "Epoch 1500, current patience 29, model mean validation loss 1.0054939985275269, embedding dim 1, hidden size 1, num layers 1, train loss 0.885358452796936, validation loss 1.0114294290542603\n",
      "Epoch 1510, current patience 28, model mean validation loss 1.0041351318359375, embedding dim 1, hidden size 1, num layers 1, train loss 0.8845552206039429, validation loss 0.9937785863876343\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9937785863876343_1_1_1_1510.pt\n",
      "Epoch 1520, current patience 30, model mean validation loss 1.001442551612854, embedding dim 1, hidden size 1, num layers 1, train loss 0.8755137324333191, validation loss 0.987712025642395\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.987712025642395_1_1_1_1520.pt\n",
      "Epoch 1530, current patience 30, model mean validation loss 1.000166654586792, embedding dim 1, hidden size 1, num layers 1, train loss 0.898993730545044, validation loss 0.9934933185577393\n",
      "Epoch 1540, current patience 30, model mean validation loss 0.9986249208450317, embedding dim 1, hidden size 1, num layers 1, train loss 0.8680734634399414, validation loss 0.9875365495681763\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9875365495681763_1_1_1_1540.pt\n",
      "Epoch 1550, current patience 30, model mean validation loss 0.9981135129928589, embedding dim 1, hidden size 1, num layers 1, train loss 0.9033418893814087, validation loss 0.9967905282974243\n",
      "Epoch 1560, current patience 30, model mean validation loss 0.9973703622817993, embedding dim 1, hidden size 1, num layers 1, train loss 0.976252019405365, validation loss 0.997421145439148\n",
      "Epoch 1570, current patience 30, model mean validation loss 0.9950819611549377, embedding dim 1, hidden size 1, num layers 1, train loss 0.8958507776260376, validation loss 0.9924938678741455\n",
      "Epoch 1580, current patience 30, model mean validation loss 0.9938048720359802, embedding dim 1, hidden size 1, num layers 1, train loss 0.8429431915283203, validation loss 1.0012128353118896\n",
      "Epoch 1590, current patience 30, model mean validation loss 0.9952482581138611, embedding dim 1, hidden size 1, num layers 1, train loss 0.9184114933013916, validation loss 1.0053256750106812\n",
      "Epoch 1600, current patience 29, model mean validation loss 0.9958473443984985, embedding dim 1, hidden size 1, num layers 1, train loss 0.8388336896896362, validation loss 0.9925049543380737\n",
      "Epoch 1610, current patience 28, model mean validation loss 0.996631383895874, embedding dim 1, hidden size 1, num layers 1, train loss 0.8544437885284424, validation loss 0.9997650980949402\n",
      "Epoch 1620, current patience 27, model mean validation loss 0.9985394477844238, embedding dim 1, hidden size 1, num layers 1, train loss 0.8929091691970825, validation loss 1.0028014183044434\n",
      "Epoch 1630, current patience 26, model mean validation loss 0.9981493949890137, embedding dim 1, hidden size 1, num layers 1, train loss 0.9033435583114624, validation loss 0.993669867515564\n",
      "Epoch 1640, current patience 25, model mean validation loss 0.9983698725700378, embedding dim 1, hidden size 1, num layers 1, train loss 0.894153356552124, validation loss 0.99918532371521\n",
      "Epoch 1650, current patience 24, model mean validation loss 0.9981839656829834, embedding dim 1, hidden size 1, num layers 1, train loss 0.9120060801506042, validation loss 0.9910064935684204\n",
      "Epoch 1660, current patience 23, model mean validation loss 0.997017502784729, embedding dim 1, hidden size 1, num layers 1, train loss 1.0039606094360352, validation loss 0.9918807148933411\n",
      "Epoch 1670, current patience 22, model mean validation loss 0.9967737197875977, embedding dim 1, hidden size 1, num layers 1, train loss 0.8551151752471924, validation loss 1.00337553024292\n",
      "Epoch 1680, current patience 21, model mean validation loss 0.9944449663162231, embedding dim 1, hidden size 1, num layers 1, train loss 1.005847454071045, validation loss 0.9738752841949463\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9738752841949463_1_1_1_1680.pt\n",
      "Epoch 1690, current patience 20, model mean validation loss 0.9922873377799988, embedding dim 1, hidden size 1, num layers 1, train loss 0.9113984704017639, validation loss 0.9825042486190796\n",
      "Epoch 1700, current patience 30, model mean validation loss 0.9889857172966003, embedding dim 1, hidden size 1, num layers 1, train loss 0.9010764360427856, validation loss 0.9763880968093872\n",
      "Epoch 1710, current patience 30, model mean validation loss 0.9871606826782227, embedding dim 1, hidden size 1, num layers 1, train loss 0.8268904089927673, validation loss 0.9790698289871216\n",
      "Epoch 1720, current patience 30, model mean validation loss 0.9866098165512085, embedding dim 1, hidden size 1, num layers 1, train loss 0.9040349721908569, validation loss 0.9947783946990967\n",
      "Epoch 1730, current patience 30, model mean validation loss 0.9865847229957581, embedding dim 1, hidden size 1, num layers 1, train loss 0.9078179001808167, validation loss 0.9908056855201721\n",
      "Epoch 1740, current patience 30, model mean validation loss 0.9872608780860901, embedding dim 1, hidden size 1, num layers 1, train loss 0.8746998310089111, validation loss 0.9972901344299316\n",
      "Epoch 1750, current patience 29, model mean validation loss 0.9845267534255981, embedding dim 1, hidden size 1, num layers 1, train loss 0.905193567276001, validation loss 0.9815024733543396\n",
      "Epoch 1760, current patience 30, model mean validation loss 0.9851639270782471, embedding dim 1, hidden size 1, num layers 1, train loss 0.8465608358383179, validation loss 0.9789729118347168\n",
      "Epoch 1770, current patience 29, model mean validation loss 0.9847490787506104, embedding dim 1, hidden size 1, num layers 1, train loss 0.8813214302062988, validation loss 0.9791848063468933\n",
      "Epoch 1780, current patience 28, model mean validation loss 0.9870682954788208, embedding dim 1, hidden size 1, num layers 1, train loss 0.9470157623291016, validation loss 0.9949424266815186\n",
      "Epoch 1790, current patience 27, model mean validation loss 0.9895735383033752, embedding dim 1, hidden size 1, num layers 1, train loss 0.8822251558303833, validation loss 0.9991116523742676\n",
      "Epoch 1800, current patience 26, model mean validation loss 0.9886988997459412, embedding dim 1, hidden size 1, num layers 1, train loss 0.8527061343193054, validation loss 0.9877811074256897\n",
      "Epoch 1810, current patience 25, model mean validation loss 0.9887568950653076, embedding dim 1, hidden size 1, num layers 1, train loss 0.859336256980896, validation loss 0.9912691712379456\n",
      "Epoch 1820, current patience 24, model mean validation loss 0.9857282042503357, embedding dim 1, hidden size 1, num layers 1, train loss 0.8533837795257568, validation loss 0.9730613827705383\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9730613827705383_1_1_1_1820.pt\n",
      "Epoch 1830, current patience 23, model mean validation loss 0.9881088137626648, embedding dim 1, hidden size 1, num layers 1, train loss 0.8213737607002258, validation loss 1.0005474090576172\n",
      "Epoch 1840, current patience 22, model mean validation loss 0.9908625483512878, embedding dim 1, hidden size 1, num layers 1, train loss 0.9567332863807678, validation loss 1.001002311706543\n",
      "Epoch 1850, current patience 21, model mean validation loss 0.990955114364624, embedding dim 1, hidden size 1, num layers 1, train loss 0.8514720797538757, validation loss 0.979925274848938\n",
      "Epoch 1860, current patience 20, model mean validation loss 0.9894620180130005, embedding dim 1, hidden size 1, num layers 1, train loss 0.8412625789642334, validation loss 0.982998251914978\n",
      "Epoch 1870, current patience 19, model mean validation loss 0.9870161414146423, embedding dim 1, hidden size 1, num layers 1, train loss 0.8892338275909424, validation loss 0.9795440435409546\n",
      "Epoch 1880, current patience 18, model mean validation loss 0.9866862893104553, embedding dim 1, hidden size 1, num layers 1, train loss 0.9578081369400024, validation loss 0.9851421117782593\n",
      "Epoch 1890, current patience 17, model mean validation loss 0.9868596792221069, embedding dim 1, hidden size 1, num layers 1, train loss 0.8373650908470154, validation loss 0.9926567673683167\n",
      "Epoch 1900, current patience 16, model mean validation loss 0.9891359210014343, embedding dim 1, hidden size 1, num layers 1, train loss 0.9512265920639038, validation loss 0.9912711977958679\n",
      "Epoch 1910, current patience 15, model mean validation loss 0.987767219543457, embedding dim 1, hidden size 1, num layers 1, train loss 0.9858992099761963, validation loss 0.9895979762077332\n",
      "Epoch 1920, current patience 14, model mean validation loss 0.9849406480789185, embedding dim 1, hidden size 1, num layers 1, train loss 0.8865869045257568, validation loss 0.9783896207809448\n",
      "Epoch 1930, current patience 13, model mean validation loss 0.9858627319335938, embedding dim 1, hidden size 1, num layers 1, train loss 0.9252923130989075, validation loss 0.9873018264770508\n",
      "Epoch 1940, current patience 12, model mean validation loss 0.986461341381073, embedding dim 1, hidden size 1, num layers 1, train loss 1.0040080547332764, validation loss 0.9877874851226807\n",
      "Epoch 1950, current patience 11, model mean validation loss 0.984548807144165, embedding dim 1, hidden size 1, num layers 1, train loss 0.8857211470603943, validation loss 0.9642431735992432\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9642431735992432_1_1_1_1950.pt\n",
      "Epoch 1960, current patience 10, model mean validation loss 0.9848160743713379, embedding dim 1, hidden size 1, num layers 1, train loss 0.8724956512451172, validation loss 0.9872804880142212\n",
      "Epoch 1970, current patience 9, model mean validation loss 0.9840668439865112, embedding dim 1, hidden size 1, num layers 1, train loss 0.8157030344009399, validation loss 0.986662745475769\n",
      "Epoch 1980, current patience 30, model mean validation loss 0.9821785688400269, embedding dim 1, hidden size 1, num layers 1, train loss 0.8318185806274414, validation loss 0.9761653542518616\n",
      "Epoch 1990, current patience 30, model mean validation loss 0.9794119596481323, embedding dim 1, hidden size 1, num layers 1, train loss 0.8227646350860596, validation loss 0.9674650430679321\n",
      "Epoch 2000, current patience 30, model mean validation loss 0.9809654951095581, embedding dim 1, hidden size 1, num layers 1, train loss 0.9003317356109619, validation loss 0.9908179044723511\n",
      "Epoch 2010, current patience 29, model mean validation loss 0.9824817180633545, embedding dim 1, hidden size 1, num layers 1, train loss 0.8149569034576416, validation loss 0.9994320273399353\n",
      "Epoch 2020, current patience 28, model mean validation loss 0.9818668365478516, embedding dim 1, hidden size 1, num layers 1, train loss 0.8733863234519958, validation loss 0.9828675985336304\n",
      "Epoch 2030, current patience 27, model mean validation loss 0.9827353954315186, embedding dim 1, hidden size 1, num layers 1, train loss 0.9184020757675171, validation loss 0.9711918830871582\n",
      "Epoch 2040, current patience 26, model mean validation loss 0.9801732301712036, embedding dim 1, hidden size 1, num layers 1, train loss 0.8668423891067505, validation loss 0.9667834043502808\n",
      "Epoch 2050, current patience 25, model mean validation loss 0.9805207252502441, embedding dim 1, hidden size 1, num layers 1, train loss 0.8814667463302612, validation loss 0.9894421100616455\n",
      "Epoch 2060, current patience 24, model mean validation loss 0.9815477132797241, embedding dim 1, hidden size 1, num layers 1, train loss 0.8399294018745422, validation loss 0.9843812584877014\n",
      "Epoch 2070, current patience 23, model mean validation loss 0.9848323464393616, embedding dim 1, hidden size 1, num layers 1, train loss 0.8359740972518921, validation loss 0.9937424659729004\n",
      "Epoch 2080, current patience 22, model mean validation loss 0.9836952090263367, embedding dim 1, hidden size 1, num layers 1, train loss 0.8254344463348389, validation loss 0.9817205667495728\n",
      "Epoch 2090, current patience 21, model mean validation loss 0.9826300740242004, embedding dim 1, hidden size 1, num layers 1, train loss 0.8397934436798096, validation loss 0.9909111857414246\n",
      "Epoch 2100, current patience 20, model mean validation loss 0.9815211892127991, embedding dim 1, hidden size 1, num layers 1, train loss 0.8643954396247864, validation loss 0.9739966988563538\n",
      "Epoch 2110, current patience 19, model mean validation loss 0.984821617603302, embedding dim 1, hidden size 1, num layers 1, train loss 0.8961858749389648, validation loss 0.9975954294204712\n",
      "Epoch 2120, current patience 18, model mean validation loss 0.9862949252128601, embedding dim 1, hidden size 1, num layers 1, train loss 0.8874086737632751, validation loss 0.978569746017456\n",
      "Epoch 2130, current patience 17, model mean validation loss 0.9862556457519531, embedding dim 1, hidden size 1, num layers 1, train loss 0.7927030324935913, validation loss 0.9891281127929688\n",
      "Epoch 2140, current patience 16, model mean validation loss 0.9871398210525513, embedding dim 1, hidden size 1, num layers 1, train loss 0.810967206954956, validation loss 0.9914544224739075\n",
      "Epoch 2150, current patience 15, model mean validation loss 0.9862571358680725, embedding dim 1, hidden size 1, num layers 1, train loss 0.7727460861206055, validation loss 0.9866809248924255\n",
      "Epoch 2160, current patience 14, model mean validation loss 0.986829400062561, embedding dim 1, hidden size 1, num layers 1, train loss 0.8490671515464783, validation loss 0.9862989187240601\n",
      "Epoch 2170, current patience 13, model mean validation loss 0.9843333959579468, embedding dim 1, hidden size 1, num layers 1, train loss 0.8620860576629639, validation loss 0.9709427356719971\n",
      "Epoch 2180, current patience 12, model mean validation loss 0.9854698181152344, embedding dim 1, hidden size 1, num layers 1, train loss 0.8057719469070435, validation loss 0.9830881357192993\n",
      "Epoch 2190, current patience 11, model mean validation loss 0.9821088314056396, embedding dim 1, hidden size 1, num layers 1, train loss 0.8643837571144104, validation loss 0.9707075953483582\n",
      "Epoch 2200, current patience 10, model mean validation loss 0.9817102551460266, embedding dim 1, hidden size 1, num layers 1, train loss 0.7791175842285156, validation loss 0.9753810167312622\n",
      "Epoch 2210, current patience 9, model mean validation loss 0.9816055297851562, embedding dim 1, hidden size 1, num layers 1, train loss 0.7863597869873047, validation loss 0.9882906079292297\n",
      "Epoch 2220, current patience 8, model mean validation loss 0.9810900688171387, embedding dim 1, hidden size 1, num layers 1, train loss 0.8049719929695129, validation loss 0.9873307347297668\n",
      "Epoch 2230, current patience 7, model mean validation loss 0.984576940536499, embedding dim 1, hidden size 1, num layers 1, train loss 0.8329132795333862, validation loss 1.0145760774612427\n",
      "Epoch 2240, current patience 6, model mean validation loss 0.9877271056175232, embedding dim 1, hidden size 1, num layers 1, train loss 0.8348538875579834, validation loss 1.0114997625350952\n",
      "Epoch 2250, current patience 5, model mean validation loss 0.9897438883781433, embedding dim 1, hidden size 1, num layers 1, train loss 0.8441575169563293, validation loss 0.9870772957801819\n",
      "Epoch 2260, current patience 4, model mean validation loss 0.9889901280403137, embedding dim 1, hidden size 1, num layers 1, train loss 0.7652132511138916, validation loss 0.9770581722259521\n",
      "Epoch 2270, current patience 3, model mean validation loss 0.9934097528457642, embedding dim 1, hidden size 1, num layers 1, train loss 0.8054090738296509, validation loss 1.0060640573501587\n",
      "Epoch 2280, current patience 2, model mean validation loss 0.9949331283569336, embedding dim 1, hidden size 1, num layers 1, train loss 0.9570276141166687, validation loss 0.9875684976577759\n",
      "Epoch 2290, current patience 1, model mean validation loss 0.9941906929016113, embedding dim 1, hidden size 1, num layers 1, train loss 0.8601825833320618, validation loss 0.9823507070541382\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1030805110931396, embedding dim 1, hidden size 2, num layers 1, train loss 1.0781383514404297, validation loss 1.1030805110931396\n",
      "Epoch 10, current patience 30, model mean validation loss 1.097733736038208, embedding dim 1, hidden size 2, num layers 1, train loss 1.0971260070800781, validation loss 1.092387080192566\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0968104600906372, embedding dim 1, hidden size 2, num layers 1, train loss 1.0877244472503662, validation loss 1.094963788986206\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0961449146270752, embedding dim 1, hidden size 2, num layers 1, train loss 1.1141968965530396, validation loss 1.0941481590270996\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0957709550857544, embedding dim 1, hidden size 2, num layers 1, train loss 1.088331937789917, validation loss 1.0942747592926025\n",
      "Epoch 50, current patience 30, model mean validation loss 1.095476746559143, embedding dim 1, hidden size 2, num layers 1, train loss 1.0930068492889404, validation loss 1.0940064191818237\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0955815315246582, embedding dim 1, hidden size 2, num layers 1, train loss 1.0839436054229736, validation loss 1.096210241317749\n",
      "Epoch 70, current patience 29, model mean validation loss 1.0956017971038818, embedding dim 1, hidden size 2, num layers 1, train loss 1.087684154510498, validation loss 1.095743179321289\n",
      "Epoch 80, current patience 28, model mean validation loss 1.0953378677368164, embedding dim 1, hidden size 2, num layers 1, train loss 1.0895886421203613, validation loss 1.1009693145751953\n",
      "Epoch 90, current patience 30, model mean validation loss 1.096170425415039, embedding dim 1, hidden size 2, num layers 1, train loss 1.0887638330459595, validation loss 1.0990482568740845\n",
      "Epoch 100, current patience 29, model mean validation loss 1.096113681793213, embedding dim 1, hidden size 2, num layers 1, train loss 1.0785313844680786, validation loss 1.094509482383728\n",
      "Epoch 110, current patience 28, model mean validation loss 1.096726894378662, embedding dim 1, hidden size 2, num layers 1, train loss 1.1057178974151611, validation loss 1.0990533828735352\n",
      "Epoch 120, current patience 27, model mean validation loss 1.0963749885559082, embedding dim 1, hidden size 2, num layers 1, train loss 1.1110819578170776, validation loss 1.0914603471755981\n",
      "Epoch 130, current patience 26, model mean validation loss 1.0963037014007568, embedding dim 1, hidden size 2, num layers 1, train loss 1.099060297012329, validation loss 1.0934361219406128\n",
      "Epoch 140, current patience 25, model mean validation loss 1.0962674617767334, embedding dim 1, hidden size 2, num layers 1, train loss 1.075761318206787, validation loss 1.0959194898605347\n",
      "Epoch 150, current patience 24, model mean validation loss 1.0962642431259155, embedding dim 1, hidden size 2, num layers 1, train loss 1.0816454887390137, validation loss 1.0957173109054565\n",
      "Epoch 160, current patience 23, model mean validation loss 1.0952997207641602, embedding dim 1, hidden size 2, num layers 1, train loss 1.0716012716293335, validation loss 1.093253493309021\n",
      "Epoch 170, current patience 30, model mean validation loss 1.094477653503418, embedding dim 1, hidden size 2, num layers 1, train loss 1.0866073369979858, validation loss 1.0924711227416992\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0948846340179443, embedding dim 1, hidden size 2, num layers 1, train loss 1.0953600406646729, validation loss 1.0977659225463867\n",
      "Epoch 190, current patience 29, model mean validation loss 1.0945165157318115, embedding dim 1, hidden size 2, num layers 1, train loss 1.0967940092086792, validation loss 1.0961077213287354\n",
      "Epoch 200, current patience 28, model mean validation loss 1.0947786569595337, embedding dim 1, hidden size 2, num layers 1, train loss 1.0936527252197266, validation loss 1.0935577154159546\n",
      "Epoch 210, current patience 27, model mean validation loss 1.0949699878692627, embedding dim 1, hidden size 2, num layers 1, train loss 1.1087636947631836, validation loss 1.0949668884277344\n",
      "Epoch 220, current patience 26, model mean validation loss 1.0946989059448242, embedding dim 1, hidden size 2, num layers 1, train loss 1.0941966772079468, validation loss 1.0937504768371582\n",
      "Epoch 230, current patience 25, model mean validation loss 1.094865322113037, embedding dim 1, hidden size 2, num layers 1, train loss 1.098621129989624, validation loss 1.0970485210418701\n",
      "Epoch 240, current patience 24, model mean validation loss 1.0952657461166382, embedding dim 1, hidden size 2, num layers 1, train loss 1.095376968383789, validation loss 1.0964574813842773\n",
      "Epoch 250, current patience 23, model mean validation loss 1.0957212448120117, embedding dim 1, hidden size 2, num layers 1, train loss 1.1112302541732788, validation loss 1.0961157083511353\n",
      "Epoch 260, current patience 22, model mean validation loss 1.0954513549804688, embedding dim 1, hidden size 2, num layers 1, train loss 1.093673825263977, validation loss 1.0956064462661743\n",
      "Epoch 270, current patience 21, model mean validation loss 1.0952261686325073, embedding dim 1, hidden size 2, num layers 1, train loss 1.1040410995483398, validation loss 1.0943061113357544\n",
      "Epoch 280, current patience 20, model mean validation loss 1.095428705215454, embedding dim 1, hidden size 2, num layers 1, train loss 1.093152403831482, validation loss 1.095178246498108\n",
      "Epoch 290, current patience 19, model mean validation loss 1.0955051183700562, embedding dim 1, hidden size 2, num layers 1, train loss 1.0902152061462402, validation loss 1.0955781936645508\n",
      "Epoch 300, current patience 18, model mean validation loss 1.095487356185913, embedding dim 1, hidden size 2, num layers 1, train loss 1.0992631912231445, validation loss 1.093607783317566\n",
      "Epoch 310, current patience 17, model mean validation loss 1.0953822135925293, embedding dim 1, hidden size 2, num layers 1, train loss 1.0905481576919556, validation loss 1.0962083339691162\n",
      "Epoch 320, current patience 16, model mean validation loss 1.0955232381820679, embedding dim 1, hidden size 2, num layers 1, train loss 1.0899322032928467, validation loss 1.0975849628448486\n",
      "Epoch 330, current patience 15, model mean validation loss 1.0953235626220703, embedding dim 1, hidden size 2, num layers 1, train loss 1.0950360298156738, validation loss 1.0945186614990234\n",
      "Epoch 340, current patience 14, model mean validation loss 1.0952250957489014, embedding dim 1, hidden size 2, num layers 1, train loss 1.0789695978164673, validation loss 1.0948177576065063\n",
      "Epoch 350, current patience 13, model mean validation loss 1.0952998399734497, embedding dim 1, hidden size 2, num layers 1, train loss 1.1092853546142578, validation loss 1.0949046611785889\n",
      "Epoch 360, current patience 12, model mean validation loss 1.0948848724365234, embedding dim 1, hidden size 2, num layers 1, train loss 1.0924105644226074, validation loss 1.091859221458435\n",
      "Epoch 370, current patience 11, model mean validation loss 1.0945541858673096, embedding dim 1, hidden size 2, num layers 1, train loss 1.08137047290802, validation loss 1.0929325819015503\n",
      "Epoch 380, current patience 10, model mean validation loss 1.0946385860443115, embedding dim 1, hidden size 2, num layers 1, train loss 1.082322597503662, validation loss 1.094282865524292\n",
      "Epoch 390, current patience 9, model mean validation loss 1.0937947034835815, embedding dim 1, hidden size 2, num layers 1, train loss 1.080173134803772, validation loss 1.0894569158554077\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0936191082000732, embedding dim 1, hidden size 2, num layers 1, train loss 1.048307180404663, validation loss 1.096179485321045\n",
      "Epoch 410, current patience 30, model mean validation loss 1.093587875366211, embedding dim 1, hidden size 2, num layers 1, train loss 1.0749404430389404, validation loss 1.0942692756652832\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0935654640197754, embedding dim 1, hidden size 2, num layers 1, train loss 1.0918118953704834, validation loss 1.0946383476257324\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0934796333312988, embedding dim 1, hidden size 2, num layers 1, train loss 1.0967533588409424, validation loss 1.0942177772521973\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0934816598892212, embedding dim 1, hidden size 2, num layers 1, train loss 1.0906732082366943, validation loss 1.091875433921814\n",
      "Epoch 450, current patience 29, model mean validation loss 1.093614101409912, embedding dim 1, hidden size 2, num layers 1, train loss 1.0975347757339478, validation loss 1.0939921140670776\n",
      "Epoch 460, current patience 28, model mean validation loss 1.0935266017913818, embedding dim 1, hidden size 2, num layers 1, train loss 1.0737614631652832, validation loss 1.093583583831787\n",
      "Epoch 470, current patience 27, model mean validation loss 1.0939407348632812, embedding dim 1, hidden size 2, num layers 1, train loss 1.0910136699676514, validation loss 1.092769980430603\n",
      "Epoch 480, current patience 26, model mean validation loss 1.0938353538513184, embedding dim 1, hidden size 2, num layers 1, train loss 1.0843926668167114, validation loss 1.0953354835510254\n",
      "Epoch 490, current patience 25, model mean validation loss 1.0935792922973633, embedding dim 1, hidden size 2, num layers 1, train loss 1.0835554599761963, validation loss 1.0922209024429321\n",
      "Epoch 500, current patience 24, model mean validation loss 1.0935466289520264, embedding dim 1, hidden size 2, num layers 1, train loss 1.0812532901763916, validation loss 1.0943772792816162\n",
      "Epoch 510, current patience 23, model mean validation loss 1.0936758518218994, embedding dim 1, hidden size 2, num layers 1, train loss 1.0896902084350586, validation loss 1.0952510833740234\n",
      "Epoch 520, current patience 22, model mean validation loss 1.0936377048492432, embedding dim 1, hidden size 2, num layers 1, train loss 1.0925184488296509, validation loss 1.0915710926055908\n",
      "Epoch 530, current patience 21, model mean validation loss 1.0940968990325928, embedding dim 1, hidden size 2, num layers 1, train loss 1.0817888975143433, validation loss 1.0976648330688477\n",
      "Epoch 540, current patience 20, model mean validation loss 1.0939301252365112, embedding dim 1, hidden size 2, num layers 1, train loss 1.0933172702789307, validation loss 1.0922505855560303\n",
      "Epoch 550, current patience 19, model mean validation loss 1.0944030284881592, embedding dim 1, hidden size 2, num layers 1, train loss 1.089147686958313, validation loss 1.0965535640716553\n",
      "Epoch 560, current patience 18, model mean validation loss 1.094626784324646, embedding dim 1, hidden size 2, num layers 1, train loss 1.0936830043792725, validation loss 1.0971250534057617\n",
      "Epoch 570, current patience 17, model mean validation loss 1.0950195789337158, embedding dim 1, hidden size 2, num layers 1, train loss 1.0855567455291748, validation loss 1.0953631401062012\n",
      "Epoch 580, current patience 16, model mean validation loss 1.0950779914855957, embedding dim 1, hidden size 2, num layers 1, train loss 1.0875952243804932, validation loss 1.0948446989059448\n",
      "Epoch 590, current patience 15, model mean validation loss 1.0946511030197144, embedding dim 1, hidden size 2, num layers 1, train loss 1.0984995365142822, validation loss 1.0918354988098145\n",
      "Epoch 600, current patience 14, model mean validation loss 1.094951868057251, embedding dim 1, hidden size 2, num layers 1, train loss 1.1019058227539062, validation loss 1.093977451324463\n",
      "Epoch 610, current patience 13, model mean validation loss 1.094526767730713, embedding dim 1, hidden size 2, num layers 1, train loss 1.0929926633834839, validation loss 1.0942637920379639\n",
      "Epoch 620, current patience 12, model mean validation loss 1.0946390628814697, embedding dim 1, hidden size 2, num layers 1, train loss 1.1044191122055054, validation loss 1.0931496620178223\n",
      "Epoch 630, current patience 11, model mean validation loss 1.0945508480072021, embedding dim 1, hidden size 2, num layers 1, train loss 1.0815935134887695, validation loss 1.0958476066589355\n",
      "Epoch 640, current patience 10, model mean validation loss 1.0941981077194214, embedding dim 1, hidden size 2, num layers 1, train loss 1.0890693664550781, validation loss 1.0943026542663574\n",
      "Epoch 650, current patience 9, model mean validation loss 1.0942373275756836, embedding dim 1, hidden size 2, num layers 1, train loss 1.1007415056228638, validation loss 1.0956770181655884\n",
      "Epoch 660, current patience 8, model mean validation loss 1.0946162939071655, embedding dim 1, hidden size 2, num layers 1, train loss 1.0997780561447144, validation loss 1.097876787185669\n",
      "Epoch 670, current patience 7, model mean validation loss 1.0947554111480713, embedding dim 1, hidden size 2, num layers 1, train loss 1.0897636413574219, validation loss 1.0929490327835083\n",
      "Epoch 680, current patience 6, model mean validation loss 1.094744324684143, embedding dim 1, hidden size 2, num layers 1, train loss 1.0849101543426514, validation loss 1.0938881635665894\n",
      "Epoch 690, current patience 5, model mean validation loss 1.0949513912200928, embedding dim 1, hidden size 2, num layers 1, train loss 1.1038134098052979, validation loss 1.0959198474884033\n",
      "Epoch 700, current patience 4, model mean validation loss 1.0954623222351074, embedding dim 1, hidden size 2, num layers 1, train loss 1.0994409322738647, validation loss 1.097237229347229\n",
      "Epoch 710, current patience 3, model mean validation loss 1.0956937074661255, embedding dim 1, hidden size 2, num layers 1, train loss 1.0786139965057373, validation loss 1.0976988077163696\n",
      "Epoch 720, current patience 2, model mean validation loss 1.095632791519165, embedding dim 1, hidden size 2, num layers 1, train loss 1.1074752807617188, validation loss 1.0938148498535156\n",
      "Epoch 730, current patience 1, model mean validation loss 1.095883846282959, embedding dim 1, hidden size 2, num layers 1, train loss 1.095644235610962, validation loss 1.0976853370666504\n",
      "Epoch 0, current patience 30, model mean validation loss 1.20841383934021, embedding dim 1, hidden size 4, num layers 1, train loss 1.1817032098770142, validation loss 1.20841383934021\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1838064193725586, embedding dim 1, hidden size 4, num layers 1, train loss 1.157250165939331, validation loss 1.1591989994049072\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1657778024673462, embedding dim 1, hidden size 4, num layers 1, train loss 1.1110951900482178, validation loss 1.1297208070755005\n",
      "Epoch 30, current patience 30, model mean validation loss 1.153147578239441, embedding dim 1, hidden size 4, num layers 1, train loss 1.102586030960083, validation loss 1.115256905555725\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1432582139968872, embedding dim 1, hidden size 4, num layers 1, train loss 1.1218674182891846, validation loss 1.1037003993988037\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1361298561096191, embedding dim 1, hidden size 4, num layers 1, train loss 1.1134706735610962, validation loss 1.100488543510437\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1303620338439941, embedding dim 1, hidden size 4, num layers 1, train loss 1.0994855165481567, validation loss 1.095755696296692\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1258774995803833, embedding dim 1, hidden size 4, num layers 1, train loss 1.0911833047866821, validation loss 1.094484806060791\n",
      "Epoch 80, current patience 30, model mean validation loss 1.111324667930603, embedding dim 1, hidden size 4, num layers 1, train loss 1.1067849397659302, validation loss 1.0919914245605469\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1030434370040894, embedding dim 1, hidden size 4, num layers 1, train loss 1.1028468608856201, validation loss 1.0929489135742188\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0996661186218262, embedding dim 1, hidden size 4, num layers 1, train loss 1.074044108390808, validation loss 1.1027016639709473\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0969715118408203, embedding dim 1, hidden size 4, num layers 1, train loss 1.077435851097107, validation loss 1.093700647354126\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0958967208862305, embedding dim 1, hidden size 4, num layers 1, train loss 1.102039098739624, validation loss 1.0951027870178223\n",
      "Epoch 130, current patience 30, model mean validation loss 1.094989538192749, embedding dim 1, hidden size 4, num layers 1, train loss 1.089900016784668, validation loss 1.0932310819625854\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0946142673492432, embedding dim 1, hidden size 4, num layers 1, train loss 1.0935399532318115, validation loss 1.092752456665039\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0944525003433228, embedding dim 1, hidden size 4, num layers 1, train loss 1.0986706018447876, validation loss 1.0931909084320068\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0947761535644531, embedding dim 1, hidden size 4, num layers 1, train loss 1.0892906188964844, validation loss 1.094580888748169\n",
      "Epoch 170, current patience 29, model mean validation loss 1.094869613647461, embedding dim 1, hidden size 4, num layers 1, train loss 1.1014429330825806, validation loss 1.0936970710754395\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0938382148742676, embedding dim 1, hidden size 4, num layers 1, train loss 1.086225986480713, validation loss 1.094449758529663\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0940821170806885, embedding dim 1, hidden size 4, num layers 1, train loss 1.0839495658874512, validation loss 1.095651388168335\n",
      "Epoch 200, current patience 29, model mean validation loss 1.093568205833435, embedding dim 1, hidden size 4, num layers 1, train loss 1.0810350179672241, validation loss 1.0909919738769531\n",
      "Epoch 210, current patience 30, model mean validation loss 1.093488097190857, embedding dim 1, hidden size 4, num layers 1, train loss 1.0838978290557861, validation loss 1.0925909280776978\n",
      "Epoch 220, current patience 30, model mean validation loss 1.093742847442627, embedding dim 1, hidden size 4, num layers 1, train loss 1.095956802368164, validation loss 1.0947901010513306\n",
      "Epoch 230, current patience 29, model mean validation loss 1.0935537815093994, embedding dim 1, hidden size 4, num layers 1, train loss 1.076589822769165, validation loss 1.0916781425476074\n",
      "Epoch 240, current patience 28, model mean validation loss 1.0929116010665894, embedding dim 1, hidden size 4, num layers 1, train loss 1.0754454135894775, validation loss 1.0894432067871094\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0929367542266846, embedding dim 1, hidden size 4, num layers 1, train loss 1.1003615856170654, validation loss 1.0938981771469116\n",
      "Epoch 260, current patience 29, model mean validation loss 1.0925880670547485, embedding dim 1, hidden size 4, num layers 1, train loss 1.0961405038833618, validation loss 1.0916608572006226\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0913978815078735, embedding dim 1, hidden size 4, num layers 1, train loss 1.1063756942749023, validation loss 1.0861296653747559\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0906693935394287, embedding dim 1, hidden size 4, num layers 1, train loss 1.0983513593673706, validation loss 1.0851640701293945\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0885756015777588, embedding dim 1, hidden size 4, num layers 1, train loss 1.0937731266021729, validation loss 1.0758399963378906\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0841346979141235, embedding dim 1, hidden size 4, num layers 1, train loss 1.0621906518936157, validation loss 1.0592632293701172\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0782520771026611, embedding dim 1, hidden size 4, num layers 1, train loss 1.0908950567245483, validation loss 1.04461669921875\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0708239078521729, embedding dim 1, hidden size 4, num layers 1, train loss 1.038329839706421, validation loss 1.0300185680389404\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0632381439208984, embedding dim 1, hidden size 4, num layers 1, train loss 1.0913761854171753, validation loss 1.0332112312316895\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0562541484832764, embedding dim 1, hidden size 4, num layers 1, train loss 1.04254150390625, validation loss 1.0357904434204102\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0482752323150635, embedding dim 1, hidden size 4, num layers 1, train loss 1.004196047782898, validation loss 1.0222980976104736\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0388984680175781, embedding dim 1, hidden size 4, num layers 1, train loss 0.9931147694587708, validation loss 1.0101498365402222\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0301241874694824, embedding dim 1, hidden size 4, num layers 1, train loss 0.9771153926849365, validation loss 1.005645751953125\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0243297815322876, embedding dim 1, hidden size 4, num layers 1, train loss 0.9631586074829102, validation loss 1.0129072666168213\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0188729763031006, embedding dim 1, hidden size 4, num layers 1, train loss 1.0054121017456055, validation loss 1.0009629726409912\n",
      "Epoch 400, current patience 30, model mean validation loss 1.012679934501648, embedding dim 1, hidden size 4, num layers 1, train loss 1.102459192276001, validation loss 0.9804739952087402\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0070087909698486, embedding dim 1, hidden size 4, num layers 1, train loss 0.9331361055374146, validation loss 0.9878419637680054\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9992889165878296, embedding dim 1, hidden size 4, num layers 1, train loss 0.9565508365631104, validation loss 0.9740314483642578\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9951229095458984, embedding dim 1, hidden size 4, num layers 1, train loss 0.9813929796218872, validation loss 0.9889702796936035\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9892777800559998, embedding dim 1, hidden size 4, num layers 1, train loss 1.1128838062286377, validation loss 0.9633883833885193\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9633883833885193_1_4_1_440.pt\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9824040532112122, embedding dim 1, hidden size 4, num layers 1, train loss 0.9702640771865845, validation loss 0.950655996799469\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.950655996799469_1_4_1_450.pt\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9751310348510742, embedding dim 1, hidden size 4, num layers 1, train loss 0.8830084800720215, validation loss 0.9547234773635864\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9686480760574341, embedding dim 1, hidden size 4, num layers 1, train loss 0.9348384141921997, validation loss 0.9490990042686462\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9490990042686462_1_4_1_470.pt\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9636175632476807, embedding dim 1, hidden size 4, num layers 1, train loss 0.8803290724754333, validation loss 0.9402296543121338\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9402296543121338_1_4_1_480.pt\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9579454660415649, embedding dim 1, hidden size 4, num layers 1, train loss 0.9392677545547485, validation loss 0.942465603351593\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9523593187332153, embedding dim 1, hidden size 4, num layers 1, train loss 0.858180820941925, validation loss 0.9293422102928162\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9293422102928162_1_4_1_500.pt\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9442869424819946, embedding dim 1, hidden size 4, num layers 1, train loss 0.8481989502906799, validation loss 0.9243913888931274\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9243913888931274_1_4_1_510.pt\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9379496574401855, embedding dim 1, hidden size 4, num layers 1, train loss 0.8350631594657898, validation loss 0.9126896858215332\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.9126896858215332_1_4_1_520.pt\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9314420223236084, embedding dim 1, hidden size 4, num layers 1, train loss 0.9650000333786011, validation loss 0.8985947370529175\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8985947370529175_1_4_1_530.pt\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9270386695861816, embedding dim 1, hidden size 4, num layers 1, train loss 0.7957767248153687, validation loss 0.9194968938827515\n",
      "Epoch 550, current patience 30, model mean validation loss 0.921467125415802, embedding dim 1, hidden size 4, num layers 1, train loss 0.8025290966033936, validation loss 0.9045267105102539\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9156444072723389, embedding dim 1, hidden size 4, num layers 1, train loss 0.8788392543792725, validation loss 0.8936478495597839\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8936478495597839_1_4_1_560.pt\n",
      "Epoch 570, current patience 30, model mean validation loss 0.9087232351303101, embedding dim 1, hidden size 4, num layers 1, train loss 0.8259031772613525, validation loss 0.8870967626571655\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8870967626571655_1_4_1_570.pt\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9027738571166992, embedding dim 1, hidden size 4, num layers 1, train loss 0.8357385396957397, validation loss 0.8817470073699951\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8817470073699951_1_4_1_580.pt\n",
      "Epoch 590, current patience 30, model mean validation loss 0.89830482006073, embedding dim 1, hidden size 4, num layers 1, train loss 0.8063037395477295, validation loss 0.8886388540267944\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8958044052124023, embedding dim 1, hidden size 4, num layers 1, train loss 0.8641836643218994, validation loss 0.8926863670349121\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8930537104606628, embedding dim 1, hidden size 4, num layers 1, train loss 0.8666062355041504, validation loss 0.8765888214111328\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8765888214111328_1_4_1_610.pt\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8867594003677368, embedding dim 1, hidden size 4, num layers 1, train loss 0.8515270948410034, validation loss 0.8691425323486328\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8691425323486328_1_4_1_620.pt\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8816874623298645, embedding dim 1, hidden size 4, num layers 1, train loss 0.8340972661972046, validation loss 0.8639518618583679\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8639518618583679_1_4_1_630.pt\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8819474577903748, embedding dim 1, hidden size 4, num layers 1, train loss 0.8748092651367188, validation loss 0.8957275152206421\n",
      "Epoch 650, current patience 29, model mean validation loss 0.8768804669380188, embedding dim 1, hidden size 4, num layers 1, train loss 0.7657216787338257, validation loss 0.8465608358383179\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8465608358383179_1_4_1_650.pt\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8736280202865601, embedding dim 1, hidden size 4, num layers 1, train loss 0.8504793047904968, validation loss 0.8557273745536804\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8688133955001831, embedding dim 1, hidden size 4, num layers 1, train loss 0.9152047634124756, validation loss 0.850121796131134\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8612461686134338, embedding dim 1, hidden size 4, num layers 1, train loss 0.6657932996749878, validation loss 0.8321486115455627\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8321486115455627_1_4_1_680.pt\n",
      "Epoch 690, current patience 30, model mean validation loss 0.857471227645874, embedding dim 1, hidden size 4, num layers 1, train loss 0.8525753617286682, validation loss 0.846389651298523\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8563357591629028, embedding dim 1, hidden size 4, num layers 1, train loss 0.7724947929382324, validation loss 0.8600585460662842\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8512181043624878, embedding dim 1, hidden size 4, num layers 1, train loss 0.8661693334579468, validation loss 0.8230103254318237\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8230103254318237_1_4_1_710.pt\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8435937166213989, embedding dim 1, hidden size 4, num layers 1, train loss 0.8637052178382874, validation loss 0.8347322344779968\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8399925231933594, embedding dim 1, hidden size 4, num layers 1, train loss 0.878463625907898, validation loss 0.8177515864372253\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8177515864372253_1_4_1_730.pt\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8378760814666748, embedding dim 1, hidden size 4, num layers 1, train loss 0.7985275387763977, validation loss 0.8387956023216248\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8354455828666687, embedding dim 1, hidden size 4, num layers 1, train loss 0.7066720724105835, validation loss 0.8306782245635986\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8359546661376953, embedding dim 1, hidden size 4, num layers 1, train loss 0.777570366859436, validation loss 0.8362212181091309\n",
      "Epoch 770, current patience 29, model mean validation loss 0.8330680727958679, embedding dim 1, hidden size 4, num layers 1, train loss 0.6555640697479248, validation loss 0.8232962489128113\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8309446573257446, embedding dim 1, hidden size 4, num layers 1, train loss 0.7814058065414429, validation loss 0.8430713415145874\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8347443342208862, embedding dim 1, hidden size 4, num layers 1, train loss 0.6796369552612305, validation loss 0.8534085154533386\n",
      "Epoch 800, current patience 29, model mean validation loss 0.8347282409667969, embedding dim 1, hidden size 4, num layers 1, train loss 0.7951327562332153, validation loss 0.8346031904220581\n",
      "Epoch 810, current patience 28, model mean validation loss 0.8345761299133301, embedding dim 1, hidden size 4, num layers 1, train loss 0.7128918170928955, validation loss 0.8165347576141357\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8165347576141357_1_4_1_810.pt\n",
      "Epoch 820, current patience 27, model mean validation loss 0.8330666422843933, embedding dim 1, hidden size 4, num layers 1, train loss 0.7333971261978149, validation loss 0.8267192840576172\n",
      "Epoch 830, current patience 26, model mean validation loss 0.833271324634552, embedding dim 1, hidden size 4, num layers 1, train loss 0.7314072847366333, validation loss 0.8323157429695129\n",
      "Epoch 840, current patience 25, model mean validation loss 0.8315998315811157, embedding dim 1, hidden size 4, num layers 1, train loss 0.6829934120178223, validation loss 0.8228495121002197\n",
      "Epoch 850, current patience 24, model mean validation loss 0.8307845592498779, embedding dim 1, hidden size 4, num layers 1, train loss 0.6728193759918213, validation loss 0.816774308681488\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8315650224685669, embedding dim 1, hidden size 4, num layers 1, train loss 0.7065476179122925, validation loss 0.84931480884552\n",
      "Epoch 870, current patience 29, model mean validation loss 0.8304139375686646, embedding dim 1, hidden size 4, num layers 1, train loss 0.9015489220619202, validation loss 0.8442001342773438\n",
      "Epoch 880, current patience 30, model mean validation loss 0.8269477486610413, embedding dim 1, hidden size 4, num layers 1, train loss 0.664499819278717, validation loss 0.8068735599517822\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8068735599517822_1_4_1_880.pt\n",
      "Epoch 890, current patience 30, model mean validation loss 0.8282087445259094, embedding dim 1, hidden size 4, num layers 1, train loss 0.7450807094573975, validation loss 0.8266226649284363\n",
      "Epoch 900, current patience 29, model mean validation loss 0.828803300857544, embedding dim 1, hidden size 4, num layers 1, train loss 0.7777761220932007, validation loss 0.8314753770828247\n",
      "Epoch 910, current patience 28, model mean validation loss 0.8287451267242432, embedding dim 1, hidden size 4, num layers 1, train loss 0.7700988054275513, validation loss 0.8318507075309753\n",
      "Epoch 920, current patience 27, model mean validation loss 0.8278576731681824, embedding dim 1, hidden size 4, num layers 1, train loss 0.6578357219696045, validation loss 0.8157492876052856\n",
      "Epoch 930, current patience 26, model mean validation loss 0.8271682858467102, embedding dim 1, hidden size 4, num layers 1, train loss 0.8231309652328491, validation loss 0.8112595081329346\n",
      "Epoch 940, current patience 25, model mean validation loss 0.8244233131408691, embedding dim 1, hidden size 4, num layers 1, train loss 0.5815063714981079, validation loss 0.8273554444313049\n",
      "Epoch 950, current patience 30, model mean validation loss 0.8204277157783508, embedding dim 1, hidden size 4, num layers 1, train loss 0.6437814831733704, validation loss 0.8122348189353943\n",
      "Epoch 960, current patience 30, model mean validation loss 0.8244194984436035, embedding dim 1, hidden size 4, num layers 1, train loss 0.6289458274841309, validation loss 0.8388079404830933\n",
      "Epoch 970, current patience 29, model mean validation loss 0.8211707472801208, embedding dim 1, hidden size 4, num layers 1, train loss 0.7294334173202515, validation loss 0.8006327748298645\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.8006327748298645_1_4_1_970.pt\n",
      "Epoch 980, current patience 28, model mean validation loss 0.8267784714698792, embedding dim 1, hidden size 4, num layers 1, train loss 0.7313452959060669, validation loss 0.8763373494148254\n",
      "Epoch 990, current patience 27, model mean validation loss 0.822275698184967, embedding dim 1, hidden size 4, num layers 1, train loss 0.7505186796188354, validation loss 0.7958283424377441\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7958283424377441_1_4_1_990.pt\n",
      "Epoch 1000, current patience 26, model mean validation loss 0.8184109330177307, embedding dim 1, hidden size 4, num layers 1, train loss 0.6960538625717163, validation loss 0.7848310470581055\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7848310470581055_1_4_1_1000.pt\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.8170635104179382, embedding dim 1, hidden size 4, num layers 1, train loss 0.7892049551010132, validation loss 0.8004801273345947\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.8083942532539368, embedding dim 1, hidden size 4, num layers 1, train loss 0.6866534948348999, validation loss 0.758001446723938\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.758001446723938_1_4_1_1020.pt\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.8062686324119568, embedding dim 1, hidden size 4, num layers 1, train loss 0.7936595678329468, validation loss 0.7952300310134888\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.8044400811195374, embedding dim 1, hidden size 4, num layers 1, train loss 0.5986673831939697, validation loss 0.8241795897483826\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.8084201216697693, embedding dim 1, hidden size 4, num layers 1, train loss 0.6702677011489868, validation loss 0.8324731588363647\n",
      "Epoch 1060, current patience 29, model mean validation loss 0.800310492515564, embedding dim 1, hidden size 4, num layers 1, train loss 0.6704293489456177, validation loss 0.8114606142044067\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.8016289472579956, embedding dim 1, hidden size 4, num layers 1, train loss 0.6426641941070557, validation loss 0.80637526512146\n",
      "Epoch 1080, current patience 29, model mean validation loss 0.8132156729698181, embedding dim 1, hidden size 4, num layers 1, train loss 0.6792659163475037, validation loss 0.8775248527526855\n",
      "Epoch 1090, current patience 28, model mean validation loss 0.8113222122192383, embedding dim 1, hidden size 4, num layers 1, train loss 0.6454362273216248, validation loss 0.7853326201438904\n",
      "Epoch 1100, current patience 27, model mean validation loss 0.8162384033203125, embedding dim 1, hidden size 4, num layers 1, train loss 0.7662537097930908, validation loss 0.7973304390907288\n",
      "Epoch 1110, current patience 26, model mean validation loss 0.8189179301261902, embedding dim 1, hidden size 4, num layers 1, train loss 0.6229508519172668, validation loss 0.816666841506958\n",
      "Epoch 1120, current patience 25, model mean validation loss 0.8145599365234375, embedding dim 1, hidden size 4, num layers 1, train loss 0.6725665330886841, validation loss 0.7893155217170715\n",
      "Epoch 1130, current patience 24, model mean validation loss 0.8127896785736084, embedding dim 1, hidden size 4, num layers 1, train loss 0.6276327967643738, validation loss 0.8183115720748901\n",
      "Epoch 1140, current patience 23, model mean validation loss 0.8110259771347046, embedding dim 1, hidden size 4, num layers 1, train loss 0.5668366551399231, validation loss 0.797351062297821\n",
      "Epoch 1150, current patience 22, model mean validation loss 0.8110882639884949, embedding dim 1, hidden size 4, num layers 1, train loss 0.6989265084266663, validation loss 0.8068736791610718\n",
      "Epoch 1160, current patience 21, model mean validation loss 0.7999285459518433, embedding dim 1, hidden size 4, num layers 1, train loss 0.7159207463264465, validation loss 0.7882469296455383\n",
      "Epoch 1170, current patience 30, model mean validation loss 0.8052769303321838, embedding dim 1, hidden size 4, num layers 1, train loss 0.6945120096206665, validation loss 0.8281192779541016\n",
      "Epoch 1180, current patience 29, model mean validation loss 0.8065683841705322, embedding dim 1, hidden size 4, num layers 1, train loss 0.6635125875473022, validation loss 0.8076624274253845\n",
      "Epoch 1190, current patience 28, model mean validation loss 0.8057889342308044, embedding dim 1, hidden size 4, num layers 1, train loss 0.597383975982666, validation loss 0.8104311227798462\n",
      "Epoch 1200, current patience 27, model mean validation loss 0.8082449436187744, embedding dim 1, hidden size 4, num layers 1, train loss 0.6070963144302368, validation loss 0.8089637756347656\n",
      "Epoch 1210, current patience 26, model mean validation loss 0.8067260980606079, embedding dim 1, hidden size 4, num layers 1, train loss 0.5681428909301758, validation loss 0.8061607480049133\n",
      "Epoch 1220, current patience 25, model mean validation loss 0.8084282875061035, embedding dim 1, hidden size 4, num layers 1, train loss 0.7019985914230347, validation loss 0.8109685182571411\n",
      "Epoch 1230, current patience 24, model mean validation loss 0.8081514239311218, embedding dim 1, hidden size 4, num layers 1, train loss 0.6932003498077393, validation loss 0.8046586513519287\n",
      "Epoch 1240, current patience 23, model mean validation loss 0.8139052391052246, embedding dim 1, hidden size 4, num layers 1, train loss 0.6630995869636536, validation loss 0.8342778086662292\n",
      "Epoch 1250, current patience 22, model mean validation loss 0.8086766004562378, embedding dim 1, hidden size 4, num layers 1, train loss 0.6766177415847778, validation loss 0.7862894535064697\n",
      "Epoch 1260, current patience 21, model mean validation loss 0.8089156150817871, embedding dim 1, hidden size 4, num layers 1, train loss 0.711688756942749, validation loss 0.8095749616622925\n",
      "Epoch 1270, current patience 20, model mean validation loss 0.8100146055221558, embedding dim 1, hidden size 4, num layers 1, train loss 0.7446631789207458, validation loss 0.8192228674888611\n",
      "Epoch 1280, current patience 19, model mean validation loss 0.8128044009208679, embedding dim 1, hidden size 4, num layers 1, train loss 0.6576281189918518, validation loss 0.831282377243042\n",
      "Epoch 1290, current patience 18, model mean validation loss 0.8125519156455994, embedding dim 1, hidden size 4, num layers 1, train loss 0.7580661177635193, validation loss 0.8041403293609619\n",
      "Epoch 1300, current patience 17, model mean validation loss 0.8154224157333374, embedding dim 1, hidden size 4, num layers 1, train loss 0.5684094429016113, validation loss 0.8339328765869141\n",
      "Epoch 1310, current patience 16, model mean validation loss 0.8140608072280884, embedding dim 1, hidden size 4, num layers 1, train loss 0.6401889324188232, validation loss 0.7937658429145813\n",
      "Epoch 1320, current patience 15, model mean validation loss 0.8195501565933228, embedding dim 1, hidden size 4, num layers 1, train loss 0.7163807153701782, validation loss 0.8781924843788147\n",
      "Epoch 1330, current patience 14, model mean validation loss 0.8209214210510254, embedding dim 1, hidden size 4, num layers 1, train loss 0.6113190650939941, validation loss 0.7972602248191833\n",
      "Epoch 1340, current patience 13, model mean validation loss 0.8232130408287048, embedding dim 1, hidden size 4, num layers 1, train loss 0.622341513633728, validation loss 0.8279069662094116\n",
      "Epoch 1350, current patience 12, model mean validation loss 0.8198938369750977, embedding dim 1, hidden size 4, num layers 1, train loss 0.5724672079086304, validation loss 0.7926697731018066\n",
      "Epoch 1360, current patience 11, model mean validation loss 0.8194601535797119, embedding dim 1, hidden size 4, num layers 1, train loss 0.5387482643127441, validation loss 0.827812671661377\n",
      "Epoch 1370, current patience 10, model mean validation loss 0.820859432220459, embedding dim 1, hidden size 4, num layers 1, train loss 0.5807325839996338, validation loss 0.8153350353240967\n",
      "Epoch 1380, current patience 9, model mean validation loss 0.8180233240127563, embedding dim 1, hidden size 4, num layers 1, train loss 0.6319613456726074, validation loss 0.81124347448349\n",
      "Epoch 1390, current patience 8, model mean validation loss 0.8194664120674133, embedding dim 1, hidden size 4, num layers 1, train loss 0.6198635697364807, validation loss 0.8053107857704163\n",
      "Epoch 1400, current patience 7, model mean validation loss 0.8178058862686157, embedding dim 1, hidden size 4, num layers 1, train loss 0.572313129901886, validation loss 0.8649080395698547\n",
      "Epoch 1410, current patience 6, model mean validation loss 0.8217586874961853, embedding dim 1, hidden size 4, num layers 1, train loss 0.6961963176727295, validation loss 0.8288829922676086\n",
      "Epoch 1420, current patience 5, model mean validation loss 0.817847728729248, embedding dim 1, hidden size 4, num layers 1, train loss 0.7469196319580078, validation loss 0.7966189384460449\n",
      "Epoch 1430, current patience 4, model mean validation loss 0.8268094062805176, embedding dim 1, hidden size 4, num layers 1, train loss 0.5077757835388184, validation loss 0.8643628358840942\n",
      "Epoch 1440, current patience 3, model mean validation loss 0.8269680142402649, embedding dim 1, hidden size 4, num layers 1, train loss 0.6795010566711426, validation loss 0.8290821313858032\n",
      "Epoch 1450, current patience 2, model mean validation loss 0.8263362646102905, embedding dim 1, hidden size 4, num layers 1, train loss 0.49155953526496887, validation loss 0.810280978679657\n",
      "Epoch 1460, current patience 1, model mean validation loss 0.8288628458976746, embedding dim 1, hidden size 4, num layers 1, train loss 0.6231552362442017, validation loss 0.8314563035964966\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1188199520111084, embedding dim 1, hidden size 8, num layers 1, train loss 1.0991895198822021, validation loss 1.1188199520111084\n",
      "Epoch 10, current patience 30, model mean validation loss 1.10771644115448, embedding dim 1, hidden size 8, num layers 1, train loss 1.0993354320526123, validation loss 1.0966129302978516\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1036999225616455, embedding dim 1, hidden size 8, num layers 1, train loss 1.0989079475402832, validation loss 1.0956668853759766\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1015342473983765, embedding dim 1, hidden size 8, num layers 1, train loss 1.1048085689544678, validation loss 1.0950372219085693\n",
      "Epoch 40, current patience 30, model mean validation loss 1.10006844997406, embedding dim 1, hidden size 8, num layers 1, train loss 1.1031081676483154, validation loss 1.094205379486084\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0994281768798828, embedding dim 1, hidden size 8, num layers 1, train loss 1.0938770771026611, validation loss 1.096226692199707\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0988487005233765, embedding dim 1, hidden size 8, num layers 1, train loss 1.0888960361480713, validation loss 1.0953716039657593\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0981647968292236, embedding dim 1, hidden size 8, num layers 1, train loss 1.0962040424346924, validation loss 1.0933778285980225\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0953443050384521, embedding dim 1, hidden size 8, num layers 1, train loss 1.1002039909362793, validation loss 1.0962557792663574\n",
      "Epoch 90, current patience 30, model mean validation loss 1.094876766204834, embedding dim 1, hidden size 8, num layers 1, train loss 1.0883039236068726, validation loss 1.0928730964660645\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0948734283447266, embedding dim 1, hidden size 8, num layers 1, train loss 1.080066204071045, validation loss 1.095639705657959\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0947160720825195, embedding dim 1, hidden size 8, num layers 1, train loss 1.0835025310516357, validation loss 1.0937780141830444\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0945944786071777, embedding dim 1, hidden size 8, num layers 1, train loss 1.0914318561553955, validation loss 1.0932328701019287\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0941169261932373, embedding dim 1, hidden size 8, num layers 1, train loss 1.092383861541748, validation loss 1.0924071073532104\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0938220024108887, embedding dim 1, hidden size 8, num layers 1, train loss 1.092766284942627, validation loss 1.0930120944976807\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0937812328338623, embedding dim 1, hidden size 8, num layers 1, train loss 1.0790295600891113, validation loss 1.093050241470337\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0933433771133423, embedding dim 1, hidden size 8, num layers 1, train loss 1.0973541736602783, validation loss 1.0927541255950928\n",
      "Epoch 170, current patience 30, model mean validation loss 1.092785120010376, embedding dim 1, hidden size 8, num layers 1, train loss 1.100635051727295, validation loss 1.0884071588516235\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0914628505706787, embedding dim 1, hidden size 8, num layers 1, train loss 1.1071490049362183, validation loss 1.0850614309310913\n",
      "Epoch 190, current patience 30, model mean validation loss 1.087798833847046, embedding dim 1, hidden size 8, num layers 1, train loss 1.096562385559082, validation loss 1.0644654035568237\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0838830471038818, embedding dim 1, hidden size 8, num layers 1, train loss 1.0456268787384033, validation loss 1.0619072914123535\n",
      "Epoch 210, current patience 30, model mean validation loss 1.077646255493164, embedding dim 1, hidden size 8, num layers 1, train loss 1.0068397521972656, validation loss 1.0425126552581787\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0703688859939575, embedding dim 1, hidden size 8, num layers 1, train loss 1.08854341506958, validation loss 1.0347929000854492\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0612905025482178, embedding dim 1, hidden size 8, num layers 1, train loss 1.0079929828643799, validation loss 1.0204226970672607\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0536391735076904, embedding dim 1, hidden size 8, num layers 1, train loss 0.9978376030921936, validation loss 1.0315439701080322\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0430314540863037, embedding dim 1, hidden size 8, num layers 1, train loss 0.9599610567092896, validation loss 1.003544569015503\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0328046083450317, embedding dim 1, hidden size 8, num layers 1, train loss 0.9298115968704224, validation loss 1.0032479763031006\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0251355171203613, embedding dim 1, hidden size 8, num layers 1, train loss 0.9261293411254883, validation loss 1.003111720085144\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0160419940948486, embedding dim 1, hidden size 8, num layers 1, train loss 1.0274571180343628, validation loss 0.9891594052314758\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0087891817092896, embedding dim 1, hidden size 8, num layers 1, train loss 0.9033793210983276, validation loss 0.9844909906387329\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0028547048568726, embedding dim 1, hidden size 8, num layers 1, train loss 0.9208656549453735, validation loss 0.9873164296150208\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9964550733566284, embedding dim 1, hidden size 8, num layers 1, train loss 0.9057055115699768, validation loss 0.9692254066467285\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9882422089576721, embedding dim 1, hidden size 8, num layers 1, train loss 0.976601243019104, validation loss 0.9658410549163818\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9832292795181274, embedding dim 1, hidden size 8, num layers 1, train loss 1.0198004245758057, validation loss 0.9634411334991455\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9789514541625977, embedding dim 1, hidden size 8, num layers 1, train loss 0.9794919490814209, validation loss 0.9690253138542175\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9789468050003052, embedding dim 1, hidden size 8, num layers 1, train loss 0.9533787965774536, validation loss 1.0030744075775146\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9769191741943359, embedding dim 1, hidden size 8, num layers 1, train loss 0.909479022026062, validation loss 0.9729385375976562\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9727692604064941, embedding dim 1, hidden size 8, num layers 1, train loss 0.9069352746009827, validation loss 0.9512915015220642\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9677531719207764, embedding dim 1, hidden size 8, num layers 1, train loss 0.8525075912475586, validation loss 0.9471875429153442\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9660918116569519, embedding dim 1, hidden size 8, num layers 1, train loss 0.953761637210846, validation loss 0.9559352993965149\n",
      "Epoch 400, current patience 30, model mean validation loss 0.963748574256897, embedding dim 1, hidden size 8, num layers 1, train loss 0.9392976760864258, validation loss 0.9470951557159424\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9607563614845276, embedding dim 1, hidden size 8, num layers 1, train loss 0.8576905727386475, validation loss 0.9395033121109009\n",
      "Epoch 420, current patience 30, model mean validation loss 0.960486650466919, embedding dim 1, hidden size 8, num layers 1, train loss 0.8727992177009583, validation loss 0.9668670892715454\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9523850679397583, embedding dim 1, hidden size 8, num layers 1, train loss 0.7815689444541931, validation loss 0.9382621645927429\n",
      "Epoch 440, current patience 30, model mean validation loss 0.948383092880249, embedding dim 1, hidden size 8, num layers 1, train loss 0.9234671592712402, validation loss 0.9409225583076477\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9470341205596924, embedding dim 1, hidden size 8, num layers 1, train loss 0.9817751049995422, validation loss 0.9404994249343872\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9453034400939941, embedding dim 1, hidden size 8, num layers 1, train loss 0.8935132026672363, validation loss 0.9333422183990479\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9388346672058105, embedding dim 1, hidden size 8, num layers 1, train loss 1.0062282085418701, validation loss 0.9041855335235596\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9339320659637451, embedding dim 1, hidden size 8, num layers 1, train loss 0.8789429664611816, validation loss 0.907874345779419\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9302310943603516, embedding dim 1, hidden size 8, num layers 1, train loss 0.8711519241333008, validation loss 0.9098954796791077\n",
      "Epoch 500, current patience 30, model mean validation loss 0.924233078956604, embedding dim 1, hidden size 8, num layers 1, train loss 0.8304426670074463, validation loss 0.9188833832740784\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9225931167602539, embedding dim 1, hidden size 8, num layers 1, train loss 0.8722555637359619, validation loss 0.925142228603363\n",
      "Epoch 520, current patience 30, model mean validation loss 0.919030487537384, embedding dim 1, hidden size 8, num layers 1, train loss 0.8295342326164246, validation loss 0.9124215841293335\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9140421152114868, embedding dim 1, hidden size 8, num layers 1, train loss 0.8948938846588135, validation loss 0.9005920886993408\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9077500700950623, embedding dim 1, hidden size 8, num layers 1, train loss 0.7938834428787231, validation loss 0.8830054998397827\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9056754112243652, embedding dim 1, hidden size 8, num layers 1, train loss 0.8322588205337524, validation loss 0.887588620185852\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9038220643997192, embedding dim 1, hidden size 8, num layers 1, train loss 0.815253734588623, validation loss 0.8930478692054749\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8983577489852905, embedding dim 1, hidden size 8, num layers 1, train loss 0.8389574885368347, validation loss 0.8661807179450989\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8939982652664185, embedding dim 1, hidden size 8, num layers 1, train loss 0.804993212223053, validation loss 0.8840073347091675\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8898876309394836, embedding dim 1, hidden size 8, num layers 1, train loss 0.8764621615409851, validation loss 0.8922571539878845\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8839761018753052, embedding dim 1, hidden size 8, num layers 1, train loss 0.7558897137641907, validation loss 0.8651299476623535\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8819103240966797, embedding dim 1, hidden size 8, num layers 1, train loss 0.7788714170455933, validation loss 0.8840650916099548\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8777440786361694, embedding dim 1, hidden size 8, num layers 1, train loss 0.7517035007476807, validation loss 0.8496764302253723\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8735443353652954, embedding dim 1, hidden size 8, num layers 1, train loss 0.7732424736022949, validation loss 0.853990375995636\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8707822561264038, embedding dim 1, hidden size 8, num layers 1, train loss 0.7923030853271484, validation loss 0.8709509372711182\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8716534376144409, embedding dim 1, hidden size 8, num layers 1, train loss 0.7151672840118408, validation loss 0.8731503486633301\n",
      "Epoch 660, current patience 29, model mean validation loss 0.8657110929489136, embedding dim 1, hidden size 8, num layers 1, train loss 0.8645437955856323, validation loss 0.8364686965942383\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8603058457374573, embedding dim 1, hidden size 8, num layers 1, train loss 0.7107813358306885, validation loss 0.849014937877655\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8588976860046387, embedding dim 1, hidden size 8, num layers 1, train loss 0.8045624494552612, validation loss 0.8538645505905151\n",
      "Epoch 690, current patience 30, model mean validation loss 0.855928361415863, embedding dim 1, hidden size 8, num layers 1, train loss 0.7202378511428833, validation loss 0.8603106737136841\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8574450016021729, embedding dim 1, hidden size 8, num layers 1, train loss 0.7130911350250244, validation loss 0.8618096113204956\n",
      "Epoch 710, current patience 29, model mean validation loss 0.8561681509017944, embedding dim 1, hidden size 8, num layers 1, train loss 0.73152095079422, validation loss 0.8437756299972534\n",
      "Epoch 720, current patience 28, model mean validation loss 0.8519994020462036, embedding dim 1, hidden size 8, num layers 1, train loss 0.6955043077468872, validation loss 0.8376010656356812\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8467382192611694, embedding dim 1, hidden size 8, num layers 1, train loss 0.7558580636978149, validation loss 0.831059992313385\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8472985625267029, embedding dim 1, hidden size 8, num layers 1, train loss 0.7544823884963989, validation loss 0.8409519195556641\n",
      "Epoch 750, current patience 29, model mean validation loss 0.8430327773094177, embedding dim 1, hidden size 8, num layers 1, train loss 0.7187093496322632, validation loss 0.814888596534729\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8395958542823792, embedding dim 1, hidden size 8, num layers 1, train loss 0.9271131157875061, validation loss 0.8263694643974304\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8330044746398926, embedding dim 1, hidden size 8, num layers 1, train loss 0.7454657554626465, validation loss 0.8075793385505676\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8282622694969177, embedding dim 1, hidden size 8, num layers 1, train loss 0.6670815944671631, validation loss 0.8238722085952759\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8245556950569153, embedding dim 1, hidden size 8, num layers 1, train loss 0.6710991859436035, validation loss 0.8141231536865234\n",
      "Epoch 800, current patience 30, model mean validation loss 0.8233057260513306, embedding dim 1, hidden size 8, num layers 1, train loss 0.6703894138336182, validation loss 0.8276015520095825\n",
      "Epoch 810, current patience 30, model mean validation loss 0.8224691152572632, embedding dim 1, hidden size 8, num layers 1, train loss 0.7760301828384399, validation loss 0.8243670463562012\n",
      "Epoch 820, current patience 30, model mean validation loss 0.8211852312088013, embedding dim 1, hidden size 8, num layers 1, train loss 0.7103200554847717, validation loss 0.8306801319122314\n",
      "Epoch 830, current patience 30, model mean validation loss 0.8247401714324951, embedding dim 1, hidden size 8, num layers 1, train loss 0.7558050155639648, validation loss 0.8433282971382141\n",
      "Epoch 840, current patience 29, model mean validation loss 0.8270180225372314, embedding dim 1, hidden size 8, num layers 1, train loss 0.7575210332870483, validation loss 0.8445928692817688\n",
      "Epoch 850, current patience 28, model mean validation loss 0.8313231468200684, embedding dim 1, hidden size 8, num layers 1, train loss 0.8226672410964966, validation loss 0.8420197367668152\n",
      "Epoch 860, current patience 27, model mean validation loss 0.8277884721755981, embedding dim 1, hidden size 8, num layers 1, train loss 0.6000380516052246, validation loss 0.7955949306488037\n",
      "Epoch 870, current patience 26, model mean validation loss 0.82879239320755, embedding dim 1, hidden size 8, num layers 1, train loss 0.6883068680763245, validation loss 0.822154700756073\n",
      "Epoch 880, current patience 25, model mean validation loss 0.8287240266799927, embedding dim 1, hidden size 8, num layers 1, train loss 0.6845775842666626, validation loss 0.8270543217658997\n",
      "Epoch 890, current patience 24, model mean validation loss 0.8276645541191101, embedding dim 1, hidden size 8, num layers 1, train loss 0.6138495802879333, validation loss 0.815891444683075\n",
      "Epoch 900, current patience 23, model mean validation loss 0.8234386444091797, embedding dim 1, hidden size 8, num layers 1, train loss 0.7833893299102783, validation loss 0.7968728542327881\n",
      "Epoch 910, current patience 22, model mean validation loss 0.8183368444442749, embedding dim 1, hidden size 8, num layers 1, train loss 0.6360039710998535, validation loss 0.8025137186050415\n",
      "Epoch 920, current patience 30, model mean validation loss 0.812150239944458, embedding dim 1, hidden size 8, num layers 1, train loss 0.6031076908111572, validation loss 0.7950998544692993\n",
      "Epoch 930, current patience 30, model mean validation loss 0.8087247610092163, embedding dim 1, hidden size 8, num layers 1, train loss 0.5702738165855408, validation loss 0.8146158456802368\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8095685243606567, embedding dim 1, hidden size 8, num layers 1, train loss 0.6752848029136658, validation loss 0.8023452758789062\n",
      "Epoch 950, current patience 29, model mean validation loss 0.8061505556106567, embedding dim 1, hidden size 8, num layers 1, train loss 0.5795817971229553, validation loss 0.7948108315467834\n",
      "Epoch 960, current patience 30, model mean validation loss 0.8023825883865356, embedding dim 1, hidden size 8, num layers 1, train loss 0.6758601069450378, validation loss 0.7969104051589966\n",
      "Epoch 970, current patience 30, model mean validation loss 0.8041090369224548, embedding dim 1, hidden size 8, num layers 1, train loss 0.7396398186683655, validation loss 0.8297032117843628\n",
      "Epoch 980, current patience 29, model mean validation loss 0.8026776313781738, embedding dim 1, hidden size 8, num layers 1, train loss 0.6436344385147095, validation loss 0.7854217886924744\n",
      "Epoch 990, current patience 28, model mean validation loss 0.8043731451034546, embedding dim 1, hidden size 8, num layers 1, train loss 0.631284773349762, validation loss 0.8160778880119324\n",
      "Epoch 1000, current patience 27, model mean validation loss 0.8034587502479553, embedding dim 1, hidden size 8, num layers 1, train loss 0.6101545095443726, validation loss 0.7877848148345947\n",
      "Epoch 1010, current patience 26, model mean validation loss 0.8050587177276611, embedding dim 1, hidden size 8, num layers 1, train loss 0.838148832321167, validation loss 0.8274157643318176\n",
      "Epoch 1020, current patience 25, model mean validation loss 0.8062940835952759, embedding dim 1, hidden size 8, num layers 1, train loss 0.6516268253326416, validation loss 0.8122274875640869\n",
      "Epoch 1030, current patience 24, model mean validation loss 0.809152364730835, embedding dim 1, hidden size 8, num layers 1, train loss 0.586062490940094, validation loss 0.8176776766777039\n",
      "Epoch 1040, current patience 23, model mean validation loss 0.8078925609588623, embedding dim 1, hidden size 8, num layers 1, train loss 0.6695273518562317, validation loss 0.7868313789367676\n",
      "Epoch 1050, current patience 22, model mean validation loss 0.8040454387664795, embedding dim 1, hidden size 8, num layers 1, train loss 0.727484941482544, validation loss 0.7989273071289062\n",
      "Epoch 1060, current patience 21, model mean validation loss 0.8063563108444214, embedding dim 1, hidden size 8, num layers 1, train loss 0.6674107313156128, validation loss 0.8039083480834961\n",
      "Epoch 1070, current patience 20, model mean validation loss 0.8031793832778931, embedding dim 1, hidden size 8, num layers 1, train loss 0.692966103553772, validation loss 0.790662407875061\n",
      "Epoch 1080, current patience 19, model mean validation loss 0.8001981973648071, embedding dim 1, hidden size 8, num layers 1, train loss 0.7579008936882019, validation loss 0.7639358043670654\n",
      "Epoch 1090, current patience 30, model mean validation loss 0.8007007837295532, embedding dim 1, hidden size 8, num layers 1, train loss 0.4946298599243164, validation loss 0.8314359188079834\n",
      "Epoch 1100, current patience 29, model mean validation loss 0.8017104864120483, embedding dim 1, hidden size 8, num layers 1, train loss 0.5367285013198853, validation loss 0.8203046321868896\n",
      "Epoch 1110, current patience 28, model mean validation loss 0.7964460253715515, embedding dim 1, hidden size 8, num layers 1, train loss 0.5815309286117554, validation loss 0.7755622267723083\n",
      "Epoch 1120, current patience 30, model mean validation loss 0.7988702654838562, embedding dim 1, hidden size 8, num layers 1, train loss 0.6525126695632935, validation loss 0.8062256574630737\n",
      "Epoch 1130, current patience 29, model mean validation loss 0.804722011089325, embedding dim 1, hidden size 8, num layers 1, train loss 0.518986701965332, validation loss 0.8457410335540771\n",
      "Epoch 1140, current patience 28, model mean validation loss 0.8010480403900146, embedding dim 1, hidden size 8, num layers 1, train loss 0.6683054566383362, validation loss 0.7745168805122375\n",
      "Epoch 1150, current patience 27, model mean validation loss 0.8000742197036743, embedding dim 1, hidden size 8, num layers 1, train loss 0.5852898955345154, validation loss 0.7828717231750488\n",
      "Epoch 1160, current patience 26, model mean validation loss 0.8050728440284729, embedding dim 1, hidden size 8, num layers 1, train loss 0.6223114132881165, validation loss 0.8039246797561646\n",
      "Epoch 1170, current patience 25, model mean validation loss 0.7975746989250183, embedding dim 1, hidden size 8, num layers 1, train loss 0.5912749767303467, validation loss 0.7714507579803467\n",
      "Epoch 1180, current patience 24, model mean validation loss 0.7927953004837036, embedding dim 1, hidden size 8, num layers 1, train loss 0.5981135368347168, validation loss 0.782069206237793\n",
      "Epoch 1190, current patience 30, model mean validation loss 0.7988631725311279, embedding dim 1, hidden size 8, num layers 1, train loss 0.5373944044113159, validation loss 0.8241055607795715\n",
      "Epoch 1200, current patience 29, model mean validation loss 0.7995597124099731, embedding dim 1, hidden size 8, num layers 1, train loss 0.5943273901939392, validation loss 0.8117979168891907\n",
      "Epoch 1210, current patience 28, model mean validation loss 0.7944849729537964, embedding dim 1, hidden size 8, num layers 1, train loss 0.5756515264511108, validation loss 0.8051433563232422\n",
      "Epoch 1220, current patience 27, model mean validation loss 0.7981552481651306, embedding dim 1, hidden size 8, num layers 1, train loss 0.6677299737930298, validation loss 0.803878664970398\n",
      "Epoch 1230, current patience 26, model mean validation loss 0.8008917570114136, embedding dim 1, hidden size 8, num layers 1, train loss 0.6549724340438843, validation loss 0.8047640919685364\n",
      "Epoch 1240, current patience 25, model mean validation loss 0.7984878420829773, embedding dim 1, hidden size 8, num layers 1, train loss 0.5963767170906067, validation loss 0.7846934795379639\n",
      "Epoch 1250, current patience 24, model mean validation loss 0.7985167503356934, embedding dim 1, hidden size 8, num layers 1, train loss 0.5112460851669312, validation loss 0.77168208360672\n",
      "Epoch 1260, current patience 23, model mean validation loss 0.7991768717765808, embedding dim 1, hidden size 8, num layers 1, train loss 0.49117404222488403, validation loss 0.7873501777648926\n",
      "Epoch 1270, current patience 22, model mean validation loss 0.7982138395309448, embedding dim 1, hidden size 8, num layers 1, train loss 0.6385046243667603, validation loss 0.8164008855819702\n",
      "Epoch 1280, current patience 21, model mean validation loss 0.7918225526809692, embedding dim 1, hidden size 8, num layers 1, train loss 0.5726749897003174, validation loss 0.7606679201126099\n",
      "Epoch 1290, current patience 30, model mean validation loss 0.7915924787521362, embedding dim 1, hidden size 8, num layers 1, train loss 0.6245368123054504, validation loss 0.8033021688461304\n",
      "Epoch 1300, current patience 30, model mean validation loss 0.7868034839630127, embedding dim 1, hidden size 8, num layers 1, train loss 0.5947153568267822, validation loss 0.7655675411224365\n",
      "Epoch 1310, current patience 30, model mean validation loss 0.7864099740982056, embedding dim 1, hidden size 8, num layers 1, train loss 0.5163582563400269, validation loss 0.8016154766082764\n",
      "Epoch 1320, current patience 30, model mean validation loss 0.7857608795166016, embedding dim 1, hidden size 8, num layers 1, train loss 0.5864667892456055, validation loss 0.7795009613037109\n",
      "Epoch 1330, current patience 30, model mean validation loss 0.7901920676231384, embedding dim 1, hidden size 8, num layers 1, train loss 0.7732329368591309, validation loss 0.8071315288543701\n",
      "Epoch 1340, current patience 29, model mean validation loss 0.7967711687088013, embedding dim 1, hidden size 8, num layers 1, train loss 0.669898509979248, validation loss 0.8399825692176819\n",
      "Epoch 1350, current patience 28, model mean validation loss 0.7928593754768372, embedding dim 1, hidden size 8, num layers 1, train loss 0.4884146451950073, validation loss 0.785106897354126\n",
      "Epoch 1360, current patience 27, model mean validation loss 0.7968629598617554, embedding dim 1, hidden size 8, num layers 1, train loss 0.6190328001976013, validation loss 0.7926965951919556\n",
      "Epoch 1370, current patience 26, model mean validation loss 0.7963923215866089, embedding dim 1, hidden size 8, num layers 1, train loss 0.7364102005958557, validation loss 0.799536943435669\n",
      "Epoch 1380, current patience 25, model mean validation loss 0.8005954623222351, embedding dim 1, hidden size 8, num layers 1, train loss 0.6273760795593262, validation loss 0.7991927862167358\n",
      "Epoch 1390, current patience 24, model mean validation loss 0.7998085021972656, embedding dim 1, hidden size 8, num layers 1, train loss 0.7289671301841736, validation loss 0.7953194975852966\n",
      "Epoch 1400, current patience 23, model mean validation loss 0.8023818731307983, embedding dim 1, hidden size 8, num layers 1, train loss 0.6688773036003113, validation loss 0.8000883460044861\n",
      "Epoch 1410, current patience 22, model mean validation loss 0.8024301528930664, embedding dim 1, hidden size 8, num layers 1, train loss 0.5020219087600708, validation loss 0.8075180053710938\n",
      "Epoch 1420, current patience 21, model mean validation loss 0.7963170409202576, embedding dim 1, hidden size 8, num layers 1, train loss 0.7263987064361572, validation loss 0.7910773754119873\n",
      "Epoch 1430, current patience 20, model mean validation loss 0.7957394123077393, embedding dim 1, hidden size 8, num layers 1, train loss 0.5215352177619934, validation loss 0.7804855704307556\n",
      "Epoch 1440, current patience 19, model mean validation loss 0.7979424595832825, embedding dim 1, hidden size 8, num layers 1, train loss 0.5789286494255066, validation loss 0.8103209733963013\n",
      "Epoch 1450, current patience 18, model mean validation loss 0.7962266802787781, embedding dim 1, hidden size 8, num layers 1, train loss 0.6849974393844604, validation loss 0.7858110666275024\n",
      "Epoch 1460, current patience 17, model mean validation loss 0.7962901592254639, embedding dim 1, hidden size 8, num layers 1, train loss 0.4595280587673187, validation loss 0.7997007369995117\n",
      "Epoch 1470, current patience 16, model mean validation loss 0.7988730669021606, embedding dim 1, hidden size 8, num layers 1, train loss 0.4411504566669464, validation loss 0.8159825205802917\n",
      "Epoch 1480, current patience 15, model mean validation loss 0.7990380525588989, embedding dim 1, hidden size 8, num layers 1, train loss 0.5164370536804199, validation loss 0.8014081716537476\n",
      "Epoch 1490, current patience 14, model mean validation loss 0.7989922761917114, embedding dim 1, hidden size 8, num layers 1, train loss 0.46066898107528687, validation loss 0.8071518540382385\n",
      "Epoch 1500, current patience 13, model mean validation loss 0.8011664152145386, embedding dim 1, hidden size 8, num layers 1, train loss 0.5576455593109131, validation loss 0.8084706664085388\n",
      "Epoch 1510, current patience 12, model mean validation loss 0.8072673678398132, embedding dim 1, hidden size 8, num layers 1, train loss 0.6485942602157593, validation loss 0.8292930126190186\n",
      "Epoch 1520, current patience 11, model mean validation loss 0.804595947265625, embedding dim 1, hidden size 8, num layers 1, train loss 0.41425731778144836, validation loss 0.7889496088027954\n",
      "Epoch 1530, current patience 10, model mean validation loss 0.8129662871360779, embedding dim 1, hidden size 8, num layers 1, train loss 0.7448363304138184, validation loss 0.8527736663818359\n",
      "Epoch 1540, current patience 9, model mean validation loss 0.8106157779693604, embedding dim 1, hidden size 8, num layers 1, train loss 0.6062685251235962, validation loss 0.7808965444564819\n",
      "Epoch 1550, current patience 8, model mean validation loss 0.8107441663742065, embedding dim 1, hidden size 8, num layers 1, train loss 0.6129839420318604, validation loss 0.8170099258422852\n",
      "Epoch 1560, current patience 7, model mean validation loss 0.8118814826011658, embedding dim 1, hidden size 8, num layers 1, train loss 0.808197557926178, validation loss 0.8105067014694214\n",
      "Epoch 1570, current patience 6, model mean validation loss 0.8118644952774048, embedding dim 1, hidden size 8, num layers 1, train loss 0.5350927710533142, validation loss 0.8070157766342163\n",
      "Epoch 1580, current patience 5, model mean validation loss 0.8124978542327881, embedding dim 1, hidden size 8, num layers 1, train loss 0.5140787363052368, validation loss 0.8135375380516052\n",
      "Epoch 1590, current patience 4, model mean validation loss 0.811392605304718, embedding dim 1, hidden size 8, num layers 1, train loss 0.5037302374839783, validation loss 0.8204513192176819\n",
      "Epoch 1600, current patience 3, model mean validation loss 0.8145025372505188, embedding dim 1, hidden size 8, num layers 1, train loss 0.49822425842285156, validation loss 0.8138289451599121\n",
      "Epoch 1610, current patience 2, model mean validation loss 0.8112402558326721, embedding dim 1, hidden size 8, num layers 1, train loss 0.5214706659317017, validation loss 0.8266754150390625\n",
      "Epoch 1620, current patience 1, model mean validation loss 0.8145954012870789, embedding dim 1, hidden size 8, num layers 1, train loss 0.5227150917053223, validation loss 0.8077372908592224\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1292765140533447, embedding dim 1, hidden size 16, num layers 1, train loss 1.087559700012207, validation loss 1.1292765140533447\n",
      "Epoch 10, current patience 30, model mean validation loss 1.113508701324463, embedding dim 1, hidden size 16, num layers 1, train loss 1.1072109937667847, validation loss 1.097740888595581\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1080001592636108, embedding dim 1, hidden size 16, num layers 1, train loss 1.1056767702102661, validation loss 1.0969831943511963\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1057205200195312, embedding dim 1, hidden size 16, num layers 1, train loss 1.096421718597412, validation loss 1.098881721496582\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1030724048614502, embedding dim 1, hidden size 16, num layers 1, train loss 1.0865130424499512, validation loss 1.0924795866012573\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1016188859939575, embedding dim 1, hidden size 16, num layers 1, train loss 1.0939412117004395, validation loss 1.0943516492843628\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1008838415145874, embedding dim 1, hidden size 16, num layers 1, train loss 1.089876413345337, validation loss 1.096474051475525\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1000950336456299, embedding dim 1, hidden size 16, num layers 1, train loss 1.1094439029693604, validation loss 1.0945725440979004\n",
      "Epoch 80, current patience 30, model mean validation loss 1.095935583114624, embedding dim 1, hidden size 16, num layers 1, train loss 1.097607970237732, validation loss 1.096001148223877\n",
      "Epoch 90, current patience 30, model mean validation loss 1.095668911933899, embedding dim 1, hidden size 16, num layers 1, train loss 1.1050209999084473, validation loss 1.0956073999404907\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0948575735092163, embedding dim 1, hidden size 16, num layers 1, train loss 1.0918461084365845, validation loss 1.0904924869537354\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0942189693450928, embedding dim 1, hidden size 16, num layers 1, train loss 1.0925060510635376, validation loss 1.0937728881835938\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0944151878356934, embedding dim 1, hidden size 16, num layers 1, train loss 1.0933620929718018, validation loss 1.0940494537353516\n",
      "Epoch 130, current patience 29, model mean validation loss 1.094582200050354, embedding dim 1, hidden size 16, num layers 1, train loss 1.0971999168395996, validation loss 1.095687747001648\n",
      "Epoch 140, current patience 28, model mean validation loss 1.0942318439483643, embedding dim 1, hidden size 16, num layers 1, train loss 1.1098637580871582, validation loss 1.0936709642410278\n",
      "Epoch 150, current patience 27, model mean validation loss 1.0940426588058472, embedding dim 1, hidden size 16, num layers 1, train loss 1.0978131294250488, validation loss 1.0930590629577637\n",
      "Epoch 160, current patience 30, model mean validation loss 1.093792200088501, embedding dim 1, hidden size 16, num layers 1, train loss 1.0881624221801758, validation loss 1.0939973592758179\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0932104587554932, embedding dim 1, hidden size 16, num layers 1, train loss 1.0908045768737793, validation loss 1.0909528732299805\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0934648513793945, embedding dim 1, hidden size 16, num layers 1, train loss 1.0727421045303345, validation loss 1.0925287008285522\n",
      "Epoch 190, current patience 29, model mean validation loss 1.0920082330703735, embedding dim 1, hidden size 16, num layers 1, train loss 1.0577589273452759, validation loss 1.0821197032928467\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0920544862747192, embedding dim 1, hidden size 16, num layers 1, train loss 1.06878662109375, validation loss 1.094419002532959\n",
      "Epoch 210, current patience 29, model mean validation loss 1.09059739112854, embedding dim 1, hidden size 16, num layers 1, train loss 1.0392472743988037, validation loss 1.0840314626693726\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0880141258239746, embedding dim 1, hidden size 16, num layers 1, train loss 1.0693413019180298, validation loss 1.0730047225952148\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0833572149276733, embedding dim 1, hidden size 16, num layers 1, train loss 1.0681560039520264, validation loss 1.0558032989501953\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0782051086425781, embedding dim 1, hidden size 16, num layers 1, train loss 1.0628342628479004, validation loss 1.0527803897857666\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0728635787963867, embedding dim 1, hidden size 16, num layers 1, train loss 1.047296166419983, validation loss 1.0482208728790283\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0663788318634033, embedding dim 1, hidden size 16, num layers 1, train loss 0.9821737408638, validation loss 1.0406513214111328\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0601826906204224, embedding dim 1, hidden size 16, num layers 1, train loss 1.0030028820037842, validation loss 1.032550573348999\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0508947372436523, embedding dim 1, hidden size 16, num layers 1, train loss 1.0132609605789185, validation loss 1.0201154947280884\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0435328483581543, embedding dim 1, hidden size 16, num layers 1, train loss 1.0364869832992554, validation loss 1.0251359939575195\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0361781120300293, embedding dim 1, hidden size 16, num layers 1, train loss 0.9975070357322693, validation loss 1.014166235923767\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0311174392700195, embedding dim 1, hidden size 16, num layers 1, train loss 1.000086784362793, validation loss 1.0153181552886963\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0237170457839966, embedding dim 1, hidden size 16, num layers 1, train loss 0.9537925124168396, validation loss 0.9935775995254517\n",
      "Epoch 330, current patience 30, model mean validation loss 1.017892837524414, embedding dim 1, hidden size 16, num layers 1, train loss 0.9729999303817749, validation loss 1.0016264915466309\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0115376710891724, embedding dim 1, hidden size 16, num layers 1, train loss 0.9450273513793945, validation loss 0.9898111820220947\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0059140920639038, embedding dim 1, hidden size 16, num layers 1, train loss 0.8897598385810852, validation loss 0.9875613451004028\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0005691051483154, embedding dim 1, hidden size 16, num layers 1, train loss 0.8589443564414978, validation loss 0.9773555994033813\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9943903684616089, embedding dim 1, hidden size 16, num layers 1, train loss 1.082486629486084, validation loss 0.9757068157196045\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9890916347503662, embedding dim 1, hidden size 16, num layers 1, train loss 0.9553704261779785, validation loss 0.971775472164154\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9845614433288574, embedding dim 1, hidden size 16, num layers 1, train loss 0.8660282492637634, validation loss 0.9790769815444946\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9776412844657898, embedding dim 1, hidden size 16, num layers 1, train loss 0.8384393453598022, validation loss 0.9382162094116211\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9735029935836792, embedding dim 1, hidden size 16, num layers 1, train loss 0.9461573362350464, validation loss 0.9685204029083252\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9701929688453674, embedding dim 1, hidden size 16, num layers 1, train loss 0.8320049047470093, validation loss 0.963330864906311\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9648010730743408, embedding dim 1, hidden size 16, num layers 1, train loss 0.8503382205963135, validation loss 0.9444261789321899\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9596003890037537, embedding dim 1, hidden size 16, num layers 1, train loss 1.0078628063201904, validation loss 0.9357504844665527\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9499924182891846, embedding dim 1, hidden size 16, num layers 1, train loss 0.9251445531845093, validation loss 0.8988426923751831\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9410638809204102, embedding dim 1, hidden size 16, num layers 1, train loss 0.9123141765594482, validation loss 0.900347113609314\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9329662919044495, embedding dim 1, hidden size 16, num layers 1, train loss 0.7584713101387024, validation loss 0.9142966270446777\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9268457293510437, embedding dim 1, hidden size 16, num layers 1, train loss 0.902820885181427, validation loss 0.8892516493797302\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9188859462738037, embedding dim 1, hidden size 16, num layers 1, train loss 0.9727434515953064, validation loss 0.9048418998718262\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9097675085067749, embedding dim 1, hidden size 16, num layers 1, train loss 0.8946174383163452, validation loss 0.890383243560791\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9042046666145325, embedding dim 1, hidden size 16, num layers 1, train loss 0.8967819213867188, validation loss 0.8999232649803162\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8953729271888733, embedding dim 1, hidden size 16, num layers 1, train loss 0.8944317102432251, validation loss 0.8650965094566345\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8917686939239502, embedding dim 1, hidden size 16, num layers 1, train loss 0.8876868486404419, validation loss 0.8700090646743774\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8901537656784058, embedding dim 1, hidden size 16, num layers 1, train loss 0.7635412812232971, validation loss 0.8874277472496033\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8817957639694214, embedding dim 1, hidden size 16, num layers 1, train loss 0.761683464050293, validation loss 0.8474328517913818\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8775012493133545, embedding dim 1, hidden size 16, num layers 1, train loss 0.781420111656189, validation loss 0.8548949956893921\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8706908822059631, embedding dim 1, hidden size 16, num layers 1, train loss 0.880409300327301, validation loss 0.8503592014312744\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8632810115814209, embedding dim 1, hidden size 16, num layers 1, train loss 0.7874056100845337, validation loss 0.8311046361923218\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8578038215637207, embedding dim 1, hidden size 16, num layers 1, train loss 0.7227864265441895, validation loss 0.8561057448387146\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8551700115203857, embedding dim 1, hidden size 16, num layers 1, train loss 0.7362565994262695, validation loss 0.8440260887145996\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8540910482406616, embedding dim 1, hidden size 16, num layers 1, train loss 0.7810612916946411, validation loss 0.8613767623901367\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8495944142341614, embedding dim 1, hidden size 16, num layers 1, train loss 0.8548524975776672, validation loss 0.8514548540115356\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8471764922142029, embedding dim 1, hidden size 16, num layers 1, train loss 0.8170503377914429, validation loss 0.8280897736549377\n",
      "Epoch 640, current patience 30, model mean validation loss 0.847895622253418, embedding dim 1, hidden size 16, num layers 1, train loss 0.802791953086853, validation loss 0.8606475591659546\n",
      "Epoch 650, current patience 29, model mean validation loss 0.8453850746154785, embedding dim 1, hidden size 16, num layers 1, train loss 0.8439000844955444, validation loss 0.8302751183509827\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8452507853507996, embedding dim 1, hidden size 16, num layers 1, train loss 0.7390854954719543, validation loss 0.8300302028656006\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8412743806838989, embedding dim 1, hidden size 16, num layers 1, train loss 0.8140394687652588, validation loss 0.8242946863174438\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8403012752532959, embedding dim 1, hidden size 16, num layers 1, train loss 0.8195056915283203, validation loss 0.8362411856651306\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8333532810211182, embedding dim 1, hidden size 16, num layers 1, train loss 0.6958035230636597, validation loss 0.805793046951294\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8292953968048096, embedding dim 1, hidden size 16, num layers 1, train loss 0.7609310746192932, validation loss 0.8189916014671326\n",
      "Epoch 710, current patience 30, model mean validation loss 0.825081467628479, embedding dim 1, hidden size 16, num layers 1, train loss 0.6685208082199097, validation loss 0.7943786382675171\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8151658773422241, embedding dim 1, hidden size 16, num layers 1, train loss 0.6742890477180481, validation loss 0.7813225984573364\n",
      "Epoch 730, current patience 30, model mean validation loss 0.813259482383728, embedding dim 1, hidden size 16, num layers 1, train loss 0.636633038520813, validation loss 0.8150238990783691\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8111977577209473, embedding dim 1, hidden size 16, num layers 1, train loss 0.8023160099983215, validation loss 0.813536524772644\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8104853630065918, embedding dim 1, hidden size 16, num layers 1, train loss 0.7665475606918335, validation loss 0.818595290184021\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8058569431304932, embedding dim 1, hidden size 16, num layers 1, train loss 0.7674537897109985, validation loss 0.7992139458656311\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8029369711875916, embedding dim 1, hidden size 16, num layers 1, train loss 0.7206586003303528, validation loss 0.7824333906173706\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8012229204177856, embedding dim 1, hidden size 16, num layers 1, train loss 0.679678201675415, validation loss 0.8052791357040405\n",
      "Epoch 790, current patience 30, model mean validation loss 0.803443193435669, embedding dim 1, hidden size 16, num layers 1, train loss 0.6276270747184753, validation loss 0.8121411800384521\n",
      "Epoch 800, current patience 29, model mean validation loss 0.803783118724823, embedding dim 1, hidden size 16, num layers 1, train loss 0.7524359226226807, validation loss 0.7840418815612793\n",
      "Epoch 810, current patience 28, model mean validation loss 0.8010134696960449, embedding dim 1, hidden size 16, num layers 1, train loss 0.65772545337677, validation loss 0.7928664088249207\n",
      "Epoch 820, current patience 30, model mean validation loss 0.8008445501327515, embedding dim 1, hidden size 16, num layers 1, train loss 0.8590295910835266, validation loss 0.8121852874755859\n",
      "Epoch 830, current patience 30, model mean validation loss 0.7971770763397217, embedding dim 1, hidden size 16, num layers 1, train loss 0.7173705101013184, validation loss 0.7892553806304932\n",
      "Epoch 840, current patience 30, model mean validation loss 0.7977510690689087, embedding dim 1, hidden size 16, num layers 1, train loss 0.615610659122467, validation loss 0.8038060069084167\n",
      "Epoch 850, current patience 29, model mean validation loss 0.800165057182312, embedding dim 1, hidden size 16, num layers 1, train loss 0.7578054070472717, validation loss 0.8017450571060181\n",
      "Epoch 860, current patience 28, model mean validation loss 0.7958839535713196, embedding dim 1, hidden size 16, num layers 1, train loss 0.6433098316192627, validation loss 0.7710304260253906\n",
      "Epoch 870, current patience 30, model mean validation loss 0.7944597005844116, embedding dim 1, hidden size 16, num layers 1, train loss 0.7643844485282898, validation loss 0.8007472157478333\n",
      "Epoch 880, current patience 30, model mean validation loss 0.7932838201522827, embedding dim 1, hidden size 16, num layers 1, train loss 0.6497026681900024, validation loss 0.774634838104248\n",
      "Epoch 890, current patience 30, model mean validation loss 0.7925761938095093, embedding dim 1, hidden size 16, num layers 1, train loss 0.8077574968338013, validation loss 0.7872053980827332\n",
      "Epoch 900, current patience 30, model mean validation loss 0.7938072681427002, embedding dim 1, hidden size 16, num layers 1, train loss 0.7492478489875793, validation loss 0.8220337629318237\n",
      "Epoch 910, current patience 29, model mean validation loss 0.7968574166297913, embedding dim 1, hidden size 16, num layers 1, train loss 0.7322626113891602, validation loss 0.8136564493179321\n",
      "Epoch 920, current patience 28, model mean validation loss 0.7952722311019897, embedding dim 1, hidden size 16, num layers 1, train loss 0.7265233397483826, validation loss 0.7911245822906494\n",
      "Epoch 930, current patience 27, model mean validation loss 0.7931185364723206, embedding dim 1, hidden size 16, num layers 1, train loss 0.6499246954917908, validation loss 0.7845152616500854\n",
      "Epoch 940, current patience 26, model mean validation loss 0.7976623773574829, embedding dim 1, hidden size 16, num layers 1, train loss 0.7865685224533081, validation loss 0.8073818683624268\n",
      "Epoch 950, current patience 25, model mean validation loss 0.7922643423080444, embedding dim 1, hidden size 16, num layers 1, train loss 0.6662421226501465, validation loss 0.7575626969337463\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7575626969337463_1_16_1_950.pt\n",
      "Epoch 960, current patience 30, model mean validation loss 0.7905402779579163, embedding dim 1, hidden size 16, num layers 1, train loss 0.6638383865356445, validation loss 0.7608425617218018\n",
      "Epoch 970, current patience 30, model mean validation loss 0.7917132377624512, embedding dim 1, hidden size 16, num layers 1, train loss 0.6999454498291016, validation loss 0.796588659286499\n",
      "Epoch 980, current patience 29, model mean validation loss 0.7906169295310974, embedding dim 1, hidden size 16, num layers 1, train loss 0.8126600980758667, validation loss 0.8132630586624146\n",
      "Epoch 990, current patience 28, model mean validation loss 0.7843328714370728, embedding dim 1, hidden size 16, num layers 1, train loss 0.6969006657600403, validation loss 0.7633840441703796\n",
      "Epoch 1000, current patience 30, model mean validation loss 0.7833977937698364, embedding dim 1, hidden size 16, num layers 1, train loss 0.5823249816894531, validation loss 0.7836441397666931\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.7855373620986938, embedding dim 1, hidden size 16, num layers 1, train loss 0.541991651058197, validation loss 0.8016323447227478\n",
      "Epoch 1020, current patience 29, model mean validation loss 0.7775335311889648, embedding dim 1, hidden size 16, num layers 1, train loss 0.6350374221801758, validation loss 0.7433508634567261\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7433508634567261_1_16_1_1020.pt\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.7797344923019409, embedding dim 1, hidden size 16, num layers 1, train loss 0.7024402618408203, validation loss 0.775169849395752\n",
      "Epoch 1040, current patience 29, model mean validation loss 0.7844064235687256, embedding dim 1, hidden size 16, num layers 1, train loss 0.5595746040344238, validation loss 0.7982185482978821\n",
      "Epoch 1050, current patience 28, model mean validation loss 0.779630184173584, embedding dim 1, hidden size 16, num layers 1, train loss 0.5706336498260498, validation loss 0.7583785057067871\n",
      "Epoch 1060, current patience 27, model mean validation loss 0.7732223272323608, embedding dim 1, hidden size 16, num layers 1, train loss 0.6165012121200562, validation loss 0.762000322341919\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.7753598093986511, embedding dim 1, hidden size 16, num layers 1, train loss 0.5676080584526062, validation loss 0.7804836630821228\n",
      "Epoch 1080, current patience 29, model mean validation loss 0.7741154432296753, embedding dim 1, hidden size 16, num layers 1, train loss 0.6455439329147339, validation loss 0.7736893892288208\n",
      "Epoch 1090, current patience 28, model mean validation loss 0.7672367095947266, embedding dim 1, hidden size 16, num layers 1, train loss 0.8001381158828735, validation loss 0.7466024160385132\n",
      "Epoch 1100, current patience 30, model mean validation loss 0.7733954191207886, embedding dim 1, hidden size 16, num layers 1, train loss 0.5545892119407654, validation loss 0.7926203012466431\n",
      "Epoch 1110, current patience 29, model mean validation loss 0.774793803691864, embedding dim 1, hidden size 16, num layers 1, train loss 0.5705869793891907, validation loss 0.7863568663597107\n",
      "Epoch 1120, current patience 28, model mean validation loss 0.7699052095413208, embedding dim 1, hidden size 16, num layers 1, train loss 0.5010665655136108, validation loss 0.7591103315353394\n",
      "Epoch 1130, current patience 27, model mean validation loss 0.7708882093429565, embedding dim 1, hidden size 16, num layers 1, train loss 0.678540825843811, validation loss 0.7662428617477417\n",
      "Epoch 1140, current patience 26, model mean validation loss 0.7747771143913269, embedding dim 1, hidden size 16, num layers 1, train loss 0.6144192218780518, validation loss 0.7931108474731445\n",
      "Epoch 1150, current patience 25, model mean validation loss 0.770900309085846, embedding dim 1, hidden size 16, num layers 1, train loss 0.7778568267822266, validation loss 0.7494692802429199\n",
      "Epoch 1160, current patience 24, model mean validation loss 0.7686278223991394, embedding dim 1, hidden size 16, num layers 1, train loss 0.47407057881355286, validation loss 0.7555093765258789\n",
      "Epoch 1170, current patience 23, model mean validation loss 0.7766579389572144, embedding dim 1, hidden size 16, num layers 1, train loss 0.6896435022354126, validation loss 0.8108437061309814\n",
      "Epoch 1180, current patience 22, model mean validation loss 0.7765555381774902, embedding dim 1, hidden size 16, num layers 1, train loss 0.8083201050758362, validation loss 0.7918007373809814\n",
      "Epoch 1190, current patience 21, model mean validation loss 0.7762545347213745, embedding dim 1, hidden size 16, num layers 1, train loss 0.647167444229126, validation loss 0.7839492559432983\n",
      "Epoch 1200, current patience 20, model mean validation loss 0.7768043279647827, embedding dim 1, hidden size 16, num layers 1, train loss 0.5125394463539124, validation loss 0.7635080814361572\n",
      "Epoch 1210, current patience 19, model mean validation loss 0.778424859046936, embedding dim 1, hidden size 16, num layers 1, train loss 0.4238724410533905, validation loss 0.779208242893219\n",
      "Epoch 1220, current patience 18, model mean validation loss 0.7783352136611938, embedding dim 1, hidden size 16, num layers 1, train loss 0.627066433429718, validation loss 0.7923935651779175\n",
      "Epoch 1230, current patience 17, model mean validation loss 0.7883822917938232, embedding dim 1, hidden size 16, num layers 1, train loss 0.6158975958824158, validation loss 0.8298455476760864\n",
      "Epoch 1240, current patience 16, model mean validation loss 0.7911614179611206, embedding dim 1, hidden size 16, num layers 1, train loss 0.4943763017654419, validation loss 0.7777424454689026\n",
      "Epoch 1250, current patience 15, model mean validation loss 0.7887372970581055, embedding dim 1, hidden size 16, num layers 1, train loss 0.5730419158935547, validation loss 0.7914504408836365\n",
      "Epoch 1260, current patience 14, model mean validation loss 0.7830477952957153, embedding dim 1, hidden size 16, num layers 1, train loss 0.6736910939216614, validation loss 0.7462847232818604\n",
      "Epoch 1270, current patience 13, model mean validation loss 0.7836623191833496, embedding dim 1, hidden size 16, num layers 1, train loss 0.5531245470046997, validation loss 0.788865327835083\n",
      "Epoch 1280, current patience 12, model mean validation loss 0.7887606024742126, embedding dim 1, hidden size 16, num layers 1, train loss 0.6551341414451599, validation loss 0.8042945861816406\n",
      "Epoch 1290, current patience 11, model mean validation loss 0.7908511161804199, embedding dim 1, hidden size 16, num layers 1, train loss 0.5146632194519043, validation loss 0.7959321737289429\n",
      "Epoch 1300, current patience 10, model mean validation loss 0.7901711463928223, embedding dim 1, hidden size 16, num layers 1, train loss 0.6348466277122498, validation loss 0.7869534492492676\n",
      "Epoch 1310, current patience 9, model mean validation loss 0.7847607731819153, embedding dim 1, hidden size 16, num layers 1, train loss 0.6074933409690857, validation loss 0.7865631580352783\n",
      "Epoch 1320, current patience 8, model mean validation loss 0.7835288643836975, embedding dim 1, hidden size 16, num layers 1, train loss 0.524333119392395, validation loss 0.7678871154785156\n",
      "Epoch 1330, current patience 7, model mean validation loss 0.7821350693702698, embedding dim 1, hidden size 16, num layers 1, train loss 0.5617942214012146, validation loss 0.7803003787994385\n",
      "Epoch 1340, current patience 6, model mean validation loss 0.7854177951812744, embedding dim 1, hidden size 16, num layers 1, train loss 0.6085848808288574, validation loss 0.7725463509559631\n",
      "Epoch 1350, current patience 5, model mean validation loss 0.7879663705825806, embedding dim 1, hidden size 16, num layers 1, train loss 0.5167111754417419, validation loss 0.8092538118362427\n",
      "Epoch 1360, current patience 4, model mean validation loss 0.788623571395874, embedding dim 1, hidden size 16, num layers 1, train loss 0.4393278956413269, validation loss 0.8095521926879883\n",
      "Epoch 1370, current patience 3, model mean validation loss 0.7904210686683655, embedding dim 1, hidden size 16, num layers 1, train loss 0.6215232610702515, validation loss 0.8103119730949402\n",
      "Epoch 1380, current patience 2, model mean validation loss 0.7927189469337463, embedding dim 1, hidden size 16, num layers 1, train loss 0.5879402160644531, validation loss 0.8053364753723145\n",
      "Epoch 1390, current patience 1, model mean validation loss 0.7949368953704834, embedding dim 1, hidden size 16, num layers 1, train loss 0.6080400943756104, validation loss 0.8043068051338196\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0966213941574097, embedding dim 1, hidden size 32, num layers 1, train loss 1.103528380393982, validation loss 1.0966213941574097\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0927706956863403, embedding dim 1, hidden size 32, num layers 1, train loss 1.1035997867584229, validation loss 1.088919997215271\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0939146280288696, embedding dim 1, hidden size 32, num layers 1, train loss 1.0948655605316162, validation loss 1.0962027311325073\n",
      "Epoch 30, current patience 29, model mean validation loss 1.0940601825714111, embedding dim 1, hidden size 32, num layers 1, train loss 1.0911941528320312, validation loss 1.094496726989746\n",
      "Epoch 40, current patience 28, model mean validation loss 1.0942533016204834, embedding dim 1, hidden size 32, num layers 1, train loss 1.0954759120941162, validation loss 1.0950255393981934\n",
      "Epoch 50, current patience 27, model mean validation loss 1.0939873456954956, embedding dim 1, hidden size 32, num layers 1, train loss 1.1131961345672607, validation loss 1.092657446861267\n",
      "Epoch 60, current patience 26, model mean validation loss 1.093839406967163, embedding dim 1, hidden size 32, num layers 1, train loss 1.094437837600708, validation loss 1.092952013015747\n",
      "Epoch 70, current patience 25, model mean validation loss 1.0939993858337402, embedding dim 1, hidden size 32, num layers 1, train loss 1.0935373306274414, validation loss 1.0951197147369385\n",
      "Epoch 80, current patience 24, model mean validation loss 1.0934689044952393, embedding dim 1, hidden size 32, num layers 1, train loss 1.0831120014190674, validation loss 1.092377781867981\n",
      "Epoch 90, current patience 23, model mean validation loss 1.094698190689087, embedding dim 1, hidden size 32, num layers 1, train loss 1.1056112051010132, validation loss 1.0987539291381836\n",
      "Epoch 100, current patience 22, model mean validation loss 1.0944254398345947, embedding dim 1, hidden size 32, num layers 1, train loss 1.0963037014007568, validation loss 1.0940200090408325\n",
      "Epoch 110, current patience 21, model mean validation loss 1.0943812131881714, embedding dim 1, hidden size 32, num layers 1, train loss 1.0941977500915527, validation loss 1.094143033027649\n",
      "Epoch 120, current patience 20, model mean validation loss 1.0940442085266113, embedding dim 1, hidden size 32, num layers 1, train loss 1.0883326530456543, validation loss 1.0923291444778442\n",
      "Epoch 130, current patience 19, model mean validation loss 1.0934096574783325, embedding dim 1, hidden size 32, num layers 1, train loss 1.1080540418624878, validation loss 1.0875816345214844\n",
      "Epoch 140, current patience 18, model mean validation loss 1.0936223268508911, embedding dim 1, hidden size 32, num layers 1, train loss 1.0984420776367188, validation loss 1.0946531295776367\n",
      "Epoch 150, current patience 17, model mean validation loss 1.0929930210113525, embedding dim 1, hidden size 32, num layers 1, train loss 1.089471459388733, validation loss 1.0900859832763672\n",
      "Epoch 160, current patience 16, model mean validation loss 1.091991662979126, embedding dim 1, hidden size 32, num layers 1, train loss 1.0633859634399414, validation loss 1.084366798400879\n",
      "Epoch 170, current patience 30, model mean validation loss 1.089988350868225, embedding dim 1, hidden size 32, num layers 1, train loss 1.1183738708496094, validation loss 1.0827276706695557\n",
      "Epoch 180, current patience 30, model mean validation loss 1.089289903640747, embedding dim 1, hidden size 32, num layers 1, train loss 1.130509853363037, validation loss 1.0884320735931396\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0878982543945312, embedding dim 1, hidden size 32, num layers 1, train loss 1.0721981525421143, validation loss 1.0830092430114746\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0835626125335693, embedding dim 1, hidden size 32, num layers 1, train loss 1.040381669998169, validation loss 1.0576438903808594\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0795142650604248, embedding dim 1, hidden size 32, num layers 1, train loss 0.9895082712173462, validation loss 1.0551953315734863\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0732166767120361, embedding dim 1, hidden size 32, num layers 1, train loss 1.0233290195465088, validation loss 1.044272780418396\n",
      "Epoch 230, current patience 30, model mean validation loss 1.06624174118042, embedding dim 1, hidden size 32, num layers 1, train loss 0.9821162223815918, validation loss 1.0342854261398315\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0589401721954346, embedding dim 1, hidden size 32, num layers 1, train loss 1.0682289600372314, validation loss 1.0259541273117065\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0508134365081787, embedding dim 1, hidden size 32, num layers 1, train loss 0.9912996888160706, validation loss 1.0177139043807983\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0433348417282104, embedding dim 1, hidden size 32, num layers 1, train loss 1.037682056427002, validation loss 1.028603434562683\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0346723794937134, embedding dim 1, hidden size 32, num layers 1, train loss 1.028376579284668, validation loss 1.0137100219726562\n",
      "Epoch 280, current patience 30, model mean validation loss 1.027540683746338, embedding dim 1, hidden size 32, num layers 1, train loss 0.9339986443519592, validation loss 1.0005903244018555\n",
      "Epoch 290, current patience 30, model mean validation loss 1.017210841178894, embedding dim 1, hidden size 32, num layers 1, train loss 0.9161510467529297, validation loss 0.9725567698478699\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0087546110153198, embedding dim 1, hidden size 32, num layers 1, train loss 0.9161324501037598, validation loss 0.976622462272644\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0026910305023193, embedding dim 1, hidden size 32, num layers 1, train loss 0.9794425964355469, validation loss 0.9857763648033142\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9957980513572693, embedding dim 1, hidden size 32, num layers 1, train loss 0.8985742330551147, validation loss 0.9708114862442017\n",
      "Epoch 330, current patience 30, model mean validation loss 0.987484335899353, embedding dim 1, hidden size 32, num layers 1, train loss 0.9012651443481445, validation loss 0.951204240322113\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9780310392379761, embedding dim 1, hidden size 32, num layers 1, train loss 0.9625542163848877, validation loss 0.9529765248298645\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9710831642150879, embedding dim 1, hidden size 32, num layers 1, train loss 0.8900250196456909, validation loss 0.9581272006034851\n",
      "Epoch 360, current patience 30, model mean validation loss 0.962935209274292, embedding dim 1, hidden size 32, num layers 1, train loss 0.8705588579177856, validation loss 0.9354063272476196\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9608796834945679, embedding dim 1, hidden size 32, num layers 1, train loss 0.9386304020881653, validation loss 0.9561130404472351\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9566830992698669, embedding dim 1, hidden size 32, num layers 1, train loss 0.9222086668014526, validation loss 0.9430497288703918\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9492590427398682, embedding dim 1, hidden size 32, num layers 1, train loss 0.8938237428665161, validation loss 0.9263834953308105\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9424005150794983, embedding dim 1, hidden size 32, num layers 1, train loss 0.9266464114189148, validation loss 0.9159436225891113\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9397680759429932, embedding dim 1, hidden size 32, num layers 1, train loss 0.8683704733848572, validation loss 0.9301448464393616\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9341280460357666, embedding dim 1, hidden size 32, num layers 1, train loss 0.967553973197937, validation loss 0.9078553915023804\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9297078847885132, embedding dim 1, hidden size 32, num layers 1, train loss 0.9232914447784424, validation loss 0.9227660894393921\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9281743764877319, embedding dim 1, hidden size 32, num layers 1, train loss 0.8719578385353088, validation loss 0.9231387376785278\n",
      "Epoch 450, current patience 30, model mean validation loss 0.921855092048645, embedding dim 1, hidden size 32, num layers 1, train loss 0.8210225701332092, validation loss 0.9055591225624084\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9162880182266235, embedding dim 1, hidden size 32, num layers 1, train loss 0.8726535439491272, validation loss 0.8985132575035095\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9135415554046631, embedding dim 1, hidden size 32, num layers 1, train loss 0.7818928956985474, validation loss 0.9044116735458374\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9100648760795593, embedding dim 1, hidden size 32, num layers 1, train loss 0.8572162985801697, validation loss 0.8881296515464783\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9050862789154053, embedding dim 1, hidden size 32, num layers 1, train loss 0.8055410981178284, validation loss 0.8903166055679321\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9004151225090027, embedding dim 1, hidden size 32, num layers 1, train loss 0.8104091882705688, validation loss 0.8704858422279358\n",
      "Epoch 510, current patience 30, model mean validation loss 0.894534170627594, embedding dim 1, hidden size 32, num layers 1, train loss 0.8411684036254883, validation loss 0.8757181167602539\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8860944509506226, embedding dim 1, hidden size 32, num layers 1, train loss 0.8751859664916992, validation loss 0.8556212782859802\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8825007677078247, embedding dim 1, hidden size 32, num layers 1, train loss 0.7830747365951538, validation loss 0.8768094778060913\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8755045533180237, embedding dim 1, hidden size 32, num layers 1, train loss 0.6919864416122437, validation loss 0.8425434827804565\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8680316209793091, embedding dim 1, hidden size 32, num layers 1, train loss 0.7861573696136475, validation loss 0.8446285724639893\n",
      "Epoch 560, current patience 30, model mean validation loss 0.863336443901062, embedding dim 1, hidden size 32, num layers 1, train loss 0.8594286441802979, validation loss 0.8505675792694092\n",
      "Epoch 570, current patience 30, model mean validation loss 0.859089732170105, embedding dim 1, hidden size 32, num layers 1, train loss 0.7710281610488892, validation loss 0.8563436269760132\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8592954874038696, embedding dim 1, hidden size 32, num layers 1, train loss 0.7409608364105225, validation loss 0.8721315860748291\n",
      "Epoch 590, current patience 29, model mean validation loss 0.8548903465270996, embedding dim 1, hidden size 32, num layers 1, train loss 0.6867902278900146, validation loss 0.8404772877693176\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8534936904907227, embedding dim 1, hidden size 32, num layers 1, train loss 0.8426451683044434, validation loss 0.8444480299949646\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8479173183441162, embedding dim 1, hidden size 32, num layers 1, train loss 0.7356969118118286, validation loss 0.8321986198425293\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8454926609992981, embedding dim 1, hidden size 32, num layers 1, train loss 0.7511512637138367, validation loss 0.8231461048126221\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8442440629005432, embedding dim 1, hidden size 32, num layers 1, train loss 0.8187276124954224, validation loss 0.8346397876739502\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8399792909622192, embedding dim 1, hidden size 32, num layers 1, train loss 0.6628760099411011, validation loss 0.8164494633674622\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8359620571136475, embedding dim 1, hidden size 32, num layers 1, train loss 0.6682100296020508, validation loss 0.8242060542106628\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8329459428787231, embedding dim 1, hidden size 32, num layers 1, train loss 0.7582438588142395, validation loss 0.8480020761489868\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8286590576171875, embedding dim 1, hidden size 32, num layers 1, train loss 0.7330197691917419, validation loss 0.806182324886322\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8279765248298645, embedding dim 1, hidden size 32, num layers 1, train loss 0.5575237274169922, validation loss 0.8389876484870911\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8289564847946167, embedding dim 1, hidden size 32, num layers 1, train loss 0.8599377870559692, validation loss 0.8400385975837708\n",
      "Epoch 700, current patience 29, model mean validation loss 0.825783908367157, embedding dim 1, hidden size 32, num layers 1, train loss 0.7187381982803345, validation loss 0.7977651357650757\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8225951194763184, embedding dim 1, hidden size 32, num layers 1, train loss 0.814461350440979, validation loss 0.8091297745704651\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8258277773857117, embedding dim 1, hidden size 32, num layers 1, train loss 0.6278009414672852, validation loss 0.8423107266426086\n",
      "Epoch 730, current patience 29, model mean validation loss 0.8225566148757935, embedding dim 1, hidden size 32, num layers 1, train loss 0.6319581270217896, validation loss 0.798036515712738\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8171685338020325, embedding dim 1, hidden size 32, num layers 1, train loss 0.6290220022201538, validation loss 0.8048974275588989\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8173916935920715, embedding dim 1, hidden size 32, num layers 1, train loss 0.6167882680892944, validation loss 0.8079676032066345\n",
      "Epoch 760, current patience 29, model mean validation loss 0.8140082955360413, embedding dim 1, hidden size 32, num layers 1, train loss 0.6623897552490234, validation loss 0.811920702457428\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8083796501159668, embedding dim 1, hidden size 32, num layers 1, train loss 0.6737501621246338, validation loss 0.795009434223175\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8143190145492554, embedding dim 1, hidden size 32, num layers 1, train loss 0.6404838562011719, validation loss 0.8452792763710022\n",
      "Epoch 790, current patience 29, model mean validation loss 0.8146795034408569, embedding dim 1, hidden size 32, num layers 1, train loss 0.8875770568847656, validation loss 0.8120139241218567\n",
      "Epoch 800, current patience 28, model mean validation loss 0.8140840530395508, embedding dim 1, hidden size 32, num layers 1, train loss 0.6983095407485962, validation loss 0.8375476598739624\n",
      "Epoch 810, current patience 27, model mean validation loss 0.8137782216072083, embedding dim 1, hidden size 32, num layers 1, train loss 0.7017252445220947, validation loss 0.7955896258354187\n",
      "Epoch 820, current patience 26, model mean validation loss 0.8183501958847046, embedding dim 1, hidden size 32, num layers 1, train loss 0.6738090515136719, validation loss 0.8414731621742249\n",
      "Epoch 830, current patience 25, model mean validation loss 0.8148393630981445, embedding dim 1, hidden size 32, num layers 1, train loss 0.6991784572601318, validation loss 0.7798811793327332\n",
      "Epoch 840, current patience 24, model mean validation loss 0.8135392069816589, embedding dim 1, hidden size 32, num layers 1, train loss 0.6495504379272461, validation loss 0.8015195727348328\n",
      "Epoch 850, current patience 23, model mean validation loss 0.8120920062065125, embedding dim 1, hidden size 32, num layers 1, train loss 0.5529189109802246, validation loss 0.7834317088127136\n",
      "Epoch 860, current patience 22, model mean validation loss 0.8056402206420898, embedding dim 1, hidden size 32, num layers 1, train loss 0.7342597246170044, validation loss 0.7936650514602661\n",
      "Epoch 870, current patience 30, model mean validation loss 0.7991158366203308, embedding dim 1, hidden size 32, num layers 1, train loss 0.8409351110458374, validation loss 0.7598189115524292\n",
      "Epoch 880, current patience 30, model mean validation loss 0.7948980331420898, embedding dim 1, hidden size 32, num layers 1, train loss 0.6484479904174805, validation loss 0.803805410861969\n",
      "Epoch 890, current patience 30, model mean validation loss 0.7949033975601196, embedding dim 1, hidden size 32, num layers 1, train loss 0.6502776145935059, validation loss 0.7956322431564331\n",
      "Epoch 900, current patience 29, model mean validation loss 0.7891378998756409, embedding dim 1, hidden size 32, num layers 1, train loss 0.8222945928573608, validation loss 0.7953494191169739\n",
      "Epoch 910, current patience 30, model mean validation loss 0.7890933156013489, embedding dim 1, hidden size 32, num layers 1, train loss 0.7146244645118713, validation loss 0.779524564743042\n",
      "Epoch 920, current patience 30, model mean validation loss 0.7933266758918762, embedding dim 1, hidden size 32, num layers 1, train loss 0.6088260412216187, validation loss 0.8353860974311829\n",
      "Epoch 930, current patience 29, model mean validation loss 0.7955081462860107, embedding dim 1, hidden size 32, num layers 1, train loss 0.6068170070648193, validation loss 0.8008833527565002\n",
      "Epoch 940, current patience 28, model mean validation loss 0.7927573919296265, embedding dim 1, hidden size 32, num layers 1, train loss 0.5275357961654663, validation loss 0.7716593742370605\n",
      "Epoch 950, current patience 27, model mean validation loss 0.7954981327056885, embedding dim 1, hidden size 32, num layers 1, train loss 0.7210854291915894, validation loss 0.7817440032958984\n",
      "Epoch 960, current patience 26, model mean validation loss 0.7900681495666504, embedding dim 1, hidden size 32, num layers 1, train loss 0.5998536348342896, validation loss 0.7603663206100464\n",
      "Epoch 970, current patience 25, model mean validation loss 0.7905775308609009, embedding dim 1, hidden size 32, num layers 1, train loss 0.5577716827392578, validation loss 0.7997071743011475\n",
      "Epoch 980, current patience 24, model mean validation loss 0.784801721572876, embedding dim 1, hidden size 32, num layers 1, train loss 0.5869660377502441, validation loss 0.7491433620452881\n",
      "Epoch 990, current patience 30, model mean validation loss 0.7849786281585693, embedding dim 1, hidden size 32, num layers 1, train loss 0.7492495775222778, validation loss 0.7809388041496277\n",
      "Epoch 1000, current patience 29, model mean validation loss 0.7786669731140137, embedding dim 1, hidden size 32, num layers 1, train loss 0.7315035462379456, validation loss 0.7848930954933167\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.7759544849395752, embedding dim 1, hidden size 32, num layers 1, train loss 0.8212576508522034, validation loss 0.7791834473609924\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.7776291966438293, embedding dim 1, hidden size 32, num layers 1, train loss 0.5685169696807861, validation loss 0.7850571870803833\n",
      "Epoch 1030, current patience 29, model mean validation loss 0.7761333584785461, embedding dim 1, hidden size 32, num layers 1, train loss 0.5855985879898071, validation loss 0.7697776556015015\n",
      "Epoch 1040, current patience 28, model mean validation loss 0.7780029773712158, embedding dim 1, hidden size 32, num layers 1, train loss 0.5341669321060181, validation loss 0.7753231525421143\n",
      "Epoch 1050, current patience 27, model mean validation loss 0.7766722440719604, embedding dim 1, hidden size 32, num layers 1, train loss 0.5609921813011169, validation loss 0.7890611886978149\n",
      "Epoch 1060, current patience 26, model mean validation loss 0.7811273336410522, embedding dim 1, hidden size 32, num layers 1, train loss 0.6839941740036011, validation loss 0.784784197807312\n",
      "Epoch 1070, current patience 25, model mean validation loss 0.7803764939308167, embedding dim 1, hidden size 32, num layers 1, train loss 0.6164995431900024, validation loss 0.7749319672584534\n",
      "Epoch 1080, current patience 24, model mean validation loss 0.7797704935073853, embedding dim 1, hidden size 32, num layers 1, train loss 0.6747641563415527, validation loss 0.780045211315155\n",
      "Epoch 1090, current patience 23, model mean validation loss 0.7834699749946594, embedding dim 1, hidden size 32, num layers 1, train loss 0.6335921287536621, validation loss 0.808779239654541\n",
      "Epoch 1100, current patience 22, model mean validation loss 0.7927362322807312, embedding dim 1, hidden size 32, num layers 1, train loss 0.5298160314559937, validation loss 0.8591873645782471\n",
      "Epoch 1110, current patience 21, model mean validation loss 0.7949931621551514, embedding dim 1, hidden size 32, num layers 1, train loss 0.6770604848861694, validation loss 0.7878330945968628\n",
      "Epoch 1120, current patience 20, model mean validation loss 0.7929543852806091, embedding dim 1, hidden size 32, num layers 1, train loss 0.6047843098640442, validation loss 0.7590129375457764\n",
      "Epoch 1130, current patience 19, model mean validation loss 0.79472815990448, embedding dim 1, hidden size 32, num layers 1, train loss 0.5203219056129456, validation loss 0.8032512664794922\n",
      "Epoch 1140, current patience 18, model mean validation loss 0.7984075546264648, embedding dim 1, hidden size 32, num layers 1, train loss 0.6647564172744751, validation loss 0.8142189979553223\n",
      "Epoch 1150, current patience 17, model mean validation loss 0.7969499230384827, embedding dim 1, hidden size 32, num layers 1, train loss 0.577258288860321, validation loss 0.7632710337638855\n",
      "Epoch 1160, current patience 16, model mean validation loss 0.7986070513725281, embedding dim 1, hidden size 32, num layers 1, train loss 0.6385278701782227, validation loss 0.7933021783828735\n",
      "Epoch 1170, current patience 15, model mean validation loss 0.7926055788993835, embedding dim 1, hidden size 32, num layers 1, train loss 0.6127772331237793, validation loss 0.7607680559158325\n",
      "Epoch 1180, current patience 14, model mean validation loss 0.7864515781402588, embedding dim 1, hidden size 32, num layers 1, train loss 0.5744746923446655, validation loss 0.809954822063446\n",
      "Epoch 1190, current patience 13, model mean validation loss 0.7869954109191895, embedding dim 1, hidden size 32, num layers 1, train loss 0.4688488841056824, validation loss 0.7921838760375977\n",
      "Epoch 1200, current patience 12, model mean validation loss 0.7942764759063721, embedding dim 1, hidden size 32, num layers 1, train loss 0.7396999597549438, validation loss 0.8172613382339478\n",
      "Epoch 1210, current patience 11, model mean validation loss 0.7903308868408203, embedding dim 1, hidden size 32, num layers 1, train loss 0.5456898212432861, validation loss 0.7716866731643677\n",
      "Epoch 1220, current patience 10, model mean validation loss 0.7866520881652832, embedding dim 1, hidden size 32, num layers 1, train loss 0.5359236598014832, validation loss 0.7847889065742493\n",
      "Epoch 1230, current patience 9, model mean validation loss 0.7856948971748352, embedding dim 1, hidden size 32, num layers 1, train loss 0.598934531211853, validation loss 0.755613386631012\n",
      "Epoch 1240, current patience 8, model mean validation loss 0.7822922468185425, embedding dim 1, hidden size 32, num layers 1, train loss 0.4831903576850891, validation loss 0.7660812139511108\n",
      "Epoch 1250, current patience 7, model mean validation loss 0.7863062620162964, embedding dim 1, hidden size 32, num layers 1, train loss 0.7715210914611816, validation loss 0.7928799390792847\n",
      "Epoch 1260, current patience 6, model mean validation loss 0.7817878723144531, embedding dim 1, hidden size 32, num layers 1, train loss 0.8281786441802979, validation loss 0.7738077044487\n",
      "Epoch 1270, current patience 5, model mean validation loss 0.7839099168777466, embedding dim 1, hidden size 32, num layers 1, train loss 0.44360971450805664, validation loss 0.8091602325439453\n",
      "Epoch 1280, current patience 4, model mean validation loss 0.7778688073158264, embedding dim 1, hidden size 32, num layers 1, train loss 0.4637441039085388, validation loss 0.7689325213432312\n",
      "Epoch 1290, current patience 3, model mean validation loss 0.7826290726661682, embedding dim 1, hidden size 32, num layers 1, train loss 0.5978796482086182, validation loss 0.8097689151763916\n",
      "Epoch 1300, current patience 2, model mean validation loss 0.7899559736251831, embedding dim 1, hidden size 32, num layers 1, train loss 0.8357315063476562, validation loss 0.843404233455658\n",
      "Epoch 1310, current patience 1, model mean validation loss 0.795290470123291, embedding dim 1, hidden size 32, num layers 1, train loss 0.5797492265701294, validation loss 0.7982890605926514\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0957527160644531, embedding dim 1, hidden size 64, num layers 1, train loss 1.095801830291748, validation loss 1.0957527160644531\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0980684757232666, embedding dim 1, hidden size 64, num layers 1, train loss 1.0962655544281006, validation loss 1.10038423538208\n",
      "Epoch 20, current patience 29, model mean validation loss 1.097116470336914, embedding dim 1, hidden size 64, num layers 1, train loss 1.0882391929626465, validation loss 1.0952123403549194\n",
      "Epoch 30, current patience 28, model mean validation loss 1.0967416763305664, embedding dim 1, hidden size 64, num layers 1, train loss 1.09157395362854, validation loss 1.0956170558929443\n",
      "Epoch 40, current patience 27, model mean validation loss 1.0965324640274048, embedding dim 1, hidden size 64, num layers 1, train loss 1.106675624847412, validation loss 1.0956953763961792\n",
      "Epoch 50, current patience 26, model mean validation loss 1.0961819887161255, embedding dim 1, hidden size 64, num layers 1, train loss 1.0792145729064941, validation loss 1.0944304466247559\n",
      "Epoch 60, current patience 25, model mean validation loss 1.09682297706604, embedding dim 1, hidden size 64, num layers 1, train loss 1.1016124486923218, validation loss 1.1006687879562378\n",
      "Epoch 70, current patience 24, model mean validation loss 1.0967931747436523, embedding dim 1, hidden size 64, num layers 1, train loss 1.0785915851593018, validation loss 1.0965843200683594\n",
      "Epoch 80, current patience 23, model mean validation loss 1.0965261459350586, embedding dim 1, hidden size 64, num layers 1, train loss 1.0859098434448242, validation loss 1.0936168432235718\n",
      "Epoch 90, current patience 22, model mean validation loss 1.0962039232254028, embedding dim 1, hidden size 64, num layers 1, train loss 1.088735818862915, validation loss 1.0978063344955444\n",
      "Epoch 100, current patience 21, model mean validation loss 1.0960546731948853, embedding dim 1, hidden size 64, num layers 1, train loss 1.1097832918167114, validation loss 1.0940178632736206\n",
      "Epoch 110, current patience 20, model mean validation loss 1.0951632261276245, embedding dim 1, hidden size 64, num layers 1, train loss 1.0934529304504395, validation loss 1.0884859561920166\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0947115421295166, embedding dim 1, hidden size 64, num layers 1, train loss 1.109860897064209, validation loss 1.0920813083648682\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0947061777114868, embedding dim 1, hidden size 64, num layers 1, train loss 1.0933504104614258, validation loss 1.0943880081176758\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0936393737792969, embedding dim 1, hidden size 64, num layers 1, train loss 1.090778112411499, validation loss 1.092134714126587\n",
      "Epoch 150, current patience 30, model mean validation loss 1.093530535697937, embedding dim 1, hidden size 64, num layers 1, train loss 1.0940461158752441, validation loss 1.0957131385803223\n",
      "Epoch 160, current patience 30, model mean validation loss 1.092890977859497, embedding dim 1, hidden size 64, num layers 1, train loss 1.1043543815612793, validation loss 1.0885009765625\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0913493633270264, embedding dim 1, hidden size 64, num layers 1, train loss 1.085774302482605, validation loss 1.0854730606079102\n",
      "Epoch 180, current patience 30, model mean validation loss 1.089639663696289, embedding dim 1, hidden size 64, num layers 1, train loss 1.1025629043579102, validation loss 1.0803403854370117\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0883750915527344, embedding dim 1, hidden size 64, num layers 1, train loss 1.109037160873413, validation loss 1.0783698558807373\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0870802402496338, embedding dim 1, hidden size 64, num layers 1, train loss 1.0807147026062012, validation loss 1.081722378730774\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0852326154708862, embedding dim 1, hidden size 64, num layers 1, train loss 1.046816349029541, validation loss 1.0796067714691162\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0827088356018066, embedding dim 1, hidden size 64, num layers 1, train loss 1.0863277912139893, validation loss 1.0719448328018188\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0781757831573486, embedding dim 1, hidden size 64, num layers 1, train loss 1.1064822673797607, validation loss 1.0594475269317627\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0764243602752686, embedding dim 1, hidden size 64, num layers 1, train loss 1.021848440170288, validation loss 1.074489951133728\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0712320804595947, embedding dim 1, hidden size 64, num layers 1, train loss 1.0446302890777588, validation loss 1.0439350605010986\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0666511058807373, embedding dim 1, hidden size 64, num layers 1, train loss 0.971200704574585, validation loss 1.0436919927597046\n",
      "Epoch 270, current patience 30, model mean validation loss 1.060189962387085, embedding dim 1, hidden size 64, num layers 1, train loss 1.023263692855835, validation loss 1.0266809463500977\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0521595478057861, embedding dim 1, hidden size 64, num layers 1, train loss 1.020870566368103, validation loss 1.0174798965454102\n",
      "Epoch 290, current patience 30, model mean validation loss 1.039677619934082, embedding dim 1, hidden size 64, num layers 1, train loss 1.0328478813171387, validation loss 0.9797502756118774\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0297919511795044, embedding dim 1, hidden size 64, num layers 1, train loss 1.009110927581787, validation loss 0.9928596019744873\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0226452350616455, embedding dim 1, hidden size 64, num layers 1, train loss 0.8866722583770752, validation loss 1.0022735595703125\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0111125707626343, embedding dim 1, hidden size 64, num layers 1, train loss 0.972488522529602, validation loss 0.9822292923927307\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0045161247253418, embedding dim 1, hidden size 64, num layers 1, train loss 0.9661670327186584, validation loss 0.9911638498306274\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9934660196304321, embedding dim 1, hidden size 64, num layers 1, train loss 1.0247362852096558, validation loss 0.955291211605072\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9823359251022339, embedding dim 1, hidden size 64, num layers 1, train loss 0.9073456525802612, validation loss 0.9376398921012878\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9751760959625244, embedding dim 1, hidden size 64, num layers 1, train loss 1.0014677047729492, validation loss 0.9602010846138\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9698588848114014, embedding dim 1, hidden size 64, num layers 1, train loss 0.9643551707267761, validation loss 0.9372121095657349\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9643145799636841, embedding dim 1, hidden size 64, num layers 1, train loss 0.9625106453895569, validation loss 0.9485057592391968\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9572926759719849, embedding dim 1, hidden size 64, num layers 1, train loss 0.9801700711250305, validation loss 0.9460984468460083\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9518787860870361, embedding dim 1, hidden size 64, num layers 1, train loss 0.8517678380012512, validation loss 0.9389185905456543\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9411977529525757, embedding dim 1, hidden size 64, num layers 1, train loss 0.9343469738960266, validation loss 0.9057146310806274\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9391183853149414, embedding dim 1, hidden size 64, num layers 1, train loss 0.7832998037338257, validation loss 0.9386564493179321\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9365852475166321, embedding dim 1, hidden size 64, num layers 1, train loss 0.7881072759628296, validation loss 0.9173750877380371\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9304136037826538, embedding dim 1, hidden size 64, num layers 1, train loss 0.8659027814865112, validation loss 0.9108273386955261\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9264310598373413, embedding dim 1, hidden size 64, num layers 1, train loss 0.9256637692451477, validation loss 0.9053517580032349\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9204212427139282, embedding dim 1, hidden size 64, num layers 1, train loss 0.8844702839851379, validation loss 0.9004272222518921\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9145094156265259, embedding dim 1, hidden size 64, num layers 1, train loss 0.8572263717651367, validation loss 0.8988041877746582\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9090621471405029, embedding dim 1, hidden size 64, num layers 1, train loss 0.883040189743042, validation loss 0.8953404426574707\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9051824808120728, embedding dim 1, hidden size 64, num layers 1, train loss 0.7340680360794067, validation loss 0.8746775984764099\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8984156847000122, embedding dim 1, hidden size 64, num layers 1, train loss 0.7768142819404602, validation loss 0.8845219612121582\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8927040100097656, embedding dim 1, hidden size 64, num layers 1, train loss 0.8268263936042786, validation loss 0.871681809425354\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8889936208724976, embedding dim 1, hidden size 64, num layers 1, train loss 0.79973304271698, validation loss 0.8811441659927368\n",
      "Epoch 530, current patience 30, model mean validation loss 0.88167405128479, embedding dim 1, hidden size 64, num layers 1, train loss 0.8679962158203125, validation loss 0.8467949628829956\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8765466213226318, embedding dim 1, hidden size 64, num layers 1, train loss 0.7518014907836914, validation loss 0.859407901763916\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8703792691230774, embedding dim 1, hidden size 64, num layers 1, train loss 0.781157374382019, validation loss 0.8494653701782227\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8647828102111816, embedding dim 1, hidden size 64, num layers 1, train loss 0.8502335548400879, validation loss 0.850568413734436\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8627714514732361, embedding dim 1, hidden size 64, num layers 1, train loss 0.8086077570915222, validation loss 0.858586847782135\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8550472855567932, embedding dim 1, hidden size 64, num layers 1, train loss 0.8216374516487122, validation loss 0.8227285146713257\n",
      "Epoch 590, current patience 30, model mean validation loss 0.851769208908081, embedding dim 1, hidden size 64, num layers 1, train loss 0.8390751481056213, validation loss 0.8454575538635254\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8477911353111267, embedding dim 1, hidden size 64, num layers 1, train loss 0.6856728792190552, validation loss 0.8493193984031677\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8440356254577637, embedding dim 1, hidden size 64, num layers 1, train loss 0.7896244525909424, validation loss 0.8167511224746704\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8419703245162964, embedding dim 1, hidden size 64, num layers 1, train loss 0.7830554842948914, validation loss 0.8428856134414673\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8416222333908081, embedding dim 1, hidden size 64, num layers 1, train loss 0.7717100381851196, validation loss 0.8466802835464478\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8385219573974609, embedding dim 1, hidden size 64, num layers 1, train loss 0.7998142242431641, validation loss 0.8257659077644348\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8370429277420044, embedding dim 1, hidden size 64, num layers 1, train loss 0.7237778902053833, validation loss 0.8467552661895752\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8368998765945435, embedding dim 1, hidden size 64, num layers 1, train loss 0.8918179273605347, validation loss 0.8215835094451904\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8323475122451782, embedding dim 1, hidden size 64, num layers 1, train loss 0.7553783059120178, validation loss 0.8090390563011169\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8302035331726074, embedding dim 1, hidden size 64, num layers 1, train loss 0.8774172067642212, validation loss 0.8321676254272461\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8310878276824951, embedding dim 1, hidden size 64, num layers 1, train loss 0.7300190329551697, validation loss 0.8238255381584167\n",
      "Epoch 700, current patience 29, model mean validation loss 0.8309880495071411, embedding dim 1, hidden size 64, num layers 1, train loss 0.7257320880889893, validation loss 0.8420871496200562\n",
      "Epoch 710, current patience 28, model mean validation loss 0.8295267820358276, embedding dim 1, hidden size 64, num layers 1, train loss 0.7658607363700867, validation loss 0.8349901437759399\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8277320861816406, embedding dim 1, hidden size 64, num layers 1, train loss 0.6010884046554565, validation loss 0.8114086389541626\n",
      "Epoch 730, current patience 30, model mean validation loss 0.821176290512085, embedding dim 1, hidden size 64, num layers 1, train loss 0.5652841329574585, validation loss 0.7943087816238403\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8191375732421875, embedding dim 1, hidden size 64, num layers 1, train loss 0.7865556478500366, validation loss 0.8052735328674316\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8205914497375488, embedding dim 1, hidden size 64, num layers 1, train loss 0.595133900642395, validation loss 0.8206697106361389\n",
      "Epoch 760, current patience 29, model mean validation loss 0.8185163736343384, embedding dim 1, hidden size 64, num layers 1, train loss 0.8315269351005554, validation loss 0.8155673742294312\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8159505128860474, embedding dim 1, hidden size 64, num layers 1, train loss 0.7542427182197571, validation loss 0.8032987117767334\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8092633485794067, embedding dim 1, hidden size 64, num layers 1, train loss 0.7743557691574097, validation loss 0.7885899543762207\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8048746585845947, embedding dim 1, hidden size 64, num layers 1, train loss 0.6296558380126953, validation loss 0.7998806238174438\n",
      "Epoch 800, current patience 30, model mean validation loss 0.8050345778465271, embedding dim 1, hidden size 64, num layers 1, train loss 0.6223652362823486, validation loss 0.8126879930496216\n",
      "Epoch 810, current patience 29, model mean validation loss 0.8055417537689209, embedding dim 1, hidden size 64, num layers 1, train loss 0.7880209684371948, validation loss 0.7983660697937012\n",
      "Epoch 820, current patience 28, model mean validation loss 0.8083625435829163, embedding dim 1, hidden size 64, num layers 1, train loss 0.772655725479126, validation loss 0.8278398513793945\n",
      "Epoch 830, current patience 27, model mean validation loss 0.8089908361434937, embedding dim 1, hidden size 64, num layers 1, train loss 0.6434457302093506, validation loss 0.8256960511207581\n",
      "Epoch 840, current patience 26, model mean validation loss 0.8084558844566345, embedding dim 1, hidden size 64, num layers 1, train loss 0.803276538848877, validation loss 0.8112877607345581\n",
      "Epoch 850, current patience 25, model mean validation loss 0.8085432052612305, embedding dim 1, hidden size 64, num layers 1, train loss 0.6449007987976074, validation loss 0.8039976358413696\n",
      "Epoch 860, current patience 24, model mean validation loss 0.8082995414733887, embedding dim 1, hidden size 64, num layers 1, train loss 0.7778177857398987, validation loss 0.7866402864456177\n",
      "Epoch 870, current patience 23, model mean validation loss 0.8067089915275574, embedding dim 1, hidden size 64, num layers 1, train loss 0.6495175361633301, validation loss 0.7871564626693726\n",
      "Epoch 880, current patience 22, model mean validation loss 0.8049354553222656, embedding dim 1, hidden size 64, num layers 1, train loss 0.5078087449073792, validation loss 0.7984992861747742\n",
      "Epoch 890, current patience 21, model mean validation loss 0.8048041462898254, embedding dim 1, hidden size 64, num layers 1, train loss 0.4821942448616028, validation loss 0.7973159551620483\n",
      "Epoch 900, current patience 30, model mean validation loss 0.800392746925354, embedding dim 1, hidden size 64, num layers 1, train loss 0.5877454280853271, validation loss 0.7925487756729126\n",
      "Epoch 910, current patience 30, model mean validation loss 0.7934983968734741, embedding dim 1, hidden size 64, num layers 1, train loss 0.611404299736023, validation loss 0.7705409526824951\n",
      "Epoch 920, current patience 30, model mean validation loss 0.790824294090271, embedding dim 1, hidden size 64, num layers 1, train loss 0.8193529844284058, validation loss 0.7898949980735779\n",
      "Epoch 930, current patience 30, model mean validation loss 0.7928975820541382, embedding dim 1, hidden size 64, num layers 1, train loss 0.7287362813949585, validation loss 0.820583701133728\n",
      "Epoch 940, current patience 29, model mean validation loss 0.7927365899085999, embedding dim 1, hidden size 64, num layers 1, train loss 0.7449790239334106, validation loss 0.7853524684906006\n",
      "Epoch 950, current patience 28, model mean validation loss 0.7943386435508728, embedding dim 1, hidden size 64, num layers 1, train loss 0.6510928869247437, validation loss 0.7999728918075562\n",
      "Epoch 960, current patience 27, model mean validation loss 0.797122597694397, embedding dim 1, hidden size 64, num layers 1, train loss 0.5566973090171814, validation loss 0.8207715749740601\n",
      "Epoch 970, current patience 26, model mean validation loss 0.7950766086578369, embedding dim 1, hidden size 64, num layers 1, train loss 0.7341210246086121, validation loss 0.7809470295906067\n",
      "Epoch 980, current patience 25, model mean validation loss 0.7996418476104736, embedding dim 1, hidden size 64, num layers 1, train loss 0.6931990385055542, validation loss 0.8290711045265198\n",
      "Epoch 990, current patience 24, model mean validation loss 0.8016899824142456, embedding dim 1, hidden size 64, num layers 1, train loss 0.7239183187484741, validation loss 0.7869259715080261\n",
      "Epoch 1000, current patience 23, model mean validation loss 0.798041045665741, embedding dim 1, hidden size 64, num layers 1, train loss 0.6701486110687256, validation loss 0.7607035636901855\n",
      "Epoch 1010, current patience 22, model mean validation loss 0.7948160171508789, embedding dim 1, hidden size 64, num layers 1, train loss 0.5053867697715759, validation loss 0.7947836518287659\n",
      "Epoch 1020, current patience 21, model mean validation loss 0.7996416091918945, embedding dim 1, hidden size 64, num layers 1, train loss 0.5402764081954956, validation loss 0.8239568471908569\n",
      "Epoch 1030, current patience 20, model mean validation loss 0.8004131317138672, embedding dim 1, hidden size 64, num layers 1, train loss 0.775502622127533, validation loss 0.8061453104019165\n",
      "Epoch 1040, current patience 19, model mean validation loss 0.798052191734314, embedding dim 1, hidden size 64, num layers 1, train loss 0.6676214337348938, validation loss 0.8018843531608582\n",
      "Epoch 1050, current patience 18, model mean validation loss 0.801333487033844, embedding dim 1, hidden size 64, num layers 1, train loss 0.6121017336845398, validation loss 0.807197093963623\n",
      "Epoch 1060, current patience 17, model mean validation loss 0.7980425357818604, embedding dim 1, hidden size 64, num layers 1, train loss 0.6369215250015259, validation loss 0.8027433156967163\n",
      "Epoch 1070, current patience 16, model mean validation loss 0.799435019493103, embedding dim 1, hidden size 64, num layers 1, train loss 0.6900362968444824, validation loss 0.7980658411979675\n",
      "Epoch 1080, current patience 15, model mean validation loss 0.803317666053772, embedding dim 1, hidden size 64, num layers 1, train loss 0.5939290523529053, validation loss 0.7917647361755371\n",
      "Epoch 1090, current patience 14, model mean validation loss 0.8041694164276123, embedding dim 1, hidden size 64, num layers 1, train loss 0.6300886869430542, validation loss 0.8015977740287781\n",
      "Epoch 1100, current patience 13, model mean validation loss 0.7974352240562439, embedding dim 1, hidden size 64, num layers 1, train loss 0.5557291507720947, validation loss 0.7700834274291992\n",
      "Epoch 1110, current patience 12, model mean validation loss 0.7943248748779297, embedding dim 1, hidden size 64, num layers 1, train loss 0.5360392332077026, validation loss 0.7812619209289551\n",
      "Epoch 1120, current patience 11, model mean validation loss 0.7889394760131836, embedding dim 1, hidden size 64, num layers 1, train loss 0.5018100142478943, validation loss 0.7588021755218506\n",
      "Epoch 1130, current patience 30, model mean validation loss 0.7845712900161743, embedding dim 1, hidden size 64, num layers 1, train loss 0.5554221868515015, validation loss 0.7722511887550354\n",
      "Epoch 1140, current patience 30, model mean validation loss 0.7857240438461304, embedding dim 1, hidden size 64, num layers 1, train loss 0.6231274008750916, validation loss 0.811964750289917\n",
      "Epoch 1150, current patience 29, model mean validation loss 0.7809858918190002, embedding dim 1, hidden size 64, num layers 1, train loss 0.6873857975006104, validation loss 0.760161280632019\n",
      "Epoch 1160, current patience 30, model mean validation loss 0.786338210105896, embedding dim 1, hidden size 64, num layers 1, train loss 0.6006239652633667, validation loss 0.8345831632614136\n",
      "Epoch 1170, current patience 29, model mean validation loss 0.784044623374939, embedding dim 1, hidden size 64, num layers 1, train loss 0.6962403059005737, validation loss 0.783249020576477\n",
      "Epoch 1180, current patience 28, model mean validation loss 0.7827860116958618, embedding dim 1, hidden size 64, num layers 1, train loss 0.6095584630966187, validation loss 0.760014533996582\n",
      "Epoch 1190, current patience 27, model mean validation loss 0.7854890823364258, embedding dim 1, hidden size 64, num layers 1, train loss 0.6924492716789246, validation loss 0.802886426448822\n",
      "Epoch 1200, current patience 26, model mean validation loss 0.7846615314483643, embedding dim 1, hidden size 64, num layers 1, train loss 0.667169451713562, validation loss 0.7521820068359375\n",
      "Epoch 1210, current patience 25, model mean validation loss 0.7891216278076172, embedding dim 1, hidden size 64, num layers 1, train loss 0.6002210378646851, validation loss 0.8079317212104797\n",
      "Epoch 1220, current patience 24, model mean validation loss 0.7836921215057373, embedding dim 1, hidden size 64, num layers 1, train loss 0.6864007115364075, validation loss 0.7685288786888123\n",
      "Epoch 1230, current patience 23, model mean validation loss 0.7859841585159302, embedding dim 1, hidden size 64, num layers 1, train loss 0.6289262771606445, validation loss 0.778497576713562\n",
      "Epoch 1240, current patience 22, model mean validation loss 0.7804757356643677, embedding dim 1, hidden size 64, num layers 1, train loss 0.6496477723121643, validation loss 0.7905157804489136\n",
      "Epoch 1250, current patience 30, model mean validation loss 0.7830328345298767, embedding dim 1, hidden size 64, num layers 1, train loss 0.5783505439758301, validation loss 0.8037059307098389\n",
      "Epoch 1260, current patience 29, model mean validation loss 0.7914013266563416, embedding dim 1, hidden size 64, num layers 1, train loss 0.4723784029483795, validation loss 0.8269624710083008\n",
      "Epoch 1270, current patience 28, model mean validation loss 0.7893149852752686, embedding dim 1, hidden size 64, num layers 1, train loss 0.5473175048828125, validation loss 0.7861955165863037\n",
      "Epoch 1280, current patience 27, model mean validation loss 0.7958253622055054, embedding dim 1, hidden size 64, num layers 1, train loss 0.6531901359558105, validation loss 0.8042649030685425\n",
      "Epoch 1290, current patience 26, model mean validation loss 0.7910407781600952, embedding dim 1, hidden size 64, num layers 1, train loss 0.640148937702179, validation loss 0.7696552276611328\n",
      "Epoch 1300, current patience 25, model mean validation loss 0.7943159341812134, embedding dim 1, hidden size 64, num layers 1, train loss 0.47795701026916504, validation loss 0.7947298884391785\n",
      "Epoch 1310, current patience 24, model mean validation loss 0.7964478731155396, embedding dim 1, hidden size 64, num layers 1, train loss 0.5110470652580261, validation loss 0.7955536842346191\n",
      "Epoch 1320, current patience 23, model mean validation loss 0.7984911799430847, embedding dim 1, hidden size 64, num layers 1, train loss 0.5982115268707275, validation loss 0.8068614602088928\n",
      "Epoch 1330, current patience 22, model mean validation loss 0.796052098274231, embedding dim 1, hidden size 64, num layers 1, train loss 0.6241873502731323, validation loss 0.7841933369636536\n",
      "Epoch 1340, current patience 21, model mean validation loss 0.7940492630004883, embedding dim 1, hidden size 64, num layers 1, train loss 0.4760980010032654, validation loss 0.8109399676322937\n",
      "Epoch 1350, current patience 20, model mean validation loss 0.7940415740013123, embedding dim 1, hidden size 64, num layers 1, train loss 0.47355419397354126, validation loss 0.7861342430114746\n",
      "Epoch 1360, current patience 19, model mean validation loss 0.7961001396179199, embedding dim 1, hidden size 64, num layers 1, train loss 0.4544880986213684, validation loss 0.8207334876060486\n",
      "Epoch 1370, current patience 18, model mean validation loss 0.8031496405601501, embedding dim 1, hidden size 64, num layers 1, train loss 0.5895218849182129, validation loss 0.8260509967803955\n",
      "Epoch 1380, current patience 17, model mean validation loss 0.8031505346298218, embedding dim 1, hidden size 64, num layers 1, train loss 0.4528646767139435, validation loss 0.7947373986244202\n",
      "Epoch 1390, current patience 16, model mean validation loss 0.8078125715255737, embedding dim 1, hidden size 64, num layers 1, train loss 0.6919853091239929, validation loss 0.8328502774238586\n",
      "Epoch 1400, current patience 15, model mean validation loss 0.8041020035743713, embedding dim 1, hidden size 64, num layers 1, train loss 0.5599205493927002, validation loss 0.7771763801574707\n",
      "Epoch 1410, current patience 14, model mean validation loss 0.80516517162323, embedding dim 1, hidden size 64, num layers 1, train loss 0.46554216742515564, validation loss 0.7926986217498779\n",
      "Epoch 1420, current patience 13, model mean validation loss 0.8103360533714294, embedding dim 1, hidden size 64, num layers 1, train loss 0.5792872905731201, validation loss 0.8523073196411133\n",
      "Epoch 1430, current patience 12, model mean validation loss 0.8157580494880676, embedding dim 1, hidden size 64, num layers 1, train loss 0.5933504104614258, validation loss 0.8295099139213562\n",
      "Epoch 1440, current patience 11, model mean validation loss 0.8127020597457886, embedding dim 1, hidden size 64, num layers 1, train loss 0.565736711025238, validation loss 0.7962858080863953\n",
      "Epoch 1450, current patience 10, model mean validation loss 0.8101989030838013, embedding dim 1, hidden size 64, num layers 1, train loss 0.446580708026886, validation loss 0.8060256838798523\n",
      "Epoch 1460, current patience 9, model mean validation loss 0.8146029114723206, embedding dim 1, hidden size 64, num layers 1, train loss 0.48275625705718994, validation loss 0.8299689292907715\n",
      "Epoch 1470, current patience 8, model mean validation loss 0.8164166808128357, embedding dim 1, hidden size 64, num layers 1, train loss 0.49390044808387756, validation loss 0.8473608493804932\n",
      "Epoch 1480, current patience 7, model mean validation loss 0.8163439631462097, embedding dim 1, hidden size 64, num layers 1, train loss 0.4697631597518921, validation loss 0.7765944004058838\n",
      "Epoch 1490, current patience 6, model mean validation loss 0.8170074820518494, embedding dim 1, hidden size 64, num layers 1, train loss 0.7085630893707275, validation loss 0.7980067133903503\n",
      "Epoch 1500, current patience 5, model mean validation loss 0.8136281371116638, embedding dim 1, hidden size 64, num layers 1, train loss 0.57084059715271, validation loss 0.8252725601196289\n",
      "Epoch 1510, current patience 4, model mean validation loss 0.8155944347381592, embedding dim 1, hidden size 64, num layers 1, train loss 0.5007728338241577, validation loss 0.845240592956543\n",
      "Epoch 1520, current patience 3, model mean validation loss 0.8246394991874695, embedding dim 1, hidden size 64, num layers 1, train loss 0.6658684611320496, validation loss 0.8686460256576538\n",
      "Epoch 1530, current patience 2, model mean validation loss 0.8246352672576904, embedding dim 1, hidden size 64, num layers 1, train loss 0.5013018250465393, validation loss 0.8059917688369751\n",
      "Epoch 1540, current patience 1, model mean validation loss 0.8277418613433838, embedding dim 1, hidden size 64, num layers 1, train loss 0.5174028873443604, validation loss 0.8548223972320557\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1025944948196411, embedding dim 1, hidden size 128, num layers 1, train loss 1.0986549854278564, validation loss 1.1025944948196411\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1001250743865967, embedding dim 1, hidden size 128, num layers 1, train loss 1.098818302154541, validation loss 1.0976557731628418\n",
      "Epoch 20, current patience 30, model mean validation loss 1.099676251411438, embedding dim 1, hidden size 128, num layers 1, train loss 1.070172667503357, validation loss 1.098778486251831\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0985981225967407, embedding dim 1, hidden size 128, num layers 1, train loss 1.104223608970642, validation loss 1.0953638553619385\n",
      "Epoch 40, current patience 30, model mean validation loss 1.097660779953003, embedding dim 1, hidden size 128, num layers 1, train loss 1.103453516960144, validation loss 1.0939116477966309\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0974301099777222, embedding dim 1, hidden size 128, num layers 1, train loss 1.0965677499771118, validation loss 1.096276879310608\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0967442989349365, embedding dim 1, hidden size 128, num layers 1, train loss 1.0913182497024536, validation loss 1.092629075050354\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0967899560928345, embedding dim 1, hidden size 128, num layers 1, train loss 1.0959293842315674, validation loss 1.0971095561981201\n",
      "Epoch 80, current patience 29, model mean validation loss 1.0960111618041992, embedding dim 1, hidden size 128, num layers 1, train loss 1.0950496196746826, validation loss 1.0963640213012695\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0956599712371826, embedding dim 1, hidden size 128, num layers 1, train loss 1.0951919555664062, validation loss 1.0948460102081299\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0954231023788452, embedding dim 1, hidden size 128, num layers 1, train loss 1.0747337341308594, validation loss 1.0968835353851318\n",
      "Epoch 110, current patience 30, model mean validation loss 1.095258116722107, embedding dim 1, hidden size 128, num layers 1, train loss 1.1193745136260986, validation loss 1.0940442085266113\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0952880382537842, embedding dim 1, hidden size 128, num layers 1, train loss 1.0952050685882568, validation loss 1.0941500663757324\n",
      "Epoch 130, current patience 29, model mean validation loss 1.0953233242034912, embedding dim 1, hidden size 128, num layers 1, train loss 1.0942827463150024, validation loss 1.0965592861175537\n",
      "Epoch 140, current patience 28, model mean validation loss 1.0951064825057983, embedding dim 1, hidden size 128, num layers 1, train loss 1.086555004119873, validation loss 1.0908949375152588\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0947531461715698, embedding dim 1, hidden size 128, num layers 1, train loss 1.111868143081665, validation loss 1.0942829847335815\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0940974950790405, embedding dim 1, hidden size 128, num layers 1, train loss 1.0788941383361816, validation loss 1.0911188125610352\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0934453010559082, embedding dim 1, hidden size 128, num layers 1, train loss 1.0620689392089844, validation loss 1.0896286964416504\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0910638570785522, embedding dim 1, hidden size 128, num layers 1, train loss 1.0575708150863647, validation loss 1.077831745147705\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0887302160263062, embedding dim 1, hidden size 128, num layers 1, train loss 1.1098922491073608, validation loss 1.0753746032714844\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0878748893737793, embedding dim 1, hidden size 128, num layers 1, train loss 1.0438055992126465, validation loss 1.0873078107833862\n",
      "Epoch 210, current patience 30, model mean validation loss 1.085561990737915, embedding dim 1, hidden size 128, num layers 1, train loss 1.0600851774215698, validation loss 1.0780562162399292\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0808074474334717, embedding dim 1, hidden size 128, num layers 1, train loss 1.114776849746704, validation loss 1.0528581142425537\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0752594470977783, embedding dim 1, hidden size 128, num layers 1, train loss 0.9889899492263794, validation loss 1.0498988628387451\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0730546712875366, embedding dim 1, hidden size 128, num layers 1, train loss 1.092444896697998, validation loss 1.073480486869812\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0662580728530884, embedding dim 1, hidden size 128, num layers 1, train loss 1.032680869102478, validation loss 1.035256266593933\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0626431703567505, embedding dim 1, hidden size 128, num layers 1, train loss 0.9889452457427979, validation loss 1.0489131212234497\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0570508241653442, embedding dim 1, hidden size 128, num layers 1, train loss 1.045542597770691, validation loss 1.0306355953216553\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0468995571136475, embedding dim 1, hidden size 128, num layers 1, train loss 0.9495139718055725, validation loss 1.0060970783233643\n",
      "Epoch 290, current patience 30, model mean validation loss 1.038573145866394, embedding dim 1, hidden size 128, num layers 1, train loss 0.906076967716217, validation loss 1.01144540309906\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0292953252792358, embedding dim 1, hidden size 128, num layers 1, train loss 1.0075088739395142, validation loss 0.9786359667778015\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0218983888626099, embedding dim 1, hidden size 128, num layers 1, train loss 1.131536602973938, validation loss 0.9907239079475403\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0116400718688965, embedding dim 1, hidden size 128, num layers 1, train loss 0.8749731183052063, validation loss 0.9914133548736572\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0068705081939697, embedding dim 1, hidden size 128, num layers 1, train loss 0.9424736499786377, validation loss 0.9971004128456116\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9941055774688721, embedding dim 1, hidden size 128, num layers 1, train loss 0.9140049815177917, validation loss 0.9467926025390625\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9845536947250366, embedding dim 1, hidden size 128, num layers 1, train loss 0.9157489538192749, validation loss 0.9542204141616821\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9780887365341187, embedding dim 1, hidden size 128, num layers 1, train loss 0.830245852470398, validation loss 0.9543777704238892\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9665032625198364, embedding dim 1, hidden size 128, num layers 1, train loss 0.9396554231643677, validation loss 0.9187616109848022\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9633703231811523, embedding dim 1, hidden size 128, num layers 1, train loss 0.8682399988174438, validation loss 0.9535723924636841\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9530692100524902, embedding dim 1, hidden size 128, num layers 1, train loss 0.9517934918403625, validation loss 0.9083148241043091\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9450135231018066, embedding dim 1, hidden size 128, num layers 1, train loss 0.8254038691520691, validation loss 0.9269676804542542\n",
      "Epoch 410, current patience 30, model mean validation loss 0.933823823928833, embedding dim 1, hidden size 128, num layers 1, train loss 0.8510714769363403, validation loss 0.907582700252533\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9294788837432861, embedding dim 1, hidden size 128, num layers 1, train loss 0.8660544157028198, validation loss 0.9120337963104248\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9211409091949463, embedding dim 1, hidden size 128, num layers 1, train loss 0.7352689504623413, validation loss 0.8875163197517395\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9136075973510742, embedding dim 1, hidden size 128, num layers 1, train loss 0.8561862707138062, validation loss 0.894111692905426\n",
      "Epoch 450, current patience 30, model mean validation loss 0.909537136554718, embedding dim 1, hidden size 128, num layers 1, train loss 0.9328478574752808, validation loss 0.886197566986084\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9015425443649292, embedding dim 1, hidden size 128, num layers 1, train loss 0.775876522064209, validation loss 0.8896158933639526\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9009919166564941, embedding dim 1, hidden size 128, num layers 1, train loss 0.9563289284706116, validation loss 0.9039100408554077\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8952009677886963, embedding dim 1, hidden size 128, num layers 1, train loss 0.9382001161575317, validation loss 0.8806396722793579\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8923110961914062, embedding dim 1, hidden size 128, num layers 1, train loss 0.9040303230285645, validation loss 0.884463906288147\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8901623487472534, embedding dim 1, hidden size 128, num layers 1, train loss 0.8086267709732056, validation loss 0.8948437571525574\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8861168622970581, embedding dim 1, hidden size 128, num layers 1, train loss 0.6563130617141724, validation loss 0.8551524877548218\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8832331895828247, embedding dim 1, hidden size 128, num layers 1, train loss 0.7406415343284607, validation loss 0.8710426092147827\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8805429339408875, embedding dim 1, hidden size 128, num layers 1, train loss 0.8653318285942078, validation loss 0.8646754026412964\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8768836259841919, embedding dim 1, hidden size 128, num layers 1, train loss 0.8321928381919861, validation loss 0.8603411912918091\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8717023730278015, embedding dim 1, hidden size 128, num layers 1, train loss 0.8461089730262756, validation loss 0.8624603748321533\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8687475919723511, embedding dim 1, hidden size 128, num layers 1, train loss 0.7767271399497986, validation loss 0.8570011854171753\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8658533096313477, embedding dim 1, hidden size 128, num layers 1, train loss 0.8731231689453125, validation loss 0.861309289932251\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8582989573478699, embedding dim 1, hidden size 128, num layers 1, train loss 0.8638055324554443, validation loss 0.834409236907959\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8577743172645569, embedding dim 1, hidden size 128, num layers 1, train loss 0.798870325088501, validation loss 0.8509553670883179\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8609322309494019, embedding dim 1, hidden size 128, num layers 1, train loss 0.8186434507369995, validation loss 0.8963056802749634\n",
      "Epoch 610, current patience 29, model mean validation loss 0.85951828956604, embedding dim 1, hidden size 128, num layers 1, train loss 0.7536752223968506, validation loss 0.8533637523651123\n",
      "Epoch 620, current patience 28, model mean validation loss 0.8563657999038696, embedding dim 1, hidden size 128, num layers 1, train loss 0.8573191165924072, validation loss 0.8351216912269592\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8518022894859314, embedding dim 1, hidden size 128, num layers 1, train loss 0.6674101948738098, validation loss 0.8259520530700684\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8492835760116577, embedding dim 1, hidden size 128, num layers 1, train loss 0.8196333646774292, validation loss 0.836851179599762\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8442835807800293, embedding dim 1, hidden size 128, num layers 1, train loss 0.7721874713897705, validation loss 0.8213092088699341\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8412789702415466, embedding dim 1, hidden size 128, num layers 1, train loss 0.7828185558319092, validation loss 0.8103728890419006\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8408187031745911, embedding dim 1, hidden size 128, num layers 1, train loss 0.8478341698646545, validation loss 0.8472732305526733\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8349922895431519, embedding dim 1, hidden size 128, num layers 1, train loss 0.893756091594696, validation loss 0.8496943712234497\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8307948112487793, embedding dim 1, hidden size 128, num layers 1, train loss 0.6159986257553101, validation loss 0.8197840452194214\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8302581310272217, embedding dim 1, hidden size 128, num layers 1, train loss 0.720335841178894, validation loss 0.8308278322219849\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8333232402801514, embedding dim 1, hidden size 128, num layers 1, train loss 0.8865166902542114, validation loss 0.850473165512085\n",
      "Epoch 720, current patience 29, model mean validation loss 0.8296449184417725, embedding dim 1, hidden size 128, num layers 1, train loss 0.7729862332344055, validation loss 0.8074245452880859\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8285636901855469, embedding dim 1, hidden size 128, num layers 1, train loss 0.7493045330047607, validation loss 0.812659502029419\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8313871622085571, embedding dim 1, hidden size 128, num layers 1, train loss 0.708382248878479, validation loss 0.8329604864120483\n",
      "Epoch 750, current patience 29, model mean validation loss 0.8283106684684753, embedding dim 1, hidden size 128, num layers 1, train loss 0.8660165071487427, validation loss 0.822661280632019\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8248186111450195, embedding dim 1, hidden size 128, num layers 1, train loss 0.6550997495651245, validation loss 0.8217585682868958\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8269013166427612, embedding dim 1, hidden size 128, num layers 1, train loss 0.7649675607681274, validation loss 0.836445689201355\n",
      "Epoch 780, current patience 29, model mean validation loss 0.8238222599029541, embedding dim 1, hidden size 128, num layers 1, train loss 0.7318665981292725, validation loss 0.8061950206756592\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8172711730003357, embedding dim 1, hidden size 128, num layers 1, train loss 0.6593182682991028, validation loss 0.7980643510818481\n",
      "Epoch 800, current patience 30, model mean validation loss 0.8193387389183044, embedding dim 1, hidden size 128, num layers 1, train loss 0.6592400074005127, validation loss 0.823965311050415\n",
      "Epoch 810, current patience 29, model mean validation loss 0.8208874464035034, embedding dim 1, hidden size 128, num layers 1, train loss 0.8363915681838989, validation loss 0.8250492811203003\n",
      "Epoch 820, current patience 28, model mean validation loss 0.8157354593276978, embedding dim 1, hidden size 128, num layers 1, train loss 0.7036595344543457, validation loss 0.7917443513870239\n",
      "Epoch 830, current patience 30, model mean validation loss 0.815253496170044, embedding dim 1, hidden size 128, num layers 1, train loss 0.6616365909576416, validation loss 0.8188058137893677\n",
      "Epoch 840, current patience 30, model mean validation loss 0.8176980018615723, embedding dim 1, hidden size 128, num layers 1, train loss 0.7162004709243774, validation loss 0.8413140177726746\n",
      "Epoch 850, current patience 29, model mean validation loss 0.8151563405990601, embedding dim 1, hidden size 128, num layers 1, train loss 0.5986409187316895, validation loss 0.8161128759384155\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8213968873023987, embedding dim 1, hidden size 128, num layers 1, train loss 0.6221719980239868, validation loss 0.8561191558837891\n",
      "Epoch 870, current patience 29, model mean validation loss 0.8265826106071472, embedding dim 1, hidden size 128, num layers 1, train loss 0.7081601619720459, validation loss 0.8395497798919678\n",
      "Epoch 880, current patience 28, model mean validation loss 0.8270329236984253, embedding dim 1, hidden size 128, num layers 1, train loss 0.7728960514068604, validation loss 0.8275675773620605\n",
      "Epoch 890, current patience 27, model mean validation loss 0.827424168586731, embedding dim 1, hidden size 128, num layers 1, train loss 0.690110981464386, validation loss 0.8281797170639038\n",
      "Epoch 900, current patience 26, model mean validation loss 0.8287659287452698, embedding dim 1, hidden size 128, num layers 1, train loss 0.6686476469039917, validation loss 0.8024783134460449\n",
      "Epoch 910, current patience 25, model mean validation loss 0.8292509317398071, embedding dim 1, hidden size 128, num layers 1, train loss 0.6210504174232483, validation loss 0.8226861953735352\n",
      "Epoch 920, current patience 24, model mean validation loss 0.82452392578125, embedding dim 1, hidden size 128, num layers 1, train loss 0.6891152858734131, validation loss 0.8034975528717041\n",
      "Epoch 930, current patience 23, model mean validation loss 0.824639081954956, embedding dim 1, hidden size 128, num layers 1, train loss 0.6516683101654053, validation loss 0.8170343041419983\n",
      "Epoch 940, current patience 22, model mean validation loss 0.8159618377685547, embedding dim 1, hidden size 128, num layers 1, train loss 0.740389883518219, validation loss 0.7867012023925781\n",
      "Epoch 950, current patience 21, model mean validation loss 0.8113011121749878, embedding dim 1, hidden size 128, num layers 1, train loss 0.5285054445266724, validation loss 0.8022639751434326\n",
      "Epoch 960, current patience 30, model mean validation loss 0.8135008811950684, embedding dim 1, hidden size 128, num layers 1, train loss 0.5993626713752747, validation loss 0.8451659679412842\n",
      "Epoch 970, current patience 29, model mean validation loss 0.8112996816635132, embedding dim 1, hidden size 128, num layers 1, train loss 0.7554506063461304, validation loss 0.8105701804161072\n",
      "Epoch 980, current patience 30, model mean validation loss 0.8094689846038818, embedding dim 1, hidden size 128, num layers 1, train loss 0.7120060920715332, validation loss 0.7878323793411255\n",
      "Epoch 990, current patience 30, model mean validation loss 0.8107266426086426, embedding dim 1, hidden size 128, num layers 1, train loss 0.7188670039176941, validation loss 0.8327479958534241\n",
      "Epoch 1000, current patience 29, model mean validation loss 0.8127752542495728, embedding dim 1, hidden size 128, num layers 1, train loss 0.5383744835853577, validation loss 0.8198867440223694\n",
      "Epoch 1010, current patience 28, model mean validation loss 0.809096097946167, embedding dim 1, hidden size 128, num layers 1, train loss 0.6355634331703186, validation loss 0.7875999212265015\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.8108311891555786, embedding dim 1, hidden size 128, num layers 1, train loss 0.755351185798645, validation loss 0.8005827069282532\n",
      "Epoch 1030, current patience 29, model mean validation loss 0.8116590976715088, embedding dim 1, hidden size 128, num layers 1, train loss 0.6996230483055115, validation loss 0.8088871240615845\n",
      "Epoch 1040, current patience 28, model mean validation loss 0.8085629940032959, embedding dim 1, hidden size 128, num layers 1, train loss 0.6098196506500244, validation loss 0.8203966021537781\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.8110997676849365, embedding dim 1, hidden size 128, num layers 1, train loss 0.6709392666816711, validation loss 0.830864429473877\n",
      "Epoch 1060, current patience 29, model mean validation loss 0.8181237578392029, embedding dim 1, hidden size 128, num layers 1, train loss 0.6663697957992554, validation loss 0.8440243005752563\n",
      "Epoch 1070, current patience 28, model mean validation loss 0.8181494474411011, embedding dim 1, hidden size 128, num layers 1, train loss 0.7235003709793091, validation loss 0.832953929901123\n",
      "Epoch 1080, current patience 27, model mean validation loss 0.8203729391098022, embedding dim 1, hidden size 128, num layers 1, train loss 0.46692031621932983, validation loss 0.8376745581626892\n",
      "Epoch 1090, current patience 26, model mean validation loss 0.8260629177093506, embedding dim 1, hidden size 128, num layers 1, train loss 0.5493988394737244, validation loss 0.8331198692321777\n",
      "Epoch 1100, current patience 25, model mean validation loss 0.8285461068153381, embedding dim 1, hidden size 128, num layers 1, train loss 0.6662304401397705, validation loss 0.8204477429389954\n",
      "Epoch 1110, current patience 24, model mean validation loss 0.82517009973526, embedding dim 1, hidden size 128, num layers 1, train loss 0.5576601624488831, validation loss 0.7818793058395386\n",
      "Epoch 1120, current patience 23, model mean validation loss 0.8273299932479858, embedding dim 1, hidden size 128, num layers 1, train loss 0.753158688545227, validation loss 0.8376753926277161\n",
      "Epoch 1130, current patience 22, model mean validation loss 0.8282473087310791, embedding dim 1, hidden size 128, num layers 1, train loss 0.7099168300628662, validation loss 0.8382027745246887\n",
      "Epoch 1140, current patience 21, model mean validation loss 0.824452817440033, embedding dim 1, hidden size 128, num layers 1, train loss 0.5313253402709961, validation loss 0.813668966293335\n",
      "Epoch 1150, current patience 20, model mean validation loss 0.8229573369026184, embedding dim 1, hidden size 128, num layers 1, train loss 0.7373703718185425, validation loss 0.8209901452064514\n",
      "Epoch 1160, current patience 19, model mean validation loss 0.8186563849449158, embedding dim 1, hidden size 128, num layers 1, train loss 0.596703827381134, validation loss 0.8032666444778442\n",
      "Epoch 1170, current patience 18, model mean validation loss 0.8167600631713867, embedding dim 1, hidden size 128, num layers 1, train loss 0.6654099822044373, validation loss 0.8179491758346558\n",
      "Epoch 1180, current patience 17, model mean validation loss 0.816907525062561, embedding dim 1, hidden size 128, num layers 1, train loss 0.5447269678115845, validation loss 0.821627676486969\n",
      "Epoch 1190, current patience 16, model mean validation loss 0.8182834386825562, embedding dim 1, hidden size 128, num layers 1, train loss 0.638943076133728, validation loss 0.7928865551948547\n",
      "Epoch 1200, current patience 15, model mean validation loss 0.8185014128684998, embedding dim 1, hidden size 128, num layers 1, train loss 0.49153733253479004, validation loss 0.8394191265106201\n",
      "Epoch 1210, current patience 14, model mean validation loss 0.817984938621521, embedding dim 1, hidden size 128, num layers 1, train loss 0.6050184369087219, validation loss 0.834071159362793\n",
      "Epoch 1220, current patience 13, model mean validation loss 0.8170031309127808, embedding dim 1, hidden size 128, num layers 1, train loss 0.5061221122741699, validation loss 0.8058143854141235\n",
      "Epoch 1230, current patience 12, model mean validation loss 0.8183226585388184, embedding dim 1, hidden size 128, num layers 1, train loss 0.5000203847885132, validation loss 0.8315466642379761\n",
      "Epoch 1240, current patience 11, model mean validation loss 0.8235214948654175, embedding dim 1, hidden size 128, num layers 1, train loss 0.4677339792251587, validation loss 0.844857394695282\n",
      "Epoch 1250, current patience 10, model mean validation loss 0.8261765241622925, embedding dim 1, hidden size 128, num layers 1, train loss 0.49334070086479187, validation loss 0.8391892910003662\n",
      "Epoch 1260, current patience 9, model mean validation loss 0.8298565149307251, embedding dim 1, hidden size 128, num layers 1, train loss 0.5710736513137817, validation loss 0.8510676026344299\n",
      "Epoch 1270, current patience 8, model mean validation loss 0.8341115713119507, embedding dim 1, hidden size 128, num layers 1, train loss 0.6841310858726501, validation loss 0.826927125453949\n",
      "Epoch 1280, current patience 7, model mean validation loss 0.8367362022399902, embedding dim 1, hidden size 128, num layers 1, train loss 0.5369778275489807, validation loss 0.8604162335395813\n",
      "Epoch 1290, current patience 6, model mean validation loss 0.8297858238220215, embedding dim 1, hidden size 128, num layers 1, train loss 0.6026369333267212, validation loss 0.7784677147865295\n",
      "Epoch 1300, current patience 5, model mean validation loss 0.8303940296173096, embedding dim 1, hidden size 128, num layers 1, train loss 0.5322878360748291, validation loss 0.8106802105903625\n",
      "Epoch 1310, current patience 4, model mean validation loss 0.8273787498474121, embedding dim 1, hidden size 128, num layers 1, train loss 0.48898106813430786, validation loss 0.8074245452880859\n",
      "Epoch 1320, current patience 3, model mean validation loss 0.8218580484390259, embedding dim 1, hidden size 128, num layers 1, train loss 0.5543497800827026, validation loss 0.8006918430328369\n",
      "Epoch 1330, current patience 2, model mean validation loss 0.8235747814178467, embedding dim 1, hidden size 128, num layers 1, train loss 0.5741202235221863, validation loss 0.8529227375984192\n",
      "Epoch 1340, current patience 1, model mean validation loss 0.8266476988792419, embedding dim 1, hidden size 128, num layers 1, train loss 0.47479113936424255, validation loss 0.8756511211395264\n",
      "Epoch 0, current patience 30, model mean validation loss 1.107292890548706, embedding dim 1, hidden size 256, num layers 1, train loss 1.0960283279418945, validation loss 1.107292890548706\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1002936363220215, embedding dim 1, hidden size 256, num layers 1, train loss 1.088470697402954, validation loss 1.0932945013046265\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0967851877212524, embedding dim 1, hidden size 256, num layers 1, train loss 1.0881189107894897, validation loss 1.089768409729004\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0980224609375, embedding dim 1, hidden size 256, num layers 1, train loss 1.0952794551849365, validation loss 1.101733922958374\n",
      "Epoch 40, current patience 29, model mean validation loss 1.09731924533844, embedding dim 1, hidden size 256, num layers 1, train loss 1.0955238342285156, validation loss 1.094506025314331\n",
      "Epoch 50, current patience 28, model mean validation loss 1.0967826843261719, embedding dim 1, hidden size 256, num layers 1, train loss 1.0878276824951172, validation loss 1.0941005945205688\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0960391759872437, embedding dim 1, hidden size 256, num layers 1, train loss 1.090491771697998, validation loss 1.0915777683258057\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0962626934051514, embedding dim 1, hidden size 256, num layers 1, train loss 1.1165499687194824, validation loss 1.097827672958374\n",
      "Epoch 80, current patience 29, model mean validation loss 1.0947420597076416, embedding dim 1, hidden size 256, num layers 1, train loss 1.0936405658721924, validation loss 1.0951279401779175\n",
      "Epoch 90, current patience 30, model mean validation loss 1.094586730003357, embedding dim 1, hidden size 256, num layers 1, train loss 1.0914101600646973, validation loss 1.092051386833191\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094574213027954, embedding dim 1, hidden size 256, num layers 1, train loss 1.1014859676361084, validation loss 1.0896687507629395\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0934579372406006, embedding dim 1, hidden size 256, num layers 1, train loss 1.0836430788040161, validation loss 1.0928038358688354\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0930047035217285, embedding dim 1, hidden size 256, num layers 1, train loss 1.085564374923706, validation loss 1.0908805131912231\n",
      "Epoch 130, current patience 30, model mean validation loss 1.092847466468811, embedding dim 1, hidden size 256, num layers 1, train loss 1.0860388278961182, validation loss 1.09284245967865\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0920963287353516, embedding dim 1, hidden size 256, num layers 1, train loss 1.0991780757904053, validation loss 1.0855684280395508\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0902352333068848, embedding dim 1, hidden size 256, num layers 1, train loss 1.071021556854248, validation loss 1.0829381942749023\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0892393589019775, embedding dim 1, hidden size 256, num layers 1, train loss 1.0537984371185303, validation loss 1.087160587310791\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0868756771087646, embedding dim 1, hidden size 256, num layers 1, train loss 1.054626703262329, validation loss 1.0731432437896729\n",
      "Epoch 180, current patience 30, model mean validation loss 1.086077332496643, embedding dim 1, hidden size 256, num layers 1, train loss 1.0585289001464844, validation loss 1.083281397819519\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0824261903762817, embedding dim 1, hidden size 256, num layers 1, train loss 1.0695903301239014, validation loss 1.0635950565338135\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0793536901474, embedding dim 1, hidden size 256, num layers 1, train loss 1.0588064193725586, validation loss 1.0662996768951416\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0751146078109741, embedding dim 1, hidden size 256, num layers 1, train loss 1.0366127490997314, validation loss 1.0589302778244019\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0713715553283691, embedding dim 1, hidden size 256, num layers 1, train loss 1.0763181447982788, validation loss 1.0556238889694214\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0697040557861328, embedding dim 1, hidden size 256, num layers 1, train loss 1.050079107284546, validation loss 1.0695983171463013\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0654370784759521, embedding dim 1, hidden size 256, num layers 1, train loss 1.058434247970581, validation loss 1.0530248880386353\n",
      "Epoch 250, current patience 30, model mean validation loss 1.063165307044983, embedding dim 1, hidden size 256, num layers 1, train loss 1.0398869514465332, validation loss 1.054969072341919\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0586776733398438, embedding dim 1, hidden size 256, num layers 1, train loss 1.0532565116882324, validation loss 1.0473802089691162\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0558898448944092, embedding dim 1, hidden size 256, num layers 1, train loss 0.995156466960907, validation loss 1.0412923097610474\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0526974201202393, embedding dim 1, hidden size 256, num layers 1, train loss 1.0046449899673462, validation loss 1.0407605171203613\n",
      "Epoch 290, current patience 30, model mean validation loss 1.048050045967102, embedding dim 1, hidden size 256, num layers 1, train loss 0.9856245517730713, validation loss 1.0217509269714355\n",
      "Epoch 300, current patience 30, model mean validation loss 1.044909954071045, embedding dim 1, hidden size 256, num layers 1, train loss 0.9666107296943665, validation loss 1.0305033922195435\n",
      "Epoch 310, current patience 30, model mean validation loss 1.038390874862671, embedding dim 1, hidden size 256, num layers 1, train loss 0.9892556667327881, validation loss 1.0174460411071777\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0332094430923462, embedding dim 1, hidden size 256, num layers 1, train loss 1.0007703304290771, validation loss 1.0115728378295898\n",
      "Epoch 330, current patience 30, model mean validation loss 1.025774359703064, embedding dim 1, hidden size 256, num layers 1, train loss 1.0095429420471191, validation loss 0.9954888820648193\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0177241563796997, embedding dim 1, hidden size 256, num layers 1, train loss 1.0284106731414795, validation loss 0.9829787611961365\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0118801593780518, embedding dim 1, hidden size 256, num layers 1, train loss 0.9844651222229004, validation loss 0.9945402145385742\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0049430131912231, embedding dim 1, hidden size 256, num layers 1, train loss 0.9535877704620361, validation loss 0.9852637052536011\n",
      "Epoch 370, current patience 30, model mean validation loss 0.998383641242981, embedding dim 1, hidden size 256, num layers 1, train loss 1.020836591720581, validation loss 0.9692754745483398\n",
      "Epoch 380, current patience 30, model mean validation loss 0.991465151309967, embedding dim 1, hidden size 256, num layers 1, train loss 0.9578016996383667, validation loss 0.9751555323600769\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9852187633514404, embedding dim 1, hidden size 256, num layers 1, train loss 1.0442616939544678, validation loss 0.9674750566482544\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9800506830215454, embedding dim 1, hidden size 256, num layers 1, train loss 0.9878484010696411, validation loss 0.9702280759811401\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9754738807678223, embedding dim 1, hidden size 256, num layers 1, train loss 0.9227076768875122, validation loss 0.9588743448257446\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9720748662948608, embedding dim 1, hidden size 256, num layers 1, train loss 0.9533729553222656, validation loss 0.9557864665985107\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9658401012420654, embedding dim 1, hidden size 256, num layers 1, train loss 0.891446590423584, validation loss 0.9446620941162109\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9615129232406616, embedding dim 1, hidden size 256, num layers 1, train loss 0.9729952812194824, validation loss 0.9506467580795288\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9589098691940308, embedding dim 1, hidden size 256, num layers 1, train loss 0.9413130283355713, validation loss 0.9484505653381348\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9561476707458496, embedding dim 1, hidden size 256, num layers 1, train loss 0.9044003486633301, validation loss 0.9530577659606934\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9520689249038696, embedding dim 1, hidden size 256, num layers 1, train loss 0.8959736824035645, validation loss 0.9348452091217041\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9485442638397217, embedding dim 1, hidden size 256, num layers 1, train loss 0.9142769575119019, validation loss 0.942030668258667\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9441066384315491, embedding dim 1, hidden size 256, num layers 1, train loss 0.866399884223938, validation loss 0.923373818397522\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9398586750030518, embedding dim 1, hidden size 256, num layers 1, train loss 0.8893261551856995, validation loss 0.9218025207519531\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9350804686546326, embedding dim 1, hidden size 256, num layers 1, train loss 0.899532675743103, validation loss 0.9064362049102783\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9293637275695801, embedding dim 1, hidden size 256, num layers 1, train loss 0.8662479519844055, validation loss 0.9049134254455566\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9206570386886597, embedding dim 1, hidden size 256, num layers 1, train loss 0.8449183106422424, validation loss 0.8787970542907715\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9153966307640076, embedding dim 1, hidden size 256, num layers 1, train loss 0.7927780151367188, validation loss 0.9109739065170288\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9083820581436157, embedding dim 1, hidden size 256, num layers 1, train loss 0.8466029167175293, validation loss 0.8787283897399902\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9043253660202026, embedding dim 1, hidden size 256, num layers 1, train loss 0.7889097332954407, validation loss 0.9095777273178101\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8955078125, embedding dim 1, hidden size 256, num layers 1, train loss 0.9154474139213562, validation loss 0.8528332710266113\n",
      "Epoch 580, current patience 30, model mean validation loss 0.889922022819519, embedding dim 1, hidden size 256, num layers 1, train loss 0.8800212740898132, validation loss 0.8771160244941711\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8834207057952881, embedding dim 1, hidden size 256, num layers 1, train loss 0.8023693561553955, validation loss 0.8544262051582336\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8772544860839844, embedding dim 1, hidden size 256, num layers 1, train loss 0.8141995668411255, validation loss 0.8555833101272583\n",
      "Epoch 610, current patience 30, model mean validation loss 0.873479425907135, embedding dim 1, hidden size 256, num layers 1, train loss 0.7472918033599854, validation loss 0.8485965132713318\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8664528131484985, embedding dim 1, hidden size 256, num layers 1, train loss 0.805712103843689, validation loss 0.8547613620758057\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8646345138549805, embedding dim 1, hidden size 256, num layers 1, train loss 0.7331514358520508, validation loss 0.8641815185546875\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8569660186767578, embedding dim 1, hidden size 256, num layers 1, train loss 0.7519657611846924, validation loss 0.8482299447059631\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8542121052742004, embedding dim 1, hidden size 256, num layers 1, train loss 0.8551236391067505, validation loss 0.8308020234107971\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8491210341453552, embedding dim 1, hidden size 256, num layers 1, train loss 0.8286854028701782, validation loss 0.8363875150680542\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8439849019050598, embedding dim 1, hidden size 256, num layers 1, train loss 0.783066987991333, validation loss 0.813336968421936\n",
      "Epoch 680, current patience 30, model mean validation loss 0.840211033821106, embedding dim 1, hidden size 256, num layers 1, train loss 0.6651947498321533, validation loss 0.8253924250602722\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8362776041030884, embedding dim 1, hidden size 256, num layers 1, train loss 0.6623257994651794, validation loss 0.817129373550415\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8344271779060364, embedding dim 1, hidden size 256, num layers 1, train loss 0.632324755191803, validation loss 0.8399579524993896\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8278149366378784, embedding dim 1, hidden size 256, num layers 1, train loss 0.6333235502243042, validation loss 0.8112832307815552\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8236161470413208, embedding dim 1, hidden size 256, num layers 1, train loss 0.6161938905715942, validation loss 0.8146395683288574\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8208485841751099, embedding dim 1, hidden size 256, num layers 1, train loss 0.7177377939224243, validation loss 0.8086614012718201\n",
      "Epoch 740, current patience 30, model mean validation loss 0.815453827381134, embedding dim 1, hidden size 256, num layers 1, train loss 0.7438886761665344, validation loss 0.7932296991348267\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8162848353385925, embedding dim 1, hidden size 256, num layers 1, train loss 0.6581478714942932, validation loss 0.8199846744537354\n",
      "Epoch 760, current patience 29, model mean validation loss 0.8125317096710205, embedding dim 1, hidden size 256, num layers 1, train loss 0.8526279330253601, validation loss 0.7953675389289856\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8126224875450134, embedding dim 1, hidden size 256, num layers 1, train loss 0.7728662490844727, validation loss 0.8178557753562927\n",
      "Epoch 780, current patience 29, model mean validation loss 0.8060629367828369, embedding dim 1, hidden size 256, num layers 1, train loss 0.8294135332107544, validation loss 0.7874817848205566\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8058157563209534, embedding dim 1, hidden size 256, num layers 1, train loss 0.731553316116333, validation loss 0.8093057870864868\n",
      "Epoch 800, current patience 30, model mean validation loss 0.804142951965332, embedding dim 1, hidden size 256, num layers 1, train loss 0.7448527216911316, validation loss 0.801256537437439\n",
      "Epoch 810, current patience 30, model mean validation loss 0.8051586151123047, embedding dim 1, hidden size 256, num layers 1, train loss 0.6301518678665161, validation loss 0.8167867064476013\n",
      "Epoch 820, current patience 29, model mean validation loss 0.8090327978134155, embedding dim 1, hidden size 256, num layers 1, train loss 0.72911536693573, validation loss 0.8242236375808716\n",
      "Epoch 830, current patience 28, model mean validation loss 0.8080650568008423, embedding dim 1, hidden size 256, num layers 1, train loss 0.7497246265411377, validation loss 0.8122428059577942\n",
      "Epoch 840, current patience 27, model mean validation loss 0.8090938329696655, embedding dim 1, hidden size 256, num layers 1, train loss 0.5629522204399109, validation loss 0.8035975098609924\n",
      "Epoch 850, current patience 26, model mean validation loss 0.7995915412902832, embedding dim 1, hidden size 256, num layers 1, train loss 0.6688563823699951, validation loss 0.7418375015258789\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7418375015258789_1_256_1_850.pt\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8031006455421448, embedding dim 1, hidden size 256, num layers 1, train loss 0.7294902801513672, validation loss 0.8155543804168701\n",
      "Epoch 870, current patience 29, model mean validation loss 0.797622561454773, embedding dim 1, hidden size 256, num layers 1, train loss 0.6065583229064941, validation loss 0.7654808759689331\n",
      "Epoch 880, current patience 30, model mean validation loss 0.7941055297851562, embedding dim 1, hidden size 256, num layers 1, train loss 0.6638689041137695, validation loss 0.7731205224990845\n",
      "Epoch 890, current patience 30, model mean validation loss 0.7899643182754517, embedding dim 1, hidden size 256, num layers 1, train loss 0.642564594745636, validation loss 0.7836568355560303\n",
      "Epoch 900, current patience 30, model mean validation loss 0.7878815531730652, embedding dim 1, hidden size 256, num layers 1, train loss 0.7861859798431396, validation loss 0.8075616359710693\n",
      "Epoch 910, current patience 30, model mean validation loss 0.7828333377838135, embedding dim 1, hidden size 256, num layers 1, train loss 0.7085051536560059, validation loss 0.7718571424484253\n",
      "Epoch 920, current patience 30, model mean validation loss 0.7848589420318604, embedding dim 1, hidden size 256, num layers 1, train loss 0.5692472457885742, validation loss 0.8198029398918152\n",
      "Epoch 930, current patience 29, model mean validation loss 0.7859398126602173, embedding dim 1, hidden size 256, num layers 1, train loss 0.6864349842071533, validation loss 0.7504842877388\n",
      "Epoch 940, current patience 28, model mean validation loss 0.7835687398910522, embedding dim 1, hidden size 256, num layers 1, train loss 0.7116071581840515, validation loss 0.7965858578681946\n",
      "Epoch 950, current patience 27, model mean validation loss 0.7828059792518616, embedding dim 1, hidden size 256, num layers 1, train loss 0.4942440390586853, validation loss 0.759378969669342\n",
      "Epoch 960, current patience 30, model mean validation loss 0.7839547395706177, embedding dim 1, hidden size 256, num layers 1, train loss 0.5325430631637573, validation loss 0.7823102474212646\n",
      "Epoch 970, current patience 29, model mean validation loss 0.7805353999137878, embedding dim 1, hidden size 256, num layers 1, train loss 0.6623181104660034, validation loss 0.7563020586967468\n",
      "Epoch 980, current patience 30, model mean validation loss 0.7762346267700195, embedding dim 1, hidden size 256, num layers 1, train loss 0.5594605207443237, validation loss 0.7731556296348572\n",
      "Epoch 990, current patience 30, model mean validation loss 0.7762818336486816, embedding dim 1, hidden size 256, num layers 1, train loss 0.7184460163116455, validation loss 0.772234320640564\n",
      "Epoch 1000, current patience 29, model mean validation loss 0.7701373100280762, embedding dim 1, hidden size 256, num layers 1, train loss 0.7247694730758667, validation loss 0.7706472873687744\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.7740523815155029, embedding dim 1, hidden size 256, num layers 1, train loss 0.708663821220398, validation loss 0.7818048000335693\n",
      "Epoch 1020, current patience 29, model mean validation loss 0.7684527635574341, embedding dim 1, hidden size 256, num layers 1, train loss 0.724641740322113, validation loss 0.7517889142036438\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.7702896595001221, embedding dim 1, hidden size 256, num layers 1, train loss 0.7495719194412231, validation loss 0.774074375629425\n",
      "Epoch 1040, current patience 29, model mean validation loss 0.767240583896637, embedding dim 1, hidden size 256, num layers 1, train loss 0.7089329361915588, validation loss 0.7579171657562256\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.7669492959976196, embedding dim 1, hidden size 256, num layers 1, train loss 0.5728698968887329, validation loss 0.7539721131324768\n",
      "Epoch 1060, current patience 30, model mean validation loss 0.7653554677963257, embedding dim 1, hidden size 256, num layers 1, train loss 0.675360381603241, validation loss 0.7604048252105713\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.7681297659873962, embedding dim 1, hidden size 256, num layers 1, train loss 0.6165748834609985, validation loss 0.7944285869598389\n",
      "Epoch 1080, current patience 29, model mean validation loss 0.7747976779937744, embedding dim 1, hidden size 256, num layers 1, train loss 0.526949942111969, validation loss 0.8239908218383789\n",
      "Epoch 1090, current patience 28, model mean validation loss 0.7751775979995728, embedding dim 1, hidden size 256, num layers 1, train loss 0.6920903921127319, validation loss 0.7848443984985352\n",
      "Epoch 1100, current patience 27, model mean validation loss 0.7745057940483093, embedding dim 1, hidden size 256, num layers 1, train loss 0.5889795422554016, validation loss 0.746414303779602\n",
      "Epoch 1110, current patience 26, model mean validation loss 0.7707184553146362, embedding dim 1, hidden size 256, num layers 1, train loss 0.6968678832054138, validation loss 0.743775486946106\n",
      "Epoch 1120, current patience 25, model mean validation loss 0.7721445560455322, embedding dim 1, hidden size 256, num layers 1, train loss 0.6349332332611084, validation loss 0.7693256139755249\n",
      "Epoch 1130, current patience 24, model mean validation loss 0.7773809432983398, embedding dim 1, hidden size 256, num layers 1, train loss 0.573482871055603, validation loss 0.795863926410675\n",
      "Epoch 1140, current patience 23, model mean validation loss 0.7854123115539551, embedding dim 1, hidden size 256, num layers 1, train loss 0.5240907073020935, validation loss 0.824655294418335\n",
      "Epoch 1150, current patience 22, model mean validation loss 0.7808578014373779, embedding dim 1, hidden size 256, num layers 1, train loss 0.5951502323150635, validation loss 0.7579928636550903\n",
      "Epoch 1160, current patience 21, model mean validation loss 0.7765703797340393, embedding dim 1, hidden size 256, num layers 1, train loss 0.6883096098899841, validation loss 0.7896910309791565\n",
      "Epoch 1170, current patience 20, model mean validation loss 0.7787137031555176, embedding dim 1, hidden size 256, num layers 1, train loss 0.5826671719551086, validation loss 0.8019909262657166\n",
      "Epoch 1180, current patience 19, model mean validation loss 0.7823314070701599, embedding dim 1, hidden size 256, num layers 1, train loss 0.8427692651748657, validation loss 0.7753560543060303\n",
      "Epoch 1190, current patience 18, model mean validation loss 0.7872788906097412, embedding dim 1, hidden size 256, num layers 1, train loss 0.5417589545249939, validation loss 0.7833554744720459\n",
      "Epoch 1200, current patience 17, model mean validation loss 0.789463996887207, embedding dim 1, hidden size 256, num layers 1, train loss 0.5237360596656799, validation loss 0.7868062853813171\n",
      "Epoch 1210, current patience 16, model mean validation loss 0.7915531992912292, embedding dim 1, hidden size 256, num layers 1, train loss 0.6349949836730957, validation loss 0.8125774264335632\n",
      "Epoch 1220, current patience 15, model mean validation loss 0.7856428027153015, embedding dim 1, hidden size 256, num layers 1, train loss 0.6091172099113464, validation loss 0.7773724794387817\n",
      "Epoch 1230, current patience 14, model mean validation loss 0.7885860204696655, embedding dim 1, hidden size 256, num layers 1, train loss 0.5929520130157471, validation loss 0.7815380692481995\n",
      "Epoch 1240, current patience 13, model mean validation loss 0.7851409912109375, embedding dim 1, hidden size 256, num layers 1, train loss 0.5476747155189514, validation loss 0.7621316909790039\n",
      "Epoch 1250, current patience 12, model mean validation loss 0.7821165323257446, embedding dim 1, hidden size 256, num layers 1, train loss 0.5645538568496704, validation loss 0.7777947187423706\n",
      "Epoch 1260, current patience 11, model mean validation loss 0.7844045758247375, embedding dim 1, hidden size 256, num layers 1, train loss 0.5142739415168762, validation loss 0.793660581111908\n",
      "Epoch 1270, current patience 10, model mean validation loss 0.785362958908081, embedding dim 1, hidden size 256, num layers 1, train loss 0.6198179721832275, validation loss 0.7910221219062805\n",
      "Epoch 1280, current patience 9, model mean validation loss 0.7880094051361084, embedding dim 1, hidden size 256, num layers 1, train loss 0.7057158946990967, validation loss 0.8079779148101807\n",
      "Epoch 1290, current patience 8, model mean validation loss 0.7793282866477966, embedding dim 1, hidden size 256, num layers 1, train loss 0.6938167810440063, validation loss 0.7431284189224243\n",
      "Epoch 1300, current patience 7, model mean validation loss 0.7797360420227051, embedding dim 1, hidden size 256, num layers 1, train loss 0.6424187421798706, validation loss 0.7806351780891418\n",
      "Epoch 1310, current patience 6, model mean validation loss 0.779252827167511, embedding dim 1, hidden size 256, num layers 1, train loss 0.4989156126976013, validation loss 0.7776719331741333\n",
      "Epoch 1320, current patience 5, model mean validation loss 0.7830749154090881, embedding dim 1, hidden size 256, num layers 1, train loss 0.6223531365394592, validation loss 0.7927086353302002\n",
      "Epoch 1330, current patience 4, model mean validation loss 0.7900648713111877, embedding dim 1, hidden size 256, num layers 1, train loss 0.4900728762149811, validation loss 0.8337142467498779\n",
      "Epoch 1340, current patience 3, model mean validation loss 0.7948035597801208, embedding dim 1, hidden size 256, num layers 1, train loss 0.5497913360595703, validation loss 0.8315697908401489\n",
      "Epoch 1350, current patience 2, model mean validation loss 0.7932183742523193, embedding dim 1, hidden size 256, num layers 1, train loss 0.6384719610214233, validation loss 0.7783409953117371\n",
      "Epoch 1360, current patience 1, model mean validation loss 0.7933464050292969, embedding dim 1, hidden size 256, num layers 1, train loss 0.6048129796981812, validation loss 0.8090019822120667\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1208703517913818, embedding dim 1, hidden size 512, num layers 1, train loss 1.0973005294799805, validation loss 1.1208703517913818\n",
      "Epoch 10, current patience 30, model mean validation loss 1.107940912246704, embedding dim 1, hidden size 512, num layers 1, train loss 1.1206709146499634, validation loss 1.0950113534927368\n",
      "Epoch 20, current patience 30, model mean validation loss 1.104111671447754, embedding dim 1, hidden size 512, num layers 1, train loss 1.0963242053985596, validation loss 1.0964531898498535\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1018425226211548, embedding dim 1, hidden size 512, num layers 1, train loss 1.0880985260009766, validation loss 1.0950349569320679\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0996568202972412, embedding dim 1, hidden size 512, num layers 1, train loss 1.0830943584442139, validation loss 1.0909144878387451\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0990798473358154, embedding dim 1, hidden size 512, num layers 1, train loss 1.103790044784546, validation loss 1.0961946249008179\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0983707904815674, embedding dim 1, hidden size 512, num layers 1, train loss 1.088938593864441, validation loss 1.0941169261932373\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0978162288665771, embedding dim 1, hidden size 512, num layers 1, train loss 1.0928939580917358, validation loss 1.093933343887329\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0947842597961426, embedding dim 1, hidden size 512, num layers 1, train loss 1.0959118604660034, validation loss 1.0966155529022217\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0945560932159424, embedding dim 1, hidden size 512, num layers 1, train loss 1.100800633430481, validation loss 1.0931849479675293\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094300389289856, embedding dim 1, hidden size 512, num layers 1, train loss 1.0920817852020264, validation loss 1.0944080352783203\n",
      "Epoch 110, current patience 30, model mean validation loss 1.094038486480713, embedding dim 1, hidden size 512, num layers 1, train loss 1.0873422622680664, validation loss 1.0929402112960815\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0946629047393799, embedding dim 1, hidden size 512, num layers 1, train loss 1.1053414344787598, validation loss 1.0959093570709229\n",
      "Epoch 130, current patience 29, model mean validation loss 1.0949147939682007, embedding dim 1, hidden size 512, num layers 1, train loss 1.1035385131835938, validation loss 1.0982096195220947\n",
      "Epoch 140, current patience 28, model mean validation loss 1.0949976444244385, embedding dim 1, hidden size 512, num layers 1, train loss 1.0898323059082031, validation loss 1.0947794914245605\n",
      "Epoch 150, current patience 27, model mean validation loss 1.095375657081604, embedding dim 1, hidden size 512, num layers 1, train loss 1.0884590148925781, validation loss 1.096958041191101\n",
      "Epoch 160, current patience 26, model mean validation loss 1.0952937602996826, embedding dim 1, hidden size 512, num layers 1, train loss 1.0741822719573975, validation loss 1.0959608554840088\n",
      "Epoch 170, current patience 25, model mean validation loss 1.0956308841705322, embedding dim 1, hidden size 512, num layers 1, train loss 1.0751512050628662, validation loss 1.0958821773529053\n",
      "Epoch 180, current patience 24, model mean validation loss 1.0956196784973145, embedding dim 1, hidden size 512, num layers 1, train loss 1.088076114654541, validation loss 1.0943183898925781\n",
      "Epoch 190, current patience 23, model mean validation loss 1.0955286026000977, embedding dim 1, hidden size 512, num layers 1, train loss 1.1263148784637451, validation loss 1.092210292816162\n",
      "Epoch 200, current patience 22, model mean validation loss 1.098031759262085, embedding dim 1, hidden size 512, num layers 1, train loss 1.0912811756134033, validation loss 1.1159353256225586\n",
      "Epoch 210, current patience 21, model mean validation loss 1.0976037979125977, embedding dim 1, hidden size 512, num layers 1, train loss 1.0680842399597168, validation loss 1.094785451889038\n",
      "Epoch 220, current patience 20, model mean validation loss 1.0990862846374512, embedding dim 1, hidden size 512, num layers 1, train loss 1.1027640104293823, validation loss 1.1066399812698364\n",
      "Epoch 230, current patience 19, model mean validation loss 1.0988436937332153, embedding dim 1, hidden size 512, num layers 1, train loss 1.1079603433609009, validation loss 1.0950171947479248\n",
      "Epoch 240, current patience 18, model mean validation loss 1.0993754863739014, embedding dim 1, hidden size 512, num layers 1, train loss 1.1145936250686646, validation loss 1.1002155542373657\n",
      "Epoch 250, current patience 17, model mean validation loss 1.100010633468628, embedding dim 1, hidden size 512, num layers 1, train loss 1.0917906761169434, validation loss 1.1009632349014282\n",
      "Epoch 260, current patience 16, model mean validation loss 1.0999115705490112, embedding dim 1, hidden size 512, num layers 1, train loss 1.0948809385299683, validation loss 1.0935255289077759\n",
      "Epoch 270, current patience 15, model mean validation loss 1.1005829572677612, embedding dim 1, hidden size 512, num layers 1, train loss 1.0723541975021362, validation loss 1.097581148147583\n",
      "Epoch 280, current patience 14, model mean validation loss 1.1012780666351318, embedding dim 1, hidden size 512, num layers 1, train loss 1.1020234823226929, validation loss 1.1214959621429443\n",
      "Epoch 290, current patience 13, model mean validation loss 1.1009337902069092, embedding dim 1, hidden size 512, num layers 1, train loss 1.1316072940826416, validation loss 1.0920315980911255\n",
      "Epoch 300, current patience 12, model mean validation loss 1.0994224548339844, embedding dim 1, hidden size 512, num layers 1, train loss 1.0807843208312988, validation loss 1.0945500135421753\n",
      "Epoch 310, current patience 11, model mean validation loss 1.0979809761047363, embedding dim 1, hidden size 512, num layers 1, train loss 1.0700174570083618, validation loss 1.0834848880767822\n",
      "Epoch 320, current patience 10, model mean validation loss 1.0957022905349731, embedding dim 1, hidden size 512, num layers 1, train loss 1.0776147842407227, validation loss 1.0819861888885498\n",
      "Epoch 330, current patience 9, model mean validation loss 1.0930767059326172, embedding dim 1, hidden size 512, num layers 1, train loss 1.0618808269500732, validation loss 1.0799586772918701\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0911284685134888, embedding dim 1, hidden size 512, num layers 1, train loss 1.0916674137115479, validation loss 1.0779389142990112\n",
      "Epoch 350, current patience 30, model mean validation loss 1.087907314300537, embedding dim 1, hidden size 512, num layers 1, train loss 1.0161980390548706, validation loss 1.0718128681182861\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0825873613357544, embedding dim 1, hidden size 512, num layers 1, train loss 1.0726311206817627, validation loss 1.0789356231689453\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0793462991714478, embedding dim 1, hidden size 512, num layers 1, train loss 1.0499591827392578, validation loss 1.066103458404541\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0745902061462402, embedding dim 1, hidden size 512, num layers 1, train loss 1.0476617813110352, validation loss 1.0565012693405151\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0727089643478394, embedding dim 1, hidden size 512, num layers 1, train loss 1.0597472190856934, validation loss 1.068434238433838\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0709660053253174, embedding dim 1, hidden size 512, num layers 1, train loss 1.0977988243103027, validation loss 1.0680423974990845\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0673946142196655, embedding dim 1, hidden size 512, num layers 1, train loss 1.079566240310669, validation loss 1.0513885021209717\n",
      "Epoch 420, current patience 30, model mean validation loss 1.063263177871704, embedding dim 1, hidden size 512, num layers 1, train loss 1.0709645748138428, validation loss 1.0448870658874512\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0604573488235474, embedding dim 1, hidden size 512, num layers 1, train loss 0.9588961005210876, validation loss 1.0493662357330322\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0587077140808105, embedding dim 1, hidden size 512, num layers 1, train loss 1.06498122215271, validation loss 1.0649373531341553\n",
      "Epoch 450, current patience 30, model mean validation loss 1.0561074018478394, embedding dim 1, hidden size 512, num layers 1, train loss 1.0629686117172241, validation loss 1.045302152633667\n",
      "Epoch 460, current patience 30, model mean validation loss 1.053932547569275, embedding dim 1, hidden size 512, num layers 1, train loss 1.0000317096710205, validation loss 1.03910231590271\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0506577491760254, embedding dim 1, hidden size 512, num layers 1, train loss 1.0150487422943115, validation loss 1.0422356128692627\n",
      "Epoch 480, current patience 30, model mean validation loss 1.0498292446136475, embedding dim 1, hidden size 512, num layers 1, train loss 0.9808935523033142, validation loss 1.061414122581482\n",
      "Epoch 490, current patience 30, model mean validation loss 1.0483144521713257, embedding dim 1, hidden size 512, num layers 1, train loss 0.9979343414306641, validation loss 1.0392706394195557\n",
      "Epoch 500, current patience 30, model mean validation loss 1.0456129312515259, embedding dim 1, hidden size 512, num layers 1, train loss 0.9695679545402527, validation loss 1.0232751369476318\n",
      "Epoch 510, current patience 30, model mean validation loss 1.043379306793213, embedding dim 1, hidden size 512, num layers 1, train loss 1.0215990543365479, validation loss 1.0314970016479492\n",
      "Epoch 520, current patience 30, model mean validation loss 1.0374681949615479, embedding dim 1, hidden size 512, num layers 1, train loss 1.0381813049316406, validation loss 1.0176483392715454\n",
      "Epoch 530, current patience 30, model mean validation loss 1.0314286947250366, embedding dim 1, hidden size 512, num layers 1, train loss 0.9357501268386841, validation loss 0.9969860315322876\n",
      "Epoch 540, current patience 30, model mean validation loss 1.0255584716796875, embedding dim 1, hidden size 512, num layers 1, train loss 0.8446168899536133, validation loss 0.9921414852142334\n",
      "Epoch 550, current patience 30, model mean validation loss 1.0183159112930298, embedding dim 1, hidden size 512, num layers 1, train loss 0.8952400088310242, validation loss 0.9842945337295532\n",
      "Epoch 560, current patience 30, model mean validation loss 1.0066338777542114, embedding dim 1, hidden size 512, num layers 1, train loss 0.8082495927810669, validation loss 0.9679575562477112\n",
      "Epoch 570, current patience 30, model mean validation loss 0.9969139695167542, embedding dim 1, hidden size 512, num layers 1, train loss 0.9538516402244568, validation loss 0.9615114331245422\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9869962930679321, embedding dim 1, hidden size 512, num layers 1, train loss 0.8948577642440796, validation loss 0.9439342021942139\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9798372983932495, embedding dim 1, hidden size 512, num layers 1, train loss 0.9453048706054688, validation loss 0.974224328994751\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9703326225280762, embedding dim 1, hidden size 512, num layers 1, train loss 0.8997600078582764, validation loss 0.9416113495826721\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9624871611595154, embedding dim 1, hidden size 512, num layers 1, train loss 0.786042332649231, validation loss 0.9342225193977356\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9610040187835693, embedding dim 1, hidden size 512, num layers 1, train loss 0.8549438714981079, validation loss 0.980276346206665\n",
      "Epoch 630, current patience 30, model mean validation loss 0.960086464881897, embedding dim 1, hidden size 512, num layers 1, train loss 0.7649350762367249, validation loss 0.9769542217254639\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9542053937911987, embedding dim 1, hidden size 512, num layers 1, train loss 0.8715769052505493, validation loss 0.9209088087081909\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9496803879737854, embedding dim 1, hidden size 512, num layers 1, train loss 0.9028300642967224, validation loss 0.925311267375946\n",
      "Epoch 660, current patience 30, model mean validation loss 0.9462202787399292, embedding dim 1, hidden size 512, num layers 1, train loss 0.8743091225624084, validation loss 0.9162530303001404\n",
      "Epoch 670, current patience 30, model mean validation loss 0.9405544400215149, embedding dim 1, hidden size 512, num layers 1, train loss 0.8397459983825684, validation loss 0.928897500038147\n",
      "Epoch 680, current patience 30, model mean validation loss 0.9370778203010559, embedding dim 1, hidden size 512, num layers 1, train loss 0.8389633893966675, validation loss 0.9137988090515137\n",
      "Epoch 690, current patience 30, model mean validation loss 0.9335274696350098, embedding dim 1, hidden size 512, num layers 1, train loss 0.8294097185134888, validation loss 0.9058194756507874\n",
      "Epoch 700, current patience 30, model mean validation loss 0.9254392385482788, embedding dim 1, hidden size 512, num layers 1, train loss 0.773357629776001, validation loss 0.9155710339546204\n",
      "Epoch 710, current patience 30, model mean validation loss 0.9171566963195801, embedding dim 1, hidden size 512, num layers 1, train loss 0.8156548738479614, validation loss 0.9106932878494263\n",
      "Epoch 720, current patience 30, model mean validation loss 0.9126801490783691, embedding dim 1, hidden size 512, num layers 1, train loss 0.7713280916213989, validation loss 0.8850967884063721\n",
      "Epoch 730, current patience 30, model mean validation loss 0.9071499705314636, embedding dim 1, hidden size 512, num layers 1, train loss 0.9262336492538452, validation loss 0.8810700178146362\n",
      "Epoch 740, current patience 30, model mean validation loss 0.9018682837486267, embedding dim 1, hidden size 512, num layers 1, train loss 0.7260109186172485, validation loss 0.8739994168281555\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8946120738983154, embedding dim 1, hidden size 512, num layers 1, train loss 0.8487741351127625, validation loss 0.8708475828170776\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8910343050956726, embedding dim 1, hidden size 512, num layers 1, train loss 0.8694872856140137, validation loss 0.8851768970489502\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8882526159286499, embedding dim 1, hidden size 512, num layers 1, train loss 0.8261220455169678, validation loss 0.8835659027099609\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8841822743415833, embedding dim 1, hidden size 512, num layers 1, train loss 0.872812807559967, validation loss 0.8830081224441528\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8784528970718384, embedding dim 1, hidden size 512, num layers 1, train loss 0.8745906352996826, validation loss 0.8648584485054016\n",
      "Epoch 800, current patience 30, model mean validation loss 0.8753685355186462, embedding dim 1, hidden size 512, num layers 1, train loss 0.8459228277206421, validation loss 0.8604214191436768\n",
      "Epoch 810, current patience 30, model mean validation loss 0.8740848302841187, embedding dim 1, hidden size 512, num layers 1, train loss 0.7095241546630859, validation loss 0.8708008527755737\n",
      "Epoch 820, current patience 30, model mean validation loss 0.8713805675506592, embedding dim 1, hidden size 512, num layers 1, train loss 0.7577947974205017, validation loss 0.8523651361465454\n",
      "Epoch 830, current patience 30, model mean validation loss 0.8693494200706482, embedding dim 1, hidden size 512, num layers 1, train loss 0.6324199438095093, validation loss 0.8545986413955688\n",
      "Epoch 840, current patience 30, model mean validation loss 0.8628196716308594, embedding dim 1, hidden size 512, num layers 1, train loss 0.9438170194625854, validation loss 0.8329387903213501\n",
      "Epoch 850, current patience 30, model mean validation loss 0.8586660027503967, embedding dim 1, hidden size 512, num layers 1, train loss 0.8162660598754883, validation loss 0.8503366708755493\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8538333177566528, embedding dim 1, hidden size 512, num layers 1, train loss 0.5910959243774414, validation loss 0.8443465232849121\n",
      "Epoch 870, current patience 30, model mean validation loss 0.8504806756973267, embedding dim 1, hidden size 512, num layers 1, train loss 0.8315593004226685, validation loss 0.8380376100540161\n",
      "Epoch 880, current patience 30, model mean validation loss 0.8502918481826782, embedding dim 1, hidden size 512, num layers 1, train loss 0.7682806253433228, validation loss 0.8589111566543579\n",
      "Epoch 890, current patience 30, model mean validation loss 0.8482643365859985, embedding dim 1, hidden size 512, num layers 1, train loss 0.6773348450660706, validation loss 0.8545805811882019\n",
      "Epoch 900, current patience 30, model mean validation loss 0.8491610884666443, embedding dim 1, hidden size 512, num layers 1, train loss 0.7508116960525513, validation loss 0.8595390319824219\n",
      "Epoch 910, current patience 29, model mean validation loss 0.8448523283004761, embedding dim 1, hidden size 512, num layers 1, train loss 0.7459217309951782, validation loss 0.8201286196708679\n",
      "Epoch 920, current patience 30, model mean validation loss 0.8420088291168213, embedding dim 1, hidden size 512, num layers 1, train loss 0.8101492524147034, validation loss 0.8101907968521118\n",
      "Epoch 930, current patience 30, model mean validation loss 0.8401620984077454, embedding dim 1, hidden size 512, num layers 1, train loss 0.7815195322036743, validation loss 0.8355624675750732\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8426556587219238, embedding dim 1, hidden size 512, num layers 1, train loss 0.6146631240844727, validation loss 0.8642950057983398\n",
      "Epoch 950, current patience 29, model mean validation loss 0.8466959595680237, embedding dim 1, hidden size 512, num layers 1, train loss 0.7665615081787109, validation loss 0.8703596591949463\n",
      "Epoch 960, current patience 28, model mean validation loss 0.8463409543037415, embedding dim 1, hidden size 512, num layers 1, train loss 0.7052152156829834, validation loss 0.8560714721679688\n",
      "Epoch 970, current patience 27, model mean validation loss 0.8441248536109924, embedding dim 1, hidden size 512, num layers 1, train loss 0.8084988594055176, validation loss 0.8368517160415649\n",
      "Epoch 980, current patience 26, model mean validation loss 0.8390264511108398, embedding dim 1, hidden size 512, num layers 1, train loss 0.6716911792755127, validation loss 0.8187515139579773\n",
      "Epoch 990, current patience 30, model mean validation loss 0.8418478965759277, embedding dim 1, hidden size 512, num layers 1, train loss 0.674541175365448, validation loss 0.8427004814147949\n",
      "Epoch 1000, current patience 29, model mean validation loss 0.8467381596565247, embedding dim 1, hidden size 512, num layers 1, train loss 0.6840025782585144, validation loss 0.8493131399154663\n",
      "Epoch 1010, current patience 28, model mean validation loss 0.8497055172920227, embedding dim 1, hidden size 512, num layers 1, train loss 0.8050311803817749, validation loss 0.8593008518218994\n",
      "Epoch 1020, current patience 27, model mean validation loss 0.846712589263916, embedding dim 1, hidden size 512, num layers 1, train loss 0.6216848492622375, validation loss 0.840351939201355\n",
      "Epoch 1030, current patience 26, model mean validation loss 0.8382577896118164, embedding dim 1, hidden size 512, num layers 1, train loss 0.6161574721336365, validation loss 0.802721381187439\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.8343192934989929, embedding dim 1, hidden size 512, num layers 1, train loss 0.7338351011276245, validation loss 0.8245630860328674\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.8353986740112305, embedding dim 1, hidden size 512, num layers 1, train loss 0.6905838847160339, validation loss 0.8454867005348206\n",
      "Epoch 1060, current patience 29, model mean validation loss 0.8340553045272827, embedding dim 1, hidden size 512, num layers 1, train loss 0.703342616558075, validation loss 0.8080044984817505\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.8325928449630737, embedding dim 1, hidden size 512, num layers 1, train loss 0.6576316356658936, validation loss 0.8310009241104126\n",
      "Epoch 1080, current patience 30, model mean validation loss 0.8304834365844727, embedding dim 1, hidden size 512, num layers 1, train loss 0.680145263671875, validation loss 0.832438588142395\n",
      "Epoch 1090, current patience 30, model mean validation loss 0.8255959749221802, embedding dim 1, hidden size 512, num layers 1, train loss 0.7250218391418457, validation loss 0.8202008008956909\n",
      "Epoch 1100, current patience 30, model mean validation loss 0.8218233585357666, embedding dim 1, hidden size 512, num layers 1, train loss 0.5369439125061035, validation loss 0.8101711869239807\n",
      "Epoch 1110, current patience 30, model mean validation loss 0.8215526342391968, embedding dim 1, hidden size 512, num layers 1, train loss 0.5071233510971069, validation loss 0.8005552291870117\n",
      "Epoch 1120, current patience 30, model mean validation loss 0.8198583126068115, embedding dim 1, hidden size 512, num layers 1, train loss 0.6113986968994141, validation loss 0.811008632183075\n",
      "Epoch 1130, current patience 30, model mean validation loss 0.8194723129272461, embedding dim 1, hidden size 512, num layers 1, train loss 0.5517780780792236, validation loss 0.8423985838890076\n",
      "Epoch 1140, current patience 30, model mean validation loss 0.8241803646087646, embedding dim 1, hidden size 512, num layers 1, train loss 0.7019494771957397, validation loss 0.8456690311431885\n",
      "Epoch 1150, current patience 29, model mean validation loss 0.8220958709716797, embedding dim 1, hidden size 512, num layers 1, train loss 0.6892390251159668, validation loss 0.8143250942230225\n",
      "Epoch 1160, current patience 28, model mean validation loss 0.8172508478164673, embedding dim 1, hidden size 512, num layers 1, train loss 0.5441263914108276, validation loss 0.7936779260635376\n",
      "Epoch 1170, current patience 30, model mean validation loss 0.8158718347549438, embedding dim 1, hidden size 512, num layers 1, train loss 0.7449550032615662, validation loss 0.8091690540313721\n",
      "Epoch 1180, current patience 30, model mean validation loss 0.8161741495132446, embedding dim 1, hidden size 512, num layers 1, train loss 0.6208474636077881, validation loss 0.812589168548584\n",
      "Epoch 1190, current patience 29, model mean validation loss 0.8202816843986511, embedding dim 1, hidden size 512, num layers 1, train loss 0.768485426902771, validation loss 0.8334157466888428\n",
      "Epoch 1200, current patience 28, model mean validation loss 0.8192054629325867, embedding dim 1, hidden size 512, num layers 1, train loss 0.591090977191925, validation loss 0.8023989796638489\n",
      "Epoch 1210, current patience 27, model mean validation loss 0.8179096579551697, embedding dim 1, hidden size 512, num layers 1, train loss 0.6537685394287109, validation loss 0.832032322883606\n",
      "Epoch 1220, current patience 26, model mean validation loss 0.8133082985877991, embedding dim 1, hidden size 512, num layers 1, train loss 0.5664339065551758, validation loss 0.8088580369949341\n",
      "Epoch 1230, current patience 30, model mean validation loss 0.8100470900535583, embedding dim 1, hidden size 512, num layers 1, train loss 0.7543498277664185, validation loss 0.7882355451583862\n",
      "Epoch 1240, current patience 30, model mean validation loss 0.8117324113845825, embedding dim 1, hidden size 512, num layers 1, train loss 0.7034658193588257, validation loss 0.8071607351303101\n",
      "Epoch 1250, current patience 29, model mean validation loss 0.8120517730712891, embedding dim 1, hidden size 512, num layers 1, train loss 0.6816354393959045, validation loss 0.8117238283157349\n",
      "Epoch 1260, current patience 28, model mean validation loss 0.8138587474822998, embedding dim 1, hidden size 512, num layers 1, train loss 0.6161901950836182, validation loss 0.8270441293716431\n",
      "Epoch 1270, current patience 27, model mean validation loss 0.8113125562667847, embedding dim 1, hidden size 512, num layers 1, train loss 0.6126514673233032, validation loss 0.8130466341972351\n",
      "Epoch 1280, current patience 26, model mean validation loss 0.8122637271881104, embedding dim 1, hidden size 512, num layers 1, train loss 0.49318528175354004, validation loss 0.8100089430809021\n",
      "Epoch 1290, current patience 25, model mean validation loss 0.8120173215866089, embedding dim 1, hidden size 512, num layers 1, train loss 0.7086488008499146, validation loss 0.8300609588623047\n",
      "Epoch 1300, current patience 24, model mean validation loss 0.8133955001831055, embedding dim 1, hidden size 512, num layers 1, train loss 0.6454640030860901, validation loss 0.8198833465576172\n",
      "Epoch 1310, current patience 23, model mean validation loss 0.8141161203384399, embedding dim 1, hidden size 512, num layers 1, train loss 0.44281232357025146, validation loss 0.794000506401062\n",
      "Epoch 1320, current patience 22, model mean validation loss 0.816653311252594, embedding dim 1, hidden size 512, num layers 1, train loss 0.625162661075592, validation loss 0.8274579048156738\n",
      "Epoch 1330, current patience 21, model mean validation loss 0.8206443786621094, embedding dim 1, hidden size 512, num layers 1, train loss 0.4149264097213745, validation loss 0.8436524868011475\n",
      "Epoch 1340, current patience 20, model mean validation loss 0.8191463947296143, embedding dim 1, hidden size 512, num layers 1, train loss 0.651600182056427, validation loss 0.8150608539581299\n",
      "Epoch 1350, current patience 19, model mean validation loss 0.820564866065979, embedding dim 1, hidden size 512, num layers 1, train loss 0.6548404097557068, validation loss 0.8243941068649292\n",
      "Epoch 1360, current patience 18, model mean validation loss 0.8248410820960999, embedding dim 1, hidden size 512, num layers 1, train loss 0.7355642318725586, validation loss 0.8442181348800659\n",
      "Epoch 1370, current patience 17, model mean validation loss 0.8241143822669983, embedding dim 1, hidden size 512, num layers 1, train loss 0.5348174571990967, validation loss 0.8242475390434265\n",
      "Epoch 1380, current patience 16, model mean validation loss 0.8184151649475098, embedding dim 1, hidden size 512, num layers 1, train loss 0.5566082000732422, validation loss 0.7742900848388672\n",
      "Epoch 1390, current patience 15, model mean validation loss 0.8215829133987427, embedding dim 1, hidden size 512, num layers 1, train loss 0.5131182670593262, validation loss 0.8193419575691223\n",
      "Epoch 1400, current patience 14, model mean validation loss 0.8225960731506348, embedding dim 1, hidden size 512, num layers 1, train loss 0.6979113817214966, validation loss 0.8355633616447449\n",
      "Epoch 1410, current patience 13, model mean validation loss 0.8226946592330933, embedding dim 1, hidden size 512, num layers 1, train loss 0.5062963366508484, validation loss 0.844441294670105\n",
      "Epoch 1420, current patience 12, model mean validation loss 0.8313872814178467, embedding dim 1, hidden size 512, num layers 1, train loss 0.521575927734375, validation loss 0.8846015334129333\n",
      "Epoch 1430, current patience 11, model mean validation loss 0.8357532024383545, embedding dim 1, hidden size 512, num layers 1, train loss 0.5572202801704407, validation loss 0.8593219518661499\n",
      "Epoch 1440, current patience 10, model mean validation loss 0.8354692459106445, embedding dim 1, hidden size 512, num layers 1, train loss 0.7530999183654785, validation loss 0.8419457674026489\n",
      "Epoch 1450, current patience 9, model mean validation loss 0.8324388265609741, embedding dim 1, hidden size 512, num layers 1, train loss 0.5367851853370667, validation loss 0.8000043034553528\n",
      "Epoch 1460, current patience 8, model mean validation loss 0.8419356346130371, embedding dim 1, hidden size 512, num layers 1, train loss 0.5422686338424683, validation loss 0.8502643704414368\n",
      "Epoch 1470, current patience 7, model mean validation loss 0.845552921295166, embedding dim 1, hidden size 512, num layers 1, train loss 0.6079419255256653, validation loss 0.8482804894447327\n",
      "Epoch 1480, current patience 6, model mean validation loss 0.8461912870407104, embedding dim 1, hidden size 512, num layers 1, train loss 0.6795943975448608, validation loss 0.8406705856323242\n",
      "Epoch 1490, current patience 5, model mean validation loss 0.8443091511726379, embedding dim 1, hidden size 512, num layers 1, train loss 0.608906626701355, validation loss 0.8293839693069458\n",
      "Epoch 1500, current patience 4, model mean validation loss 0.8472046852111816, embedding dim 1, hidden size 512, num layers 1, train loss 0.7010898590087891, validation loss 0.9077657461166382\n",
      "Epoch 1510, current patience 3, model mean validation loss 0.847017228603363, embedding dim 1, hidden size 512, num layers 1, train loss 0.5552271604537964, validation loss 0.8578224778175354\n",
      "Epoch 1520, current patience 2, model mean validation loss 0.8487098813056946, embedding dim 1, hidden size 512, num layers 1, train loss 0.4873294234275818, validation loss 0.8554869294166565\n",
      "Epoch 1530, current patience 1, model mean validation loss 0.8541202545166016, embedding dim 1, hidden size 512, num layers 1, train loss 0.7448492050170898, validation loss 0.8432873487472534\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2512038946151733, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1014636754989624, validation loss 1.2512038946151733\n",
      "Epoch 10, current patience 30, model mean validation loss 1.5802249908447266, embedding dim 1, hidden size 1024, num layers 1, train loss 1.2061996459960938, validation loss 1.9092459678649902\n",
      "Epoch 20, current patience 29, model mean validation loss 1.4694470167160034, embedding dim 1, hidden size 1024, num layers 1, train loss 1.2230325937271118, validation loss 1.2478909492492676\n",
      "Epoch 30, current patience 28, model mean validation loss 1.3808352947235107, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1238594055175781, validation loss 1.1150002479553223\n",
      "Epoch 40, current patience 27, model mean validation loss 1.3318264484405518, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1269841194152832, validation loss 1.135791540145874\n",
      "Epoch 50, current patience 26, model mean validation loss 1.3060163259506226, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1026384830474854, validation loss 1.1769654750823975\n",
      "Epoch 60, current patience 25, model mean validation loss 1.2783008813858032, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1264524459838867, validation loss 1.112007737159729\n",
      "Epoch 70, current patience 24, model mean validation loss 1.2589659690856934, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1003782749176025, validation loss 1.1236228942871094\n",
      "Epoch 80, current patience 23, model mean validation loss 1.2419990301132202, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1241631507873535, validation loss 1.1154680252075195\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1459670066833496, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0990386009216309, validation loss 1.1409894227981567\n",
      "Epoch 100, current patience 30, model mean validation loss 1.129996657371521, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0914936065673828, validation loss 1.1201279163360596\n",
      "Epoch 110, current patience 30, model mean validation loss 1.137227177619934, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1980417966842651, validation loss 1.1728441715240479\n",
      "Epoch 120, current patience 29, model mean validation loss 1.1356947422027588, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1459519863128662, validation loss 1.123532772064209\n",
      "Epoch 130, current patience 28, model mean validation loss 1.1322442293167114, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1852319240570068, validation loss 1.149361252784729\n",
      "Epoch 140, current patience 27, model mean validation loss 1.1337149143218994, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1131861209869385, validation loss 1.123772382736206\n",
      "Epoch 150, current patience 26, model mean validation loss 1.1305055618286133, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1241284608840942, validation loss 1.0979489088058472\n",
      "Epoch 160, current patience 25, model mean validation loss 1.1325095891952515, embedding dim 1, hidden size 1024, num layers 1, train loss 1.187424659729004, validation loss 1.1314997673034668\n",
      "Epoch 170, current patience 24, model mean validation loss 1.130509853363037, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1361517906188965, validation loss 1.124991774559021\n",
      "Epoch 180, current patience 23, model mean validation loss 1.1280364990234375, embedding dim 1, hidden size 1024, num layers 1, train loss 1.135392665863037, validation loss 1.1003413200378418\n",
      "Epoch 190, current patience 30, model mean validation loss 1.1178221702575684, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1594316959381104, validation loss 1.0911293029785156\n",
      "Epoch 200, current patience 30, model mean validation loss 1.1153948307037354, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0893627405166626, validation loss 1.1041146516799927\n",
      "Epoch 210, current patience 30, model mean validation loss 1.1087650060653687, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0982036590576172, validation loss 1.0963222980499268\n",
      "Epoch 220, current patience 30, model mean validation loss 1.105621099472046, embedding dim 1, hidden size 1024, num layers 1, train loss 1.061531901359558, validation loss 1.0986212491989136\n",
      "Epoch 230, current patience 30, model mean validation loss 1.1056880950927734, embedding dim 1, hidden size 1024, num layers 1, train loss 1.082399845123291, validation loss 1.098484754562378\n",
      "Epoch 240, current patience 29, model mean validation loss 1.102096676826477, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0954173803329468, validation loss 1.1027675867080688\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0996477603912354, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0915343761444092, validation loss 1.1054012775421143\n",
      "Epoch 260, current patience 30, model mean validation loss 1.101830005645752, embedding dim 1, hidden size 1024, num layers 1, train loss 1.087125539779663, validation loss 1.1177990436553955\n",
      "Epoch 270, current patience 29, model mean validation loss 1.1007636785507202, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1004292964935303, validation loss 1.08259916305542\n",
      "Epoch 280, current patience 28, model mean validation loss 1.0987772941589355, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0962598323822021, validation loss 1.0882222652435303\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0976879596710205, embedding dim 1, hidden size 1024, num layers 1, train loss 1.075763463973999, validation loss 1.0876083374023438\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0951391458511353, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1119568347930908, validation loss 1.078230857849121\n",
      "Epoch 310, current patience 30, model mean validation loss 1.10107421875, embedding dim 1, hidden size 1024, num layers 1, train loss 1.098596215248108, validation loss 1.1459650993347168\n",
      "Epoch 320, current patience 29, model mean validation loss 1.0995070934295654, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1089388132095337, validation loss 1.09023118019104\n",
      "Epoch 330, current patience 28, model mean validation loss 1.105482816696167, embedding dim 1, hidden size 1024, num layers 1, train loss 1.141634225845337, validation loss 1.1532074213027954\n",
      "Epoch 340, current patience 27, model mean validation loss 1.1046292781829834, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0974303483963013, validation loss 1.1109694242477417\n",
      "Epoch 350, current patience 26, model mean validation loss 1.1108909845352173, embedding dim 1, hidden size 1024, num layers 1, train loss 1.1595999002456665, validation loss 1.1326932907104492\n",
      "Epoch 360, current patience 25, model mean validation loss 1.1148409843444824, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0815550088882446, validation loss 1.1198220252990723\n",
      "Epoch 370, current patience 24, model mean validation loss 1.1126887798309326, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0403200387954712, validation loss 1.0703907012939453\n",
      "Epoch 380, current patience 23, model mean validation loss 1.110339879989624, embedding dim 1, hidden size 1024, num layers 1, train loss 1.039893627166748, validation loss 1.0594408512115479\n",
      "Epoch 390, current patience 22, model mean validation loss 1.1019994020462036, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0574755668640137, validation loss 1.0792409181594849\n",
      "Epoch 400, current patience 21, model mean validation loss 1.0977425575256348, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0564444065093994, validation loss 1.0561763048171997\n",
      "Epoch 410, current patience 20, model mean validation loss 1.0865592956542969, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0742299556732178, validation loss 1.0637409687042236\n",
      "Epoch 420, current patience 30, model mean validation loss 1.084890365600586, embedding dim 1, hidden size 1024, num layers 1, train loss 1.044158935546875, validation loss 1.0976181030273438\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0741620063781738, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0189929008483887, validation loss 1.046866536140442\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0686759948730469, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9464982151985168, validation loss 1.0759327411651611\n",
      "Epoch 450, current patience 30, model mean validation loss 1.0654934644699097, embedding dim 1, hidden size 1024, num layers 1, train loss 1.086575984954834, validation loss 1.0449309349060059\n",
      "Epoch 460, current patience 30, model mean validation loss 1.063128113746643, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0652614831924438, validation loss 1.0405175685882568\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0588805675506592, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9439313411712646, validation loss 1.0452607870101929\n",
      "Epoch 480, current patience 30, model mean validation loss 1.0562866926193237, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0561414957046509, validation loss 1.0354259014129639\n",
      "Epoch 490, current patience 30, model mean validation loss 1.0552380084991455, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9821337461471558, validation loss 1.0553513765335083\n",
      "Epoch 500, current patience 30, model mean validation loss 1.0449738502502441, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0606663227081299, validation loss 1.0155047178268433\n",
      "Epoch 510, current patience 30, model mean validation loss 1.0420572757720947, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0361993312835693, validation loss 1.0235347747802734\n",
      "Epoch 520, current patience 30, model mean validation loss 1.0316524505615234, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0568130016326904, validation loss 0.9926942586898804\n",
      "Epoch 530, current patience 30, model mean validation loss 1.030777931213379, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9622498750686646, validation loss 1.0379340648651123\n",
      "Epoch 540, current patience 30, model mean validation loss 1.0251108407974243, embedding dim 1, hidden size 1024, num layers 1, train loss 0.996872067451477, validation loss 0.9951807260513306\n",
      "Epoch 550, current patience 30, model mean validation loss 1.0190563201904297, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9115960597991943, validation loss 0.9968241453170776\n",
      "Epoch 560, current patience 30, model mean validation loss 1.016297698020935, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9824740290641785, validation loss 1.013357400894165\n",
      "Epoch 570, current patience 30, model mean validation loss 1.0031914710998535, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9337961673736572, validation loss 0.9505021572113037\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9969711303710938, embedding dim 1, hidden size 1024, num layers 1, train loss 1.0493191480636597, validation loss 0.9657412767410278\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9890031814575195, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9338383674621582, validation loss 0.9597916007041931\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9840942621231079, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9339936971664429, validation loss 0.9534229040145874\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9735392332077026, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9321163296699524, validation loss 0.953493595123291\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9670391082763672, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9278559684753418, validation loss 0.9431797862052917\n",
      "Epoch 630, current patience 30, model mean validation loss 0.9607818126678467, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7600072622299194, validation loss 0.9467651844024658\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9488472938537598, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9587193727493286, validation loss 0.9178813099861145\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9452958106994629, embedding dim 1, hidden size 1024, num layers 1, train loss 0.815208911895752, validation loss 0.9220908284187317\n",
      "Epoch 660, current patience 30, model mean validation loss 0.9359496235847473, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9486196637153625, validation loss 0.8909720182418823\n",
      "Epoch 670, current patience 30, model mean validation loss 0.932097852230072, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7663989663124084, validation loss 0.9289772510528564\n",
      "Epoch 680, current patience 30, model mean validation loss 0.9307990074157715, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9201141595840454, validation loss 0.9430322647094727\n",
      "Epoch 690, current patience 30, model mean validation loss 0.9222307205200195, embedding dim 1, hidden size 1024, num layers 1, train loss 0.9200078248977661, validation loss 0.8849477171897888\n",
      "Epoch 700, current patience 30, model mean validation loss 0.916114091873169, embedding dim 1, hidden size 1024, num layers 1, train loss 0.852910578250885, validation loss 0.894246518611908\n",
      "Epoch 710, current patience 30, model mean validation loss 0.9080828428268433, embedding dim 1, hidden size 1024, num layers 1, train loss 0.767307698726654, validation loss 0.8825148940086365\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8999555706977844, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7909189462661743, validation loss 0.8528629541397095\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8945559859275818, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8892448544502258, validation loss 0.8788943290710449\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8915335536003113, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7806247472763062, validation loss 0.8667922019958496\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8850296139717102, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8466756939888, validation loss 0.876945972442627\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8745006918907166, embedding dim 1, hidden size 1024, num layers 1, train loss 0.766952633857727, validation loss 0.8588008284568787\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8743444085121155, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7955078482627869, validation loss 0.8836974501609802\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8700693249702454, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7233043909072876, validation loss 0.8600460290908813\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8636489510536194, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6961167454719543, validation loss 0.8311520218849182\n",
      "Epoch 800, current patience 30, model mean validation loss 0.8669592142105103, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7493948936462402, validation loss 0.8793452978134155\n",
      "Epoch 810, current patience 29, model mean validation loss 0.8617056608200073, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8206929564476013, validation loss 0.8368654251098633\n",
      "Epoch 820, current patience 30, model mean validation loss 0.8577847480773926, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7316723465919495, validation loss 0.8354246616363525\n",
      "Epoch 830, current patience 30, model mean validation loss 0.8527332544326782, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8170288801193237, validation loss 0.8365342617034912\n",
      "Epoch 840, current patience 30, model mean validation loss 0.8580924868583679, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7599945068359375, validation loss 0.9016742706298828\n",
      "Epoch 850, current patience 29, model mean validation loss 0.8499274253845215, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6861883401870728, validation loss 0.8183772563934326\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8444007635116577, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6316534280776978, validation loss 0.8158329725265503\n",
      "Epoch 870, current patience 30, model mean validation loss 0.8467934131622314, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6917920708656311, validation loss 0.8502936363220215\n",
      "Epoch 880, current patience 29, model mean validation loss 0.8420536518096924, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7236328125, validation loss 0.8414269685745239\n",
      "Epoch 890, current patience 30, model mean validation loss 0.8431434631347656, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7195854187011719, validation loss 0.8455835580825806\n",
      "Epoch 900, current patience 29, model mean validation loss 0.8412505388259888, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8277053236961365, validation loss 0.8202813267707825\n",
      "Epoch 910, current patience 30, model mean validation loss 0.8397353887557983, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8186379075050354, validation loss 0.8244125843048096\n",
      "Epoch 920, current patience 30, model mean validation loss 0.8359560966491699, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7708841562271118, validation loss 0.8714405298233032\n",
      "Epoch 930, current patience 30, model mean validation loss 0.8396738171577454, embedding dim 1, hidden size 1024, num layers 1, train loss 0.794773280620575, validation loss 0.8481186628341675\n",
      "Epoch 940, current patience 29, model mean validation loss 0.8443588018417358, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7544934749603271, validation loss 0.8533132672309875\n",
      "Epoch 950, current patience 28, model mean validation loss 0.8387887477874756, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7700154781341553, validation loss 0.8057330846786499\n",
      "Epoch 960, current patience 27, model mean validation loss 0.8392677307128906, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6789741516113281, validation loss 0.8452593684196472\n",
      "Epoch 970, current patience 26, model mean validation loss 0.8338232040405273, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8159263134002686, validation loss 0.8020268082618713\n",
      "Epoch 980, current patience 30, model mean validation loss 0.8397780656814575, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8834530115127563, validation loss 0.8679202795028687\n",
      "Epoch 990, current patience 29, model mean validation loss 0.836539089679718, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6782476902008057, validation loss 0.7985005974769592\n",
      "Epoch 1000, current patience 28, model mean validation loss 0.8306396007537842, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7249433994293213, validation loss 0.8242449164390564\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.8292733430862427, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7631561160087585, validation loss 0.837188184261322\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.8254495859146118, embedding dim 1, hidden size 1024, num layers 1, train loss 0.764519214630127, validation loss 0.8227232694625854\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.8251850605010986, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6561696529388428, validation loss 0.8036170601844788\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.8203234076499939, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6759344935417175, validation loss 0.806365966796875\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.8232385516166687, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7027010917663574, validation loss 0.8253480792045593\n",
      "Epoch 1060, current patience 29, model mean validation loss 0.8169898986816406, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6047343015670776, validation loss 0.8179315328598022\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.8215245008468628, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5935065746307373, validation loss 0.8347772359848022\n",
      "Epoch 1080, current patience 29, model mean validation loss 0.8229824900627136, embedding dim 1, hidden size 1024, num layers 1, train loss 0.542293131351471, validation loss 0.8359085321426392\n",
      "Epoch 1090, current patience 28, model mean validation loss 0.8176299333572388, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6859311461448669, validation loss 0.7943676710128784\n",
      "Epoch 1100, current patience 27, model mean validation loss 0.8152679204940796, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6329400539398193, validation loss 0.8038275837898254\n",
      "Epoch 1110, current patience 30, model mean validation loss 0.8154165744781494, embedding dim 1, hidden size 1024, num layers 1, train loss 0.8620275259017944, validation loss 0.8048060536384583\n",
      "Epoch 1120, current patience 29, model mean validation loss 0.814919114112854, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6182809472084045, validation loss 0.8023861050605774\n",
      "Epoch 1130, current patience 30, model mean validation loss 0.8127562999725342, embedding dim 1, hidden size 1024, num layers 1, train loss 0.695215106010437, validation loss 0.8080456256866455\n",
      "Epoch 1140, current patience 30, model mean validation loss 0.8137717843055725, embedding dim 1, hidden size 1024, num layers 1, train loss 0.645605206489563, validation loss 0.8260552883148193\n",
      "Epoch 1150, current patience 29, model mean validation loss 0.811034083366394, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6736841797828674, validation loss 0.8128756880760193\n",
      "Epoch 1160, current patience 30, model mean validation loss 0.8126630783081055, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6207358837127686, validation loss 0.8489412069320679\n",
      "Epoch 1170, current patience 29, model mean validation loss 0.814664900302887, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6998514533042908, validation loss 0.8103817105293274\n",
      "Epoch 1180, current patience 28, model mean validation loss 0.8167510032653809, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7259761095046997, validation loss 0.8205164670944214\n",
      "Epoch 1190, current patience 27, model mean validation loss 0.8168509006500244, embedding dim 1, hidden size 1024, num layers 1, train loss 0.826427698135376, validation loss 0.8056048154830933\n",
      "Epoch 1200, current patience 26, model mean validation loss 0.8194578289985657, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6184554100036621, validation loss 0.8232424259185791\n",
      "Epoch 1210, current patience 25, model mean validation loss 0.8211943507194519, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5401182174682617, validation loss 0.8219371438026428\n",
      "Epoch 1220, current patience 24, model mean validation loss 0.8225734829902649, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5184071660041809, validation loss 0.8370883464813232\n",
      "Epoch 1230, current patience 23, model mean validation loss 0.8251757621765137, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5657706260681152, validation loss 0.8336942195892334\n",
      "Epoch 1240, current patience 22, model mean validation loss 0.8221948742866516, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7308807969093323, validation loss 0.8250939846038818\n",
      "Epoch 1250, current patience 21, model mean validation loss 0.8202182650566101, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6256161332130432, validation loss 0.7945690155029297\n",
      "Epoch 1260, current patience 20, model mean validation loss 0.8211038708686829, embedding dim 1, hidden size 1024, num layers 1, train loss 0.790065348148346, validation loss 0.8276011347770691\n",
      "Epoch 1270, current patience 19, model mean validation loss 0.8270288705825806, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7871479988098145, validation loss 0.8530049920082092\n",
      "Epoch 1280, current patience 18, model mean validation loss 0.825411319732666, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6322746276855469, validation loss 0.8103020191192627\n",
      "Epoch 1290, current patience 17, model mean validation loss 0.8263060450553894, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5229715704917908, validation loss 0.8290944695472717\n",
      "Epoch 1300, current patience 16, model mean validation loss 0.8300396800041199, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5939168930053711, validation loss 0.8669574856758118\n",
      "Epoch 1310, current patience 15, model mean validation loss 0.8272484540939331, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5942296981811523, validation loss 0.8113642930984497\n",
      "Epoch 1320, current patience 14, model mean validation loss 0.8276855945587158, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5297517776489258, validation loss 0.8285910487174988\n",
      "Epoch 1330, current patience 13, model mean validation loss 0.8294490575790405, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6311424970626831, validation loss 0.8086770176887512\n",
      "Epoch 1340, current patience 12, model mean validation loss 0.8297790884971619, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7024154663085938, validation loss 0.8302414417266846\n",
      "Epoch 1350, current patience 11, model mean validation loss 0.8279987573623657, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7555467486381531, validation loss 0.8387624621391296\n",
      "Epoch 1360, current patience 10, model mean validation loss 0.8305097818374634, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6102997064590454, validation loss 0.8303899765014648\n",
      "Epoch 1370, current patience 9, model mean validation loss 0.827461302280426, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5899055600166321, validation loss 0.8047066926956177\n",
      "Epoch 1380, current patience 8, model mean validation loss 0.8260049819946289, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5676466226577759, validation loss 0.8553068041801453\n",
      "Epoch 1390, current patience 7, model mean validation loss 0.8306294083595276, embedding dim 1, hidden size 1024, num layers 1, train loss 0.5998708009719849, validation loss 0.8483593463897705\n",
      "Epoch 1400, current patience 6, model mean validation loss 0.8305150270462036, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6967675685882568, validation loss 0.8276762366294861\n",
      "Epoch 1410, current patience 5, model mean validation loss 0.8338428139686584, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6395081877708435, validation loss 0.8352993726730347\n",
      "Epoch 1420, current patience 4, model mean validation loss 0.8352708220481873, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6365380883216858, validation loss 0.8416656255722046\n",
      "Epoch 1430, current patience 3, model mean validation loss 0.8351266384124756, embedding dim 1, hidden size 1024, num layers 1, train loss 0.7262473106384277, validation loss 0.8376091718673706\n",
      "Epoch 1440, current patience 2, model mean validation loss 0.8357031345367432, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6276340484619141, validation loss 0.8350022435188293\n",
      "Epoch 1450, current patience 1, model mean validation loss 0.8380994200706482, embedding dim 1, hidden size 1024, num layers 1, train loss 0.6711938977241516, validation loss 0.8238770961761475\n",
      "Epoch 0, current patience 30, model mean validation loss 1.3403127193450928, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1002180576324463, validation loss 1.3403127193450928\n",
      "Epoch 10, current patience 30, model mean validation loss 1.3990203142166138, embedding dim 1, hidden size 2048, num layers 1, train loss 1.4225876331329346, validation loss 1.4577279090881348\n",
      "Epoch 20, current patience 29, model mean validation loss 1.368796706199646, embedding dim 1, hidden size 2048, num layers 1, train loss 1.3053358793258667, validation loss 1.308349370956421\n",
      "Epoch 30, current patience 28, model mean validation loss 1.3559914827346802, embedding dim 1, hidden size 2048, num layers 1, train loss 1.220348596572876, validation loss 1.3175760507583618\n",
      "Epoch 40, current patience 27, model mean validation loss 1.3166353702545166, embedding dim 1, hidden size 2048, num layers 1, train loss 1.3413249254226685, validation loss 1.15921151638031\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2952226400375366, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1682305335998535, validation loss 1.1881585121154785\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2716771364212036, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1307473182678223, validation loss 1.130403995513916\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2578845024108887, embedding dim 1, hidden size 2048, num layers 1, train loss 1.127636432647705, validation loss 1.1613365411758423\n",
      "Epoch 80, current patience 30, model mean validation loss 1.2377405166625977, embedding dim 1, hidden size 2048, num layers 1, train loss 1.111595630645752, validation loss 1.1791610717773438\n",
      "Epoch 90, current patience 30, model mean validation loss 1.2025765180587769, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1619372367858887, validation loss 1.176414966583252\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1761703491210938, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1566975116729736, validation loss 1.0970996618270874\n",
      "Epoch 110, current patience 30, model mean validation loss 1.151740312576294, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0729894638061523, validation loss 1.1221364736557007\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1539123058319092, embedding dim 1, hidden size 2048, num layers 1, train loss 1.16359543800354, validation loss 1.1765869855880737\n",
      "Epoch 130, current patience 29, model mean validation loss 1.1556165218353271, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1786959171295166, validation loss 1.2017920017242432\n",
      "Epoch 140, current patience 28, model mean validation loss 1.15566885471344, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2536108493804932, validation loss 1.1308226585388184\n",
      "Epoch 150, current patience 27, model mean validation loss 1.147355318069458, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1469242572784424, validation loss 1.0948288440704346\n",
      "Epoch 160, current patience 30, model mean validation loss 1.148505687713623, embedding dim 1, hidden size 2048, num layers 1, train loss 1.365417718887329, validation loss 1.1883634328842163\n",
      "Epoch 170, current patience 29, model mean validation loss 1.165158748626709, embedding dim 1, hidden size 2048, num layers 1, train loss 1.227682113647461, validation loss 1.309639573097229\n",
      "Epoch 180, current patience 28, model mean validation loss 1.1677489280700684, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2773985862731934, validation loss 1.1178207397460938\n",
      "Epoch 190, current patience 27, model mean validation loss 1.1736406087875366, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1817905902862549, validation loss 1.1692709922790527\n",
      "Epoch 200, current patience 26, model mean validation loss 1.1813753843307495, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1755056381225586, validation loss 1.2384648323059082\n",
      "Epoch 210, current patience 25, model mean validation loss 1.1750667095184326, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1305100917816162, validation loss 1.151322364807129\n",
      "Epoch 220, current patience 24, model mean validation loss 1.1771098375320435, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1041924953460693, validation loss 1.1471675634384155\n",
      "Epoch 230, current patience 23, model mean validation loss 1.1807861328125, embedding dim 1, hidden size 2048, num layers 1, train loss 1.249800205230713, validation loss 1.1242400407791138\n",
      "Epoch 240, current patience 22, model mean validation loss 1.2111448049545288, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2317739725112915, validation loss 1.4312326908111572\n",
      "Epoch 250, current patience 21, model mean validation loss 1.187971591949463, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2261264324188232, validation loss 1.124253749847412\n",
      "Epoch 260, current patience 20, model mean validation loss 1.185552954673767, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1829994916915894, validation loss 1.098471999168396\n",
      "Epoch 270, current patience 19, model mean validation loss 1.1809806823730469, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1763298511505127, validation loss 1.132692813873291\n",
      "Epoch 280, current patience 18, model mean validation loss 1.1645011901855469, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2144325971603394, validation loss 1.1066290140151978\n",
      "Epoch 290, current patience 17, model mean validation loss 1.17923903465271, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1380361318588257, validation loss 1.269225001335144\n",
      "Epoch 300, current patience 16, model mean validation loss 1.1988366842269897, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1420092582702637, validation loss 1.303948163986206\n",
      "Epoch 310, current patience 15, model mean validation loss 1.2024343013763428, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1878210306167603, validation loss 1.1530202627182007\n",
      "Epoch 320, current patience 14, model mean validation loss 1.1664029359817505, embedding dim 1, hidden size 2048, num layers 1, train loss 1.261734127998352, validation loss 1.1429823637008667\n",
      "Epoch 330, current patience 13, model mean validation loss 1.1686630249023438, embedding dim 1, hidden size 2048, num layers 1, train loss 1.069357991218567, validation loss 1.1423346996307373\n",
      "Epoch 340, current patience 12, model mean validation loss 1.1979930400848389, embedding dim 1, hidden size 2048, num layers 1, train loss 1.185870885848999, validation loss 1.3331122398376465\n",
      "Epoch 350, current patience 11, model mean validation loss 1.20420503616333, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1615064144134521, validation loss 1.182388424873352\n",
      "Epoch 360, current patience 10, model mean validation loss 1.2054579257965088, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1623022556304932, validation loss 1.116652250289917\n",
      "Epoch 370, current patience 9, model mean validation loss 1.1839406490325928, embedding dim 1, hidden size 2048, num layers 1, train loss 1.101920485496521, validation loss 1.0970864295959473\n",
      "Epoch 380, current patience 8, model mean validation loss 1.1587717533111572, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1698986291885376, validation loss 1.1025971174240112\n",
      "Epoch 390, current patience 7, model mean validation loss 1.1601533889770508, embedding dim 1, hidden size 2048, num layers 1, train loss 1.104737401008606, validation loss 1.1640739440917969\n",
      "Epoch 400, current patience 6, model mean validation loss 1.1555838584899902, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1695032119750977, validation loss 1.106425404548645\n",
      "Epoch 410, current patience 5, model mean validation loss 1.164222240447998, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1251239776611328, validation loss 1.2114418745040894\n",
      "Epoch 420, current patience 4, model mean validation loss 1.1419085264205933, embedding dim 1, hidden size 2048, num layers 1, train loss 1.27457857131958, validation loss 1.1546026468276978\n",
      "Epoch 430, current patience 30, model mean validation loss 1.136695146560669, embedding dim 1, hidden size 2048, num layers 1, train loss 1.16310453414917, validation loss 1.1406813859939575\n",
      "Epoch 440, current patience 30, model mean validation loss 1.1560430526733398, embedding dim 1, hidden size 2048, num layers 1, train loss 1.171069622039795, validation loss 1.271435022354126\n",
      "Epoch 450, current patience 29, model mean validation loss 1.1765327453613281, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2886481285095215, validation loss 1.261005163192749\n",
      "Epoch 460, current patience 28, model mean validation loss 1.1948449611663818, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2339155673980713, validation loss 1.249093770980835\n",
      "Epoch 470, current patience 27, model mean validation loss 1.191085934638977, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2820141315460205, validation loss 1.1340022087097168\n",
      "Epoch 480, current patience 26, model mean validation loss 1.200257658958435, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1171261072158813, validation loss 1.1797995567321777\n",
      "Epoch 490, current patience 25, model mean validation loss 1.1886637210845947, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1099787950515747, validation loss 1.1186896562576294\n",
      "Epoch 500, current patience 24, model mean validation loss 1.1827412843704224, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0942537784576416, validation loss 1.1072237491607666\n",
      "Epoch 510, current patience 23, model mean validation loss 1.1840684413909912, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1630970239639282, validation loss 1.1512984037399292\n",
      "Epoch 520, current patience 22, model mean validation loss 1.1653988361358643, embedding dim 1, hidden size 2048, num layers 1, train loss 1.148127794265747, validation loss 1.1220784187316895\n",
      "Epoch 530, current patience 21, model mean validation loss 1.1816109418869019, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1264995336532593, validation loss 1.3907015323638916\n",
      "Epoch 540, current patience 20, model mean validation loss 1.1762746572494507, embedding dim 1, hidden size 2048, num layers 1, train loss 1.130789875984192, validation loss 1.2064034938812256\n",
      "Epoch 550, current patience 19, model mean validation loss 1.1755242347717285, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1729707717895508, validation loss 1.1279995441436768\n",
      "Epoch 560, current patience 18, model mean validation loss 1.175295352935791, embedding dim 1, hidden size 2048, num layers 1, train loss 1.101170301437378, validation loss 1.177968144416809\n",
      "Epoch 570, current patience 17, model mean validation loss 1.1737676858901978, embedding dim 1, hidden size 2048, num layers 1, train loss 1.131736397743225, validation loss 1.106468677520752\n",
      "Epoch 580, current patience 16, model mean validation loss 1.1761682033538818, embedding dim 1, hidden size 2048, num layers 1, train loss 1.14892578125, validation loss 1.1264275312423706\n",
      "Epoch 590, current patience 15, model mean validation loss 1.1702046394348145, embedding dim 1, hidden size 2048, num layers 1, train loss 1.3004372119903564, validation loss 1.103590726852417\n",
      "Epoch 600, current patience 14, model mean validation loss 1.1755685806274414, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1594462394714355, validation loss 1.1649894714355469\n",
      "Epoch 610, current patience 13, model mean validation loss 1.138122320175171, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2298070192337036, validation loss 1.0911307334899902\n",
      "Epoch 620, current patience 12, model mean validation loss 1.1275568008422852, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0914068222045898, validation loss 1.1218798160552979\n",
      "Epoch 630, current patience 30, model mean validation loss 1.123324990272522, embedding dim 1, hidden size 2048, num layers 1, train loss 1.110628604888916, validation loss 1.0941448211669922\n",
      "Epoch 640, current patience 30, model mean validation loss 1.1153695583343506, embedding dim 1, hidden size 2048, num layers 1, train loss 1.060978651046753, validation loss 1.114324688911438\n",
      "Epoch 650, current patience 30, model mean validation loss 1.123217225074768, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1030664443969727, validation loss 1.1692497730255127\n",
      "Epoch 660, current patience 29, model mean validation loss 1.1328675746917725, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1273882389068604, validation loss 1.203629970550537\n",
      "Epoch 670, current patience 28, model mean validation loss 1.1369900703430176, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1562713384628296, validation loss 1.1365704536437988\n",
      "Epoch 680, current patience 27, model mean validation loss 1.133870244026184, embedding dim 1, hidden size 2048, num layers 1, train loss 1.4267137050628662, validation loss 1.1400316953659058\n",
      "Epoch 690, current patience 26, model mean validation loss 1.147916316986084, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2019753456115723, validation loss 1.2034993171691895\n",
      "Epoch 700, current patience 25, model mean validation loss 1.165162205696106, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2435945272445679, validation loss 1.2598470449447632\n",
      "Epoch 710, current patience 24, model mean validation loss 1.1807514429092407, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1807835102081299, validation loss 1.2188583612442017\n",
      "Epoch 720, current patience 23, model mean validation loss 1.1855449676513672, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1017706394195557, validation loss 1.1526730060577393\n",
      "Epoch 730, current patience 22, model mean validation loss 1.1829619407653809, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0692732334136963, validation loss 1.1485860347747803\n",
      "Epoch 740, current patience 21, model mean validation loss 1.1730579137802124, embedding dim 1, hidden size 2048, num layers 1, train loss 1.302689790725708, validation loss 1.1243977546691895\n",
      "Epoch 750, current patience 20, model mean validation loss 1.182497501373291, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0914685726165771, validation loss 1.212087631225586\n",
      "Epoch 760, current patience 19, model mean validation loss 1.1878211498260498, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1470286846160889, validation loss 1.1826199293136597\n",
      "Epoch 770, current patience 18, model mean validation loss 1.175452470779419, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0920295715332031, validation loss 1.1045507192611694\n",
      "Epoch 780, current patience 17, model mean validation loss 1.1533914804458618, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1973342895507812, validation loss 1.0833590030670166\n",
      "Epoch 790, current patience 16, model mean validation loss 1.1458876132965088, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1466500759124756, validation loss 1.1588268280029297\n",
      "Epoch 800, current patience 15, model mean validation loss 1.1523019075393677, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1613105535507202, validation loss 1.2039871215820312\n",
      "Epoch 810, current patience 14, model mean validation loss 1.1935222148895264, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0882227420806885, validation loss 1.478347897529602\n",
      "Epoch 820, current patience 13, model mean validation loss 1.2071154117584229, embedding dim 1, hidden size 2048, num layers 1, train loss 1.3400952816009521, validation loss 1.2331444025039673\n",
      "Epoch 830, current patience 12, model mean validation loss 1.2295334339141846, embedding dim 1, hidden size 2048, num layers 1, train loss 1.4878414869308472, validation loss 1.391431450843811\n",
      "Epoch 840, current patience 11, model mean validation loss 1.2210993766784668, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2374756336212158, validation loss 1.1151477098464966\n",
      "Epoch 850, current patience 10, model mean validation loss 1.2239408493041992, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0059776306152344, validation loss 1.1272821426391602\n",
      "Epoch 860, current patience 9, model mean validation loss 1.2373850345611572, embedding dim 1, hidden size 2048, num layers 1, train loss 1.0855472087860107, validation loss 1.190913200378418\n",
      "Epoch 870, current patience 8, model mean validation loss 1.2428357601165771, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1970787048339844, validation loss 1.20243239402771\n",
      "Epoch 880, current patience 7, model mean validation loss 1.2327440977096558, embedding dim 1, hidden size 2048, num layers 1, train loss 1.370441198348999, validation loss 1.1232538223266602\n",
      "Epoch 890, current patience 6, model mean validation loss 1.1851823329925537, embedding dim 1, hidden size 2048, num layers 1, train loss 1.1107971668243408, validation loss 1.0978535413742065\n",
      "Epoch 900, current patience 5, model mean validation loss 1.1820995807647705, embedding dim 1, hidden size 2048, num layers 1, train loss 1.412611484527588, validation loss 1.2084827423095703\n",
      "Epoch 910, current patience 4, model mean validation loss 1.1879208087921143, embedding dim 1, hidden size 2048, num layers 1, train loss 1.5946755409240723, validation loss 1.4380011558532715\n",
      "Epoch 920, current patience 3, model mean validation loss 1.1898207664489746, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2532809972763062, validation loss 1.1303472518920898\n",
      "Epoch 930, current patience 2, model mean validation loss 1.1919485330581665, embedding dim 1, hidden size 2048, num layers 1, train loss 1.2278666496276855, validation loss 1.1443045139312744\n",
      "Epoch 940, current patience 1, model mean validation loss 1.1941914558410645, embedding dim 1, hidden size 2048, num layers 1, train loss 1.292008638381958, validation loss 1.2088570594787598\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2267849445343018, embedding dim 2, hidden size 1, num layers 1, train loss 1.2367116212844849, validation loss 1.2267849445343018\n",
      "Epoch 10, current patience 30, model mean validation loss 1.208268165588379, embedding dim 2, hidden size 1, num layers 1, train loss 1.2430728673934937, validation loss 1.1897515058517456\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1997045278549194, embedding dim 2, hidden size 1, num layers 1, train loss 1.1277769804000854, validation loss 1.182577133178711\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1933422088623047, embedding dim 2, hidden size 1, num layers 1, train loss 1.1194143295288086, validation loss 1.1742554903030396\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1846067905426025, embedding dim 2, hidden size 1, num layers 1, train loss 1.133557677268982, validation loss 1.1496646404266357\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1762837171554565, embedding dim 2, hidden size 1, num layers 1, train loss 1.1203157901763916, validation loss 1.1346688270568848\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1680899858474731, embedding dim 2, hidden size 1, num layers 1, train loss 1.1135172843933105, validation loss 1.1189274787902832\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1613268852233887, embedding dim 2, hidden size 1, num layers 1, train loss 1.1004140377044678, validation loss 1.11398446559906\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1466941833496094, embedding dim 2, hidden size 1, num layers 1, train loss 1.0720796585083008, validation loss 1.1097240447998047\n",
      "Epoch 90, current patience 30, model mean validation loss 1.135697841644287, embedding dim 2, hidden size 1, num layers 1, train loss 1.097632884979248, validation loss 1.1017807722091675\n",
      "Epoch 100, current patience 30, model mean validation loss 1.124922275543213, embedding dim 2, hidden size 1, num layers 1, train loss 1.0815911293029785, validation loss 1.096372365951538\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1152750253677368, embedding dim 2, hidden size 1, num layers 1, train loss 1.114318609237671, validation loss 1.0970778465270996\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1087998151779175, embedding dim 2, hidden size 1, num layers 1, train loss 1.0846283435821533, validation loss 1.0978622436523438\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1035258769989014, embedding dim 2, hidden size 1, num layers 1, train loss 1.0973989963531494, validation loss 1.0924773216247559\n",
      "Epoch 140, current patience 30, model mean validation loss 1.100725769996643, embedding dim 2, hidden size 1, num layers 1, train loss 1.0843594074249268, validation loss 1.0965266227722168\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0982574224472046, embedding dim 2, hidden size 1, num layers 1, train loss 1.0951639413833618, validation loss 1.0942375659942627\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0963399410247803, embedding dim 2, hidden size 1, num layers 1, train loss 1.0997416973114014, validation loss 1.0943838357925415\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0952136516571045, embedding dim 2, hidden size 1, num layers 1, train loss 1.0834603309631348, validation loss 1.0927718877792358\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0944526195526123, embedding dim 2, hidden size 1, num layers 1, train loss 1.103190302848816, validation loss 1.0902838706970215\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0941252708435059, embedding dim 2, hidden size 1, num layers 1, train loss 1.0940155982971191, validation loss 1.0944585800170898\n",
      "Epoch 200, current patience 30, model mean validation loss 1.093915343284607, embedding dim 2, hidden size 1, num layers 1, train loss 1.09244704246521, validation loss 1.0961833000183105\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0938420295715332, embedding dim 2, hidden size 1, num layers 1, train loss 1.0782170295715332, validation loss 1.0918903350830078\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0932748317718506, embedding dim 2, hidden size 1, num layers 1, train loss 1.1076900959014893, validation loss 1.0919893980026245\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0927761793136597, embedding dim 2, hidden size 1, num layers 1, train loss 1.0687769651412964, validation loss 1.0902478694915771\n",
      "Epoch 240, current patience 30, model mean validation loss 1.091909646987915, embedding dim 2, hidden size 1, num layers 1, train loss 1.072662115097046, validation loss 1.0874512195587158\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0911977291107178, embedding dim 2, hidden size 1, num layers 1, train loss 1.089146375656128, validation loss 1.0870771408081055\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0910378694534302, embedding dim 2, hidden size 1, num layers 1, train loss 1.0871574878692627, validation loss 1.0890053510665894\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0899486541748047, embedding dim 2, hidden size 1, num layers 1, train loss 1.0851898193359375, validation loss 1.0857443809509277\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0885955095291138, embedding dim 2, hidden size 1, num layers 1, train loss 1.0944194793701172, validation loss 1.0853583812713623\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0876531600952148, embedding dim 2, hidden size 1, num layers 1, train loss 1.0779355764389038, validation loss 1.0843521356582642\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0864169597625732, embedding dim 2, hidden size 1, num layers 1, train loss 1.0629634857177734, validation loss 1.0820996761322021\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0849692821502686, embedding dim 2, hidden size 1, num layers 1, train loss 1.0724999904632568, validation loss 1.0786664485931396\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0833131074905396, embedding dim 2, hidden size 1, num layers 1, train loss 1.0538915395736694, validation loss 1.0742017030715942\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0812633037567139, embedding dim 2, hidden size 1, num layers 1, train loss 1.0764682292938232, validation loss 1.0706778764724731\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0776214599609375, embedding dim 2, hidden size 1, num layers 1, train loss 1.0777255296707153, validation loss 1.0598704814910889\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0746057033538818, embedding dim 2, hidden size 1, num layers 1, train loss 1.066741704940796, validation loss 1.061618685722351\n",
      "Epoch 360, current patience 30, model mean validation loss 1.070923089981079, embedding dim 2, hidden size 1, num layers 1, train loss 1.0488853454589844, validation loss 1.05589759349823\n",
      "Epoch 370, current patience 30, model mean validation loss 1.066860318183899, embedding dim 2, hidden size 1, num layers 1, train loss 1.0192326307296753, validation loss 1.0518503189086914\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0616111755371094, embedding dim 2, hidden size 1, num layers 1, train loss 1.0082893371582031, validation loss 1.040105938911438\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0548756122589111, embedding dim 2, hidden size 1, num layers 1, train loss 0.980736494064331, validation loss 1.0247818231582642\n",
      "Epoch 400, current patience 30, model mean validation loss 1.048493504524231, embedding dim 2, hidden size 1, num layers 1, train loss 1.0021793842315674, validation loss 1.023145318031311\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0407168865203857, embedding dim 2, hidden size 1, num layers 1, train loss 0.9956692457199097, validation loss 1.008465051651001\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0330922603607178, embedding dim 2, hidden size 1, num layers 1, train loss 0.9625091552734375, validation loss 0.9988729953765869\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0240404605865479, embedding dim 2, hidden size 1, num layers 1, train loss 0.9304955005645752, validation loss 0.9892042279243469\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0159809589385986, embedding dim 2, hidden size 1, num layers 1, train loss 0.9436784982681274, validation loss 0.9914213418960571\n",
      "Epoch 450, current patience 30, model mean validation loss 1.0074272155761719, embedding dim 2, hidden size 1, num layers 1, train loss 0.897384524345398, validation loss 0.9834213256835938\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9992676377296448, embedding dim 2, hidden size 1, num layers 1, train loss 0.9606462717056274, validation loss 0.9748290777206421\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9922271370887756, embedding dim 2, hidden size 1, num layers 1, train loss 0.9294415712356567, validation loss 0.968457818031311\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9862451553344727, embedding dim 2, hidden size 1, num layers 1, train loss 0.8805750012397766, validation loss 0.9752889275550842\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9804420471191406, embedding dim 2, hidden size 1, num layers 1, train loss 0.9111259579658508, validation loss 0.9620407819747925\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9760371446609497, embedding dim 2, hidden size 1, num layers 1, train loss 0.9716123938560486, validation loss 0.9636337757110596\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9718806743621826, embedding dim 2, hidden size 1, num layers 1, train loss 0.9123356342315674, validation loss 0.9559527039527893\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9672530889511108, embedding dim 2, hidden size 1, num layers 1, train loss 0.8651260137557983, validation loss 0.9544007778167725\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9622484445571899, embedding dim 2, hidden size 1, num layers 1, train loss 0.9062916040420532, validation loss 0.9433830976486206\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9594652652740479, embedding dim 2, hidden size 1, num layers 1, train loss 0.8373063802719116, validation loss 0.9525639414787292\n",
      "Epoch 550, current patience 30, model mean validation loss 0.958480715751648, embedding dim 2, hidden size 1, num layers 1, train loss 0.9105775952339172, validation loss 0.9605820178985596\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9550824165344238, embedding dim 2, hidden size 1, num layers 1, train loss 0.9134538769721985, validation loss 0.9481023550033569\n",
      "Epoch 570, current patience 30, model mean validation loss 0.9527831077575684, embedding dim 2, hidden size 1, num layers 1, train loss 0.9136505126953125, validation loss 0.943646252155304\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9503897428512573, embedding dim 2, hidden size 1, num layers 1, train loss 0.8891103267669678, validation loss 0.9444867968559265\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9472852945327759, embedding dim 2, hidden size 1, num layers 1, train loss 0.9492473602294922, validation loss 0.9311168193817139\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9440887570381165, embedding dim 2, hidden size 1, num layers 1, train loss 0.8863543272018433, validation loss 0.9288288354873657\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9434574246406555, embedding dim 2, hidden size 1, num layers 1, train loss 0.8500418066978455, validation loss 0.9383321404457092\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9403926134109497, embedding dim 2, hidden size 1, num layers 1, train loss 0.9254117012023926, validation loss 0.9280455112457275\n",
      "Epoch 630, current patience 30, model mean validation loss 0.9379787445068359, embedding dim 2, hidden size 1, num layers 1, train loss 0.897480309009552, validation loss 0.9412710070610046\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9370812177658081, embedding dim 2, hidden size 1, num layers 1, train loss 0.8343835473060608, validation loss 0.9409222602844238\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9365272521972656, embedding dim 2, hidden size 1, num layers 1, train loss 0.9222962260246277, validation loss 0.9392144083976746\n",
      "Epoch 660, current patience 30, model mean validation loss 0.9339308738708496, embedding dim 2, hidden size 1, num layers 1, train loss 0.8678745031356812, validation loss 0.9237165451049805\n",
      "Epoch 670, current patience 30, model mean validation loss 0.9355183839797974, embedding dim 2, hidden size 1, num layers 1, train loss 0.8128160238265991, validation loss 0.943816065788269\n",
      "Epoch 680, current patience 29, model mean validation loss 0.9371165037155151, embedding dim 2, hidden size 1, num layers 1, train loss 0.9269493222236633, validation loss 0.941614031791687\n",
      "Epoch 690, current patience 28, model mean validation loss 0.935931384563446, embedding dim 2, hidden size 1, num layers 1, train loss 0.9463368058204651, validation loss 0.9288514256477356\n",
      "Epoch 700, current patience 27, model mean validation loss 0.9337191581726074, embedding dim 2, hidden size 1, num layers 1, train loss 0.8811892867088318, validation loss 0.9103472828865051\n",
      "Epoch 710, current patience 30, model mean validation loss 0.9301182627677917, embedding dim 2, hidden size 1, num layers 1, train loss 0.9971252083778381, validation loss 0.9124638438224792\n",
      "Epoch 720, current patience 30, model mean validation loss 0.927489161491394, embedding dim 2, hidden size 1, num layers 1, train loss 0.8808822631835938, validation loss 0.9198893308639526\n",
      "Epoch 730, current patience 30, model mean validation loss 0.924086332321167, embedding dim 2, hidden size 1, num layers 1, train loss 0.8893444538116455, validation loss 0.9119924902915955\n",
      "Epoch 740, current patience 30, model mean validation loss 0.9232488870620728, embedding dim 2, hidden size 1, num layers 1, train loss 0.876922607421875, validation loss 0.9170166254043579\n",
      "Epoch 750, current patience 30, model mean validation loss 0.9193670153617859, embedding dim 2, hidden size 1, num layers 1, train loss 0.8677141666412354, validation loss 0.9127609133720398\n",
      "Epoch 760, current patience 30, model mean validation loss 0.9174229502677917, embedding dim 2, hidden size 1, num layers 1, train loss 0.8090827465057373, validation loss 0.9260616898536682\n",
      "Epoch 770, current patience 30, model mean validation loss 0.9124054908752441, embedding dim 2, hidden size 1, num layers 1, train loss 0.9621636271476746, validation loss 0.8887113928794861\n",
      "Epoch 780, current patience 30, model mean validation loss 0.9107229113578796, embedding dim 2, hidden size 1, num layers 1, train loss 0.8447107076644897, validation loss 0.8968867063522339\n",
      "Epoch 790, current patience 30, model mean validation loss 0.9125289916992188, embedding dim 2, hidden size 1, num layers 1, train loss 0.9021646976470947, validation loss 0.926912784576416\n",
      "Epoch 800, current patience 29, model mean validation loss 0.9117680788040161, embedding dim 2, hidden size 1, num layers 1, train loss 0.8014559745788574, validation loss 0.9138023257255554\n",
      "Epoch 810, current patience 28, model mean validation loss 0.9116812944412231, embedding dim 2, hidden size 1, num layers 1, train loss 0.7416383624076843, validation loss 0.9112977385520935\n",
      "Epoch 820, current patience 27, model mean validation loss 0.9085037112236023, embedding dim 2, hidden size 1, num layers 1, train loss 0.8090046644210815, validation loss 0.8915959000587463\n",
      "Epoch 830, current patience 30, model mean validation loss 0.9066685438156128, embedding dim 2, hidden size 1, num layers 1, train loss 0.7841536998748779, validation loss 0.8980798721313477\n",
      "Epoch 840, current patience 30, model mean validation loss 0.9063079357147217, embedding dim 2, hidden size 1, num layers 1, train loss 0.8196151852607727, validation loss 0.9231765270233154\n",
      "Epoch 850, current patience 30, model mean validation loss 0.9056718945503235, embedding dim 2, hidden size 1, num layers 1, train loss 0.760177731513977, validation loss 0.8836231231689453\n",
      "Epoch 860, current patience 30, model mean validation loss 0.9039236903190613, embedding dim 2, hidden size 1, num layers 1, train loss 0.7614848613739014, validation loss 0.8829012513160706\n",
      "Epoch 870, current patience 30, model mean validation loss 0.9002853631973267, embedding dim 2, hidden size 1, num layers 1, train loss 0.7702764868736267, validation loss 0.8978060483932495\n",
      "Epoch 880, current patience 30, model mean validation loss 0.8985971212387085, embedding dim 2, hidden size 1, num layers 1, train loss 0.8697408437728882, validation loss 0.9002965092658997\n",
      "Epoch 890, current patience 30, model mean validation loss 0.8968226313591003, embedding dim 2, hidden size 1, num layers 1, train loss 0.9985474944114685, validation loss 0.897101879119873\n",
      "Epoch 900, current patience 30, model mean validation loss 0.8977243304252625, embedding dim 2, hidden size 1, num layers 1, train loss 0.8745508193969727, validation loss 0.8988093137741089\n",
      "Epoch 910, current patience 29, model mean validation loss 0.8991683721542358, embedding dim 2, hidden size 1, num layers 1, train loss 0.7700939774513245, validation loss 0.9096320867538452\n",
      "Epoch 920, current patience 28, model mean validation loss 0.8926162719726562, embedding dim 2, hidden size 1, num layers 1, train loss 0.8358791470527649, validation loss 0.8707594871520996\n",
      "Epoch 930, current patience 30, model mean validation loss 0.8899608850479126, embedding dim 2, hidden size 1, num layers 1, train loss 0.8948183655738831, validation loss 0.8623806834220886\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8894625902175903, embedding dim 2, hidden size 1, num layers 1, train loss 0.7426364421844482, validation loss 0.8789149522781372\n",
      "Epoch 950, current patience 30, model mean validation loss 0.8895044326782227, embedding dim 2, hidden size 1, num layers 1, train loss 0.782543420791626, validation loss 0.8981404900550842\n",
      "Epoch 960, current patience 29, model mean validation loss 0.8866667151451111, embedding dim 2, hidden size 1, num layers 1, train loss 0.7904382944107056, validation loss 0.8775950074195862\n",
      "Epoch 970, current patience 30, model mean validation loss 0.8862154483795166, embedding dim 2, hidden size 1, num layers 1, train loss 0.7416841983795166, validation loss 0.8934913873672485\n",
      "Epoch 980, current patience 30, model mean validation loss 0.8876577019691467, embedding dim 2, hidden size 1, num layers 1, train loss 0.782355546951294, validation loss 0.9103472232818604\n",
      "Epoch 990, current patience 29, model mean validation loss 0.8857759237289429, embedding dim 2, hidden size 1, num layers 1, train loss 0.773177981376648, validation loss 0.8945780992507935\n",
      "Epoch 1000, current patience 30, model mean validation loss 0.8869067430496216, embedding dim 2, hidden size 1, num layers 1, train loss 0.7535132765769958, validation loss 0.8798061609268188\n",
      "Epoch 1010, current patience 29, model mean validation loss 0.8872429132461548, embedding dim 2, hidden size 1, num layers 1, train loss 0.863900899887085, validation loss 0.8650698661804199\n",
      "Epoch 1020, current patience 28, model mean validation loss 0.8847707509994507, embedding dim 2, hidden size 1, num layers 1, train loss 0.7268409132957458, validation loss 0.859137773513794\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.8864240646362305, embedding dim 2, hidden size 1, num layers 1, train loss 0.6977639198303223, validation loss 0.9113665819168091\n",
      "Epoch 1040, current patience 29, model mean validation loss 0.8873785138130188, embedding dim 2, hidden size 1, num layers 1, train loss 0.7239311337471008, validation loss 0.8852307796478271\n",
      "Epoch 1050, current patience 28, model mean validation loss 0.8869511485099792, embedding dim 2, hidden size 1, num layers 1, train loss 0.7637984156608582, validation loss 0.8900728821754456\n",
      "Epoch 1060, current patience 27, model mean validation loss 0.8850187063217163, embedding dim 2, hidden size 1, num layers 1, train loss 0.7674410939216614, validation loss 0.8948879241943359\n",
      "Epoch 1070, current patience 26, model mean validation loss 0.8840105533599854, embedding dim 2, hidden size 1, num layers 1, train loss 0.7369109392166138, validation loss 0.8865123987197876\n",
      "Epoch 1080, current patience 30, model mean validation loss 0.8816548585891724, embedding dim 2, hidden size 1, num layers 1, train loss 0.684120774269104, validation loss 0.8609609007835388\n",
      "Epoch 1090, current patience 30, model mean validation loss 0.8810038566589355, embedding dim 2, hidden size 1, num layers 1, train loss 0.9176522493362427, validation loss 0.8598610758781433\n",
      "Epoch 1100, current patience 30, model mean validation loss 0.8838919401168823, embedding dim 2, hidden size 1, num layers 1, train loss 0.715028703212738, validation loss 0.8822434544563293\n",
      "Epoch 1110, current patience 29, model mean validation loss 0.8800861835479736, embedding dim 2, hidden size 1, num layers 1, train loss 0.8296948075294495, validation loss 0.8809196949005127\n",
      "Epoch 1120, current patience 30, model mean validation loss 0.8826724290847778, embedding dim 2, hidden size 1, num layers 1, train loss 0.7664890289306641, validation loss 0.9059209227561951\n",
      "Epoch 1130, current patience 29, model mean validation loss 0.8799581527709961, embedding dim 2, hidden size 1, num layers 1, train loss 0.8667591214179993, validation loss 0.8683590292930603\n",
      "Epoch 1140, current patience 30, model mean validation loss 0.8785749077796936, embedding dim 2, hidden size 1, num layers 1, train loss 0.7524291276931763, validation loss 0.8838216066360474\n",
      "Epoch 1150, current patience 30, model mean validation loss 0.8789994716644287, embedding dim 2, hidden size 1, num layers 1, train loss 0.6903183460235596, validation loss 0.8899087309837341\n",
      "Epoch 1160, current patience 29, model mean validation loss 0.8814654350280762, embedding dim 2, hidden size 1, num layers 1, train loss 0.7395293712615967, validation loss 0.880688488483429\n",
      "Epoch 1170, current patience 28, model mean validation loss 0.8846404552459717, embedding dim 2, hidden size 1, num layers 1, train loss 0.7079881429672241, validation loss 0.8852613568305969\n",
      "Epoch 1180, current patience 27, model mean validation loss 0.8809300661087036, embedding dim 2, hidden size 1, num layers 1, train loss 0.750169038772583, validation loss 0.8525608777999878\n",
      "Epoch 1190, current patience 26, model mean validation loss 0.8823434114456177, embedding dim 2, hidden size 1, num layers 1, train loss 0.7475311756134033, validation loss 0.8922260403633118\n",
      "Epoch 1200, current patience 25, model mean validation loss 0.8781789541244507, embedding dim 2, hidden size 1, num layers 1, train loss 0.6847474575042725, validation loss 0.8726053237915039\n",
      "Epoch 1210, current patience 30, model mean validation loss 0.882282018661499, embedding dim 2, hidden size 1, num layers 1, train loss 0.684075117111206, validation loss 0.9011834859848022\n",
      "Epoch 1220, current patience 29, model mean validation loss 0.881436824798584, embedding dim 2, hidden size 1, num layers 1, train loss 0.7962883114814758, validation loss 0.8770599365234375\n",
      "Epoch 1230, current patience 28, model mean validation loss 0.88020920753479, embedding dim 2, hidden size 1, num layers 1, train loss 0.6862462162971497, validation loss 0.8800877332687378\n",
      "Epoch 1240, current patience 27, model mean validation loss 0.8786948919296265, embedding dim 2, hidden size 1, num layers 1, train loss 0.7104743719100952, validation loss 0.8685740828514099\n",
      "Epoch 1250, current patience 26, model mean validation loss 0.8781493902206421, embedding dim 2, hidden size 1, num layers 1, train loss 0.6974615454673767, validation loss 0.8808975219726562\n",
      "Epoch 1260, current patience 30, model mean validation loss 0.8820542693138123, embedding dim 2, hidden size 1, num layers 1, train loss 0.6348065137863159, validation loss 0.8838001489639282\n",
      "Epoch 1270, current patience 29, model mean validation loss 0.8813884258270264, embedding dim 2, hidden size 1, num layers 1, train loss 0.7448909878730774, validation loss 0.8868988156318665\n",
      "Epoch 1280, current patience 28, model mean validation loss 0.886428713798523, embedding dim 2, hidden size 1, num layers 1, train loss 0.692547619342804, validation loss 0.9129278063774109\n",
      "Epoch 1290, current patience 27, model mean validation loss 0.8814705610275269, embedding dim 2, hidden size 1, num layers 1, train loss 0.768275260925293, validation loss 0.8615183234214783\n",
      "Epoch 1300, current patience 26, model mean validation loss 0.8860937356948853, embedding dim 2, hidden size 1, num layers 1, train loss 0.5580174326896667, validation loss 0.9140449166297913\n",
      "Epoch 1310, current patience 25, model mean validation loss 0.8882057070732117, embedding dim 2, hidden size 1, num layers 1, train loss 0.7080006003379822, validation loss 0.8969839215278625\n",
      "Epoch 1320, current patience 24, model mean validation loss 0.8932409286499023, embedding dim 2, hidden size 1, num layers 1, train loss 0.8608095645904541, validation loss 0.9088560342788696\n",
      "Epoch 1330, current patience 23, model mean validation loss 0.8956248164176941, embedding dim 2, hidden size 1, num layers 1, train loss 0.6673468351364136, validation loss 0.8999682664871216\n",
      "Epoch 1340, current patience 22, model mean validation loss 0.8958300352096558, embedding dim 2, hidden size 1, num layers 1, train loss 0.7654051780700684, validation loss 0.8854419589042664\n",
      "Epoch 1350, current patience 21, model mean validation loss 0.8976020812988281, embedding dim 2, hidden size 1, num layers 1, train loss 0.7293601036071777, validation loss 0.9010754823684692\n",
      "Epoch 1360, current patience 20, model mean validation loss 0.8956012725830078, embedding dim 2, hidden size 1, num layers 1, train loss 0.7106031179428101, validation loss 0.8969217538833618\n",
      "Epoch 1370, current patience 19, model mean validation loss 0.8994588255882263, embedding dim 2, hidden size 1, num layers 1, train loss 0.7072607278823853, validation loss 0.8923781514167786\n",
      "Epoch 1380, current patience 18, model mean validation loss 0.8988872170448303, embedding dim 2, hidden size 1, num layers 1, train loss 0.6254069805145264, validation loss 0.909471869468689\n",
      "Epoch 1390, current patience 17, model mean validation loss 0.8969508409500122, embedding dim 2, hidden size 1, num layers 1, train loss 0.6573979258537292, validation loss 0.8814932107925415\n",
      "Epoch 1400, current patience 16, model mean validation loss 0.8968120217323303, embedding dim 2, hidden size 1, num layers 1, train loss 0.6864546537399292, validation loss 0.9077451229095459\n",
      "Epoch 1410, current patience 15, model mean validation loss 0.8942966461181641, embedding dim 2, hidden size 1, num layers 1, train loss 0.7424936890602112, validation loss 0.8798460364341736\n",
      "Epoch 1420, current patience 14, model mean validation loss 0.8979105949401855, embedding dim 2, hidden size 1, num layers 1, train loss 0.642747163772583, validation loss 0.9143533110618591\n",
      "Epoch 1430, current patience 13, model mean validation loss 0.8963963389396667, embedding dim 2, hidden size 1, num layers 1, train loss 0.5799117088317871, validation loss 0.8889616131782532\n",
      "Epoch 1440, current patience 12, model mean validation loss 0.8959123492240906, embedding dim 2, hidden size 1, num layers 1, train loss 0.7060723304748535, validation loss 0.8930493593215942\n",
      "Epoch 1450, current patience 11, model mean validation loss 0.9014707207679749, embedding dim 2, hidden size 1, num layers 1, train loss 0.7163049578666687, validation loss 0.9368452429771423\n",
      "Epoch 1460, current patience 10, model mean validation loss 0.8981781005859375, embedding dim 2, hidden size 1, num layers 1, train loss 0.6593018770217896, validation loss 0.8831306099891663\n",
      "Epoch 1470, current patience 9, model mean validation loss 0.8989964723587036, embedding dim 2, hidden size 1, num layers 1, train loss 0.631811261177063, validation loss 0.8880407810211182\n",
      "Epoch 1480, current patience 8, model mean validation loss 0.8994852304458618, embedding dim 2, hidden size 1, num layers 1, train loss 0.6915237903594971, validation loss 0.9116547107696533\n",
      "Epoch 1490, current patience 7, model mean validation loss 0.8987771272659302, embedding dim 2, hidden size 1, num layers 1, train loss 0.7193247675895691, validation loss 0.8741815090179443\n",
      "Epoch 1500, current patience 6, model mean validation loss 0.8972311615943909, embedding dim 2, hidden size 1, num layers 1, train loss 0.6336396932601929, validation loss 0.9019851088523865\n",
      "Epoch 1510, current patience 5, model mean validation loss 0.8956707119941711, embedding dim 2, hidden size 1, num layers 1, train loss 0.6691489815711975, validation loss 0.8764785528182983\n",
      "Epoch 1520, current patience 4, model mean validation loss 0.8939036130905151, embedding dim 2, hidden size 1, num layers 1, train loss 0.6210339665412903, validation loss 0.8789119124412537\n",
      "Epoch 1530, current patience 3, model mean validation loss 0.8881112337112427, embedding dim 2, hidden size 1, num layers 1, train loss 0.5910254120826721, validation loss 0.8905067443847656\n",
      "Epoch 1540, current patience 2, model mean validation loss 0.8874357342720032, embedding dim 2, hidden size 1, num layers 1, train loss 0.6605697870254517, validation loss 0.877726137638092\n",
      "Epoch 1550, current patience 1, model mean validation loss 0.8884965181350708, embedding dim 2, hidden size 1, num layers 1, train loss 0.6827754378318787, validation loss 0.8965275287628174\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1857259273529053, embedding dim 2, hidden size 2, num layers 1, train loss 1.1925616264343262, validation loss 1.1857259273529053\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1672495603561401, embedding dim 2, hidden size 2, num layers 1, train loss 1.147289752960205, validation loss 1.148773193359375\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1504292488098145, embedding dim 2, hidden size 2, num layers 1, train loss 1.1239575147628784, validation loss 1.1167887449264526\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1390602588653564, embedding dim 2, hidden size 2, num layers 1, train loss 1.09228515625, validation loss 1.1049530506134033\n",
      "Epoch 40, current patience 30, model mean validation loss 1.130632758140564, embedding dim 2, hidden size 2, num layers 1, train loss 1.0778735876083374, validation loss 1.0969226360321045\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1243880987167358, embedding dim 2, hidden size 2, num layers 1, train loss 1.1192896366119385, validation loss 1.0931651592254639\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1198889017105103, embedding dim 2, hidden size 2, num layers 1, train loss 1.0948518514633179, validation loss 1.092893362045288\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1165817975997925, embedding dim 2, hidden size 2, num layers 1, train loss 1.0954210758209229, validation loss 1.0934327840805054\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1050879955291748, embedding dim 2, hidden size 2, num layers 1, train loss 1.0919405221939087, validation loss 1.093775987625122\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0985177755355835, embedding dim 2, hidden size 2, num layers 1, train loss 1.087127447128296, validation loss 1.0962109565734863\n",
      "Epoch 100, current patience 30, model mean validation loss 1.095611572265625, embedding dim 2, hidden size 2, num layers 1, train loss 1.0919920206069946, validation loss 1.0935388803482056\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0936510562896729, embedding dim 2, hidden size 2, num layers 1, train loss 1.0573827028274536, validation loss 1.0892691612243652\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0930976867675781, embedding dim 2, hidden size 2, num layers 1, train loss 1.083834171295166, validation loss 1.0924944877624512\n",
      "Epoch 130, current patience 30, model mean validation loss 1.092543363571167, embedding dim 2, hidden size 2, num layers 1, train loss 1.0700253248214722, validation loss 1.0887309312820435\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0920419692993164, embedding dim 2, hidden size 2, num layers 1, train loss 1.075775384902954, validation loss 1.0888824462890625\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0911060571670532, embedding dim 2, hidden size 2, num layers 1, train loss 1.0751930475234985, validation loss 1.085945963859558\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0902340412139893, embedding dim 2, hidden size 2, num layers 1, train loss 1.066723108291626, validation loss 1.0867996215820312\n",
      "Epoch 170, current patience 30, model mean validation loss 1.08909010887146, embedding dim 2, hidden size 2, num layers 1, train loss 1.0636584758758545, validation loss 1.087059736251831\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0875756740570068, embedding dim 2, hidden size 2, num layers 1, train loss 1.0888018608093262, validation loss 1.081423282623291\n",
      "Epoch 190, current patience 30, model mean validation loss 1.085913896560669, embedding dim 2, hidden size 2, num layers 1, train loss 1.0735657215118408, validation loss 1.0759751796722412\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0840015411376953, embedding dim 2, hidden size 2, num layers 1, train loss 1.0609203577041626, validation loss 1.077195167541504\n",
      "Epoch 210, current patience 30, model mean validation loss 1.081254005432129, embedding dim 2, hidden size 2, num layers 1, train loss 1.0647339820861816, validation loss 1.0667508840560913\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0784624814987183, embedding dim 2, hidden size 2, num layers 1, train loss 1.0514662265777588, validation loss 1.0665504932403564\n",
      "Epoch 230, current patience 30, model mean validation loss 1.075792908668518, embedding dim 2, hidden size 2, num layers 1, train loss 1.0640344619750977, validation loss 1.064589023590088\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0720584392547607, embedding dim 2, hidden size 2, num layers 1, train loss 1.028244972229004, validation loss 1.0569243431091309\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0680984258651733, embedding dim 2, hidden size 2, num layers 1, train loss 1.0296770334243774, validation loss 1.0553789138793945\n",
      "Epoch 260, current patience 30, model mean validation loss 1.063795804977417, embedding dim 2, hidden size 2, num layers 1, train loss 1.0547103881835938, validation loss 1.0470023155212402\n",
      "Epoch 270, current patience 30, model mean validation loss 1.057384729385376, embedding dim 2, hidden size 2, num layers 1, train loss 0.9606567621231079, validation loss 1.0246859788894653\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0516576766967773, embedding dim 2, hidden size 2, num layers 1, train loss 1.0296828746795654, validation loss 1.0313799381256104\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0450942516326904, embedding dim 2, hidden size 2, num layers 1, train loss 0.9477056860923767, validation loss 1.0142433643341064\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0390352010726929, embedding dim 2, hidden size 2, num layers 1, train loss 0.9160659313201904, validation loss 1.018078327178955\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0313137769699097, embedding dim 2, hidden size 2, num layers 1, train loss 0.9229719638824463, validation loss 1.002817153930664\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0221524238586426, embedding dim 2, hidden size 2, num layers 1, train loss 0.9413822889328003, validation loss 0.9836341738700867\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0135631561279297, embedding dim 2, hidden size 2, num layers 1, train loss 0.9042261838912964, validation loss 0.9866641759872437\n",
      "Epoch 340, current patience 30, model mean validation loss 1.005691409111023, embedding dim 2, hidden size 2, num layers 1, train loss 0.9318613409996033, validation loss 0.9840283393859863\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0019166469573975, embedding dim 2, hidden size 2, num layers 1, train loss 0.8818449974060059, validation loss 0.9944881200790405\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9937753677368164, embedding dim 2, hidden size 2, num layers 1, train loss 0.9951863884925842, validation loss 0.9662491679191589\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9873439073562622, embedding dim 2, hidden size 2, num layers 1, train loss 0.9928271174430847, validation loss 0.9627918004989624\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9790344834327698, embedding dim 2, hidden size 2, num layers 1, train loss 0.9941788911819458, validation loss 0.9516028165817261\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9713419079780579, embedding dim 2, hidden size 2, num layers 1, train loss 0.8998438119888306, validation loss 0.9412766695022583\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9663447141647339, embedding dim 2, hidden size 2, num layers 1, train loss 0.8677307367324829, validation loss 0.9436567425727844\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9581588506698608, embedding dim 2, hidden size 2, num layers 1, train loss 0.870405912399292, validation loss 0.9211769104003906\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9501702785491943, embedding dim 2, hidden size 2, num layers 1, train loss 0.8872101902961731, validation loss 0.9201200604438782\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9411627054214478, embedding dim 2, hidden size 2, num layers 1, train loss 0.792665421962738, validation loss 0.9224269986152649\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9354646801948547, embedding dim 2, hidden size 2, num layers 1, train loss 0.8549737930297852, validation loss 0.9206655025482178\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9298804998397827, embedding dim 2, hidden size 2, num layers 1, train loss 0.8391151428222656, validation loss 0.9181184768676758\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9259138107299805, embedding dim 2, hidden size 2, num layers 1, train loss 0.8467130661010742, validation loss 0.9198688268661499\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9222670793533325, embedding dim 2, hidden size 2, num layers 1, train loss 0.7534002065658569, validation loss 0.9121026396751404\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9179414510726929, embedding dim 2, hidden size 2, num layers 1, train loss 0.8577460050582886, validation loss 0.9090523719787598\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9166604280471802, embedding dim 2, hidden size 2, num layers 1, train loss 0.8693141937255859, validation loss 0.9109286069869995\n",
      "Epoch 500, current patience 30, model mean validation loss 0.915597140789032, embedding dim 2, hidden size 2, num layers 1, train loss 0.935450553894043, validation loss 0.9116135835647583\n",
      "Epoch 510, current patience 30, model mean validation loss 0.91419517993927, embedding dim 2, hidden size 2, num layers 1, train loss 0.8401564955711365, validation loss 0.9112117290496826\n",
      "Epoch 520, current patience 30, model mean validation loss 0.913041353225708, embedding dim 2, hidden size 2, num layers 1, train loss 0.8152971267700195, validation loss 0.9114344716072083\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9116998910903931, embedding dim 2, hidden size 2, num layers 1, train loss 0.8563567399978638, validation loss 0.9073870182037354\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9068690538406372, embedding dim 2, hidden size 2, num layers 1, train loss 0.7873152494430542, validation loss 0.8812218308448792\n",
      "Epoch 550, current patience 30, model mean validation loss 0.905778706073761, embedding dim 2, hidden size 2, num layers 1, train loss 0.839030385017395, validation loss 0.903380274772644\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9030188322067261, embedding dim 2, hidden size 2, num layers 1, train loss 0.7584757804870605, validation loss 0.8869728446006775\n",
      "Epoch 570, current patience 30, model mean validation loss 0.900109589099884, embedding dim 2, hidden size 2, num layers 1, train loss 0.8459275960922241, validation loss 0.8876544237136841\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8950708508491516, embedding dim 2, hidden size 2, num layers 1, train loss 0.776210606098175, validation loss 0.8713038563728333\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8930744528770447, embedding dim 2, hidden size 2, num layers 1, train loss 0.7949111461639404, validation loss 0.8952409029006958\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8894880414009094, embedding dim 2, hidden size 2, num layers 1, train loss 0.7820661067962646, validation loss 0.8827430009841919\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8877079486846924, embedding dim 2, hidden size 2, num layers 1, train loss 0.744970977306366, validation loss 0.8931465148925781\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8877019286155701, embedding dim 2, hidden size 2, num layers 1, train loss 0.8346809148788452, validation loss 0.8811739087104797\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8827098608016968, embedding dim 2, hidden size 2, num layers 1, train loss 0.7601765394210815, validation loss 0.8634434342384338\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8820825815200806, embedding dim 2, hidden size 2, num layers 1, train loss 0.7187268733978271, validation loss 0.881954550743103\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8804841041564941, embedding dim 2, hidden size 2, num layers 1, train loss 0.6996843814849854, validation loss 0.8748667240142822\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8833394050598145, embedding dim 2, hidden size 2, num layers 1, train loss 0.7217217683792114, validation loss 0.8941463232040405\n",
      "Epoch 670, current patience 29, model mean validation loss 0.877159595489502, embedding dim 2, hidden size 2, num layers 1, train loss 0.694902241230011, validation loss 0.8458019495010376\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8736379742622375, embedding dim 2, hidden size 2, num layers 1, train loss 0.6834990978240967, validation loss 0.8545703887939453\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8682520985603333, embedding dim 2, hidden size 2, num layers 1, train loss 0.7141742706298828, validation loss 0.8500591516494751\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8634343147277832, embedding dim 2, hidden size 2, num layers 1, train loss 0.7276173233985901, validation loss 0.8426320552825928\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8644992709159851, embedding dim 2, hidden size 2, num layers 1, train loss 0.6715990304946899, validation loss 0.8719630241394043\n",
      "Epoch 720, current patience 29, model mean validation loss 0.8614789247512817, embedding dim 2, hidden size 2, num layers 1, train loss 0.729742169380188, validation loss 0.8577919602394104\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8589442372322083, embedding dim 2, hidden size 2, num layers 1, train loss 0.8496682047843933, validation loss 0.8545894026756287\n",
      "Epoch 740, current patience 30, model mean validation loss 0.856791079044342, embedding dim 2, hidden size 2, num layers 1, train loss 0.718873143196106, validation loss 0.8769208192825317\n",
      "Epoch 750, current patience 30, model mean validation loss 0.857820451259613, embedding dim 2, hidden size 2, num layers 1, train loss 0.627261221408844, validation loss 0.8540366888046265\n",
      "Epoch 760, current patience 29, model mean validation loss 0.860089898109436, embedding dim 2, hidden size 2, num layers 1, train loss 0.7257728576660156, validation loss 0.8727259635925293\n",
      "Epoch 770, current patience 28, model mean validation loss 0.860166072845459, embedding dim 2, hidden size 2, num layers 1, train loss 0.6485636234283447, validation loss 0.8506686687469482\n",
      "Epoch 780, current patience 27, model mean validation loss 0.8704303503036499, embedding dim 2, hidden size 2, num layers 1, train loss 0.7170562744140625, validation loss 0.9247461557388306\n",
      "Epoch 790, current patience 26, model mean validation loss 0.8696889877319336, embedding dim 2, hidden size 2, num layers 1, train loss 0.6955350041389465, validation loss 0.8660321235656738\n",
      "Epoch 800, current patience 25, model mean validation loss 0.8748540878295898, embedding dim 2, hidden size 2, num layers 1, train loss 0.7438185214996338, validation loss 0.8991127014160156\n",
      "Epoch 810, current patience 24, model mean validation loss 0.8753753900527954, embedding dim 2, hidden size 2, num layers 1, train loss 0.6557754874229431, validation loss 0.8587599992752075\n",
      "Epoch 820, current patience 23, model mean validation loss 0.8759571313858032, embedding dim 2, hidden size 2, num layers 1, train loss 0.7103810906410217, validation loss 0.8815746903419495\n",
      "Epoch 830, current patience 22, model mean validation loss 0.877797544002533, embedding dim 2, hidden size 2, num layers 1, train loss 0.6830354332923889, validation loss 0.8687599897384644\n",
      "Epoch 840, current patience 21, model mean validation loss 0.8764139413833618, embedding dim 2, hidden size 2, num layers 1, train loss 0.7266095876693726, validation loss 0.861656904220581\n",
      "Epoch 850, current patience 20, model mean validation loss 0.8758162260055542, embedding dim 2, hidden size 2, num layers 1, train loss 0.5640240907669067, validation loss 0.8458873629570007\n",
      "Epoch 860, current patience 19, model mean validation loss 0.8720698356628418, embedding dim 2, hidden size 2, num layers 1, train loss 0.6571347713470459, validation loss 0.8947750926017761\n",
      "Epoch 870, current patience 18, model mean validation loss 0.8669134378433228, embedding dim 2, hidden size 2, num layers 1, train loss 0.7204095721244812, validation loss 0.8247804641723633\n",
      "Epoch 880, current patience 17, model mean validation loss 0.8581284880638123, embedding dim 2, hidden size 2, num layers 1, train loss 0.6451022624969482, validation loss 0.8288332223892212\n",
      "Epoch 890, current patience 16, model mean validation loss 0.8540215492248535, embedding dim 2, hidden size 2, num layers 1, train loss 0.6477738618850708, validation loss 0.825904369354248\n",
      "Epoch 900, current patience 30, model mean validation loss 0.8497404456138611, embedding dim 2, hidden size 2, num layers 1, train loss 0.668921172618866, validation loss 0.8473259806632996\n",
      "Epoch 910, current patience 30, model mean validation loss 0.850796639919281, embedding dim 2, hidden size 2, num layers 1, train loss 0.654703676700592, validation loss 0.8772096037864685\n",
      "Epoch 920, current patience 29, model mean validation loss 0.8503317832946777, embedding dim 2, hidden size 2, num layers 1, train loss 0.6807483434677124, validation loss 0.8579378724098206\n",
      "Epoch 930, current patience 28, model mean validation loss 0.8589495420455933, embedding dim 2, hidden size 2, num layers 1, train loss 0.713362455368042, validation loss 0.9148296117782593\n",
      "Epoch 940, current patience 27, model mean validation loss 0.8582261800765991, embedding dim 2, hidden size 2, num layers 1, train loss 0.6504335403442383, validation loss 0.8889880776405334\n",
      "Epoch 950, current patience 26, model mean validation loss 0.8684971332550049, embedding dim 2, hidden size 2, num layers 1, train loss 0.5521494150161743, validation loss 0.9069480895996094\n",
      "Epoch 960, current patience 25, model mean validation loss 0.8706890344619751, embedding dim 2, hidden size 2, num layers 1, train loss 0.7748534083366394, validation loss 0.8463687896728516\n",
      "Epoch 970, current patience 24, model mean validation loss 0.8778319954872131, embedding dim 2, hidden size 2, num layers 1, train loss 0.6207946538925171, validation loss 0.8830481767654419\n",
      "Epoch 980, current patience 23, model mean validation loss 0.8794019222259521, embedding dim 2, hidden size 2, num layers 1, train loss 0.6357815861701965, validation loss 0.8598849773406982\n",
      "Epoch 990, current patience 22, model mean validation loss 0.8758513927459717, embedding dim 2, hidden size 2, num layers 1, train loss 0.616155207157135, validation loss 0.8488055467605591\n",
      "Epoch 1000, current patience 21, model mean validation loss 0.8737831711769104, embedding dim 2, hidden size 2, num layers 1, train loss 0.6396155953407288, validation loss 0.8413920998573303\n",
      "Epoch 1010, current patience 20, model mean validation loss 0.8693081140518188, embedding dim 2, hidden size 2, num layers 1, train loss 0.6896289587020874, validation loss 0.8790291547775269\n",
      "Epoch 1020, current patience 19, model mean validation loss 0.8628233671188354, embedding dim 2, hidden size 2, num layers 1, train loss 0.621638834476471, validation loss 0.8371102809906006\n",
      "Epoch 1030, current patience 18, model mean validation loss 0.8576154112815857, embedding dim 2, hidden size 2, num layers 1, train loss 0.638582706451416, validation loss 0.8652843832969666\n",
      "Epoch 1040, current patience 17, model mean validation loss 0.8572515249252319, embedding dim 2, hidden size 2, num layers 1, train loss 0.6067107915878296, validation loss 0.8434579372406006\n",
      "Epoch 1050, current patience 16, model mean validation loss 0.8543986082077026, embedding dim 2, hidden size 2, num layers 1, train loss 0.5399582982063293, validation loss 0.860224723815918\n",
      "Epoch 1060, current patience 15, model mean validation loss 0.854516863822937, embedding dim 2, hidden size 2, num layers 1, train loss 0.5612220764160156, validation loss 0.8608312606811523\n",
      "Epoch 1070, current patience 14, model mean validation loss 0.8587648868560791, embedding dim 2, hidden size 2, num layers 1, train loss 0.6044681668281555, validation loss 0.8827893733978271\n",
      "Epoch 1080, current patience 13, model mean validation loss 0.8655188083648682, embedding dim 2, hidden size 2, num layers 1, train loss 0.7318058013916016, validation loss 0.8954229354858398\n",
      "Epoch 1090, current patience 12, model mean validation loss 0.8638092875480652, embedding dim 2, hidden size 2, num layers 1, train loss 0.6501604914665222, validation loss 0.8653532266616821\n",
      "Epoch 1100, current patience 11, model mean validation loss 0.868888258934021, embedding dim 2, hidden size 2, num layers 1, train loss 0.5748312473297119, validation loss 0.877742350101471\n",
      "Epoch 1110, current patience 10, model mean validation loss 0.8686514496803284, embedding dim 2, hidden size 2, num layers 1, train loss 0.630307674407959, validation loss 0.8633897304534912\n",
      "Epoch 1120, current patience 9, model mean validation loss 0.8719756603240967, embedding dim 2, hidden size 2, num layers 1, train loss 0.5746402740478516, validation loss 0.87005215883255\n",
      "Epoch 1130, current patience 8, model mean validation loss 0.875466525554657, embedding dim 2, hidden size 2, num layers 1, train loss 0.6538660526275635, validation loss 0.8881509304046631\n",
      "Epoch 1140, current patience 7, model mean validation loss 0.868789553642273, embedding dim 2, hidden size 2, num layers 1, train loss 0.6815608739852905, validation loss 0.8074162006378174\n",
      "Epoch 1150, current patience 6, model mean validation loss 0.8678167462348938, embedding dim 2, hidden size 2, num layers 1, train loss 0.6770739555358887, validation loss 0.8750064969062805\n",
      "Epoch 1160, current patience 5, model mean validation loss 0.8658912777900696, embedding dim 2, hidden size 2, num layers 1, train loss 0.5902564525604248, validation loss 0.8800193071365356\n",
      "Epoch 1170, current patience 4, model mean validation loss 0.864267110824585, embedding dim 2, hidden size 2, num layers 1, train loss 0.5780857801437378, validation loss 0.8523603081703186\n",
      "Epoch 1180, current patience 3, model mean validation loss 0.8590435981750488, embedding dim 2, hidden size 2, num layers 1, train loss 0.5653402209281921, validation loss 0.8359535932540894\n",
      "Epoch 1190, current patience 2, model mean validation loss 0.8618807196617126, embedding dim 2, hidden size 2, num layers 1, train loss 0.6157431602478027, validation loss 0.8860865831375122\n",
      "Epoch 1200, current patience 1, model mean validation loss 0.8634493947029114, embedding dim 2, hidden size 2, num layers 1, train loss 0.5529926419258118, validation loss 0.8826017379760742\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1155946254730225, embedding dim 2, hidden size 4, num layers 1, train loss 1.135003924369812, validation loss 1.1155946254730225\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1072893142700195, embedding dim 2, hidden size 4, num layers 1, train loss 1.0851528644561768, validation loss 1.0989840030670166\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1033141613006592, embedding dim 2, hidden size 4, num layers 1, train loss 1.0823075771331787, validation loss 1.0953638553619385\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1004431247711182, embedding dim 2, hidden size 4, num layers 1, train loss 1.092496395111084, validation loss 1.0918300151824951\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0988366603851318, embedding dim 2, hidden size 4, num layers 1, train loss 1.1006155014038086, validation loss 1.0924108028411865\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0986360311508179, embedding dim 2, hidden size 4, num layers 1, train loss 1.0898385047912598, validation loss 1.0976322889328003\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0980911254882812, embedding dim 2, hidden size 4, num layers 1, train loss 1.0873441696166992, validation loss 1.094822645187378\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0978169441223145, embedding dim 2, hidden size 4, num layers 1, train loss 1.1046321392059326, validation loss 1.095897912979126\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0948472023010254, embedding dim 2, hidden size 4, num layers 1, train loss 1.0841598510742188, validation loss 1.0918359756469727\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0944499969482422, embedding dim 2, hidden size 4, num layers 1, train loss 1.105828046798706, validation loss 1.0958067178726196\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0942736864089966, embedding dim 2, hidden size 4, num layers 1, train loss 1.0876635313034058, validation loss 1.0939528942108154\n",
      "Epoch 110, current patience 30, model mean validation loss 1.093889594078064, embedding dim 2, hidden size 4, num layers 1, train loss 1.1018600463867188, validation loss 1.088757872581482\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0938376188278198, embedding dim 2, hidden size 4, num layers 1, train loss 1.0902934074401855, validation loss 1.0919947624206543\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0931591987609863, embedding dim 2, hidden size 4, num layers 1, train loss 1.104744553565979, validation loss 1.092205286026001\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0931587219238281, embedding dim 2, hidden size 4, num layers 1, train loss 1.081019639968872, validation loss 1.0948188304901123\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0928106307983398, embedding dim 2, hidden size 4, num layers 1, train loss 1.0906039476394653, validation loss 1.0931130647659302\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0929744243621826, embedding dim 2, hidden size 4, num layers 1, train loss 1.055220603942871, validation loss 1.0931463241577148\n",
      "Epoch 170, current patience 29, model mean validation loss 1.0925884246826172, embedding dim 2, hidden size 4, num layers 1, train loss 1.1084744930267334, validation loss 1.092718482017517\n",
      "Epoch 180, current patience 30, model mean validation loss 1.090898036956787, embedding dim 2, hidden size 4, num layers 1, train loss 1.0980712175369263, validation loss 1.080430030822754\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0897712707519531, embedding dim 2, hidden size 4, num layers 1, train loss 1.087282419204712, validation loss 1.0797430276870728\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0879771709442139, embedding dim 2, hidden size 4, num layers 1, train loss 1.0399348735809326, validation loss 1.0776419639587402\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0845494270324707, embedding dim 2, hidden size 4, num layers 1, train loss 1.11703360080719, validation loss 1.064784049987793\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0794007778167725, embedding dim 2, hidden size 4, num layers 1, train loss 1.025947093963623, validation loss 1.053628921508789\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0727277994155884, embedding dim 2, hidden size 4, num layers 1, train loss 1.0448863506317139, validation loss 1.039729356765747\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0647310018539429, embedding dim 2, hidden size 4, num layers 1, train loss 1.008518934249878, validation loss 1.0291719436645508\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0560352802276611, embedding dim 2, hidden size 4, num layers 1, train loss 1.0034575462341309, validation loss 1.0231527090072632\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0465397834777832, embedding dim 2, hidden size 4, num layers 1, train loss 1.0187008380889893, validation loss 1.0044658184051514\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0352051258087158, embedding dim 2, hidden size 4, num layers 1, train loss 0.9926567077636719, validation loss 0.9890663027763367\n",
      "Epoch 280, current patience 30, model mean validation loss 1.023017406463623, embedding dim 2, hidden size 4, num layers 1, train loss 1.0142089128494263, validation loss 0.9801403284072876\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0117018222808838, embedding dim 2, hidden size 4, num layers 1, train loss 0.9310685396194458, validation loss 0.9742592573165894\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0035169124603271, embedding dim 2, hidden size 4, num layers 1, train loss 0.9726839065551758, validation loss 0.9881500601768494\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9952387809753418, embedding dim 2, hidden size 4, num layers 1, train loss 0.9126479625701904, validation loss 0.9735039472579956\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9874502420425415, embedding dim 2, hidden size 4, num layers 1, train loss 0.8983634114265442, validation loss 0.966863214969635\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9805384874343872, embedding dim 2, hidden size 4, num layers 1, train loss 0.88496994972229, validation loss 0.967858612537384\n",
      "Epoch 340, current patience 30, model mean validation loss 0.974533200263977, embedding dim 2, hidden size 4, num layers 1, train loss 0.9721208214759827, validation loss 0.9564239978790283\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9698671698570251, embedding dim 2, hidden size 4, num layers 1, train loss 1.0062960386276245, validation loss 0.9517378807067871\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9657697081565857, embedding dim 2, hidden size 4, num layers 1, train loss 0.8803640007972717, validation loss 0.9473603963851929\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9620230793952942, embedding dim 2, hidden size 4, num layers 1, train loss 0.8994483947753906, validation loss 0.944286584854126\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9555272459983826, embedding dim 2, hidden size 4, num layers 1, train loss 0.8594722151756287, validation loss 0.9361830949783325\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9505061507225037, embedding dim 2, hidden size 4, num layers 1, train loss 0.8964827060699463, validation loss 0.9333353042602539\n",
      "Epoch 400, current patience 30, model mean validation loss 0.947163462638855, embedding dim 2, hidden size 4, num layers 1, train loss 0.8314801454544067, validation loss 0.9401216506958008\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9436452984809875, embedding dim 2, hidden size 4, num layers 1, train loss 0.9225369691848755, validation loss 0.9397132992744446\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9375617504119873, embedding dim 2, hidden size 4, num layers 1, train loss 0.9269330501556396, validation loss 0.9077557325363159\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9339625239372253, embedding dim 2, hidden size 4, num layers 1, train loss 0.8223369121551514, validation loss 0.922944188117981\n",
      "Epoch 440, current patience 30, model mean validation loss 0.927482008934021, embedding dim 2, hidden size 4, num layers 1, train loss 0.7885473370552063, validation loss 0.8955163955688477\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9218012094497681, embedding dim 2, hidden size 4, num layers 1, train loss 0.8526273369789124, validation loss 0.8988401889801025\n",
      "Epoch 460, current patience 30, model mean validation loss 0.914655327796936, embedding dim 2, hidden size 4, num layers 1, train loss 0.9167830944061279, validation loss 0.8790160417556763\n",
      "Epoch 470, current patience 30, model mean validation loss 0.909822404384613, embedding dim 2, hidden size 4, num layers 1, train loss 0.8561370372772217, validation loss 0.8946719169616699\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9054121971130371, embedding dim 2, hidden size 4, num layers 1, train loss 0.7608574628829956, validation loss 0.9048401117324829\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8998140096664429, embedding dim 2, hidden size 4, num layers 1, train loss 0.8455952405929565, validation loss 0.8949276208877563\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8955791592597961, embedding dim 2, hidden size 4, num layers 1, train loss 0.7274745106697083, validation loss 0.8738768696784973\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8903682231903076, embedding dim 2, hidden size 4, num layers 1, train loss 0.8712472915649414, validation loss 0.8812563419342041\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8870416879653931, embedding dim 2, hidden size 4, num layers 1, train loss 0.8210140466690063, validation loss 0.8689047694206238\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8830613493919373, embedding dim 2, hidden size 4, num layers 1, train loss 0.7493488788604736, validation loss 0.8669970035552979\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8814133405685425, embedding dim 2, hidden size 4, num layers 1, train loss 0.8425920009613037, validation loss 0.8658322691917419\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8788346648216248, embedding dim 2, hidden size 4, num layers 1, train loss 0.7386201620101929, validation loss 0.8740426898002625\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8761932849884033, embedding dim 2, hidden size 4, num layers 1, train loss 0.7868926525115967, validation loss 0.8837088346481323\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8704932928085327, embedding dim 2, hidden size 4, num layers 1, train loss 0.7214571237564087, validation loss 0.8493276238441467\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8699460029602051, embedding dim 2, hidden size 4, num layers 1, train loss 0.7819143533706665, validation loss 0.8694980144500732\n",
      "Epoch 590, current patience 30, model mean validation loss 0.869671642780304, embedding dim 2, hidden size 4, num layers 1, train loss 0.6476123929023743, validation loss 0.8790619969367981\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8661856651306152, embedding dim 2, hidden size 4, num layers 1, train loss 0.7791870832443237, validation loss 0.8410170078277588\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8672915697097778, embedding dim 2, hidden size 4, num layers 1, train loss 0.689136266708374, validation loss 0.8758437037467957\n",
      "Epoch 620, current patience 29, model mean validation loss 0.8689804077148438, embedding dim 2, hidden size 4, num layers 1, train loss 0.7911125421524048, validation loss 0.8793433904647827\n",
      "Epoch 630, current patience 28, model mean validation loss 0.8631366491317749, embedding dim 2, hidden size 4, num layers 1, train loss 0.7758899927139282, validation loss 0.8272925615310669\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8580465316772461, embedding dim 2, hidden size 4, num layers 1, train loss 0.6308298110961914, validation loss 0.8429878950119019\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8579577207565308, embedding dim 2, hidden size 4, num layers 1, train loss 0.5882204174995422, validation loss 0.8486172556877136\n",
      "Epoch 660, current patience 30, model mean validation loss 0.855772852897644, embedding dim 2, hidden size 4, num layers 1, train loss 0.7854103446006775, validation loss 0.8520187139511108\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8504288792610168, embedding dim 2, hidden size 4, num layers 1, train loss 0.8353230953216553, validation loss 0.8363107442855835\n",
      "Epoch 680, current patience 30, model mean validation loss 0.85135817527771, embedding dim 2, hidden size 4, num layers 1, train loss 0.8455005884170532, validation loss 0.8484510779380798\n",
      "Epoch 690, current patience 29, model mean validation loss 0.8468145728111267, embedding dim 2, hidden size 4, num layers 1, train loss 0.7434538006782532, validation loss 0.8394949436187744\n",
      "Epoch 700, current patience 30, model mean validation loss 0.842758297920227, embedding dim 2, hidden size 4, num layers 1, train loss 0.7027040719985962, validation loss 0.8468930721282959\n",
      "Epoch 710, current patience 30, model mean validation loss 0.84397292137146, embedding dim 2, hidden size 4, num layers 1, train loss 0.755183219909668, validation loss 0.837009608745575\n",
      "Epoch 720, current patience 29, model mean validation loss 0.838080883026123, embedding dim 2, hidden size 4, num layers 1, train loss 0.6317762136459351, validation loss 0.7958517074584961\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8409957885742188, embedding dim 2, hidden size 4, num layers 1, train loss 0.747296929359436, validation loss 0.8719363212585449\n",
      "Epoch 740, current patience 29, model mean validation loss 0.8401612043380737, embedding dim 2, hidden size 4, num layers 1, train loss 0.6522766351699829, validation loss 0.8453418016433716\n",
      "Epoch 750, current patience 28, model mean validation loss 0.8398676514625549, embedding dim 2, hidden size 4, num layers 1, train loss 0.6711376309394836, validation loss 0.8339627981185913\n",
      "Epoch 760, current patience 27, model mean validation loss 0.8376291990280151, embedding dim 2, hidden size 4, num layers 1, train loss 0.6252925395965576, validation loss 0.8305432796478271\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8380005359649658, embedding dim 2, hidden size 4, num layers 1, train loss 0.7848397493362427, validation loss 0.8424657583236694\n",
      "Epoch 780, current patience 29, model mean validation loss 0.8353760242462158, embedding dim 2, hidden size 4, num layers 1, train loss 0.6935544013977051, validation loss 0.8258971571922302\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8355900049209595, embedding dim 2, hidden size 4, num layers 1, train loss 0.5133160352706909, validation loss 0.8387211561203003\n",
      "Epoch 800, current patience 29, model mean validation loss 0.8406084775924683, embedding dim 2, hidden size 4, num layers 1, train loss 0.7942728996276855, validation loss 0.8359998464584351\n",
      "Epoch 810, current patience 28, model mean validation loss 0.8385365009307861, embedding dim 2, hidden size 4, num layers 1, train loss 0.705249547958374, validation loss 0.8553600311279297\n",
      "Epoch 820, current patience 27, model mean validation loss 0.836997926235199, embedding dim 2, hidden size 4, num layers 1, train loss 0.6067880392074585, validation loss 0.8330332040786743\n",
      "Epoch 830, current patience 26, model mean validation loss 0.8358124494552612, embedding dim 2, hidden size 4, num layers 1, train loss 0.7335506677627563, validation loss 0.8244789838790894\n",
      "Epoch 840, current patience 25, model mean validation loss 0.8364925980567932, embedding dim 2, hidden size 4, num layers 1, train loss 0.7491295337677002, validation loss 0.8359842300415039\n",
      "Epoch 850, current patience 24, model mean validation loss 0.8360406756401062, embedding dim 2, hidden size 4, num layers 1, train loss 0.7356743812561035, validation loss 0.8388510942459106\n",
      "Epoch 860, current patience 23, model mean validation loss 0.8355328440666199, embedding dim 2, hidden size 4, num layers 1, train loss 0.6436667442321777, validation loss 0.8218343257904053\n",
      "Epoch 870, current patience 22, model mean validation loss 0.8409483432769775, embedding dim 2, hidden size 4, num layers 1, train loss 0.7827759981155396, validation loss 0.8820446133613586\n",
      "Epoch 880, current patience 21, model mean validation loss 0.8386653065681458, embedding dim 2, hidden size 4, num layers 1, train loss 0.7243329286575317, validation loss 0.8177360892295837\n",
      "Epoch 890, current patience 20, model mean validation loss 0.8345548510551453, embedding dim 2, hidden size 4, num layers 1, train loss 0.7337201237678528, validation loss 0.822476327419281\n",
      "Epoch 900, current patience 30, model mean validation loss 0.8310883641242981, embedding dim 2, hidden size 4, num layers 1, train loss 0.6731413006782532, validation loss 0.805301308631897\n",
      "Epoch 910, current patience 30, model mean validation loss 0.8244485855102539, embedding dim 2, hidden size 4, num layers 1, train loss 0.5587862133979797, validation loss 0.7713606953620911\n",
      "Epoch 920, current patience 30, model mean validation loss 0.8227379322052002, embedding dim 2, hidden size 4, num layers 1, train loss 0.7241860628128052, validation loss 0.8222987651824951\n",
      "Epoch 930, current patience 30, model mean validation loss 0.82206130027771, embedding dim 2, hidden size 4, num layers 1, train loss 0.61966872215271, validation loss 0.8334379196166992\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8265113830566406, embedding dim 2, hidden size 4, num layers 1, train loss 0.6759098768234253, validation loss 0.8574352264404297\n",
      "Epoch 950, current patience 29, model mean validation loss 0.8206127882003784, embedding dim 2, hidden size 4, num layers 1, train loss 0.7295012474060059, validation loss 0.8348554372787476\n",
      "Epoch 960, current patience 30, model mean validation loss 0.8266111612319946, embedding dim 2, hidden size 4, num layers 1, train loss 0.4941059350967407, validation loss 0.865723729133606\n",
      "Epoch 970, current patience 29, model mean validation loss 0.8290567398071289, embedding dim 2, hidden size 4, num layers 1, train loss 0.6099052429199219, validation loss 0.8420407772064209\n",
      "Epoch 980, current patience 28, model mean validation loss 0.8351894617080688, embedding dim 2, hidden size 4, num layers 1, train loss 0.681913435459137, validation loss 0.8543635010719299\n",
      "Epoch 990, current patience 27, model mean validation loss 0.8394008278846741, embedding dim 2, hidden size 4, num layers 1, train loss 0.7084232568740845, validation loss 0.8050515055656433\n",
      "Epoch 1000, current patience 26, model mean validation loss 0.8491660356521606, embedding dim 2, hidden size 4, num layers 1, train loss 0.7558057904243469, validation loss 0.900420069694519\n",
      "Epoch 1010, current patience 25, model mean validation loss 0.8545889854431152, embedding dim 2, hidden size 4, num layers 1, train loss 0.5682641863822937, validation loss 0.8768215775489807\n",
      "Epoch 1020, current patience 24, model mean validation loss 0.8537973165512085, embedding dim 2, hidden size 4, num layers 1, train loss 0.6191436052322388, validation loss 0.8511021137237549\n",
      "Epoch 1030, current patience 23, model mean validation loss 0.853602409362793, embedding dim 2, hidden size 4, num layers 1, train loss 0.5389939546585083, validation loss 0.8332961201667786\n",
      "Epoch 1040, current patience 22, model mean validation loss 0.8471121788024902, embedding dim 2, hidden size 4, num layers 1, train loss 0.540980339050293, validation loss 0.8138018250465393\n",
      "Epoch 1050, current patience 21, model mean validation loss 0.845089316368103, embedding dim 2, hidden size 4, num layers 1, train loss 0.43093669414520264, validation loss 0.8258580565452576\n",
      "Epoch 1060, current patience 20, model mean validation loss 0.8460827469825745, embedding dim 2, hidden size 4, num layers 1, train loss 0.7142155170440674, validation loss 0.8623106479644775\n",
      "Epoch 1070, current patience 19, model mean validation loss 0.8522509336471558, embedding dim 2, hidden size 4, num layers 1, train loss 0.5531805157661438, validation loss 0.854397177696228\n",
      "Epoch 1080, current patience 18, model mean validation loss 0.846027135848999, embedding dim 2, hidden size 4, num layers 1, train loss 0.5122592449188232, validation loss 0.850629985332489\n",
      "Epoch 1090, current patience 17, model mean validation loss 0.8441421985626221, embedding dim 2, hidden size 4, num layers 1, train loss 0.6332159638404846, validation loss 0.8617416620254517\n",
      "Epoch 1100, current patience 16, model mean validation loss 0.8472617268562317, embedding dim 2, hidden size 4, num layers 1, train loss 0.60850590467453, validation loss 0.8760582208633423\n",
      "Epoch 1110, current patience 15, model mean validation loss 0.8499682545661926, embedding dim 2, hidden size 4, num layers 1, train loss 0.4829738736152649, validation loss 0.8549486398696899\n",
      "Epoch 1120, current patience 14, model mean validation loss 0.8568897247314453, embedding dim 2, hidden size 4, num layers 1, train loss 0.6639276742935181, validation loss 0.8691735863685608\n",
      "Epoch 1130, current patience 13, model mean validation loss 0.8641477823257446, embedding dim 2, hidden size 4, num layers 1, train loss 0.545373797416687, validation loss 0.8839220404624939\n",
      "Epoch 1140, current patience 12, model mean validation loss 0.8563158512115479, embedding dim 2, hidden size 4, num layers 1, train loss 0.40643221139907837, validation loss 0.7996553182601929\n",
      "Epoch 1150, current patience 11, model mean validation loss 0.8542826771736145, embedding dim 2, hidden size 4, num layers 1, train loss 0.5625343322753906, validation loss 0.8381319046020508\n",
      "Epoch 1160, current patience 10, model mean validation loss 0.8607815504074097, embedding dim 2, hidden size 4, num layers 1, train loss 0.3937062919139862, validation loss 0.9026212692260742\n",
      "Epoch 1170, current patience 9, model mean validation loss 0.8607615232467651, embedding dim 2, hidden size 4, num layers 1, train loss 0.7377612590789795, validation loss 0.8615810871124268\n",
      "Epoch 1180, current patience 8, model mean validation loss 0.8643194437026978, embedding dim 2, hidden size 4, num layers 1, train loss 0.5714551210403442, validation loss 0.9045214653015137\n",
      "Epoch 1190, current patience 7, model mean validation loss 0.8650312423706055, embedding dim 2, hidden size 4, num layers 1, train loss 0.4750676155090332, validation loss 0.8606431484222412\n",
      "Epoch 1200, current patience 6, model mean validation loss 0.8640391230583191, embedding dim 2, hidden size 4, num layers 1, train loss 0.572641909122467, validation loss 0.8612370491027832\n",
      "Epoch 1210, current patience 5, model mean validation loss 0.858911395072937, embedding dim 2, hidden size 4, num layers 1, train loss 0.6236879825592041, validation loss 0.8428997993469238\n",
      "Epoch 1220, current patience 4, model mean validation loss 0.8685185313224792, embedding dim 2, hidden size 4, num layers 1, train loss 0.6309478282928467, validation loss 0.8765125274658203\n",
      "Epoch 1230, current patience 3, model mean validation loss 0.8708250522613525, embedding dim 2, hidden size 4, num layers 1, train loss 0.5053908824920654, validation loss 0.8565837144851685\n",
      "Epoch 1240, current patience 2, model mean validation loss 0.8653172254562378, embedding dim 2, hidden size 4, num layers 1, train loss 0.513553261756897, validation loss 0.858559250831604\n",
      "Epoch 1250, current patience 1, model mean validation loss 0.8672565221786499, embedding dim 2, hidden size 4, num layers 1, train loss 0.5025214552879333, validation loss 0.8770950436592102\n",
      "Epoch 0, current patience 30, model mean validation loss 1.114174485206604, embedding dim 2, hidden size 8, num layers 1, train loss 1.1476560831069946, validation loss 1.114174485206604\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1054555177688599, embedding dim 2, hidden size 8, num layers 1, train loss 1.0937083959579468, validation loss 1.0967365503311157\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1049388647079468, embedding dim 2, hidden size 8, num layers 1, train loss 1.0928492546081543, validation loss 1.1039056777954102\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1029713153839111, embedding dim 2, hidden size 8, num layers 1, train loss 1.0758302211761475, validation loss 1.097068428993225\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1012582778930664, embedding dim 2, hidden size 8, num layers 1, train loss 1.0846669673919678, validation loss 1.0944066047668457\n",
      "Epoch 50, current patience 30, model mean validation loss 1.10025155544281, embedding dim 2, hidden size 8, num layers 1, train loss 1.0979185104370117, validation loss 1.0952174663543701\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0999083518981934, embedding dim 2, hidden size 8, num layers 1, train loss 1.0936226844787598, validation loss 1.0978493690490723\n",
      "Epoch 70, current patience 30, model mean validation loss 1.099073886871338, embedding dim 2, hidden size 8, num layers 1, train loss 1.110921859741211, validation loss 1.0932328701019287\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0968631505966187, embedding dim 2, hidden size 8, num layers 1, train loss 1.0906920433044434, validation loss 1.0964879989624023\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0968148708343506, embedding dim 2, hidden size 8, num layers 1, train loss 1.091027855873108, validation loss 1.0963505506515503\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0957423448562622, embedding dim 2, hidden size 8, num layers 1, train loss 1.088657259941101, validation loss 1.0953254699707031\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0955533981323242, embedding dim 2, hidden size 8, num layers 1, train loss 1.0906237363815308, validation loss 1.0955572128295898\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0955159664154053, embedding dim 2, hidden size 8, num layers 1, train loss 1.0830333232879639, validation loss 1.0941070318222046\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0951992273330688, embedding dim 2, hidden size 8, num layers 1, train loss 1.0975220203399658, validation loss 1.0926835536956787\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0949387550354004, embedding dim 2, hidden size 8, num layers 1, train loss 1.0864368677139282, validation loss 1.095765471458435\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0940029621124268, embedding dim 2, hidden size 8, num layers 1, train loss 1.1070654392242432, validation loss 1.08574640750885\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0931955575942993, embedding dim 2, hidden size 8, num layers 1, train loss 1.0888593196868896, validation loss 1.0900286436080933\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0908911228179932, embedding dim 2, hidden size 8, num layers 1, train loss 1.051072120666504, validation loss 1.077915906906128\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0871933698654175, embedding dim 2, hidden size 8, num layers 1, train loss 1.0204753875732422, validation loss 1.0657424926757812\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0812205076217651, embedding dim 2, hidden size 8, num layers 1, train loss 0.9895233511924744, validation loss 1.047774314880371\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0743120908737183, embedding dim 2, hidden size 8, num layers 1, train loss 1.0250897407531738, validation loss 1.0388396978378296\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0650513172149658, embedding dim 2, hidden size 8, num layers 1, train loss 1.040287971496582, validation loss 1.0185980796813965\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0555682182312012, embedding dim 2, hidden size 8, num layers 1, train loss 0.9960633516311646, validation loss 1.0199003219604492\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0463985204696655, embedding dim 2, hidden size 8, num layers 1, train loss 1.0142641067504883, validation loss 1.0123885869979858\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0359420776367188, embedding dim 2, hidden size 8, num layers 1, train loss 0.9648707509040833, validation loss 1.0063767433166504\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0278747081756592, embedding dim 2, hidden size 8, num layers 1, train loss 1.017125129699707, validation loss 1.0133774280548096\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0196502208709717, embedding dim 2, hidden size 8, num layers 1, train loss 1.0222883224487305, validation loss 0.999946653842926\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0139609575271606, embedding dim 2, hidden size 8, num layers 1, train loss 0.9370483160018921, validation loss 1.0022597312927246\n",
      "Epoch 280, current patience 30, model mean validation loss 1.006762981414795, embedding dim 2, hidden size 8, num layers 1, train loss 0.9407044649124146, validation loss 0.9812557697296143\n",
      "Epoch 290, current patience 30, model mean validation loss 1.002923846244812, embedding dim 2, hidden size 8, num layers 1, train loss 1.0168707370758057, validation loss 0.9878849387168884\n",
      "Epoch 300, current patience 30, model mean validation loss 0.996799886226654, embedding dim 2, hidden size 8, num layers 1, train loss 0.9865617752075195, validation loss 0.9709085822105408\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9889143705368042, embedding dim 2, hidden size 8, num layers 1, train loss 0.9256059527397156, validation loss 0.9493050575256348\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9824106097221375, embedding dim 2, hidden size 8, num layers 1, train loss 0.8404192924499512, validation loss 0.954346776008606\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9769717454910278, embedding dim 2, hidden size 8, num layers 1, train loss 0.8691352009773254, validation loss 0.9698662757873535\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9713654518127441, embedding dim 2, hidden size 8, num layers 1, train loss 0.8929347395896912, validation loss 0.9550960063934326\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9659096598625183, embedding dim 2, hidden size 8, num layers 1, train loss 0.9566367864608765, validation loss 0.958613395690918\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9609761834144592, embedding dim 2, hidden size 8, num layers 1, train loss 0.9143394231796265, validation loss 0.9417880773544312\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9561193585395813, embedding dim 2, hidden size 8, num layers 1, train loss 0.9219179153442383, validation loss 0.9490309953689575\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9527485370635986, embedding dim 2, hidden size 8, num layers 1, train loss 0.8153524994850159, validation loss 0.943942129611969\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9503359794616699, embedding dim 2, hidden size 8, num layers 1, train loss 0.8594905734062195, validation loss 0.9300044178962708\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9457072019577026, embedding dim 2, hidden size 8, num layers 1, train loss 0.9543967247009277, validation loss 0.9173163175582886\n",
      "Epoch 410, current patience 30, model mean validation loss 0.940300464630127, embedding dim 2, hidden size 8, num layers 1, train loss 0.9551403522491455, validation loss 0.9266127943992615\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9371212720870972, embedding dim 2, hidden size 8, num layers 1, train loss 0.8168847560882568, validation loss 0.9296618700027466\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9327183961868286, embedding dim 2, hidden size 8, num layers 1, train loss 0.8110045790672302, validation loss 0.9233908653259277\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9283663034439087, embedding dim 2, hidden size 8, num layers 1, train loss 0.9668092727661133, validation loss 0.9069713354110718\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9233852028846741, embedding dim 2, hidden size 8, num layers 1, train loss 0.8651909828186035, validation loss 0.9091821908950806\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9162314534187317, embedding dim 2, hidden size 8, num layers 1, train loss 0.881331205368042, validation loss 0.8867119550704956\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9149060249328613, embedding dim 2, hidden size 8, num layers 1, train loss 0.8126223087310791, validation loss 0.9194009304046631\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9109289050102234, embedding dim 2, hidden size 8, num layers 1, train loss 0.7415659427642822, validation loss 0.885499119758606\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9048632979393005, embedding dim 2, hidden size 8, num layers 1, train loss 0.7746291756629944, validation loss 0.8780879378318787\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8989540338516235, embedding dim 2, hidden size 8, num layers 1, train loss 0.8546003103256226, validation loss 0.8823880553245544\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8913758993148804, embedding dim 2, hidden size 8, num layers 1, train loss 0.6793898344039917, validation loss 0.8627656102180481\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8861439824104309, embedding dim 2, hidden size 8, num layers 1, train loss 0.7565263509750366, validation loss 0.865116536617279\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8786003589630127, embedding dim 2, hidden size 8, num layers 1, train loss 0.7974369525909424, validation loss 0.8488332629203796\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8745225667953491, embedding dim 2, hidden size 8, num layers 1, train loss 0.7993791103363037, validation loss 0.8540892004966736\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8700515627861023, embedding dim 2, hidden size 8, num layers 1, train loss 0.7160462141036987, validation loss 0.8836328387260437\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8657292127609253, embedding dim 2, hidden size 8, num layers 1, train loss 0.7093296647071838, validation loss 0.8509199619293213\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8618238568305969, embedding dim 2, hidden size 8, num layers 1, train loss 0.6859262585639954, validation loss 0.8468449711799622\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8565013408660889, embedding dim 2, hidden size 8, num layers 1, train loss 0.7411798238754272, validation loss 0.8398083448410034\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8545100688934326, embedding dim 2, hidden size 8, num layers 1, train loss 0.8257880210876465, validation loss 0.8468354344367981\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8528144359588623, embedding dim 2, hidden size 8, num layers 1, train loss 0.5358403921127319, validation loss 0.8515520691871643\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8529268503189087, embedding dim 2, hidden size 8, num layers 1, train loss 0.7429356575012207, validation loss 0.8497319221496582\n",
      "Epoch 620, current patience 29, model mean validation loss 0.8533025979995728, embedding dim 2, hidden size 8, num layers 1, train loss 0.7660905122756958, validation loss 0.8570955395698547\n",
      "Epoch 630, current patience 28, model mean validation loss 0.8472619652748108, embedding dim 2, hidden size 8, num layers 1, train loss 0.7227400541305542, validation loss 0.8353074193000793\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8427039384841919, embedding dim 2, hidden size 8, num layers 1, train loss 0.66026771068573, validation loss 0.8144561052322388\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8425301313400269, embedding dim 2, hidden size 8, num layers 1, train loss 0.7456526756286621, validation loss 0.8454535007476807\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8407634496688843, embedding dim 2, hidden size 8, num layers 1, train loss 0.648620069026947, validation loss 0.8256750106811523\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8402954339981079, embedding dim 2, hidden size 8, num layers 1, train loss 0.630067765712738, validation loss 0.8430918455123901\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8368643522262573, embedding dim 2, hidden size 8, num layers 1, train loss 0.654423713684082, validation loss 0.824103057384491\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8353261351585388, embedding dim 2, hidden size 8, num layers 1, train loss 0.632725715637207, validation loss 0.8374263644218445\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8328725695610046, embedding dim 2, hidden size 8, num layers 1, train loss 0.49041879177093506, validation loss 0.8374672532081604\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8294641375541687, embedding dim 2, hidden size 8, num layers 1, train loss 0.5974118709564209, validation loss 0.8080403804779053\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8313612937927246, embedding dim 2, hidden size 8, num layers 1, train loss 0.6636107563972473, validation loss 0.829633355140686\n",
      "Epoch 730, current patience 29, model mean validation loss 0.8295567035675049, embedding dim 2, hidden size 8, num layers 1, train loss 0.6751258373260498, validation loss 0.8310164213180542\n",
      "Epoch 740, current patience 28, model mean validation loss 0.8370043039321899, embedding dim 2, hidden size 8, num layers 1, train loss 0.6665132641792297, validation loss 0.8852554559707642\n",
      "Epoch 750, current patience 27, model mean validation loss 0.8319712281227112, embedding dim 2, hidden size 8, num layers 1, train loss 0.648543119430542, validation loss 0.8028275966644287\n",
      "Epoch 760, current patience 26, model mean validation loss 0.8309569358825684, embedding dim 2, hidden size 8, num layers 1, train loss 0.6635826230049133, validation loss 0.8159888386726379\n",
      "Epoch 770, current patience 25, model mean validation loss 0.8271099328994751, embedding dim 2, hidden size 8, num layers 1, train loss 0.6583756804466248, validation loss 0.8066500425338745\n",
      "Epoch 780, current patience 30, model mean validation loss 0.825397253036499, embedding dim 2, hidden size 8, num layers 1, train loss 0.6788257360458374, validation loss 0.8237663507461548\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8304973244667053, embedding dim 2, hidden size 8, num layers 1, train loss 0.6565981507301331, validation loss 0.8488405346870422\n",
      "Epoch 800, current patience 29, model mean validation loss 0.8289064764976501, embedding dim 2, hidden size 8, num layers 1, train loss 0.5271713733673096, validation loss 0.8169066905975342\n",
      "Epoch 810, current patience 28, model mean validation loss 0.8290125131607056, embedding dim 2, hidden size 8, num layers 1, train loss 0.8238915205001831, validation loss 0.831864595413208\n",
      "Epoch 820, current patience 27, model mean validation loss 0.8223140835762024, embedding dim 2, hidden size 8, num layers 1, train loss 0.696882963180542, validation loss 0.8316681385040283\n",
      "Epoch 830, current patience 30, model mean validation loss 0.8202085494995117, embedding dim 2, hidden size 8, num layers 1, train loss 0.58375483751297, validation loss 0.7859833240509033\n",
      "Epoch 840, current patience 30, model mean validation loss 0.8210248947143555, embedding dim 2, hidden size 8, num layers 1, train loss 0.717605710029602, validation loss 0.8225196599960327\n",
      "Epoch 850, current patience 29, model mean validation loss 0.8217421174049377, embedding dim 2, hidden size 8, num layers 1, train loss 0.5517208576202393, validation loss 0.8123877048492432\n",
      "Epoch 860, current patience 28, model mean validation loss 0.8206153512001038, embedding dim 2, hidden size 8, num layers 1, train loss 0.5840135812759399, validation loss 0.8147522807121277\n",
      "Epoch 870, current patience 27, model mean validation loss 0.8121992349624634, embedding dim 2, hidden size 8, num layers 1, train loss 0.6915068030357361, validation loss 0.7815117835998535\n",
      "Epoch 880, current patience 30, model mean validation loss 0.8099082708358765, embedding dim 2, hidden size 8, num layers 1, train loss 0.6393591165542603, validation loss 0.7985789775848389\n",
      "Epoch 890, current patience 30, model mean validation loss 0.8066956400871277, embedding dim 2, hidden size 8, num layers 1, train loss 0.7968426942825317, validation loss 0.8061631917953491\n",
      "Epoch 900, current patience 30, model mean validation loss 0.8037628531455994, embedding dim 2, hidden size 8, num layers 1, train loss 0.5904111862182617, validation loss 0.8082058429718018\n",
      "Epoch 910, current patience 30, model mean validation loss 0.8100612163543701, embedding dim 2, hidden size 8, num layers 1, train loss 0.4685589671134949, validation loss 0.8363699913024902\n",
      "Epoch 920, current patience 29, model mean validation loss 0.8140424489974976, embedding dim 2, hidden size 8, num layers 1, train loss 0.56562340259552, validation loss 0.8543699979782104\n",
      "Epoch 930, current patience 28, model mean validation loss 0.8141599893569946, embedding dim 2, hidden size 8, num layers 1, train loss 0.6234126091003418, validation loss 0.8133279085159302\n",
      "Epoch 940, current patience 27, model mean validation loss 0.8191069960594177, embedding dim 2, hidden size 8, num layers 1, train loss 0.4837026000022888, validation loss 0.8543285131454468\n",
      "Epoch 950, current patience 26, model mean validation loss 0.8270423412322998, embedding dim 2, hidden size 8, num layers 1, train loss 0.5453909039497375, validation loss 0.8449945449829102\n",
      "Epoch 960, current patience 25, model mean validation loss 0.8263221979141235, embedding dim 2, hidden size 8, num layers 1, train loss 0.6055786609649658, validation loss 0.792818009853363\n",
      "Epoch 970, current patience 24, model mean validation loss 0.8302245736122131, embedding dim 2, hidden size 8, num layers 1, train loss 0.558175265789032, validation loss 0.8373817205429077\n",
      "Epoch 980, current patience 23, model mean validation loss 0.8317238092422485, embedding dim 2, hidden size 8, num layers 1, train loss 0.5212992429733276, validation loss 0.8201994895935059\n",
      "Epoch 990, current patience 22, model mean validation loss 0.8305357098579407, embedding dim 2, hidden size 8, num layers 1, train loss 0.5799785256385803, validation loss 0.8268656730651855\n",
      "Epoch 1000, current patience 21, model mean validation loss 0.8249039649963379, embedding dim 2, hidden size 8, num layers 1, train loss 0.4672073721885681, validation loss 0.8093156814575195\n",
      "Epoch 1010, current patience 20, model mean validation loss 0.8267613053321838, embedding dim 2, hidden size 8, num layers 1, train loss 0.5882638692855835, validation loss 0.8281865119934082\n",
      "Epoch 1020, current patience 19, model mean validation loss 0.8214428424835205, embedding dim 2, hidden size 8, num layers 1, train loss 0.6909477710723877, validation loss 0.8117806315422058\n",
      "Epoch 1030, current patience 18, model mean validation loss 0.823911190032959, embedding dim 2, hidden size 8, num layers 1, train loss 0.6310006976127625, validation loss 0.8647415041923523\n",
      "Epoch 1040, current patience 17, model mean validation loss 0.8294930458068848, embedding dim 2, hidden size 8, num layers 1, train loss 0.7214829921722412, validation loss 0.8374728560447693\n",
      "Epoch 1050, current patience 16, model mean validation loss 0.8259969353675842, embedding dim 2, hidden size 8, num layers 1, train loss 0.40248095989227295, validation loss 0.8094130754470825\n",
      "Epoch 1060, current patience 15, model mean validation loss 0.8269131779670715, embedding dim 2, hidden size 8, num layers 1, train loss 0.41284745931625366, validation loss 0.8275291323661804\n",
      "Epoch 1070, current patience 14, model mean validation loss 0.830069899559021, embedding dim 2, hidden size 8, num layers 1, train loss 0.3706210255622864, validation loss 0.852120041847229\n",
      "Epoch 1080, current patience 13, model mean validation loss 0.8363757729530334, embedding dim 2, hidden size 8, num layers 1, train loss 0.6344532370567322, validation loss 0.8597627878189087\n",
      "Epoch 1090, current patience 12, model mean validation loss 0.8338256478309631, embedding dim 2, hidden size 8, num layers 1, train loss 0.4520280063152313, validation loss 0.8077855110168457\n",
      "Epoch 1100, current patience 11, model mean validation loss 0.8321260213851929, embedding dim 2, hidden size 8, num layers 1, train loss 0.692024827003479, validation loss 0.7981833219528198\n",
      "Epoch 1110, current patience 10, model mean validation loss 0.8280837535858154, embedding dim 2, hidden size 8, num layers 1, train loss 0.6025198698043823, validation loss 0.832403302192688\n",
      "Epoch 1120, current patience 9, model mean validation loss 0.8267984390258789, embedding dim 2, hidden size 8, num layers 1, train loss 0.5729634761810303, validation loss 0.8271907567977905\n",
      "Epoch 1130, current patience 8, model mean validation loss 0.8249237537384033, embedding dim 2, hidden size 8, num layers 1, train loss 0.5942351222038269, validation loss 0.7944148182868958\n",
      "Epoch 1140, current patience 7, model mean validation loss 0.8314459323883057, embedding dim 2, hidden size 8, num layers 1, train loss 0.48268380761146545, validation loss 0.8797067403793335\n",
      "Epoch 1150, current patience 6, model mean validation loss 0.8279311656951904, embedding dim 2, hidden size 8, num layers 1, train loss 0.5431537628173828, validation loss 0.8240020871162415\n",
      "Epoch 1160, current patience 5, model mean validation loss 0.8215054273605347, embedding dim 2, hidden size 8, num layers 1, train loss 0.60474693775177, validation loss 0.8083566427230835\n",
      "Epoch 1170, current patience 4, model mean validation loss 0.8234111070632935, embedding dim 2, hidden size 8, num layers 1, train loss 0.6238117218017578, validation loss 0.8230313658714294\n",
      "Epoch 1180, current patience 3, model mean validation loss 0.8347427845001221, embedding dim 2, hidden size 8, num layers 1, train loss 0.57989102602005, validation loss 0.8888362646102905\n",
      "Epoch 1190, current patience 2, model mean validation loss 0.83808434009552, embedding dim 2, hidden size 8, num layers 1, train loss 0.7342896461486816, validation loss 0.8591359853744507\n",
      "Epoch 1200, current patience 1, model mean validation loss 0.8410868048667908, embedding dim 2, hidden size 8, num layers 1, train loss 0.46109747886657715, validation loss 0.8512108325958252\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0972601175308228, embedding dim 2, hidden size 16, num layers 1, train loss 1.0981720685958862, validation loss 1.0972601175308228\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0956716537475586, embedding dim 2, hidden size 16, num layers 1, train loss 1.1065744161605835, validation loss 1.0940830707550049\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0951191186904907, embedding dim 2, hidden size 16, num layers 1, train loss 1.0901546478271484, validation loss 1.0940141677856445\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0945303440093994, embedding dim 2, hidden size 16, num layers 1, train loss 1.084632396697998, validation loss 1.092763900756836\n",
      "Epoch 40, current patience 30, model mean validation loss 1.093733787536621, embedding dim 2, hidden size 16, num layers 1, train loss 1.0934847593307495, validation loss 1.090548038482666\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0940040349960327, embedding dim 2, hidden size 16, num layers 1, train loss 1.0825529098510742, validation loss 1.0953543186187744\n",
      "Epoch 60, current patience 29, model mean validation loss 1.093894600868225, embedding dim 2, hidden size 16, num layers 1, train loss 1.0932689905166626, validation loss 1.0932378768920898\n",
      "Epoch 70, current patience 28, model mean validation loss 1.0940452814102173, embedding dim 2, hidden size 16, num layers 1, train loss 1.0968317985534668, validation loss 1.0951006412506104\n",
      "Epoch 80, current patience 27, model mean validation loss 1.0929970741271973, embedding dim 2, hidden size 16, num layers 1, train loss 1.0805292129516602, validation loss 1.0888738632202148\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0922255516052246, embedding dim 2, hidden size 16, num layers 1, train loss 1.1016478538513184, validation loss 1.0879124402999878\n",
      "Epoch 100, current patience 30, model mean validation loss 1.090991497039795, embedding dim 2, hidden size 16, num layers 1, train loss 1.0945346355438232, validation loss 1.084140419960022\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0894490480422974, embedding dim 2, hidden size 16, num layers 1, train loss 1.0721848011016846, validation loss 1.0804247856140137\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0870258808135986, embedding dim 2, hidden size 16, num layers 1, train loss 1.0460807085037231, validation loss 1.0711634159088135\n",
      "Epoch 130, current patience 30, model mean validation loss 1.083543062210083, embedding dim 2, hidden size 16, num layers 1, train loss 1.0154132843017578, validation loss 1.0674911737442017\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0787286758422852, embedding dim 2, hidden size 16, num layers 1, train loss 0.996900737285614, validation loss 1.054722547531128\n",
      "Epoch 150, current patience 30, model mean validation loss 1.073448896408081, embedding dim 2, hidden size 16, num layers 1, train loss 1.0184822082519531, validation loss 1.0528619289398193\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0678941011428833, embedding dim 2, hidden size 16, num layers 1, train loss 1.0090949535369873, validation loss 1.0444363355636597\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0616868734359741, embedding dim 2, hidden size 16, num layers 1, train loss 1.111532211303711, validation loss 1.0382540225982666\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0553675889968872, embedding dim 2, hidden size 16, num layers 1, train loss 0.9986736178398132, validation loss 1.0335869789123535\n",
      "Epoch 190, current patience 30, model mean validation loss 1.048459529876709, embedding dim 2, hidden size 16, num layers 1, train loss 0.9750248193740845, validation loss 1.025159478187561\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0413432121276855, embedding dim 2, hidden size 16, num layers 1, train loss 0.9822955131530762, validation loss 1.014232873916626\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0350329875946045, embedding dim 2, hidden size 16, num layers 1, train loss 1.1802562475204468, validation loss 1.0170092582702637\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0294150114059448, embedding dim 2, hidden size 16, num layers 1, train loss 0.9511464834213257, validation loss 1.0097792148590088\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0229336023330688, embedding dim 2, hidden size 16, num layers 1, train loss 0.9327398538589478, validation loss 1.0010100603103638\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0173310041427612, embedding dim 2, hidden size 16, num layers 1, train loss 0.9554705023765564, validation loss 0.999616265296936\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0103332996368408, embedding dim 2, hidden size 16, num layers 1, train loss 1.0084681510925293, validation loss 0.9822724461555481\n",
      "Epoch 260, current patience 30, model mean validation loss 1.003036618232727, embedding dim 2, hidden size 16, num layers 1, train loss 0.9258291721343994, validation loss 0.9752129316329956\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9987203478813171, embedding dim 2, hidden size 16, num layers 1, train loss 0.9448888301849365, validation loss 0.9906296730041504\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9939194917678833, embedding dim 2, hidden size 16, num layers 1, train loss 0.9166837930679321, validation loss 0.9758262634277344\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9869850873947144, embedding dim 2, hidden size 16, num layers 1, train loss 0.9133948087692261, validation loss 0.9615340232849121\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9813364744186401, embedding dim 2, hidden size 16, num layers 1, train loss 0.8774869441986084, validation loss 0.9645900130271912\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9730126261711121, embedding dim 2, hidden size 16, num layers 1, train loss 0.8788169622421265, validation loss 0.934419572353363\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9657177925109863, embedding dim 2, hidden size 16, num layers 1, train loss 0.8301761150360107, validation loss 0.9412577748298645\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9590280055999756, embedding dim 2, hidden size 16, num layers 1, train loss 0.9755977392196655, validation loss 0.9287535548210144\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9527941942214966, embedding dim 2, hidden size 16, num layers 1, train loss 0.8786025047302246, validation loss 0.9253427982330322\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9431115984916687, embedding dim 2, hidden size 16, num layers 1, train loss 0.8873305320739746, validation loss 0.9131686091423035\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9334936141967773, embedding dim 2, hidden size 16, num layers 1, train loss 0.8742784857749939, validation loss 0.8988823890686035\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9271607398986816, embedding dim 2, hidden size 16, num layers 1, train loss 0.8963079452514648, validation loss 0.910871148109436\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9175593256950378, embedding dim 2, hidden size 16, num layers 1, train loss 0.9371545314788818, validation loss 0.8877785801887512\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9109031558036804, embedding dim 2, hidden size 16, num layers 1, train loss 0.7846763730049133, validation loss 0.8811705112457275\n",
      "Epoch 400, current patience 30, model mean validation loss 0.906700611114502, embedding dim 2, hidden size 16, num layers 1, train loss 0.8497775197029114, validation loss 0.9076372385025024\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8975541591644287, embedding dim 2, hidden size 16, num layers 1, train loss 0.8962916731834412, validation loss 0.855582058429718\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8962686657905579, embedding dim 2, hidden size 16, num layers 1, train loss 0.9346286058425903, validation loss 0.9150586724281311\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8912016749382019, embedding dim 2, hidden size 16, num layers 1, train loss 0.8290169835090637, validation loss 0.8726328015327454\n",
      "Epoch 440, current patience 30, model mean validation loss 0.886513352394104, embedding dim 2, hidden size 16, num layers 1, train loss 0.7899072170257568, validation loss 0.861375629901886\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8824082016944885, embedding dim 2, hidden size 16, num layers 1, train loss 0.9101523756980896, validation loss 0.8780299425125122\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8799234628677368, embedding dim 2, hidden size 16, num layers 1, train loss 0.7641820311546326, validation loss 0.8679009079933167\n",
      "Epoch 470, current patience 30, model mean validation loss 0.880261242389679, embedding dim 2, hidden size 16, num layers 1, train loss 0.8020516633987427, validation loss 0.8838726878166199\n",
      "Epoch 480, current patience 29, model mean validation loss 0.8722996711730957, embedding dim 2, hidden size 16, num layers 1, train loss 0.7776123285293579, validation loss 0.8439444303512573\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8732621073722839, embedding dim 2, hidden size 16, num layers 1, train loss 0.8282370567321777, validation loss 0.8632814884185791\n",
      "Epoch 500, current patience 29, model mean validation loss 0.8652414679527283, embedding dim 2, hidden size 16, num layers 1, train loss 0.7976324558258057, validation loss 0.8508937954902649\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8641671538352966, embedding dim 2, hidden size 16, num layers 1, train loss 0.7429924011230469, validation loss 0.864038348197937\n",
      "Epoch 520, current patience 30, model mean validation loss 0.865933895111084, embedding dim 2, hidden size 16, num layers 1, train loss 0.7452316284179688, validation loss 0.8755096793174744\n",
      "Epoch 530, current patience 29, model mean validation loss 0.8642569780349731, embedding dim 2, hidden size 16, num layers 1, train loss 0.8268887996673584, validation loss 0.8646143078804016\n",
      "Epoch 540, current patience 28, model mean validation loss 0.8632514476776123, embedding dim 2, hidden size 16, num layers 1, train loss 0.6912711262702942, validation loss 0.8598564863204956\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8616741895675659, embedding dim 2, hidden size 16, num layers 1, train loss 0.8003774881362915, validation loss 0.8712550401687622\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8623566627502441, embedding dim 2, hidden size 16, num layers 1, train loss 0.8150858879089355, validation loss 0.8494042158126831\n",
      "Epoch 570, current patience 29, model mean validation loss 0.8631454706192017, embedding dim 2, hidden size 16, num layers 1, train loss 0.717505693435669, validation loss 0.8695921897888184\n",
      "Epoch 580, current patience 28, model mean validation loss 0.861111044883728, embedding dim 2, hidden size 16, num layers 1, train loss 0.6955368518829346, validation loss 0.834618091583252\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8536561131477356, embedding dim 2, hidden size 16, num layers 1, train loss 0.7089784741401672, validation loss 0.8043988943099976\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8506863713264465, embedding dim 2, hidden size 16, num layers 1, train loss 0.7421194911003113, validation loss 0.8517518639564514\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8497693538665771, embedding dim 2, hidden size 16, num layers 1, train loss 0.7576346397399902, validation loss 0.8572778701782227\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8493552803993225, embedding dim 2, hidden size 16, num layers 1, train loss 0.7174570560455322, validation loss 0.8565440773963928\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8442522287368774, embedding dim 2, hidden size 16, num layers 1, train loss 0.862285852432251, validation loss 0.8304307460784912\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8450443148612976, embedding dim 2, hidden size 16, num layers 1, train loss 0.6800544261932373, validation loss 0.8557409048080444\n",
      "Epoch 650, current patience 29, model mean validation loss 0.840564489364624, embedding dim 2, hidden size 16, num layers 1, train loss 0.6679369211196899, validation loss 0.8337537050247192\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8442745208740234, embedding dim 2, hidden size 16, num layers 1, train loss 0.8354928493499756, validation loss 0.8642981648445129\n",
      "Epoch 670, current patience 29, model mean validation loss 0.8516858220100403, embedding dim 2, hidden size 16, num layers 1, train loss 0.7168644070625305, validation loss 0.8636891841888428\n",
      "Epoch 680, current patience 28, model mean validation loss 0.8497021198272705, embedding dim 2, hidden size 16, num layers 1, train loss 0.6755928993225098, validation loss 0.8358825445175171\n",
      "Epoch 690, current patience 27, model mean validation loss 0.8487530946731567, embedding dim 2, hidden size 16, num layers 1, train loss 0.7683554887771606, validation loss 0.8496856689453125\n",
      "Epoch 700, current patience 26, model mean validation loss 0.8477509021759033, embedding dim 2, hidden size 16, num layers 1, train loss 0.6903838515281677, validation loss 0.8485260009765625\n",
      "Epoch 710, current patience 25, model mean validation loss 0.8497022390365601, embedding dim 2, hidden size 16, num layers 1, train loss 0.6323601007461548, validation loss 0.8460416197776794\n",
      "Epoch 720, current patience 24, model mean validation loss 0.8482271432876587, embedding dim 2, hidden size 16, num layers 1, train loss 0.6768980622291565, validation loss 0.8439400792121887\n",
      "Epoch 730, current patience 23, model mean validation loss 0.8502023220062256, embedding dim 2, hidden size 16, num layers 1, train loss 0.7702734470367432, validation loss 0.8495550155639648\n",
      "Epoch 740, current patience 22, model mean validation loss 0.8481155633926392, embedding dim 2, hidden size 16, num layers 1, train loss 0.7031650543212891, validation loss 0.8476042151451111\n",
      "Epoch 750, current patience 21, model mean validation loss 0.8455756306648254, embedding dim 2, hidden size 16, num layers 1, train loss 0.68352210521698, validation loss 0.8433700203895569\n",
      "Epoch 760, current patience 20, model mean validation loss 0.844646692276001, embedding dim 2, hidden size 16, num layers 1, train loss 0.6693053245544434, validation loss 0.8284506797790527\n",
      "Epoch 770, current patience 19, model mean validation loss 0.8396782875061035, embedding dim 2, hidden size 16, num layers 1, train loss 0.7366818189620972, validation loss 0.8099385499954224\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8393237590789795, embedding dim 2, hidden size 16, num layers 1, train loss 0.6687527894973755, validation loss 0.8456900119781494\n",
      "Epoch 790, current patience 30, model mean validation loss 0.8409579992294312, embedding dim 2, hidden size 16, num layers 1, train loss 0.6061150431632996, validation loss 0.8591153025627136\n",
      "Epoch 800, current patience 29, model mean validation loss 0.8432967662811279, embedding dim 2, hidden size 16, num layers 1, train loss 0.6110082864761353, validation loss 0.8626501560211182\n",
      "Epoch 810, current patience 28, model mean validation loss 0.8436934947967529, embedding dim 2, hidden size 16, num layers 1, train loss 0.6344538927078247, validation loss 0.852728545665741\n",
      "Epoch 820, current patience 27, model mean validation loss 0.8473485708236694, embedding dim 2, hidden size 16, num layers 1, train loss 0.6628316640853882, validation loss 0.8768450021743774\n",
      "Epoch 830, current patience 26, model mean validation loss 0.8464077711105347, embedding dim 2, hidden size 16, num layers 1, train loss 0.6560695767402649, validation loss 0.8358440399169922\n",
      "Epoch 840, current patience 25, model mean validation loss 0.853047251701355, embedding dim 2, hidden size 16, num layers 1, train loss 0.6220145225524902, validation loss 0.8815669417381287\n",
      "Epoch 850, current patience 24, model mean validation loss 0.8592658638954163, embedding dim 2, hidden size 16, num layers 1, train loss 0.611135721206665, validation loss 0.859686553478241\n",
      "Epoch 860, current patience 23, model mean validation loss 0.856251060962677, embedding dim 2, hidden size 16, num layers 1, train loss 0.6972581148147583, validation loss 0.8215718269348145\n",
      "Epoch 870, current patience 22, model mean validation loss 0.8534137010574341, embedding dim 2, hidden size 16, num layers 1, train loss 0.590164303779602, validation loss 0.8364165425300598\n",
      "Epoch 880, current patience 21, model mean validation loss 0.8528193235397339, embedding dim 2, hidden size 16, num layers 1, train loss 0.5739569664001465, validation loss 0.857894778251648\n",
      "Epoch 890, current patience 20, model mean validation loss 0.8529729843139648, embedding dim 2, hidden size 16, num layers 1, train loss 0.6139439940452576, validation loss 0.8539583683013916\n",
      "Epoch 900, current patience 19, model mean validation loss 0.8478524684906006, embedding dim 2, hidden size 16, num layers 1, train loss 0.6823976635932922, validation loss 0.8358808755874634\n",
      "Epoch 910, current patience 18, model mean validation loss 0.8463500738143921, embedding dim 2, hidden size 16, num layers 1, train loss 0.6937296390533447, validation loss 0.8238245844841003\n",
      "Epoch 920, current patience 17, model mean validation loss 0.8422790765762329, embedding dim 2, hidden size 16, num layers 1, train loss 0.6616843938827515, validation loss 0.8489989042282104\n",
      "Epoch 930, current patience 16, model mean validation loss 0.8383370637893677, embedding dim 2, hidden size 16, num layers 1, train loss 0.584660530090332, validation loss 0.8281503319740295\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8431161642074585, embedding dim 2, hidden size 16, num layers 1, train loss 0.5911312103271484, validation loss 0.8598049283027649\n",
      "Epoch 950, current patience 29, model mean validation loss 0.8443639874458313, embedding dim 2, hidden size 16, num layers 1, train loss 0.4973818063735962, validation loss 0.8463990092277527\n",
      "Epoch 960, current patience 28, model mean validation loss 0.8395382165908813, embedding dim 2, hidden size 16, num layers 1, train loss 0.5900756120681763, validation loss 0.819288969039917\n",
      "Epoch 970, current patience 27, model mean validation loss 0.8392555713653564, embedding dim 2, hidden size 16, num layers 1, train loss 0.558796763420105, validation loss 0.8516966104507446\n",
      "Epoch 980, current patience 26, model mean validation loss 0.8424715995788574, embedding dim 2, hidden size 16, num layers 1, train loss 0.6452429294586182, validation loss 0.8616098165512085\n",
      "Epoch 990, current patience 25, model mean validation loss 0.8443905115127563, embedding dim 2, hidden size 16, num layers 1, train loss 0.5284066200256348, validation loss 0.8391757607460022\n",
      "Epoch 1000, current patience 24, model mean validation loss 0.8465464115142822, embedding dim 2, hidden size 16, num layers 1, train loss 0.4510721266269684, validation loss 0.8662455081939697\n",
      "Epoch 1010, current patience 23, model mean validation loss 0.8504495620727539, embedding dim 2, hidden size 16, num layers 1, train loss 0.5343184471130371, validation loss 0.8593759536743164\n",
      "Epoch 1020, current patience 22, model mean validation loss 0.8502975702285767, embedding dim 2, hidden size 16, num layers 1, train loss 0.5199955105781555, validation loss 0.8585888147354126\n",
      "Epoch 1030, current patience 21, model mean validation loss 0.8519387245178223, embedding dim 2, hidden size 16, num layers 1, train loss 0.5642638802528381, validation loss 0.8595281839370728\n",
      "Epoch 1040, current patience 20, model mean validation loss 0.8549646139144897, embedding dim 2, hidden size 16, num layers 1, train loss 0.6504628658294678, validation loss 0.8434959650039673\n",
      "Epoch 1050, current patience 19, model mean validation loss 0.8561388850212097, embedding dim 2, hidden size 16, num layers 1, train loss 0.5798126459121704, validation loss 0.8610910773277283\n",
      "Epoch 1060, current patience 18, model mean validation loss 0.8507587909698486, embedding dim 2, hidden size 16, num layers 1, train loss 0.6470353603363037, validation loss 0.8185693025588989\n",
      "Epoch 1070, current patience 17, model mean validation loss 0.8525896668434143, embedding dim 2, hidden size 16, num layers 1, train loss 0.6318881511688232, validation loss 0.8538225889205933\n",
      "Epoch 1080, current patience 16, model mean validation loss 0.8524160385131836, embedding dim 2, hidden size 16, num layers 1, train loss 0.5468001365661621, validation loss 0.8648562431335449\n",
      "Epoch 1090, current patience 15, model mean validation loss 0.8535344004631042, embedding dim 2, hidden size 16, num layers 1, train loss 0.5864589214324951, validation loss 0.8683229684829712\n",
      "Epoch 1100, current patience 14, model mean validation loss 0.8577275276184082, embedding dim 2, hidden size 16, num layers 1, train loss 0.6096518635749817, validation loss 0.8921342492103577\n",
      "Epoch 1110, current patience 13, model mean validation loss 0.8608540296554565, embedding dim 2, hidden size 16, num layers 1, train loss 0.667506217956543, validation loss 0.8845400214195251\n",
      "Epoch 1120, current patience 12, model mean validation loss 0.8621406555175781, embedding dim 2, hidden size 16, num layers 1, train loss 0.632671594619751, validation loss 0.8537887334823608\n",
      "Epoch 1130, current patience 11, model mean validation loss 0.8627524971961975, embedding dim 2, hidden size 16, num layers 1, train loss 0.41834691166877747, validation loss 0.8659858107566833\n",
      "Epoch 1140, current patience 10, model mean validation loss 0.8684897422790527, embedding dim 2, hidden size 16, num layers 1, train loss 0.6383604407310486, validation loss 0.8644673824310303\n",
      "Epoch 1150, current patience 9, model mean validation loss 0.8663097023963928, embedding dim 2, hidden size 16, num layers 1, train loss 0.3945555090904236, validation loss 0.8363819122314453\n",
      "Epoch 1160, current patience 8, model mean validation loss 0.8666369915008545, embedding dim 2, hidden size 16, num layers 1, train loss 0.7307206988334656, validation loss 0.8674750328063965\n",
      "Epoch 1170, current patience 7, model mean validation loss 0.8664731383323669, embedding dim 2, hidden size 16, num layers 1, train loss 0.6535807847976685, validation loss 0.8670122027397156\n",
      "Epoch 1180, current patience 6, model mean validation loss 0.8660341501235962, embedding dim 2, hidden size 16, num layers 1, train loss 0.5090943574905396, validation loss 0.8886221647262573\n",
      "Epoch 1190, current patience 5, model mean validation loss 0.8619816303253174, embedding dim 2, hidden size 16, num layers 1, train loss 0.8156940937042236, validation loss 0.8521202206611633\n",
      "Epoch 1200, current patience 4, model mean validation loss 0.8628079891204834, embedding dim 2, hidden size 16, num layers 1, train loss 0.6008622050285339, validation loss 0.8603993654251099\n",
      "Epoch 1210, current patience 3, model mean validation loss 0.864129900932312, embedding dim 2, hidden size 16, num layers 1, train loss 0.5603165626525879, validation loss 0.8765610456466675\n",
      "Epoch 1220, current patience 2, model mean validation loss 0.8682072162628174, embedding dim 2, hidden size 16, num layers 1, train loss 0.4904588758945465, validation loss 0.8970855474472046\n",
      "Epoch 1230, current patience 1, model mean validation loss 0.8763435482978821, embedding dim 2, hidden size 16, num layers 1, train loss 0.7914050817489624, validation loss 0.9014727473258972\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0980424880981445, embedding dim 2, hidden size 32, num layers 1, train loss 1.1017879247665405, validation loss 1.0980424880981445\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0964738130569458, embedding dim 2, hidden size 32, num layers 1, train loss 1.0948550701141357, validation loss 1.094905138015747\n",
      "Epoch 20, current patience 30, model mean validation loss 1.096004605293274, embedding dim 2, hidden size 32, num layers 1, train loss 1.0989131927490234, validation loss 1.0950663089752197\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0957132577896118, embedding dim 2, hidden size 32, num layers 1, train loss 1.0833673477172852, validation loss 1.094839096069336\n",
      "Epoch 40, current patience 30, model mean validation loss 1.09546959400177, embedding dim 2, hidden size 32, num layers 1, train loss 1.1012203693389893, validation loss 1.0944948196411133\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0953508615493774, embedding dim 2, hidden size 32, num layers 1, train loss 1.1127352714538574, validation loss 1.0947577953338623\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0953681468963623, embedding dim 2, hidden size 32, num layers 1, train loss 1.0963704586029053, validation loss 1.0954718589782715\n",
      "Epoch 70, current patience 29, model mean validation loss 1.0952894687652588, embedding dim 2, hidden size 32, num layers 1, train loss 1.1077749729156494, validation loss 1.094738245010376\n",
      "Epoch 80, current patience 30, model mean validation loss 1.094448447227478, embedding dim 2, hidden size 32, num layers 1, train loss 1.093558430671692, validation loss 1.0913141965866089\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0929234027862549, embedding dim 2, hidden size 32, num layers 1, train loss 1.0746712684631348, validation loss 1.0827051401138306\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0911587476730347, embedding dim 2, hidden size 32, num layers 1, train loss 1.0762529373168945, validation loss 1.080949068069458\n",
      "Epoch 110, current patience 30, model mean validation loss 1.08868408203125, embedding dim 2, hidden size 32, num layers 1, train loss 1.0148602724075317, validation loss 1.0750417709350586\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0847620964050293, embedding dim 2, hidden size 32, num layers 1, train loss 1.0543932914733887, validation loss 1.0631192922592163\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0802905559539795, embedding dim 2, hidden size 32, num layers 1, train loss 1.082134485244751, validation loss 1.058984637260437\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0739109516143799, embedding dim 2, hidden size 32, num layers 1, train loss 1.105668544769287, validation loss 1.044434905052185\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0682806968688965, embedding dim 2, hidden size 32, num layers 1, train loss 1.044780969619751, validation loss 1.0496958494186401\n",
      "Epoch 160, current patience 30, model mean validation loss 1.062309980392456, embedding dim 2, hidden size 32, num layers 1, train loss 1.0047931671142578, validation loss 1.0435497760772705\n",
      "Epoch 170, current patience 30, model mean validation loss 1.056999683380127, embedding dim 2, hidden size 32, num layers 1, train loss 1.0321472883224487, validation loss 1.04022216796875\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0497490167617798, embedding dim 2, hidden size 32, num layers 1, train loss 1.0642096996307373, validation loss 1.0229434967041016\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0433800220489502, embedding dim 2, hidden size 32, num layers 1, train loss 1.0195727348327637, validation loss 1.0240904092788696\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0367928743362427, embedding dim 2, hidden size 32, num layers 1, train loss 1.0390738248825073, validation loss 1.0104217529296875\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0306427478790283, embedding dim 2, hidden size 32, num layers 1, train loss 0.9088200330734253, validation loss 1.0097832679748535\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0248243808746338, embedding dim 2, hidden size 32, num layers 1, train loss 0.9690403938293457, validation loss 0.9978877305984497\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0185354948043823, embedding dim 2, hidden size 32, num layers 1, train loss 1.0064539909362793, validation loss 0.9993854761123657\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0114434957504272, embedding dim 2, hidden size 32, num layers 1, train loss 1.0138622522354126, validation loss 0.9868135452270508\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0026799440383911, embedding dim 2, hidden size 32, num layers 1, train loss 0.9577970504760742, validation loss 0.9701145887374878\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9978503584861755, embedding dim 2, hidden size 32, num layers 1, train loss 0.9340723752975464, validation loss 0.9843063354492188\n",
      "Epoch 270, current patience 30, model mean validation loss 0.989989161491394, embedding dim 2, hidden size 32, num layers 1, train loss 0.9537520408630371, validation loss 0.9612003564834595\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9842992424964905, embedding dim 2, hidden size 32, num layers 1, train loss 0.9014320373535156, validation loss 0.9649023413658142\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9766517281532288, embedding dim 2, hidden size 32, num layers 1, train loss 0.9002218246459961, validation loss 0.9486033320426941\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9701000452041626, embedding dim 2, hidden size 32, num layers 1, train loss 0.9244837760925293, validation loss 0.9454745054244995\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9631795883178711, embedding dim 2, hidden size 32, num layers 1, train loss 0.8201892375946045, validation loss 0.9440216422080994\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9566919803619385, embedding dim 2, hidden size 32, num layers 1, train loss 0.8054918050765991, validation loss 0.9349125027656555\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9518177509307861, embedding dim 2, hidden size 32, num layers 1, train loss 0.8934808969497681, validation loss 0.9311213493347168\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9469372630119324, embedding dim 2, hidden size 32, num layers 1, train loss 0.9116541743278503, validation loss 0.94526207447052\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9383887052536011, embedding dim 2, hidden size 32, num layers 1, train loss 0.8355540037155151, validation loss 0.8928120732307434\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9332374334335327, embedding dim 2, hidden size 32, num layers 1, train loss 0.9235868453979492, validation loss 0.9236921072006226\n",
      "Epoch 370, current patience 30, model mean validation loss 0.926833987236023, embedding dim 2, hidden size 32, num layers 1, train loss 0.9619728922843933, validation loss 0.8973753452301025\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9239677786827087, embedding dim 2, hidden size 32, num layers 1, train loss 0.7852048873901367, validation loss 0.9225449562072754\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9170859456062317, embedding dim 2, hidden size 32, num layers 1, train loss 0.9180766344070435, validation loss 0.8889673352241516\n",
      "Epoch 400, current patience 30, model mean validation loss 0.913070797920227, embedding dim 2, hidden size 32, num layers 1, train loss 0.7625434398651123, validation loss 0.902790904045105\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9065581560134888, embedding dim 2, hidden size 32, num layers 1, train loss 0.7651949524879456, validation loss 0.8790205121040344\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9022299647331238, embedding dim 2, hidden size 32, num layers 1, train loss 0.8937287926673889, validation loss 0.9106365442276001\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9019160270690918, embedding dim 2, hidden size 32, num layers 1, train loss 0.8253167867660522, validation loss 0.8903005719184875\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8965515494346619, embedding dim 2, hidden size 32, num layers 1, train loss 0.8609144687652588, validation loss 0.8807764053344727\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8921575546264648, embedding dim 2, hidden size 32, num layers 1, train loss 0.7208582758903503, validation loss 0.8622230291366577\n",
      "Epoch 460, current patience 30, model mean validation loss 0.884606122970581, embedding dim 2, hidden size 32, num layers 1, train loss 0.8354717493057251, validation loss 0.8621336221694946\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8814475536346436, embedding dim 2, hidden size 32, num layers 1, train loss 0.8031836152076721, validation loss 0.863699197769165\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8782109022140503, embedding dim 2, hidden size 32, num layers 1, train loss 0.8252167701721191, validation loss 0.8768974542617798\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8756664991378784, embedding dim 2, hidden size 32, num layers 1, train loss 0.818193793296814, validation loss 0.8586653470993042\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8667751550674438, embedding dim 2, hidden size 32, num layers 1, train loss 0.7936595678329468, validation loss 0.8395053148269653\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8632909655570984, embedding dim 2, hidden size 32, num layers 1, train loss 0.7660597562789917, validation loss 0.8624269962310791\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8639508485794067, embedding dim 2, hidden size 32, num layers 1, train loss 0.8173447847366333, validation loss 0.8860560655593872\n",
      "Epoch 530, current patience 29, model mean validation loss 0.8625073432922363, embedding dim 2, hidden size 32, num layers 1, train loss 0.7621918320655823, validation loss 0.8506749868392944\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8612440228462219, embedding dim 2, hidden size 32, num layers 1, train loss 0.7157914638519287, validation loss 0.8520268797874451\n",
      "Epoch 550, current patience 30, model mean validation loss 0.852936863899231, embedding dim 2, hidden size 32, num layers 1, train loss 0.8560557961463928, validation loss 0.7972420454025269\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8481316566467285, embedding dim 2, hidden size 32, num layers 1, train loss 0.8000115752220154, validation loss 0.838455319404602\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8444690704345703, embedding dim 2, hidden size 32, num layers 1, train loss 0.8138058185577393, validation loss 0.8293656706809998\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8428760170936584, embedding dim 2, hidden size 32, num layers 1, train loss 0.7458759546279907, validation loss 0.8267598152160645\n",
      "Epoch 590, current patience 30, model mean validation loss 0.835591197013855, embedding dim 2, hidden size 32, num layers 1, train loss 0.763424813747406, validation loss 0.8041489124298096\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8292974829673767, embedding dim 2, hidden size 32, num layers 1, train loss 0.7119204998016357, validation loss 0.8357062339782715\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8259783983230591, embedding dim 2, hidden size 32, num layers 1, train loss 0.8234864473342896, validation loss 0.8241227269172668\n",
      "Epoch 620, current patience 30, model mean validation loss 0.822300910949707, embedding dim 2, hidden size 32, num layers 1, train loss 0.7200195789337158, validation loss 0.8226066827774048\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8250068426132202, embedding dim 2, hidden size 32, num layers 1, train loss 0.6553870439529419, validation loss 0.8188893795013428\n",
      "Epoch 640, current patience 29, model mean validation loss 0.820752739906311, embedding dim 2, hidden size 32, num layers 1, train loss 0.77024245262146, validation loss 0.8044221997261047\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8179647326469421, embedding dim 2, hidden size 32, num layers 1, train loss 0.661996603012085, validation loss 0.8070624470710754\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8166539669036865, embedding dim 2, hidden size 32, num layers 1, train loss 0.7843746542930603, validation loss 0.8162728548049927\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8117212653160095, embedding dim 2, hidden size 32, num layers 1, train loss 0.7278231978416443, validation loss 0.764687180519104\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8072241544723511, embedding dim 2, hidden size 32, num layers 1, train loss 0.5825823545455933, validation loss 0.7997295260429382\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8054428100585938, embedding dim 2, hidden size 32, num layers 1, train loss 0.8178530931472778, validation loss 0.8098726272583008\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8043966293334961, embedding dim 2, hidden size 32, num layers 1, train loss 0.7468482255935669, validation loss 0.8142366409301758\n",
      "Epoch 710, current patience 30, model mean validation loss 0.7958371639251709, embedding dim 2, hidden size 32, num layers 1, train loss 0.7041142582893372, validation loss 0.7504136562347412\n",
      "Epoch 720, current patience 30, model mean validation loss 0.7928369045257568, embedding dim 2, hidden size 32, num layers 1, train loss 0.5571730732917786, validation loss 0.7804204225540161\n",
      "Epoch 730, current patience 30, model mean validation loss 0.7930654287338257, embedding dim 2, hidden size 32, num layers 1, train loss 0.6081125736236572, validation loss 0.8088904619216919\n",
      "Epoch 740, current patience 29, model mean validation loss 0.7880269289016724, embedding dim 2, hidden size 32, num layers 1, train loss 0.7097330093383789, validation loss 0.7759650349617004\n",
      "Epoch 750, current patience 30, model mean validation loss 0.7886227369308472, embedding dim 2, hidden size 32, num layers 1, train loss 0.65749192237854, validation loss 0.7694535851478577\n",
      "Epoch 760, current patience 29, model mean validation loss 0.785977840423584, embedding dim 2, hidden size 32, num layers 1, train loss 0.6389655470848083, validation loss 0.7785701751708984\n",
      "Epoch 770, current patience 30, model mean validation loss 0.7802431583404541, embedding dim 2, hidden size 32, num layers 1, train loss 0.6007013320922852, validation loss 0.7639955282211304\n",
      "Epoch 780, current patience 30, model mean validation loss 0.7778257131576538, embedding dim 2, hidden size 32, num layers 1, train loss 0.756328821182251, validation loss 0.7948967218399048\n",
      "Epoch 790, current patience 30, model mean validation loss 0.7835170030593872, embedding dim 2, hidden size 32, num layers 1, train loss 0.5934523344039917, validation loss 0.7959439754486084\n",
      "Epoch 800, current patience 29, model mean validation loss 0.7826874852180481, embedding dim 2, hidden size 32, num layers 1, train loss 0.6556757092475891, validation loss 0.7737842798233032\n",
      "Epoch 810, current patience 28, model mean validation loss 0.778812050819397, embedding dim 2, hidden size 32, num layers 1, train loss 0.6093506813049316, validation loss 0.7778869867324829\n",
      "Epoch 820, current patience 27, model mean validation loss 0.7820351123809814, embedding dim 2, hidden size 32, num layers 1, train loss 0.5654065608978271, validation loss 0.8017497658729553\n",
      "Epoch 830, current patience 26, model mean validation loss 0.7866241931915283, embedding dim 2, hidden size 32, num layers 1, train loss 0.7466977834701538, validation loss 0.8061656355857849\n",
      "Epoch 840, current patience 25, model mean validation loss 0.785428524017334, embedding dim 2, hidden size 32, num layers 1, train loss 0.5044236779212952, validation loss 0.7690054178237915\n",
      "Epoch 850, current patience 24, model mean validation loss 0.7903081178665161, embedding dim 2, hidden size 32, num layers 1, train loss 0.5597769618034363, validation loss 0.8030321598052979\n",
      "Epoch 860, current patience 23, model mean validation loss 0.7877841591835022, embedding dim 2, hidden size 32, num layers 1, train loss 0.670380175113678, validation loss 0.7747048735618591\n",
      "Epoch 870, current patience 22, model mean validation loss 0.782070517539978, embedding dim 2, hidden size 32, num layers 1, train loss 0.5739173889160156, validation loss 0.7502354383468628\n",
      "Epoch 880, current patience 21, model mean validation loss 0.7824373245239258, embedding dim 2, hidden size 32, num layers 1, train loss 0.6142699718475342, validation loss 0.776718258857727\n",
      "Epoch 890, current patience 20, model mean validation loss 0.7812241315841675, embedding dim 2, hidden size 32, num layers 1, train loss 0.7606973648071289, validation loss 0.7681818008422852\n",
      "Epoch 900, current patience 19, model mean validation loss 0.7748087644577026, embedding dim 2, hidden size 32, num layers 1, train loss 0.5213519930839539, validation loss 0.7504264712333679\n",
      "Epoch 910, current patience 30, model mean validation loss 0.7686398029327393, embedding dim 2, hidden size 32, num layers 1, train loss 0.5367270708084106, validation loss 0.7568138837814331\n",
      "Epoch 920, current patience 30, model mean validation loss 0.7682721614837646, embedding dim 2, hidden size 32, num layers 1, train loss 0.5919109582901001, validation loss 0.7660642862319946\n",
      "Epoch 930, current patience 30, model mean validation loss 0.7632162570953369, embedding dim 2, hidden size 32, num layers 1, train loss 0.5495690107345581, validation loss 0.7625848054885864\n",
      "Epoch 940, current patience 30, model mean validation loss 0.7650192379951477, embedding dim 2, hidden size 32, num layers 1, train loss 0.6121886968612671, validation loss 0.7891291379928589\n",
      "Epoch 950, current patience 29, model mean validation loss 0.7686029076576233, embedding dim 2, hidden size 32, num layers 1, train loss 0.6021262407302856, validation loss 0.7789046168327332\n",
      "Epoch 960, current patience 28, model mean validation loss 0.7678169012069702, embedding dim 2, hidden size 32, num layers 1, train loss 0.574934720993042, validation loss 0.7704306840896606\n",
      "Epoch 970, current patience 27, model mean validation loss 0.7677462100982666, embedding dim 2, hidden size 32, num layers 1, train loss 0.5372116565704346, validation loss 0.7676163911819458\n",
      "Epoch 980, current patience 26, model mean validation loss 0.7694432139396667, embedding dim 2, hidden size 32, num layers 1, train loss 0.5247290730476379, validation loss 0.7640019655227661\n",
      "Epoch 990, current patience 25, model mean validation loss 0.7697217464447021, embedding dim 2, hidden size 32, num layers 1, train loss 0.5508912205696106, validation loss 0.7590422630310059\n",
      "Epoch 1000, current patience 24, model mean validation loss 0.7714368104934692, embedding dim 2, hidden size 32, num layers 1, train loss 0.4049092233181, validation loss 0.7797846794128418\n",
      "Epoch 1010, current patience 23, model mean validation loss 0.7738524675369263, embedding dim 2, hidden size 32, num layers 1, train loss 0.5717583894729614, validation loss 0.7819095253944397\n",
      "Epoch 1020, current patience 22, model mean validation loss 0.7694298028945923, embedding dim 2, hidden size 32, num layers 1, train loss 0.47704923152923584, validation loss 0.7537475824356079\n",
      "Epoch 1030, current patience 21, model mean validation loss 0.770210862159729, embedding dim 2, hidden size 32, num layers 1, train loss 0.5961523056030273, validation loss 0.7851539254188538\n",
      "Epoch 1040, current patience 20, model mean validation loss 0.7723718285560608, embedding dim 2, hidden size 32, num layers 1, train loss 0.6987360715866089, validation loss 0.7877184152603149\n",
      "Epoch 1050, current patience 19, model mean validation loss 0.7736382484436035, embedding dim 2, hidden size 32, num layers 1, train loss 0.7209662795066833, validation loss 0.777747631072998\n",
      "Epoch 1060, current patience 18, model mean validation loss 0.7773638963699341, embedding dim 2, hidden size 32, num layers 1, train loss 0.5548769235610962, validation loss 0.7938076257705688\n",
      "Epoch 1070, current patience 17, model mean validation loss 0.7773807048797607, embedding dim 2, hidden size 32, num layers 1, train loss 0.5014032125473022, validation loss 0.7591766119003296\n",
      "Epoch 1080, current patience 16, model mean validation loss 0.7773879766464233, embedding dim 2, hidden size 32, num layers 1, train loss 0.5393733978271484, validation loss 0.7798426747322083\n",
      "Epoch 1090, current patience 15, model mean validation loss 0.7800861597061157, embedding dim 2, hidden size 32, num layers 1, train loss 0.5263615846633911, validation loss 0.8034948706626892\n",
      "Epoch 1100, current patience 14, model mean validation loss 0.7885013818740845, embedding dim 2, hidden size 32, num layers 1, train loss 0.4876053035259247, validation loss 0.8210693001747131\n",
      "Epoch 1110, current patience 13, model mean validation loss 0.7865946292877197, embedding dim 2, hidden size 32, num layers 1, train loss 0.46895456314086914, validation loss 0.7699002027511597\n",
      "Epoch 1120, current patience 12, model mean validation loss 0.7885211706161499, embedding dim 2, hidden size 32, num layers 1, train loss 0.4290355443954468, validation loss 0.8031303286552429\n",
      "Epoch 1130, current patience 11, model mean validation loss 0.795194149017334, embedding dim 2, hidden size 32, num layers 1, train loss 0.43151238560676575, validation loss 0.8311316967010498\n",
      "Epoch 1140, current patience 10, model mean validation loss 0.7947445511817932, embedding dim 2, hidden size 32, num layers 1, train loss 0.4851197898387909, validation loss 0.7902107834815979\n",
      "Epoch 1150, current patience 9, model mean validation loss 0.7984964847564697, embedding dim 2, hidden size 32, num layers 1, train loss 0.4875372052192688, validation loss 0.7891917824745178\n",
      "Epoch 1160, current patience 8, model mean validation loss 0.8015052676200867, embedding dim 2, hidden size 32, num layers 1, train loss 0.4903748631477356, validation loss 0.8039130568504333\n",
      "Epoch 1170, current patience 7, model mean validation loss 0.8002556562423706, embedding dim 2, hidden size 32, num layers 1, train loss 0.6518458127975464, validation loss 0.7934984564781189\n",
      "Epoch 1180, current patience 6, model mean validation loss 0.7933028936386108, embedding dim 2, hidden size 32, num layers 1, train loss 0.5588744878768921, validation loss 0.7654464244842529\n",
      "Epoch 1190, current patience 5, model mean validation loss 0.7998491525650024, embedding dim 2, hidden size 32, num layers 1, train loss 0.43623441457748413, validation loss 0.8222711086273193\n",
      "Epoch 1200, current patience 4, model mean validation loss 0.8024920225143433, embedding dim 2, hidden size 32, num layers 1, train loss 0.38236767053604126, validation loss 0.824273407459259\n",
      "Epoch 1210, current patience 3, model mean validation loss 0.797577977180481, embedding dim 2, hidden size 32, num layers 1, train loss 0.5446730852127075, validation loss 0.7918189764022827\n",
      "Epoch 1220, current patience 2, model mean validation loss 0.7995090484619141, embedding dim 2, hidden size 32, num layers 1, train loss 0.5916785001754761, validation loss 0.8056596517562866\n",
      "Epoch 1230, current patience 1, model mean validation loss 0.8083882927894592, embedding dim 2, hidden size 32, num layers 1, train loss 0.5619409680366516, validation loss 0.8602255582809448\n",
      "Epoch 0, current patience 30, model mean validation loss 1.095782995223999, embedding dim 2, hidden size 64, num layers 1, train loss 1.0983293056488037, validation loss 1.095782995223999\n",
      "Epoch 10, current patience 30, model mean validation loss 1.095752477645874, embedding dim 2, hidden size 64, num layers 1, train loss 1.087281346321106, validation loss 1.0957218408584595\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0954538583755493, embedding dim 2, hidden size 64, num layers 1, train loss 1.1052618026733398, validation loss 1.0948565006256104\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0949008464813232, embedding dim 2, hidden size 64, num layers 1, train loss 1.0909786224365234, validation loss 1.0932420492172241\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0950636863708496, embedding dim 2, hidden size 64, num layers 1, train loss 1.0895941257476807, validation loss 1.0957151651382446\n",
      "Epoch 50, current patience 29, model mean validation loss 1.09475839138031, embedding dim 2, hidden size 64, num layers 1, train loss 1.084346055984497, validation loss 1.0932320356369019\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0946463346481323, embedding dim 2, hidden size 64, num layers 1, train loss 1.0696322917938232, validation loss 1.0939736366271973\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0940545797348022, embedding dim 2, hidden size 64, num layers 1, train loss 1.0803041458129883, validation loss 1.0899121761322021\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0935022830963135, embedding dim 2, hidden size 64, num layers 1, train loss 1.084348201751709, validation loss 1.0913649797439575\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0933310985565186, embedding dim 2, hidden size 64, num layers 1, train loss 1.0963560342788696, validation loss 1.0943524837493896\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0929675102233887, embedding dim 2, hidden size 64, num layers 1, train loss 1.0909568071365356, validation loss 1.091947317123413\n",
      "Epoch 110, current patience 30, model mean validation loss 1.091733694076538, embedding dim 2, hidden size 64, num layers 1, train loss 1.0757532119750977, validation loss 1.0833723545074463\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0896484851837158, embedding dim 2, hidden size 64, num layers 1, train loss 1.06951904296875, validation loss 1.0790321826934814\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0859441757202148, embedding dim 2, hidden size 64, num layers 1, train loss 1.0903806686401367, validation loss 1.0635987520217896\n",
      "Epoch 140, current patience 30, model mean validation loss 1.084498643875122, embedding dim 2, hidden size 64, num layers 1, train loss 1.0947123765945435, validation loss 1.0824086666107178\n",
      "Epoch 150, current patience 30, model mean validation loss 1.084168553352356, embedding dim 2, hidden size 64, num layers 1, train loss 1.0689622163772583, validation loss 1.0872715711593628\n",
      "Epoch 160, current patience 30, model mean validation loss 1.07999587059021, embedding dim 2, hidden size 64, num layers 1, train loss 1.0734089612960815, validation loss 1.0579833984375\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0732717514038086, embedding dim 2, hidden size 64, num layers 1, train loss 1.013615608215332, validation loss 1.040560245513916\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0659488439559937, embedding dim 2, hidden size 64, num layers 1, train loss 1.046350121498108, validation loss 1.033363938331604\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0573316812515259, embedding dim 2, hidden size 64, num layers 1, train loss 1.0387829542160034, validation loss 1.014434576034546\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0517348051071167, embedding dim 2, hidden size 64, num layers 1, train loss 1.0784177780151367, validation loss 1.0342572927474976\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0438673496246338, embedding dim 2, hidden size 64, num layers 1, train loss 0.9825335144996643, validation loss 1.0006589889526367\n",
      "Epoch 220, current patience 30, model mean validation loss 1.033940076828003, embedding dim 2, hidden size 64, num layers 1, train loss 0.9504808187484741, validation loss 1.002990484237671\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0228334665298462, embedding dim 2, hidden size 64, num layers 1, train loss 0.9185633659362793, validation loss 0.9984188079833984\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0128978490829468, embedding dim 2, hidden size 64, num layers 1, train loss 0.9375988841056824, validation loss 0.9784978032112122\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0050334930419922, embedding dim 2, hidden size 64, num layers 1, train loss 0.8961279392242432, validation loss 0.9776456952095032\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9974992871284485, embedding dim 2, hidden size 64, num layers 1, train loss 0.9327791929244995, validation loss 0.9730910062789917\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9911984801292419, embedding dim 2, hidden size 64, num layers 1, train loss 0.9407483339309692, validation loss 0.9640278816223145\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9813293218612671, embedding dim 2, hidden size 64, num layers 1, train loss 0.9348828792572021, validation loss 0.9553035497665405\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9759984612464905, embedding dim 2, hidden size 64, num layers 1, train loss 0.9188330769538879, validation loss 0.9580123424530029\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9713972210884094, embedding dim 2, hidden size 64, num layers 1, train loss 0.8885592222213745, validation loss 0.9661804437637329\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9665031433105469, embedding dim 2, hidden size 64, num layers 1, train loss 0.9403902292251587, validation loss 0.9592658877372742\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9604639410972595, embedding dim 2, hidden size 64, num layers 1, train loss 0.8865267038345337, validation loss 0.930184543132782\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9548873901367188, embedding dim 2, hidden size 64, num layers 1, train loss 0.9360361099243164, validation loss 0.9330332279205322\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9498053789138794, embedding dim 2, hidden size 64, num layers 1, train loss 0.8819164037704468, validation loss 0.9324355721473694\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9417816400527954, embedding dim 2, hidden size 64, num layers 1, train loss 0.8916231393814087, validation loss 0.8998371362686157\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9405520558357239, embedding dim 2, hidden size 64, num layers 1, train loss 0.861480712890625, validation loss 0.9454672932624817\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9328910112380981, embedding dim 2, hidden size 64, num layers 1, train loss 0.8891775608062744, validation loss 0.896723747253418\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9266760945320129, embedding dim 2, hidden size 64, num layers 1, train loss 0.7955840826034546, validation loss 0.9164613485336304\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9207310080528259, embedding dim 2, hidden size 64, num layers 1, train loss 0.9260674715042114, validation loss 0.9117048978805542\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9172540903091431, embedding dim 2, hidden size 64, num layers 1, train loss 0.8593977093696594, validation loss 0.9023692607879639\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9115787148475647, embedding dim 2, hidden size 64, num layers 1, train loss 0.7434789538383484, validation loss 0.8876304030418396\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9045261740684509, embedding dim 2, hidden size 64, num layers 1, train loss 0.696915864944458, validation loss 0.8760154247283936\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9013711214065552, embedding dim 2, hidden size 64, num layers 1, train loss 0.8759523034095764, validation loss 0.8745964765548706\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8923978805541992, embedding dim 2, hidden size 64, num layers 1, train loss 0.8632967472076416, validation loss 0.8736810684204102\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8883851766586304, embedding dim 2, hidden size 64, num layers 1, train loss 0.8188902139663696, validation loss 0.8646219968795776\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8829163312911987, embedding dim 2, hidden size 64, num layers 1, train loss 0.7755234241485596, validation loss 0.8727116584777832\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8786327838897705, embedding dim 2, hidden size 64, num layers 1, train loss 0.7559760808944702, validation loss 0.8774359226226807\n",
      "Epoch 480, current patience 30, model mean validation loss 0.870722770690918, embedding dim 2, hidden size 64, num layers 1, train loss 0.8267630934715271, validation loss 0.839089572429657\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8654493093490601, embedding dim 2, hidden size 64, num layers 1, train loss 0.8034113049507141, validation loss 0.8454420566558838\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8666555881500244, embedding dim 2, hidden size 64, num layers 1, train loss 0.6976850628852844, validation loss 0.8856659531593323\n",
      "Epoch 510, current patience 29, model mean validation loss 0.8626359701156616, embedding dim 2, hidden size 64, num layers 1, train loss 0.7575588226318359, validation loss 0.8424394130706787\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8577166199684143, embedding dim 2, hidden size 64, num layers 1, train loss 0.7681108713150024, validation loss 0.8343265056610107\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8534349799156189, embedding dim 2, hidden size 64, num layers 1, train loss 0.7339918613433838, validation loss 0.8303686380386353\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8452150821685791, embedding dim 2, hidden size 64, num layers 1, train loss 0.6722671985626221, validation loss 0.8069521188735962\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8380679488182068, embedding dim 2, hidden size 64, num layers 1, train loss 0.7397101521492004, validation loss 0.8202587962150574\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8338685035705566, embedding dim 2, hidden size 64, num layers 1, train loss 0.8408814668655396, validation loss 0.8054945468902588\n",
      "Epoch 570, current patience 30, model mean validation loss 0.829795241355896, embedding dim 2, hidden size 64, num layers 1, train loss 0.8170548677444458, validation loss 0.8128559589385986\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8221404552459717, embedding dim 2, hidden size 64, num layers 1, train loss 0.7856859564781189, validation loss 0.824427604675293\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8212639093399048, embedding dim 2, hidden size 64, num layers 1, train loss 0.7245292663574219, validation loss 0.8354272842407227\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8219825029373169, embedding dim 2, hidden size 64, num layers 1, train loss 0.811560869216919, validation loss 0.8400753736495972\n",
      "Epoch 610, current patience 29, model mean validation loss 0.8177871704101562, embedding dim 2, hidden size 64, num layers 1, train loss 0.7932934165000916, validation loss 0.7968055009841919\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8183499574661255, embedding dim 2, hidden size 64, num layers 1, train loss 0.7034857273101807, validation loss 0.8114544749259949\n",
      "Epoch 630, current patience 29, model mean validation loss 0.8168071508407593, embedding dim 2, hidden size 64, num layers 1, train loss 0.640686571598053, validation loss 0.807916522026062\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8185644149780273, embedding dim 2, hidden size 64, num layers 1, train loss 0.6182924509048462, validation loss 0.819552481174469\n",
      "Epoch 650, current patience 29, model mean validation loss 0.8153057098388672, embedding dim 2, hidden size 64, num layers 1, train loss 0.6833935976028442, validation loss 0.786786675453186\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8122571706771851, embedding dim 2, hidden size 64, num layers 1, train loss 0.6367126703262329, validation loss 0.8000386357307434\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8100917339324951, embedding dim 2, hidden size 64, num layers 1, train loss 0.6972055435180664, validation loss 0.8181036710739136\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8038544654846191, embedding dim 2, hidden size 64, num layers 1, train loss 0.6839380264282227, validation loss 0.790177583694458\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8018803000450134, embedding dim 2, hidden size 64, num layers 1, train loss 0.7060034275054932, validation loss 0.7810123562812805\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8012180328369141, embedding dim 2, hidden size 64, num layers 1, train loss 0.7849469184875488, validation loss 0.8061560392379761\n",
      "Epoch 710, current patience 30, model mean validation loss 0.7973449230194092, embedding dim 2, hidden size 64, num layers 1, train loss 0.7167648077011108, validation loss 0.7769321203231812\n",
      "Epoch 720, current patience 30, model mean validation loss 0.7924802303314209, embedding dim 2, hidden size 64, num layers 1, train loss 0.7036998271942139, validation loss 0.7806345820426941\n",
      "Epoch 730, current patience 30, model mean validation loss 0.7943255305290222, embedding dim 2, hidden size 64, num layers 1, train loss 0.5761805176734924, validation loss 0.8015491962432861\n",
      "Epoch 740, current patience 29, model mean validation loss 0.7900282144546509, embedding dim 2, hidden size 64, num layers 1, train loss 0.7361924052238464, validation loss 0.7656605243682861\n",
      "Epoch 750, current patience 30, model mean validation loss 0.7856028079986572, embedding dim 2, hidden size 64, num layers 1, train loss 0.8171008825302124, validation loss 0.7827000617980957\n",
      "Epoch 760, current patience 30, model mean validation loss 0.7840343713760376, embedding dim 2, hidden size 64, num layers 1, train loss 0.6870391368865967, validation loss 0.7776303887367249\n",
      "Epoch 770, current patience 30, model mean validation loss 0.7849241495132446, embedding dim 2, hidden size 64, num layers 1, train loss 0.7344529628753662, validation loss 0.788130521774292\n",
      "Epoch 780, current patience 29, model mean validation loss 0.7854644060134888, embedding dim 2, hidden size 64, num layers 1, train loss 0.6919870376586914, validation loss 0.8104776740074158\n",
      "Epoch 790, current patience 28, model mean validation loss 0.7853379249572754, embedding dim 2, hidden size 64, num layers 1, train loss 0.5812761187553406, validation loss 0.7759201526641846\n",
      "Epoch 800, current patience 27, model mean validation loss 0.7886961698532104, embedding dim 2, hidden size 64, num layers 1, train loss 0.7605197429656982, validation loss 0.8075004816055298\n",
      "Epoch 810, current patience 26, model mean validation loss 0.7887285947799683, embedding dim 2, hidden size 64, num layers 1, train loss 0.6916369199752808, validation loss 0.8018088340759277\n",
      "Epoch 820, current patience 25, model mean validation loss 0.7937854528427124, embedding dim 2, hidden size 64, num layers 1, train loss 0.7136251926422119, validation loss 0.8061158657073975\n",
      "Epoch 830, current patience 24, model mean validation loss 0.7940642237663269, embedding dim 2, hidden size 64, num layers 1, train loss 0.6434824466705322, validation loss 0.7849295735359192\n",
      "Epoch 840, current patience 23, model mean validation loss 0.7953229546546936, embedding dim 2, hidden size 64, num layers 1, train loss 0.7646503448486328, validation loss 0.7877006530761719\n",
      "Epoch 850, current patience 22, model mean validation loss 0.7980507612228394, embedding dim 2, hidden size 64, num layers 1, train loss 0.7680284976959229, validation loss 0.8099528551101685\n",
      "Epoch 860, current patience 21, model mean validation loss 0.794965386390686, embedding dim 2, hidden size 64, num layers 1, train loss 0.7672284841537476, validation loss 0.7857950925827026\n",
      "Epoch 870, current patience 20, model mean validation loss 0.7981008887290955, embedding dim 2, hidden size 64, num layers 1, train loss 0.7261711359024048, validation loss 0.8010035157203674\n",
      "Epoch 880, current patience 19, model mean validation loss 0.7946830987930298, embedding dim 2, hidden size 64, num layers 1, train loss 0.5713331699371338, validation loss 0.7801584601402283\n",
      "Epoch 890, current patience 18, model mean validation loss 0.7949402332305908, embedding dim 2, hidden size 64, num layers 1, train loss 0.5219839215278625, validation loss 0.8038654923439026\n",
      "Epoch 900, current patience 17, model mean validation loss 0.795581579208374, embedding dim 2, hidden size 64, num layers 1, train loss 0.5428500771522522, validation loss 0.8112472295761108\n",
      "Epoch 910, current patience 16, model mean validation loss 0.7973788976669312, embedding dim 2, hidden size 64, num layers 1, train loss 0.6718007326126099, validation loss 0.7993078231811523\n",
      "Epoch 920, current patience 15, model mean validation loss 0.7979394197463989, embedding dim 2, hidden size 64, num layers 1, train loss 0.512636661529541, validation loss 0.7921850085258484\n",
      "Epoch 930, current patience 14, model mean validation loss 0.7942299842834473, embedding dim 2, hidden size 64, num layers 1, train loss 0.48267027735710144, validation loss 0.7802771925926208\n",
      "Epoch 940, current patience 13, model mean validation loss 0.7952878475189209, embedding dim 2, hidden size 64, num layers 1, train loss 0.6740531921386719, validation loss 0.7942584753036499\n",
      "Epoch 950, current patience 12, model mean validation loss 0.7935127019882202, embedding dim 2, hidden size 64, num layers 1, train loss 0.514697253704071, validation loss 0.7868022918701172\n",
      "Epoch 960, current patience 11, model mean validation loss 0.7932732105255127, embedding dim 2, hidden size 64, num layers 1, train loss 0.6058849096298218, validation loss 0.7782418727874756\n",
      "Epoch 970, current patience 10, model mean validation loss 0.7925384640693665, embedding dim 2, hidden size 64, num layers 1, train loss 0.6145339608192444, validation loss 0.7979875206947327\n",
      "Epoch 980, current patience 9, model mean validation loss 0.7939239740371704, embedding dim 2, hidden size 64, num layers 1, train loss 0.6321089267730713, validation loss 0.8223316669464111\n",
      "Epoch 990, current patience 8, model mean validation loss 0.7955071926116943, embedding dim 2, hidden size 64, num layers 1, train loss 0.659193754196167, validation loss 0.8119733333587646\n",
      "Epoch 1000, current patience 7, model mean validation loss 0.7914242744445801, embedding dim 2, hidden size 64, num layers 1, train loss 0.6449708938598633, validation loss 0.7595216035842896\n",
      "Epoch 1010, current patience 6, model mean validation loss 0.7966498732566833, embedding dim 2, hidden size 64, num layers 1, train loss 0.5702986121177673, validation loss 0.8220820426940918\n",
      "Epoch 1020, current patience 5, model mean validation loss 0.7992175221443176, embedding dim 2, hidden size 64, num layers 1, train loss 0.6051431894302368, validation loss 0.8147999048233032\n",
      "Epoch 1030, current patience 4, model mean validation loss 0.7995942831039429, embedding dim 2, hidden size 64, num layers 1, train loss 0.5294504165649414, validation loss 0.7898160815238953\n",
      "Epoch 1040, current patience 3, model mean validation loss 0.8106949329376221, embedding dim 2, hidden size 64, num layers 1, train loss 0.41546863317489624, validation loss 0.867047131061554\n",
      "Epoch 1050, current patience 2, model mean validation loss 0.8130741119384766, embedding dim 2, hidden size 64, num layers 1, train loss 0.6541612148284912, validation loss 0.8170205950737\n",
      "Epoch 1060, current patience 1, model mean validation loss 0.811557412147522, embedding dim 2, hidden size 64, num layers 1, train loss 0.6679787039756775, validation loss 0.8101984262466431\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0909922122955322, embedding dim 2, hidden size 128, num layers 1, train loss 1.1028099060058594, validation loss 1.0909922122955322\n",
      "Epoch 10, current patience 30, model mean validation loss 1.094161033630371, embedding dim 2, hidden size 128, num layers 1, train loss 1.1014496088027954, validation loss 1.09732985496521\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0940524339675903, embedding dim 2, hidden size 128, num layers 1, train loss 1.099857211112976, validation loss 1.0938353538513184\n",
      "Epoch 30, current patience 28, model mean validation loss 1.0943310260772705, embedding dim 2, hidden size 128, num layers 1, train loss 1.109586477279663, validation loss 1.0951669216156006\n",
      "Epoch 40, current patience 27, model mean validation loss 1.0947198867797852, embedding dim 2, hidden size 128, num layers 1, train loss 1.0990841388702393, validation loss 1.0962748527526855\n",
      "Epoch 50, current patience 26, model mean validation loss 1.0943613052368164, embedding dim 2, hidden size 128, num layers 1, train loss 1.0586249828338623, validation loss 1.0925685167312622\n",
      "Epoch 60, current patience 25, model mean validation loss 1.0950998067855835, embedding dim 2, hidden size 128, num layers 1, train loss 1.097623586654663, validation loss 1.0995314121246338\n",
      "Epoch 70, current patience 24, model mean validation loss 1.0945584774017334, embedding dim 2, hidden size 128, num layers 1, train loss 1.0963175296783447, validation loss 1.0907682180404663\n",
      "Epoch 80, current patience 23, model mean validation loss 1.0946069955825806, embedding dim 2, hidden size 128, num layers 1, train loss 1.106931447982788, validation loss 1.0913804769515991\n",
      "Epoch 90, current patience 22, model mean validation loss 1.0939817428588867, embedding dim 2, hidden size 128, num layers 1, train loss 1.095902442932129, validation loss 1.092327356338501\n",
      "Epoch 100, current patience 21, model mean validation loss 1.0940818786621094, embedding dim 2, hidden size 128, num layers 1, train loss 1.1048879623413086, validation loss 1.0946376323699951\n",
      "Epoch 110, current patience 20, model mean validation loss 1.0932704210281372, embedding dim 2, hidden size 128, num layers 1, train loss 1.1059787273406982, validation loss 1.0886749029159546\n",
      "Epoch 120, current patience 19, model mean validation loss 1.092675805091858, embedding dim 2, hidden size 128, num layers 1, train loss 1.0848748683929443, validation loss 1.0915180444717407\n",
      "Epoch 130, current patience 18, model mean validation loss 1.1016161441802979, embedding dim 2, hidden size 128, num layers 1, train loss 1.0791866779327393, validation loss 1.164090871810913\n",
      "Epoch 140, current patience 17, model mean validation loss 1.1013062000274658, embedding dim 2, hidden size 128, num layers 1, train loss 1.0799404382705688, validation loss 1.0970520973205566\n",
      "Epoch 150, current patience 16, model mean validation loss 1.1010780334472656, embedding dim 2, hidden size 128, num layers 1, train loss 1.1053259372711182, validation loss 1.0889434814453125\n",
      "Epoch 160, current patience 15, model mean validation loss 1.099229097366333, embedding dim 2, hidden size 128, num layers 1, train loss 1.0634976625442505, validation loss 1.0765879154205322\n",
      "Epoch 170, current patience 14, model mean validation loss 1.0994243621826172, embedding dim 2, hidden size 128, num layers 1, train loss 1.0760236978530884, validation loss 1.0938899517059326\n",
      "Epoch 180, current patience 13, model mean validation loss 1.099120855331421, embedding dim 2, hidden size 128, num layers 1, train loss 1.0923640727996826, validation loss 1.0922091007232666\n",
      "Epoch 190, current patience 12, model mean validation loss 1.096984624862671, embedding dim 2, hidden size 128, num layers 1, train loss 1.0620830059051514, validation loss 1.0715851783752441\n",
      "Epoch 200, current patience 11, model mean validation loss 1.094439148902893, embedding dim 2, hidden size 128, num layers 1, train loss 1.0585124492645264, validation loss 1.0711548328399658\n",
      "Epoch 210, current patience 10, model mean validation loss 1.0825185775756836, embedding dim 2, hidden size 128, num layers 1, train loss 1.0741273164749146, validation loss 1.068725824356079\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0765509605407715, embedding dim 2, hidden size 128, num layers 1, train loss 1.01753830909729, validation loss 1.0493110418319702\n",
      "Epoch 230, current patience 30, model mean validation loss 1.072218656539917, embedding dim 2, hidden size 128, num layers 1, train loss 0.9791411757469177, validation loss 1.054286003112793\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0693342685699463, embedding dim 2, hidden size 128, num layers 1, train loss 1.0390647649765015, validation loss 1.0535120964050293\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0619076490402222, embedding dim 2, hidden size 128, num layers 1, train loss 1.0201661586761475, validation loss 1.0344767570495605\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0556607246398926, embedding dim 2, hidden size 128, num layers 1, train loss 1.0420538187026978, validation loss 1.0422338247299194\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0489230155944824, embedding dim 2, hidden size 128, num layers 1, train loss 0.967070460319519, validation loss 1.017683982849121\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0419129133224487, embedding dim 2, hidden size 128, num layers 1, train loss 0.9131574630737305, validation loss 1.0150740146636963\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0382753610610962, embedding dim 2, hidden size 128, num layers 1, train loss 0.9492356777191162, validation loss 1.0396246910095215\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0305640697479248, embedding dim 2, hidden size 128, num layers 1, train loss 0.999488115310669, validation loss 0.9876205921173096\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0226364135742188, embedding dim 2, hidden size 128, num layers 1, train loss 1.0459868907928467, validation loss 0.9908656477928162\n",
      "Epoch 320, current patience 30, model mean validation loss 1.013136386871338, embedding dim 2, hidden size 128, num layers 1, train loss 0.9256011843681335, validation loss 0.977512001991272\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0031594038009644, embedding dim 2, hidden size 128, num layers 1, train loss 1.0176386833190918, validation loss 0.9546607732772827\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9899939298629761, embedding dim 2, hidden size 128, num layers 1, train loss 0.9152668714523315, validation loss 0.9369091987609863\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9809271693229675, embedding dim 2, hidden size 128, num layers 1, train loss 0.8416611552238464, validation loss 0.9451504945755005\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9722617268562317, embedding dim 2, hidden size 128, num layers 1, train loss 0.913124680519104, validation loss 0.9457506537437439\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9586938619613647, embedding dim 2, hidden size 128, num layers 1, train loss 0.9184722304344177, validation loss 0.9310816526412964\n",
      "Epoch 380, current patience 30, model mean validation loss 0.949702799320221, embedding dim 2, hidden size 128, num layers 1, train loss 0.8929942846298218, validation loss 0.9156922101974487\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9393531680107117, embedding dim 2, hidden size 128, num layers 1, train loss 0.9367239475250244, validation loss 0.9080686569213867\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9290850758552551, embedding dim 2, hidden size 128, num layers 1, train loss 0.9048858880996704, validation loss 0.8953673243522644\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9262071251869202, embedding dim 2, hidden size 128, num layers 1, train loss 0.7515658140182495, validation loss 0.9316368103027344\n",
      "Epoch 420, current patience 30, model mean validation loss 0.920145571231842, embedding dim 2, hidden size 128, num layers 1, train loss 0.6814188957214355, validation loss 0.8884169459342957\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9158616065979004, embedding dim 2, hidden size 128, num layers 1, train loss 0.80122971534729, validation loss 0.9108786582946777\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9090374708175659, embedding dim 2, hidden size 128, num layers 1, train loss 0.8691060543060303, validation loss 0.8911575078964233\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9006726741790771, embedding dim 2, hidden size 128, num layers 1, train loss 0.8127818703651428, validation loss 0.8641633987426758\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8947854042053223, embedding dim 2, hidden size 128, num layers 1, train loss 0.6549577713012695, validation loss 0.8685941100120544\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8902100324630737, embedding dim 2, hidden size 128, num layers 1, train loss 0.7299610376358032, validation loss 0.871465802192688\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8868316411972046, embedding dim 2, hidden size 128, num layers 1, train loss 0.8083760738372803, validation loss 0.8683403134346008\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8799540996551514, embedding dim 2, hidden size 128, num layers 1, train loss 0.6483176946640015, validation loss 0.8766158819198608\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8756031394004822, embedding dim 2, hidden size 128, num layers 1, train loss 0.8887000679969788, validation loss 0.8536092042922974\n",
      "Epoch 510, current patience 30, model mean validation loss 0.869966983795166, embedding dim 2, hidden size 128, num layers 1, train loss 0.704679548740387, validation loss 0.8657894730567932\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8581939935684204, embedding dim 2, hidden size 128, num layers 1, train loss 0.7296673059463501, validation loss 0.7969735264778137\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8543643355369568, embedding dim 2, hidden size 128, num layers 1, train loss 0.8616911768913269, validation loss 0.8335262537002563\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8505822420120239, embedding dim 2, hidden size 128, num layers 1, train loss 0.833824872970581, validation loss 0.8383371829986572\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8439675569534302, embedding dim 2, hidden size 128, num layers 1, train loss 0.7726658582687378, validation loss 0.8185485601425171\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8392983675003052, embedding dim 2, hidden size 128, num layers 1, train loss 0.7715160250663757, validation loss 0.8309867978096008\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8286226987838745, embedding dim 2, hidden size 128, num layers 1, train loss 0.7542400360107422, validation loss 0.7912102341651917\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8247868418693542, embedding dim 2, hidden size 128, num layers 1, train loss 0.7036571502685547, validation loss 0.8229228258132935\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8222959041595459, embedding dim 2, hidden size 128, num layers 1, train loss 0.48642268776893616, validation loss 0.8458617925643921\n",
      "Epoch 600, current patience 30, model mean validation loss 0.8217121362686157, embedding dim 2, hidden size 128, num layers 1, train loss 0.7386798858642578, validation loss 0.7923035621643066\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8152071833610535, embedding dim 2, hidden size 128, num layers 1, train loss 0.719253420829773, validation loss 0.7814868092536926\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8156702518463135, embedding dim 2, hidden size 128, num layers 1, train loss 0.6267492771148682, validation loss 0.842041552066803\n",
      "Epoch 630, current patience 29, model mean validation loss 0.8138590455055237, embedding dim 2, hidden size 128, num layers 1, train loss 0.7337899208068848, validation loss 0.8040590882301331\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8079344034194946, embedding dim 2, hidden size 128, num layers 1, train loss 0.7644658088684082, validation loss 0.7835896611213684\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8111358284950256, embedding dim 2, hidden size 128, num layers 1, train loss 0.6967302560806274, validation loss 0.816821277141571\n",
      "Epoch 660, current patience 29, model mean validation loss 0.8052452802658081, embedding dim 2, hidden size 128, num layers 1, train loss 0.6724942922592163, validation loss 0.7757983207702637\n",
      "Epoch 670, current patience 30, model mean validation loss 0.79680335521698, embedding dim 2, hidden size 128, num layers 1, train loss 0.7374755144119263, validation loss 0.778327226638794\n",
      "Epoch 680, current patience 30, model mean validation loss 0.799108624458313, embedding dim 2, hidden size 128, num layers 1, train loss 0.6608737111091614, validation loss 0.810745120048523\n",
      "Epoch 690, current patience 29, model mean validation loss 0.7994494438171387, embedding dim 2, hidden size 128, num layers 1, train loss 0.6321144700050354, validation loss 0.7842135429382324\n",
      "Epoch 700, current patience 28, model mean validation loss 0.792267918586731, embedding dim 2, hidden size 128, num layers 1, train loss 0.6266615986824036, validation loss 0.7845893502235413\n",
      "Epoch 710, current patience 30, model mean validation loss 0.7910677194595337, embedding dim 2, hidden size 128, num layers 1, train loss 0.5895514488220215, validation loss 0.7944571375846863\n",
      "Epoch 720, current patience 30, model mean validation loss 0.790291428565979, embedding dim 2, hidden size 128, num layers 1, train loss 0.7829582691192627, validation loss 0.7773789763450623\n",
      "Epoch 730, current patience 30, model mean validation loss 0.7912999391555786, embedding dim 2, hidden size 128, num layers 1, train loss 0.48940688371658325, validation loss 0.8248896598815918\n",
      "Epoch 740, current patience 29, model mean validation loss 0.7947431206703186, embedding dim 2, hidden size 128, num layers 1, train loss 0.7719059586524963, validation loss 0.8033437728881836\n",
      "Epoch 750, current patience 28, model mean validation loss 0.8018026351928711, embedding dim 2, hidden size 128, num layers 1, train loss 0.7715164422988892, validation loss 0.8348039388656616\n",
      "Epoch 760, current patience 27, model mean validation loss 0.7999910712242126, embedding dim 2, hidden size 128, num layers 1, train loss 0.5515714883804321, validation loss 0.7962523102760315\n",
      "Epoch 770, current patience 26, model mean validation loss 0.8023241758346558, embedding dim 2, hidden size 128, num layers 1, train loss 0.7143232822418213, validation loss 0.8028784990310669\n",
      "Epoch 780, current patience 25, model mean validation loss 0.8019375801086426, embedding dim 2, hidden size 128, num layers 1, train loss 0.5834352970123291, validation loss 0.7814964056015015\n",
      "Epoch 790, current patience 24, model mean validation loss 0.7990775108337402, embedding dim 2, hidden size 128, num layers 1, train loss 0.828264594078064, validation loss 0.7715765237808228\n",
      "Epoch 800, current patience 23, model mean validation loss 0.8006070256233215, embedding dim 2, hidden size 128, num layers 1, train loss 0.6988577842712402, validation loss 0.7896152138710022\n",
      "Epoch 810, current patience 22, model mean validation loss 0.7995393872261047, embedding dim 2, hidden size 128, num layers 1, train loss 0.7462306618690491, validation loss 0.8163484334945679\n",
      "Epoch 820, current patience 21, model mean validation loss 0.8029831647872925, embedding dim 2, hidden size 128, num layers 1, train loss 0.6461710333824158, validation loss 0.830893874168396\n",
      "Epoch 830, current patience 20, model mean validation loss 0.7990202903747559, embedding dim 2, hidden size 128, num layers 1, train loss 0.7355132699012756, validation loss 0.8031008243560791\n",
      "Epoch 840, current patience 19, model mean validation loss 0.8020153045654297, embedding dim 2, hidden size 128, num layers 1, train loss 0.5658066272735596, validation loss 0.8202129602432251\n",
      "Epoch 850, current patience 18, model mean validation loss 0.8018578290939331, embedding dim 2, hidden size 128, num layers 1, train loss 0.6791777014732361, validation loss 0.8016183376312256\n",
      "Epoch 860, current patience 17, model mean validation loss 0.8035542368888855, embedding dim 2, hidden size 128, num layers 1, train loss 0.6999425292015076, validation loss 0.7950680255889893\n",
      "Epoch 870, current patience 16, model mean validation loss 0.8043792247772217, embedding dim 2, hidden size 128, num layers 1, train loss 0.5710099339485168, validation loss 0.7781763076782227\n",
      "Epoch 880, current patience 15, model mean validation loss 0.8010189533233643, embedding dim 2, hidden size 128, num layers 1, train loss 0.6423149108886719, validation loss 0.7627329230308533\n",
      "Epoch 890, current patience 14, model mean validation loss 0.7958109378814697, embedding dim 2, hidden size 128, num layers 1, train loss 0.56818687915802, validation loss 0.7746838927268982\n",
      "Epoch 900, current patience 13, model mean validation loss 0.7923929691314697, embedding dim 2, hidden size 128, num layers 1, train loss 0.5301266312599182, validation loss 0.8035507202148438\n",
      "Epoch 910, current patience 12, model mean validation loss 0.7889997959136963, embedding dim 2, hidden size 128, num layers 1, train loss 0.7905756235122681, validation loss 0.7759551405906677\n",
      "Epoch 920, current patience 30, model mean validation loss 0.7848488092422485, embedding dim 2, hidden size 128, num layers 1, train loss 0.4706434905529022, validation loss 0.7870048880577087\n",
      "Epoch 930, current patience 30, model mean validation loss 0.7823969125747681, embedding dim 2, hidden size 128, num layers 1, train loss 0.6299843788146973, validation loss 0.7820037603378296\n",
      "Epoch 940, current patience 30, model mean validation loss 0.7813513278961182, embedding dim 2, hidden size 128, num layers 1, train loss 0.5220929980278015, validation loss 0.7867028713226318\n",
      "Epoch 950, current patience 30, model mean validation loss 0.7898797988891602, embedding dim 2, hidden size 128, num layers 1, train loss 0.6357743740081787, validation loss 0.8464041948318481\n",
      "Epoch 960, current patience 29, model mean validation loss 0.7917697429656982, embedding dim 2, hidden size 128, num layers 1, train loss 0.4710199236869812, validation loss 0.7778528928756714\n",
      "Epoch 970, current patience 28, model mean validation loss 0.7960925102233887, embedding dim 2, hidden size 128, num layers 1, train loss 0.6335471868515015, validation loss 0.8092659711837769\n",
      "Epoch 980, current patience 27, model mean validation loss 0.7929754257202148, embedding dim 2, hidden size 128, num layers 1, train loss 0.5418773889541626, validation loss 0.778613805770874\n",
      "Epoch 990, current patience 26, model mean validation loss 0.7959887981414795, embedding dim 2, hidden size 128, num layers 1, train loss 0.652141273021698, validation loss 0.8000619411468506\n",
      "Epoch 1000, current patience 25, model mean validation loss 0.7969030737876892, embedding dim 2, hidden size 128, num layers 1, train loss 0.45994678139686584, validation loss 0.7943191528320312\n",
      "Epoch 1010, current patience 24, model mean validation loss 0.7983322739601135, embedding dim 2, hidden size 128, num layers 1, train loss 0.7120437622070312, validation loss 0.7934370040893555\n",
      "Epoch 1020, current patience 23, model mean validation loss 0.7969499826431274, embedding dim 2, hidden size 128, num layers 1, train loss 0.7110207676887512, validation loss 0.775644838809967\n",
      "Epoch 1030, current patience 22, model mean validation loss 0.7914881706237793, embedding dim 2, hidden size 128, num layers 1, train loss 0.563385546207428, validation loss 0.8027099967002869\n",
      "Epoch 1040, current patience 21, model mean validation loss 0.7950879335403442, embedding dim 2, hidden size 128, num layers 1, train loss 0.3917785584926605, validation loss 0.8066511750221252\n",
      "Epoch 1050, current patience 20, model mean validation loss 0.7963810563087463, embedding dim 2, hidden size 128, num layers 1, train loss 0.6320115327835083, validation loss 0.8196104764938354\n",
      "Epoch 1060, current patience 19, model mean validation loss 0.7992088794708252, embedding dim 2, hidden size 128, num layers 1, train loss 0.6485707759857178, validation loss 0.8012362718582153\n",
      "Epoch 1070, current patience 18, model mean validation loss 0.7996362447738647, embedding dim 2, hidden size 128, num layers 1, train loss 0.475222110748291, validation loss 0.8034804463386536\n",
      "Epoch 1080, current patience 17, model mean validation loss 0.8007575869560242, embedding dim 2, hidden size 128, num layers 1, train loss 0.5412957668304443, validation loss 0.8032907247543335\n",
      "Epoch 1090, current patience 16, model mean validation loss 0.8014812469482422, embedding dim 2, hidden size 128, num layers 1, train loss 0.506979763507843, validation loss 0.7992259860038757\n",
      "Epoch 1100, current patience 15, model mean validation loss 0.8045163154602051, embedding dim 2, hidden size 128, num layers 1, train loss 0.6784300804138184, validation loss 0.799925684928894\n",
      "Epoch 1110, current patience 14, model mean validation loss 0.8109468221664429, embedding dim 2, hidden size 128, num layers 1, train loss 0.6446030139923096, validation loss 0.8541536331176758\n",
      "Epoch 1120, current patience 13, model mean validation loss 0.8130474090576172, embedding dim 2, hidden size 128, num layers 1, train loss 0.6636909246444702, validation loss 0.8234565854072571\n",
      "Epoch 1130, current patience 12, model mean validation loss 0.8117351531982422, embedding dim 2, hidden size 128, num layers 1, train loss 0.4949629604816437, validation loss 0.8091118931770325\n",
      "Epoch 1140, current patience 11, model mean validation loss 0.8096804618835449, embedding dim 2, hidden size 128, num layers 1, train loss 0.6458503007888794, validation loss 0.7847985625267029\n",
      "Epoch 1150, current patience 10, model mean validation loss 0.8116790056228638, embedding dim 2, hidden size 128, num layers 1, train loss 0.5249690413475037, validation loss 0.8194690942764282\n",
      "Epoch 1160, current patience 9, model mean validation loss 0.820393443107605, embedding dim 2, hidden size 128, num layers 1, train loss 0.42340338230133057, validation loss 0.8730059862136841\n",
      "Epoch 1170, current patience 8, model mean validation loss 0.8213668465614319, embedding dim 2, hidden size 128, num layers 1, train loss 0.6370034217834473, validation loss 0.8070131540298462\n",
      "Epoch 1180, current patience 7, model mean validation loss 0.8273028135299683, embedding dim 2, hidden size 128, num layers 1, train loss 0.42321890592575073, validation loss 0.8474134802818298\n",
      "Epoch 1190, current patience 6, model mean validation loss 0.8254861831665039, embedding dim 2, hidden size 128, num layers 1, train loss 0.6825017929077148, validation loss 0.8396201729774475\n",
      "Epoch 1200, current patience 5, model mean validation loss 0.8262474536895752, embedding dim 2, hidden size 128, num layers 1, train loss 0.37317967414855957, validation loss 0.829547107219696\n",
      "Epoch 1210, current patience 4, model mean validation loss 0.839080274105072, embedding dim 2, hidden size 128, num layers 1, train loss 0.35629746317863464, validation loss 0.9117746353149414\n",
      "Epoch 1220, current patience 3, model mean validation loss 0.8432260751724243, embedding dim 2, hidden size 128, num layers 1, train loss 0.328244149684906, validation loss 0.8179652690887451\n",
      "Epoch 1230, current patience 2, model mean validation loss 0.8501994609832764, embedding dim 2, hidden size 128, num layers 1, train loss 0.491233766078949, validation loss 0.8752560615539551\n",
      "Epoch 1240, current patience 1, model mean validation loss 0.8426026701927185, embedding dim 2, hidden size 128, num layers 1, train loss 0.5556750893592834, validation loss 0.8122314214706421\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1100680828094482, embedding dim 2, hidden size 256, num layers 1, train loss 1.0936634540557861, validation loss 1.1100680828094482\n",
      "Epoch 10, current patience 30, model mean validation loss 1.100908637046814, embedding dim 2, hidden size 256, num layers 1, train loss 1.108922004699707, validation loss 1.0917491912841797\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0988675355911255, embedding dim 2, hidden size 256, num layers 1, train loss 1.1039419174194336, validation loss 1.0947853326797485\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0979814529418945, embedding dim 2, hidden size 256, num layers 1, train loss 1.085223913192749, validation loss 1.095322847366333\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0972598791122437, embedding dim 2, hidden size 256, num layers 1, train loss 1.104369044303894, validation loss 1.0943739414215088\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0968393087387085, embedding dim 2, hidden size 256, num layers 1, train loss 1.0740550756454468, validation loss 1.0947365760803223\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0969455242156982, embedding dim 2, hidden size 256, num layers 1, train loss 1.0684528350830078, validation loss 1.0975825786590576\n",
      "Epoch 70, current patience 29, model mean validation loss 1.0968141555786133, embedding dim 2, hidden size 256, num layers 1, train loss 1.088897466659546, validation loss 1.0958939790725708\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0944249629974365, embedding dim 2, hidden size 256, num layers 1, train loss 1.1011505126953125, validation loss 1.0909545421600342\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0947855710983276, embedding dim 2, hidden size 256, num layers 1, train loss 1.0881080627441406, validation loss 1.094634771347046\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0943797826766968, embedding dim 2, hidden size 256, num layers 1, train loss 1.0992536544799805, validation loss 1.091538429260254\n",
      "Epoch 110, current patience 30, model mean validation loss 1.094298005104065, embedding dim 2, hidden size 256, num layers 1, train loss 1.0974550247192383, validation loss 1.0946693420410156\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0942535400390625, embedding dim 2, hidden size 256, num layers 1, train loss 1.0904831886291504, validation loss 1.0940182209014893\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0937083959579468, embedding dim 2, hidden size 256, num layers 1, train loss 1.0981085300445557, validation loss 1.0903749465942383\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0934120416641235, embedding dim 2, hidden size 256, num layers 1, train loss 1.1080825328826904, validation loss 1.0952119827270508\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0936063528060913, embedding dim 2, hidden size 256, num layers 1, train loss 1.0944819450378418, validation loss 1.097448468208313\n",
      "Epoch 160, current patience 29, model mean validation loss 1.094128131866455, embedding dim 2, hidden size 256, num layers 1, train loss 1.09499192237854, validation loss 1.0951287746429443\n",
      "Epoch 170, current patience 28, model mean validation loss 1.094096302986145, embedding dim 2, hidden size 256, num layers 1, train loss 1.0980327129364014, validation loss 1.0943803787231445\n",
      "Epoch 180, current patience 27, model mean validation loss 1.0940989255905151, embedding dim 2, hidden size 256, num layers 1, train loss 1.0850651264190674, validation loss 1.091559648513794\n",
      "Epoch 190, current patience 26, model mean validation loss 1.093937635421753, embedding dim 2, hidden size 256, num layers 1, train loss 1.1473219394683838, validation loss 1.0933783054351807\n",
      "Epoch 200, current patience 25, model mean validation loss 1.0938796997070312, embedding dim 2, hidden size 256, num layers 1, train loss 1.1092050075531006, validation loss 1.093555212020874\n",
      "Epoch 210, current patience 24, model mean validation loss 1.0943958759307861, embedding dim 2, hidden size 256, num layers 1, train loss 1.0791020393371582, validation loss 1.0945038795471191\n",
      "Epoch 220, current patience 23, model mean validation loss 1.0936851501464844, embedding dim 2, hidden size 256, num layers 1, train loss 1.0793964862823486, validation loss 1.089526891708374\n",
      "Epoch 230, current patience 22, model mean validation loss 1.0920991897583008, embedding dim 2, hidden size 256, num layers 1, train loss 1.083317518234253, validation loss 1.0847604274749756\n",
      "Epoch 240, current patience 30, model mean validation loss 1.09063720703125, embedding dim 2, hidden size 256, num layers 1, train loss 1.0698809623718262, validation loss 1.0834325551986694\n",
      "Epoch 250, current patience 30, model mean validation loss 1.089831829071045, embedding dim 2, hidden size 256, num layers 1, train loss 1.1019800901412964, validation loss 1.0879374742507935\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0879030227661133, embedding dim 2, hidden size 256, num layers 1, train loss 1.177286148071289, validation loss 1.076129674911499\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0862998962402344, embedding dim 2, hidden size 256, num layers 1, train loss 1.0810619592666626, validation loss 1.0805535316467285\n",
      "Epoch 280, current patience 30, model mean validation loss 1.083824634552002, embedding dim 2, hidden size 256, num layers 1, train loss 1.0826830863952637, validation loss 1.0737532377243042\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0804107189178467, embedding dim 2, hidden size 256, num layers 1, train loss 1.0274094343185425, validation loss 1.0671920776367188\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0776429176330566, embedding dim 2, hidden size 256, num layers 1, train loss 1.0395244359970093, validation loss 1.067384958267212\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0743328332901, embedding dim 2, hidden size 256, num layers 1, train loss 1.0789978504180908, validation loss 1.0582795143127441\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0694447755813599, embedding dim 2, hidden size 256, num layers 1, train loss 1.0417695045471191, validation loss 1.044327974319458\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0598193407058716, embedding dim 2, hidden size 256, num layers 1, train loss 1.0224108695983887, validation loss 1.0109339952468872\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0530905723571777, embedding dim 2, hidden size 256, num layers 1, train loss 0.9669572114944458, validation loss 1.022299885749817\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0447787046432495, embedding dim 2, hidden size 256, num layers 1, train loss 0.9656354188919067, validation loss 1.014057993888855\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0390241146087646, embedding dim 2, hidden size 256, num layers 1, train loss 1.0044665336608887, validation loss 1.0277161598205566\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0301650762557983, embedding dim 2, hidden size 256, num layers 1, train loss 0.9322089552879333, validation loss 0.9963194131851196\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0188673734664917, embedding dim 2, hidden size 256, num layers 1, train loss 0.8966941833496094, validation loss 0.9770042896270752\n",
      "Epoch 390, current patience 30, model mean validation loss 1.008785367012024, embedding dim 2, hidden size 256, num layers 1, train loss 0.838627815246582, validation loss 0.9776231050491333\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9992169141769409, embedding dim 2, hidden size 256, num layers 1, train loss 0.8135538697242737, validation loss 0.9677808284759521\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0000171661376953, embedding dim 2, hidden size 256, num layers 1, train loss 1.0643701553344727, validation loss 1.0173356533050537\n",
      "Epoch 420, current patience 29, model mean validation loss 0.9957494735717773, embedding dim 2, hidden size 256, num layers 1, train loss 0.9612401723861694, validation loss 0.988158106803894\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9857003092765808, embedding dim 2, hidden size 256, num layers 1, train loss 0.8098938465118408, validation loss 0.9336647987365723\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9750653505325317, embedding dim 2, hidden size 256, num layers 1, train loss 0.8910214304924011, validation loss 0.9426365494728088\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9682300090789795, embedding dim 2, hidden size 256, num layers 1, train loss 0.8856779336929321, validation loss 0.9416365027427673\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9626883268356323, embedding dim 2, hidden size 256, num layers 1, train loss 0.9071187376976013, validation loss 0.9326710104942322\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9548845291137695, embedding dim 2, hidden size 256, num layers 1, train loss 0.8906739950180054, validation loss 0.9151929616928101\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9488792419433594, embedding dim 2, hidden size 256, num layers 1, train loss 0.9574239253997803, validation loss 0.9197380542755127\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9396665096282959, embedding dim 2, hidden size 256, num layers 1, train loss 0.9408204555511475, validation loss 0.9436345100402832\n",
      "Epoch 500, current patience 30, model mean validation loss 0.929509699344635, embedding dim 2, hidden size 256, num layers 1, train loss 0.7989810705184937, validation loss 0.9069032669067383\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9219213128089905, embedding dim 2, hidden size 256, num layers 1, train loss 0.8773674964904785, validation loss 0.8729573488235474\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9202913045883179, embedding dim 2, hidden size 256, num layers 1, train loss 0.7327136993408203, validation loss 0.9295969605445862\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9145562648773193, embedding dim 2, hidden size 256, num layers 1, train loss 0.8932534456253052, validation loss 0.8957560658454895\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9092949032783508, embedding dim 2, hidden size 256, num layers 1, train loss 0.7938805818557739, validation loss 0.8905802965164185\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9067708253860474, embedding dim 2, hidden size 256, num layers 1, train loss 0.7925683856010437, validation loss 0.8950002193450928\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9023563265800476, embedding dim 2, hidden size 256, num layers 1, train loss 0.7559190988540649, validation loss 0.8844216465950012\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8950885534286499, embedding dim 2, hidden size 256, num layers 1, train loss 0.6819193363189697, validation loss 0.8854926824569702\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9008423089981079, embedding dim 2, hidden size 256, num layers 1, train loss 0.805079460144043, validation loss 0.9529330134391785\n",
      "Epoch 590, current patience 29, model mean validation loss 0.9043211936950684, embedding dim 2, hidden size 256, num layers 1, train loss 0.7766594290733337, validation loss 0.9007886648178101\n",
      "Epoch 600, current patience 28, model mean validation loss 0.8987892866134644, embedding dim 2, hidden size 256, num layers 1, train loss 0.8282180428504944, validation loss 0.8853417634963989\n",
      "Epoch 610, current patience 27, model mean validation loss 0.8946901559829712, embedding dim 2, hidden size 256, num layers 1, train loss 0.7556121349334717, validation loss 0.862962543964386\n",
      "Epoch 620, current patience 30, model mean validation loss 0.893923282623291, embedding dim 2, hidden size 256, num layers 1, train loss 0.8660289645195007, validation loss 0.8844457864761353\n",
      "Epoch 630, current patience 30, model mean validation loss 0.8912169337272644, embedding dim 2, hidden size 256, num layers 1, train loss 0.7822333574295044, validation loss 0.8733494281768799\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8905607461929321, embedding dim 2, hidden size 256, num layers 1, train loss 0.6619881391525269, validation loss 0.8791724443435669\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8873196840286255, embedding dim 2, hidden size 256, num layers 1, train loss 0.688012957572937, validation loss 0.8595643043518066\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8756667971611023, embedding dim 2, hidden size 256, num layers 1, train loss 0.807619035243988, validation loss 0.8597097396850586\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8700568079948425, embedding dim 2, hidden size 256, num layers 1, train loss 0.8422839045524597, validation loss 0.8559087514877319\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8680049180984497, embedding dim 2, hidden size 256, num layers 1, train loss 0.6310093402862549, validation loss 0.8689265251159668\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8662188053131104, embedding dim 2, hidden size 256, num layers 1, train loss 0.833947479724884, validation loss 0.8486730456352234\n",
      "Epoch 700, current patience 30, model mean validation loss 0.857619047164917, embedding dim 2, hidden size 256, num layers 1, train loss 0.7580724954605103, validation loss 0.815648078918457\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8533995151519775, embedding dim 2, hidden size 256, num layers 1, train loss 0.5752949118614197, validation loss 0.8395927548408508\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8549709916114807, embedding dim 2, hidden size 256, num layers 1, train loss 0.6546815633773804, validation loss 0.8917444944381714\n",
      "Epoch 730, current patience 29, model mean validation loss 0.8504574298858643, embedding dim 2, hidden size 256, num layers 1, train loss 0.618937075138092, validation loss 0.8234562277793884\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8485723733901978, embedding dim 2, hidden size 256, num layers 1, train loss 0.9608161449432373, validation loss 0.8446290493011475\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8474729061126709, embedding dim 2, hidden size 256, num layers 1, train loss 0.6782963871955872, validation loss 0.8471125364303589\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8420388698577881, embedding dim 2, hidden size 256, num layers 1, train loss 0.5617112517356873, validation loss 0.8254549503326416\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8414006233215332, embedding dim 2, hidden size 256, num layers 1, train loss 0.7942711114883423, validation loss 0.84356689453125\n",
      "Epoch 780, current patience 30, model mean validation loss 0.8415595293045044, embedding dim 2, hidden size 256, num layers 1, train loss 0.701088011264801, validation loss 0.8169193267822266\n",
      "Epoch 790, current patience 29, model mean validation loss 0.8426007032394409, embedding dim 2, hidden size 256, num layers 1, train loss 0.5127792358398438, validation loss 0.8479222059249878\n",
      "Epoch 800, current patience 28, model mean validation loss 0.8362337350845337, embedding dim 2, hidden size 256, num layers 1, train loss 0.6952568292617798, validation loss 0.8408083915710449\n",
      "Epoch 810, current patience 30, model mean validation loss 0.8452852964401245, embedding dim 2, hidden size 256, num layers 1, train loss 0.5425913333892822, validation loss 0.8958689570426941\n",
      "Epoch 820, current patience 29, model mean validation loss 0.8487253189086914, embedding dim 2, hidden size 256, num layers 1, train loss 0.7153864502906799, validation loss 0.8721492290496826\n",
      "Epoch 830, current patience 28, model mean validation loss 0.8532869815826416, embedding dim 2, hidden size 256, num layers 1, train loss 0.49350008368492126, validation loss 0.8836058974266052\n",
      "Epoch 840, current patience 27, model mean validation loss 0.857183575630188, embedding dim 2, hidden size 256, num layers 1, train loss 0.8382084369659424, validation loss 0.8566277027130127\n",
      "Epoch 850, current patience 26, model mean validation loss 0.8572927117347717, embedding dim 2, hidden size 256, num layers 1, train loss 0.5463650226593018, validation loss 0.8444403409957886\n",
      "Epoch 860, current patience 25, model mean validation loss 0.8632862567901611, embedding dim 2, hidden size 256, num layers 1, train loss 0.6940104365348816, validation loss 0.8648674488067627\n",
      "Epoch 870, current patience 24, model mean validation loss 0.8633712530136108, embedding dim 2, hidden size 256, num layers 1, train loss 0.7034427523612976, validation loss 0.8486025333404541\n",
      "Epoch 880, current patience 23, model mean validation loss 0.8663930892944336, embedding dim 2, hidden size 256, num layers 1, train loss 0.5362914204597473, validation loss 0.8649824857711792\n",
      "Epoch 890, current patience 22, model mean validation loss 0.86211097240448, embedding dim 2, hidden size 256, num layers 1, train loss 0.6921545267105103, validation loss 0.8616119623184204\n",
      "Epoch 900, current patience 21, model mean validation loss 0.8587788343429565, embedding dim 2, hidden size 256, num layers 1, train loss 0.44907519221305847, validation loss 0.845491886138916\n",
      "Epoch 910, current patience 20, model mean validation loss 0.8574900031089783, embedding dim 2, hidden size 256, num layers 1, train loss 0.5308271646499634, validation loss 0.8732960820198059\n",
      "Epoch 920, current patience 19, model mean validation loss 0.8623339533805847, embedding dim 2, hidden size 256, num layers 1, train loss 0.5524594783782959, validation loss 0.8953787088394165\n",
      "Epoch 930, current patience 18, model mean validation loss 0.8629852533340454, embedding dim 2, hidden size 256, num layers 1, train loss 0.6689639091491699, validation loss 0.8496504426002502\n",
      "Epoch 940, current patience 17, model mean validation loss 0.8600918054580688, embedding dim 2, hidden size 256, num layers 1, train loss 0.5732239484786987, validation loss 0.8417199850082397\n",
      "Epoch 950, current patience 16, model mean validation loss 0.8594725131988525, embedding dim 2, hidden size 256, num layers 1, train loss 0.48663246631622314, validation loss 0.843648374080658\n",
      "Epoch 960, current patience 15, model mean validation loss 0.8682129383087158, embedding dim 2, hidden size 256, num layers 1, train loss 0.546799898147583, validation loss 0.9349064826965332\n",
      "Epoch 970, current patience 14, model mean validation loss 0.8676477670669556, embedding dim 2, hidden size 256, num layers 1, train loss 0.7933091521263123, validation loss 0.8570905923843384\n",
      "Epoch 980, current patience 13, model mean validation loss 0.8716456890106201, embedding dim 2, hidden size 256, num layers 1, train loss 0.5390834212303162, validation loss 0.8774741888046265\n",
      "Epoch 990, current patience 12, model mean validation loss 0.8706780076026917, embedding dim 2, hidden size 256, num layers 1, train loss 0.5866175293922424, validation loss 0.8655549883842468\n",
      "Epoch 1000, current patience 11, model mean validation loss 0.8699508905410767, embedding dim 2, hidden size 256, num layers 1, train loss 0.3974742889404297, validation loss 0.88956218957901\n",
      "Epoch 1010, current patience 10, model mean validation loss 0.889899730682373, embedding dim 2, hidden size 256, num layers 1, train loss 0.835221529006958, validation loss 1.0092408657073975\n",
      "Epoch 1020, current patience 9, model mean validation loss 0.896757185459137, embedding dim 2, hidden size 256, num layers 1, train loss 0.492493212223053, validation loss 0.8965798616409302\n",
      "Epoch 1030, current patience 8, model mean validation loss 0.9038699269294739, embedding dim 2, hidden size 256, num layers 1, train loss 0.5342627763748169, validation loss 0.9005500674247742\n",
      "Epoch 1040, current patience 7, model mean validation loss 0.899159848690033, embedding dim 2, hidden size 256, num layers 1, train loss 0.5981687307357788, validation loss 0.8972259163856506\n",
      "Epoch 1050, current patience 6, model mean validation loss 0.9055154323577881, embedding dim 2, hidden size 256, num layers 1, train loss 0.34716981649398804, validation loss 0.9079350829124451\n",
      "Epoch 1060, current patience 5, model mean validation loss 0.9145896434783936, embedding dim 2, hidden size 256, num layers 1, train loss 0.5573809146881104, validation loss 0.950068473815918\n",
      "Epoch 1070, current patience 4, model mean validation loss 0.9160435199737549, embedding dim 2, hidden size 256, num layers 1, train loss 0.59376460313797, validation loss 0.8771854639053345\n",
      "Epoch 1080, current patience 3, model mean validation loss 0.9128545522689819, embedding dim 2, hidden size 256, num layers 1, train loss 0.5476467609405518, validation loss 0.8640506267547607\n",
      "Epoch 1090, current patience 2, model mean validation loss 0.9022642374038696, embedding dim 2, hidden size 256, num layers 1, train loss 0.43065765500068665, validation loss 0.9245184659957886\n",
      "Epoch 1100, current patience 1, model mean validation loss 0.8996207118034363, embedding dim 2, hidden size 256, num layers 1, train loss 0.508841335773468, validation loss 0.8754316568374634\n",
      "Epoch 0, current patience 30, model mean validation loss 1.126408576965332, embedding dim 2, hidden size 512, num layers 1, train loss 1.0993030071258545, validation loss 1.126408576965332\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1153693199157715, embedding dim 2, hidden size 512, num layers 1, train loss 1.176703691482544, validation loss 1.104330062866211\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1092580556869507, embedding dim 2, hidden size 512, num layers 1, train loss 1.0897258520126343, validation loss 1.097035527229309\n",
      "Epoch 30, current patience 30, model mean validation loss 1.105661153793335, embedding dim 2, hidden size 512, num layers 1, train loss 1.098636269569397, validation loss 1.0948703289031982\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1040327548980713, embedding dim 2, hidden size 512, num layers 1, train loss 1.0951989889144897, validation loss 1.0975186824798584\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1026018857955933, embedding dim 2, hidden size 512, num layers 1, train loss 1.0931437015533447, validation loss 1.09544837474823\n",
      "Epoch 60, current patience 30, model mean validation loss 1.101488709449768, embedding dim 2, hidden size 512, num layers 1, train loss 1.0904834270477295, validation loss 1.0948091745376587\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1007192134857178, embedding dim 2, hidden size 512, num layers 1, train loss 1.092496633529663, validation loss 1.0953319072723389\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0968289375305176, embedding dim 2, hidden size 512, num layers 1, train loss 1.076430082321167, validation loss 1.095287561416626\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0954805612564087, embedding dim 2, hidden size 512, num layers 1, train loss 1.087141990661621, validation loss 1.0935434103012085\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0950722694396973, embedding dim 2, hidden size 512, num layers 1, train loss 1.0937564373016357, validation loss 1.0937683582305908\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0952800512313843, embedding dim 2, hidden size 512, num layers 1, train loss 1.1024243831634521, validation loss 1.0965330600738525\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0948736667633057, embedding dim 2, hidden size 512, num layers 1, train loss 1.11097252368927, validation loss 1.09426748752594\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0946531295776367, embedding dim 2, hidden size 512, num layers 1, train loss 1.1002289056777954, validation loss 1.0936839580535889\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0942890644073486, embedding dim 2, hidden size 512, num layers 1, train loss 1.0970046520233154, validation loss 1.0918971300125122\n",
      "Epoch 150, current patience 30, model mean validation loss 1.094091534614563, embedding dim 2, hidden size 512, num layers 1, train loss 1.0936460494995117, validation loss 1.0937514305114746\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0942695140838623, embedding dim 2, hidden size 512, num layers 1, train loss 1.0953032970428467, validation loss 1.0967119932174683\n",
      "Epoch 170, current patience 29, model mean validation loss 1.0943636894226074, embedding dim 2, hidden size 512, num layers 1, train loss 1.0943989753723145, validation loss 1.0942964553833008\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0944797992706299, embedding dim 2, hidden size 512, num layers 1, train loss 1.082092046737671, validation loss 1.0946968793869019\n",
      "Epoch 190, current patience 27, model mean validation loss 1.0943119525909424, embedding dim 2, hidden size 512, num layers 1, train loss 1.0982152223587036, validation loss 1.0951911211013794\n",
      "Epoch 200, current patience 26, model mean validation loss 1.0941460132598877, embedding dim 2, hidden size 512, num layers 1, train loss 1.0935325622558594, validation loss 1.0929392576217651\n",
      "Epoch 210, current patience 25, model mean validation loss 1.094550371170044, embedding dim 2, hidden size 512, num layers 1, train loss 1.08388352394104, validation loss 1.096919298171997\n",
      "Epoch 220, current patience 24, model mean validation loss 1.0947896242141724, embedding dim 2, hidden size 512, num layers 1, train loss 1.1074708700180054, validation loss 1.0938113927841187\n",
      "Epoch 230, current patience 23, model mean validation loss 1.0950002670288086, embedding dim 2, hidden size 512, num layers 1, train loss 1.0852272510528564, validation loss 1.095435619354248\n",
      "Epoch 240, current patience 22, model mean validation loss 1.0943996906280518, embedding dim 2, hidden size 512, num layers 1, train loss 1.0730912685394287, validation loss 1.0919082164764404\n",
      "Epoch 250, current patience 21, model mean validation loss 1.0944825410842896, embedding dim 2, hidden size 512, num layers 1, train loss 1.0946778059005737, validation loss 1.0949583053588867\n",
      "Epoch 260, current patience 20, model mean validation loss 1.0944691896438599, embedding dim 2, hidden size 512, num layers 1, train loss 1.0875507593154907, validation loss 1.094590663909912\n",
      "Epoch 270, current patience 19, model mean validation loss 1.0943727493286133, embedding dim 2, hidden size 512, num layers 1, train loss 1.09553861618042, validation loss 1.0944185256958008\n",
      "Epoch 280, current patience 18, model mean validation loss 1.0944112539291382, embedding dim 2, hidden size 512, num layers 1, train loss 1.1012990474700928, validation loss 1.0932481288909912\n",
      "Epoch 290, current patience 17, model mean validation loss 1.0933396816253662, embedding dim 2, hidden size 512, num layers 1, train loss 1.0889859199523926, validation loss 1.0883466005325317\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0950483083724976, embedding dim 2, hidden size 512, num layers 1, train loss 1.0369582176208496, validation loss 1.1074804067611694\n",
      "Epoch 310, current patience 29, model mean validation loss 1.094748854637146, embedding dim 2, hidden size 512, num layers 1, train loss 1.099688172340393, validation loss 1.0930399894714355\n",
      "Epoch 320, current patience 28, model mean validation loss 1.0946197509765625, embedding dim 2, hidden size 512, num layers 1, train loss 1.0916318893432617, validation loss 1.0908747911453247\n",
      "Epoch 330, current patience 27, model mean validation loss 1.0933642387390137, embedding dim 2, hidden size 512, num layers 1, train loss 1.0658800601959229, validation loss 1.0849144458770752\n",
      "Epoch 340, current patience 26, model mean validation loss 1.0936152935028076, embedding dim 2, hidden size 512, num layers 1, train loss 1.0943214893341064, validation loss 1.096599817276001\n",
      "Epoch 350, current patience 25, model mean validation loss 1.093857765197754, embedding dim 2, hidden size 512, num layers 1, train loss 1.1008195877075195, validation loss 1.0963575839996338\n",
      "Epoch 360, current patience 24, model mean validation loss 1.0938332080841064, embedding dim 2, hidden size 512, num layers 1, train loss 1.0835597515106201, validation loss 1.0930511951446533\n",
      "Epoch 370, current patience 23, model mean validation loss 1.0933945178985596, embedding dim 2, hidden size 512, num layers 1, train loss 1.1016508340835571, validation loss 1.084838628768921\n",
      "Epoch 380, current patience 22, model mean validation loss 1.0902302265167236, embedding dim 2, hidden size 512, num layers 1, train loss 1.1055009365081787, validation loss 1.0821653604507446\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0916874408721924, embedding dim 2, hidden size 512, num layers 1, train loss 1.092098355293274, validation loss 1.1046968698501587\n",
      "Epoch 400, current patience 29, model mean validation loss 1.093184471130371, embedding dim 2, hidden size 512, num layers 1, train loss 1.009865164756775, validation loss 1.102851390838623\n",
      "Epoch 410, current patience 28, model mean validation loss 1.1001075506210327, embedding dim 2, hidden size 512, num layers 1, train loss 1.0909919738769531, validation loss 1.1402992010116577\n",
      "Epoch 420, current patience 27, model mean validation loss 1.1017889976501465, embedding dim 2, hidden size 512, num layers 1, train loss 1.0810259580612183, validation loss 1.1100519895553589\n",
      "Epoch 430, current patience 26, model mean validation loss 1.1066107749938965, embedding dim 2, hidden size 512, num layers 1, train loss 1.1304426193237305, validation loss 1.134932041168213\n",
      "Epoch 440, current patience 25, model mean validation loss 1.1123642921447754, embedding dim 2, hidden size 512, num layers 1, train loss 1.1083285808563232, validation loss 1.1390784978866577\n",
      "Epoch 450, current patience 24, model mean validation loss 1.117898941040039, embedding dim 2, hidden size 512, num layers 1, train loss 1.1091761589050293, validation loss 1.1291155815124512\n",
      "Epoch 460, current patience 23, model mean validation loss 1.1218013763427734, embedding dim 2, hidden size 512, num layers 1, train loss 1.1162382364273071, validation loss 1.113385558128357\n",
      "Epoch 470, current patience 22, model mean validation loss 1.1259628534317017, embedding dim 2, hidden size 512, num layers 1, train loss 1.0157713890075684, validation loss 1.137988567352295\n",
      "Epoch 480, current patience 21, model mean validation loss 1.1401550769805908, embedding dim 2, hidden size 512, num layers 1, train loss 1.1146981716156006, validation loss 1.2163889408111572\n",
      "Epoch 490, current patience 20, model mean validation loss 1.133717656135559, embedding dim 2, hidden size 512, num layers 1, train loss 1.0849871635437012, validation loss 1.0888005495071411\n",
      "Epoch 500, current patience 19, model mean validation loss 1.134383201599121, embedding dim 2, hidden size 512, num layers 1, train loss 1.0889259576797485, validation loss 1.1153767108917236\n",
      "Epoch 510, current patience 18, model mean validation loss 1.131016492843628, embedding dim 2, hidden size 512, num layers 1, train loss 1.0611822605133057, validation loss 1.1079981327056885\n",
      "Epoch 520, current patience 17, model mean validation loss 1.1252849102020264, embedding dim 2, hidden size 512, num layers 1, train loss 1.0854135751724243, validation loss 1.0932257175445557\n",
      "Epoch 530, current patience 16, model mean validation loss 1.121242880821228, embedding dim 2, hidden size 512, num layers 1, train loss 1.0872652530670166, validation loss 1.0967793464660645\n",
      "Epoch 540, current patience 15, model mean validation loss 1.1162683963775635, embedding dim 2, hidden size 512, num layers 1, train loss 1.0860801935195923, validation loss 1.07358980178833\n",
      "Epoch 550, current patience 14, model mean validation loss 1.108504295349121, embedding dim 2, hidden size 512, num layers 1, train loss 1.0561550855636597, validation loss 1.0758752822875977\n",
      "Epoch 560, current patience 13, model mean validation loss 1.0898938179016113, embedding dim 2, hidden size 512, num layers 1, train loss 1.0806491374969482, validation loss 1.0675053596496582\n",
      "Epoch 570, current patience 30, model mean validation loss 1.0865025520324707, embedding dim 2, hidden size 512, num layers 1, train loss 1.081108570098877, validation loss 1.0616698265075684\n",
      "Epoch 580, current patience 30, model mean validation loss 1.0820014476776123, embedding dim 2, hidden size 512, num layers 1, train loss 1.0501391887664795, validation loss 1.0793676376342773\n",
      "Epoch 590, current patience 30, model mean validation loss 1.0763514041900635, embedding dim 2, hidden size 512, num layers 1, train loss 0.9865617752075195, validation loss 1.062798261642456\n",
      "Epoch 600, current patience 30, model mean validation loss 1.0731364488601685, embedding dim 2, hidden size 512, num layers 1, train loss 1.020172357559204, validation loss 1.0675065517425537\n",
      "Epoch 610, current patience 30, model mean validation loss 1.068835735321045, embedding dim 2, hidden size 512, num layers 1, train loss 0.9879515171051025, validation loss 1.062373399734497\n",
      "Epoch 620, current patience 30, model mean validation loss 1.0680968761444092, embedding dim 2, hidden size 512, num layers 1, train loss 1.0298113822937012, validation loss 1.067678689956665\n",
      "Epoch 630, current patience 30, model mean validation loss 1.0662646293640137, embedding dim 2, hidden size 512, num layers 1, train loss 1.0338058471679688, validation loss 1.0612177848815918\n",
      "Epoch 640, current patience 30, model mean validation loss 1.0622889995574951, embedding dim 2, hidden size 512, num layers 1, train loss 0.9356746673583984, validation loss 1.035699486732483\n",
      "Epoch 650, current patience 30, model mean validation loss 1.063306450843811, embedding dim 2, hidden size 512, num layers 1, train loss 1.0760531425476074, validation loss 1.069809913635254\n",
      "Epoch 660, current patience 29, model mean validation loss 1.0585896968841553, embedding dim 2, hidden size 512, num layers 1, train loss 0.9606558084487915, validation loss 1.0416336059570312\n",
      "Epoch 670, current patience 30, model mean validation loss 1.054268479347229, embedding dim 2, hidden size 512, num layers 1, train loss 0.9245854616165161, validation loss 1.0282282829284668\n",
      "Epoch 680, current patience 30, model mean validation loss 1.0497498512268066, embedding dim 2, hidden size 512, num layers 1, train loss 0.9367318153381348, validation loss 1.0313578844070435\n",
      "Epoch 690, current patience 30, model mean validation loss 1.0433015823364258, embedding dim 2, hidden size 512, num layers 1, train loss 0.9465635418891907, validation loss 1.0107873678207397\n",
      "Epoch 700, current patience 30, model mean validation loss 1.0362416505813599, embedding dim 2, hidden size 512, num layers 1, train loss 0.9458333253860474, validation loss 1.0111985206604004\n",
      "Epoch 710, current patience 30, model mean validation loss 1.0265512466430664, embedding dim 2, hidden size 512, num layers 1, train loss 0.8615362644195557, validation loss 0.9836945533752441\n",
      "Epoch 720, current patience 30, model mean validation loss 1.0285913944244385, embedding dim 2, hidden size 512, num layers 1, train loss 1.0128529071807861, validation loss 1.0520212650299072\n",
      "Epoch 730, current patience 29, model mean validation loss 1.0193305015563965, embedding dim 2, hidden size 512, num layers 1, train loss 1.0329885482788086, validation loss 0.9957221746444702\n",
      "Epoch 740, current patience 30, model mean validation loss 1.0122835636138916, embedding dim 2, hidden size 512, num layers 1, train loss 0.8268858194351196, validation loss 0.9852582812309265\n",
      "Epoch 750, current patience 30, model mean validation loss 1.007879614830017, embedding dim 2, hidden size 512, num layers 1, train loss 0.9550662636756897, validation loss 0.9929970502853394\n",
      "Epoch 760, current patience 30, model mean validation loss 1.0012528896331787, embedding dim 2, hidden size 512, num layers 1, train loss 0.8188158273696899, validation loss 0.9783431887626648\n",
      "Epoch 770, current patience 30, model mean validation loss 0.9980335235595703, embedding dim 2, hidden size 512, num layers 1, train loss 0.8973173499107361, validation loss 0.985033392906189\n",
      "Epoch 780, current patience 30, model mean validation loss 0.9951226711273193, embedding dim 2, hidden size 512, num layers 1, train loss 0.8760953545570374, validation loss 0.9879111647605896\n",
      "Epoch 790, current patience 30, model mean validation loss 1.002112627029419, embedding dim 2, hidden size 512, num layers 1, train loss 0.7999749779701233, validation loss 1.0396149158477783\n",
      "Epoch 800, current patience 29, model mean validation loss 0.9925169944763184, embedding dim 2, hidden size 512, num layers 1, train loss 0.8475622534751892, validation loss 0.9752558469772339\n",
      "Epoch 810, current patience 30, model mean validation loss 0.9887183904647827, embedding dim 2, hidden size 512, num layers 1, train loss 0.8402537107467651, validation loss 0.9653334617614746\n",
      "Epoch 820, current patience 30, model mean validation loss 0.9844964742660522, embedding dim 2, hidden size 512, num layers 1, train loss 0.9214581847190857, validation loss 0.9514828324317932\n",
      "Epoch 830, current patience 30, model mean validation loss 0.9758327007293701, embedding dim 2, hidden size 512, num layers 1, train loss 0.828967809677124, validation loss 0.9236866235733032\n",
      "Epoch 840, current patience 30, model mean validation loss 0.9710995554924011, embedding dim 2, hidden size 512, num layers 1, train loss 0.7369982004165649, validation loss 0.9404780268669128\n",
      "Epoch 850, current patience 30, model mean validation loss 0.9660220742225647, embedding dim 2, hidden size 512, num layers 1, train loss 0.8230111598968506, validation loss 0.9444135427474976\n",
      "Epoch 860, current patience 30, model mean validation loss 0.9598520994186401, embedding dim 2, hidden size 512, num layers 1, train loss 0.6955853700637817, validation loss 0.9385513663291931\n",
      "Epoch 870, current patience 30, model mean validation loss 0.9459566473960876, embedding dim 2, hidden size 512, num layers 1, train loss 0.6794570088386536, validation loss 0.9284514784812927\n",
      "Epoch 880, current patience 30, model mean validation loss 0.9400898218154907, embedding dim 2, hidden size 512, num layers 1, train loss 0.9414798021316528, validation loss 0.9283211827278137\n",
      "Epoch 890, current patience 30, model mean validation loss 0.9352383613586426, embedding dim 2, hidden size 512, num layers 1, train loss 0.6908552050590515, validation loss 0.9265221357345581\n",
      "Epoch 900, current patience 30, model mean validation loss 0.9318886399269104, embedding dim 2, hidden size 512, num layers 1, train loss 0.9774297475814819, validation loss 0.9246845245361328\n",
      "Epoch 910, current patience 30, model mean validation loss 0.9332766532897949, embedding dim 2, hidden size 512, num layers 1, train loss 0.6942974925041199, validation loss 0.9347906112670898\n",
      "Epoch 920, current patience 29, model mean validation loss 0.9300756454467773, embedding dim 2, hidden size 512, num layers 1, train loss 0.8209758996963501, validation loss 0.9148702621459961\n",
      "Epoch 930, current patience 30, model mean validation loss 0.9243779182434082, embedding dim 2, hidden size 512, num layers 1, train loss 0.8607710599899292, validation loss 0.898831307888031\n",
      "Epoch 940, current patience 30, model mean validation loss 0.9217485189437866, embedding dim 2, hidden size 512, num layers 1, train loss 0.8725686073303223, validation loss 0.9175167679786682\n",
      "Epoch 950, current patience 30, model mean validation loss 0.9241674542427063, embedding dim 2, hidden size 512, num layers 1, train loss 0.7256045341491699, validation loss 0.9478031396865845\n",
      "Epoch 960, current patience 29, model mean validation loss 0.9177578687667847, embedding dim 2, hidden size 512, num layers 1, train loss 0.5884696841239929, validation loss 0.8770443201065063\n",
      "Epoch 970, current patience 30, model mean validation loss 0.9195196628570557, embedding dim 2, hidden size 512, num layers 1, train loss 0.683047354221344, validation loss 0.9406166076660156\n",
      "Epoch 980, current patience 29, model mean validation loss 0.9210268259048462, embedding dim 2, hidden size 512, num layers 1, train loss 0.7760968208312988, validation loss 0.9367419481277466\n",
      "Epoch 990, current patience 28, model mean validation loss 0.9171930551528931, embedding dim 2, hidden size 512, num layers 1, train loss 0.7783231735229492, validation loss 0.9041197896003723\n",
      "Epoch 1000, current patience 30, model mean validation loss 0.9200641512870789, embedding dim 2, hidden size 512, num layers 1, train loss 0.6570032835006714, validation loss 0.9378392696380615\n",
      "Epoch 1010, current patience 29, model mean validation loss 0.9193217158317566, embedding dim 2, hidden size 512, num layers 1, train loss 0.808832585811615, validation loss 0.8928918838500977\n",
      "Epoch 1020, current patience 28, model mean validation loss 0.915166437625885, embedding dim 2, hidden size 512, num layers 1, train loss 0.8640866279602051, validation loss 0.8842744827270508\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.9066383838653564, embedding dim 2, hidden size 512, num layers 1, train loss 0.6657705307006836, validation loss 0.8795790076255798\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.9077792763710022, embedding dim 2, hidden size 512, num layers 1, train loss 0.8821060657501221, validation loss 0.8861712217330933\n",
      "Epoch 1050, current patience 29, model mean validation loss 0.9015213847160339, embedding dim 2, hidden size 512, num layers 1, train loss 0.8171603083610535, validation loss 0.8905534148216248\n",
      "Epoch 1060, current patience 30, model mean validation loss 0.8947928547859192, embedding dim 2, hidden size 512, num layers 1, train loss 0.7064563632011414, validation loss 0.8829135894775391\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.8959592580795288, embedding dim 2, hidden size 512, num layers 1, train loss 0.6116613149642944, validation loss 0.9134514331817627\n",
      "Epoch 1080, current patience 29, model mean validation loss 0.8896547555923462, embedding dim 2, hidden size 512, num layers 1, train loss 0.7993334531784058, validation loss 0.8874027729034424\n",
      "Epoch 1090, current patience 30, model mean validation loss 0.8956884741783142, embedding dim 2, hidden size 512, num layers 1, train loss 0.6422992944717407, validation loss 0.9411618113517761\n",
      "Epoch 1100, current patience 29, model mean validation loss 0.894593358039856, embedding dim 2, hidden size 512, num layers 1, train loss 0.8189849257469177, validation loss 0.8755137920379639\n",
      "Epoch 1110, current patience 28, model mean validation loss 0.8921986222267151, embedding dim 2, hidden size 512, num layers 1, train loss 0.5280228853225708, validation loss 0.8604209423065186\n",
      "Epoch 1120, current patience 27, model mean validation loss 0.8935546875, embedding dim 2, hidden size 512, num layers 1, train loss 0.5690258145332336, validation loss 0.8970198631286621\n",
      "Epoch 1130, current patience 26, model mean validation loss 0.8978713750839233, embedding dim 2, hidden size 512, num layers 1, train loss 0.6996015310287476, validation loss 0.9250869750976562\n",
      "Epoch 1140, current patience 25, model mean validation loss 0.9124348759651184, embedding dim 2, hidden size 512, num layers 1, train loss 0.6234639883041382, validation loss 0.9994214773178101\n",
      "Epoch 1150, current patience 24, model mean validation loss 0.9354264736175537, embedding dim 2, hidden size 512, num layers 1, train loss 0.6526765823364258, validation loss 1.097383975982666\n",
      "Epoch 1160, current patience 23, model mean validation loss 0.9338947534561157, embedding dim 2, hidden size 512, num layers 1, train loss 0.8246783018112183, validation loss 0.8751495480537415\n",
      "Epoch 1170, current patience 22, model mean validation loss 0.9254716634750366, embedding dim 2, hidden size 512, num layers 1, train loss 0.7924160957336426, validation loss 0.8737764358520508\n",
      "Epoch 1180, current patience 21, model mean validation loss 0.923661470413208, embedding dim 2, hidden size 512, num layers 1, train loss 0.4814900755882263, validation loss 0.8610327839851379\n",
      "Epoch 1190, current patience 20, model mean validation loss 0.9251995086669922, embedding dim 2, hidden size 512, num layers 1, train loss 0.7938534617424011, validation loss 0.872725248336792\n",
      "Epoch 1200, current patience 19, model mean validation loss 0.9178736209869385, embedding dim 2, hidden size 512, num layers 1, train loss 0.8556102514266968, validation loss 0.8384127020835876\n",
      "Epoch 1210, current patience 18, model mean validation loss 0.9126840829849243, embedding dim 2, hidden size 512, num layers 1, train loss 0.5659530162811279, validation loss 0.8835705518722534\n",
      "Epoch 1220, current patience 17, model mean validation loss 0.8943417072296143, embedding dim 2, hidden size 512, num layers 1, train loss 0.6290851831436157, validation loss 0.8526824712753296\n",
      "Epoch 1230, current patience 16, model mean validation loss 0.8709397315979004, embedding dim 2, hidden size 512, num layers 1, train loss 0.6323152184486389, validation loss 0.9101680517196655\n",
      "Epoch 1240, current patience 30, model mean validation loss 0.8678582906723022, embedding dim 2, hidden size 512, num layers 1, train loss 0.7576783895492554, validation loss 0.850498378276825\n",
      "Epoch 1250, current patience 30, model mean validation loss 0.8670889139175415, embedding dim 2, hidden size 512, num layers 1, train loss 0.6989312171936035, validation loss 0.8676208257675171\n",
      "Epoch 1260, current patience 30, model mean validation loss 0.8667052388191223, embedding dim 2, hidden size 512, num layers 1, train loss 0.7817357778549194, validation loss 0.8579638004302979\n",
      "Epoch 1270, current patience 30, model mean validation loss 0.8667581677436829, embedding dim 2, hidden size 512, num layers 1, train loss 0.6656123399734497, validation loss 0.8731486797332764\n",
      "Epoch 1280, current patience 29, model mean validation loss 0.8642308712005615, embedding dim 2, hidden size 512, num layers 1, train loss 0.5280426740646362, validation loss 0.8181945085525513\n",
      "Epoch 1290, current patience 30, model mean validation loss 0.861068844795227, embedding dim 2, hidden size 512, num layers 1, train loss 0.5952005386352539, validation loss 0.858273983001709\n",
      "Epoch 1300, current patience 30, model mean validation loss 0.8641948103904724, embedding dim 2, hidden size 512, num layers 1, train loss 0.5915709733963013, validation loss 0.8776901960372925\n",
      "Epoch 1310, current patience 29, model mean validation loss 0.8681325912475586, embedding dim 2, hidden size 512, num layers 1, train loss 0.540775716304779, validation loss 0.9416705965995789\n",
      "Epoch 1320, current patience 28, model mean validation loss 0.873233437538147, embedding dim 2, hidden size 512, num layers 1, train loss 0.5654939413070679, validation loss 0.8913050889968872\n",
      "Epoch 1330, current patience 27, model mean validation loss 0.8731981515884399, embedding dim 2, hidden size 512, num layers 1, train loss 0.5443284511566162, validation loss 0.8673388957977295\n",
      "Epoch 1340, current patience 26, model mean validation loss 0.8749611377716064, embedding dim 2, hidden size 512, num layers 1, train loss 0.6498156785964966, validation loss 0.872066855430603\n",
      "Epoch 1350, current patience 25, model mean validation loss 0.8817897439002991, embedding dim 2, hidden size 512, num layers 1, train loss 0.4801321029663086, validation loss 0.9277775883674622\n",
      "Epoch 1360, current patience 24, model mean validation loss 0.8905667066574097, embedding dim 2, hidden size 512, num layers 1, train loss 0.6537091732025146, validation loss 0.8884105682373047\n",
      "Epoch 1370, current patience 23, model mean validation loss 0.8913820385932922, embedding dim 2, hidden size 512, num layers 1, train loss 0.4472755491733551, validation loss 0.8647963404655457\n",
      "Epoch 1380, current patience 22, model mean validation loss 0.8887698650360107, embedding dim 2, hidden size 512, num layers 1, train loss 0.613266110420227, validation loss 0.8567931652069092\n",
      "Epoch 1390, current patience 21, model mean validation loss 0.8837563395500183, embedding dim 2, hidden size 512, num layers 1, train loss 0.43508344888687134, validation loss 0.9015623331069946\n",
      "Epoch 1400, current patience 20, model mean validation loss 0.8780378103256226, embedding dim 2, hidden size 512, num layers 1, train loss 0.4141523838043213, validation loss 0.8455570340156555\n",
      "Epoch 1410, current patience 19, model mean validation loss 0.879492998123169, embedding dim 2, hidden size 512, num layers 1, train loss 0.7645334005355835, validation loss 0.8789799809455872\n",
      "Epoch 1420, current patience 18, model mean validation loss 0.8824625015258789, embedding dim 2, hidden size 512, num layers 1, train loss 0.5278879404067993, validation loss 0.8958225250244141\n",
      "Epoch 1430, current patience 17, model mean validation loss 0.8774088621139526, embedding dim 2, hidden size 512, num layers 1, train loss 0.5294821858406067, validation loss 0.8873487710952759\n",
      "Epoch 1440, current patience 16, model mean validation loss 0.8780047297477722, embedding dim 2, hidden size 512, num layers 1, train loss 0.5220018029212952, validation loss 0.8931776881217957\n",
      "Epoch 1450, current patience 15, model mean validation loss 0.8860248327255249, embedding dim 2, hidden size 512, num layers 1, train loss 0.6091897487640381, validation loss 0.9289570450782776\n",
      "Epoch 1460, current patience 14, model mean validation loss 0.8912625312805176, embedding dim 2, hidden size 512, num layers 1, train loss 0.7281132936477661, validation loss 0.8986949920654297\n",
      "Epoch 1470, current patience 13, model mean validation loss 0.8935204744338989, embedding dim 2, hidden size 512, num layers 1, train loss 0.8990888595581055, validation loss 0.9196259379386902\n",
      "Epoch 1480, current patience 12, model mean validation loss 0.8934468030929565, embedding dim 2, hidden size 512, num layers 1, train loss 0.4525149464607239, validation loss 0.8449670076370239\n",
      "Epoch 1490, current patience 11, model mean validation loss 0.8888324499130249, embedding dim 2, hidden size 512, num layers 1, train loss 0.4845219552516937, validation loss 0.8420659303665161\n",
      "Epoch 1500, current patience 10, model mean validation loss 0.8905933499336243, embedding dim 2, hidden size 512, num layers 1, train loss 0.6352118253707886, validation loss 0.9099096059799194\n",
      "Epoch 1510, current patience 9, model mean validation loss 0.8888381719589233, embedding dim 2, hidden size 512, num layers 1, train loss 0.5583784580230713, validation loss 0.8733068704605103\n",
      "Epoch 1520, current patience 8, model mean validation loss 0.8881950378417969, embedding dim 2, hidden size 512, num layers 1, train loss 0.6225554943084717, validation loss 0.8880327939987183\n",
      "Epoch 1530, current patience 7, model mean validation loss 0.889244556427002, embedding dim 2, hidden size 512, num layers 1, train loss 0.5587794780731201, validation loss 0.937353253364563\n",
      "Epoch 1540, current patience 6, model mean validation loss 0.8944927453994751, embedding dim 2, hidden size 512, num layers 1, train loss 0.4376341700553894, validation loss 0.9406803846359253\n",
      "Epoch 1550, current patience 5, model mean validation loss 0.8950788974761963, embedding dim 2, hidden size 512, num layers 1, train loss 0.6176557540893555, validation loss 0.9243155717849731\n",
      "Epoch 1560, current patience 4, model mean validation loss 0.899604320526123, embedding dim 2, hidden size 512, num layers 1, train loss 0.5014122724533081, validation loss 0.8811705112457275\n",
      "Epoch 1570, current patience 3, model mean validation loss 0.9069826602935791, embedding dim 2, hidden size 512, num layers 1, train loss 0.4794614315032959, validation loss 0.9010922312736511\n",
      "Epoch 1580, current patience 2, model mean validation loss 0.9061529636383057, embedding dim 2, hidden size 512, num layers 1, train loss 0.5337868928909302, validation loss 0.9032719135284424\n",
      "Epoch 1590, current patience 1, model mean validation loss 0.9123287200927734, embedding dim 2, hidden size 512, num layers 1, train loss 0.4458853006362915, validation loss 0.9227134585380554\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2215253114700317, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1005749702453613, validation loss 1.2215253114700317\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1585218906402588, embedding dim 2, hidden size 1024, num layers 1, train loss 1.103231430053711, validation loss 1.0955185890197754\n",
      "Epoch 20, current patience 30, model mean validation loss 1.139094352722168, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1213269233703613, validation loss 1.1002393960952759\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1298713684082031, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0977262258529663, validation loss 1.1022021770477295\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1264514923095703, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0968377590179443, validation loss 1.112771987915039\n",
      "Epoch 50, current patience 30, model mean validation loss 1.121626377105713, embedding dim 2, hidden size 1024, num layers 1, train loss 1.098189353942871, validation loss 1.097501277923584\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1182425022125244, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0883115530014038, validation loss 1.0979390144348145\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1153810024261475, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0957813262939453, validation loss 1.0953506231307983\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0994417667388916, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0960512161254883, validation loss 1.0940113067626953\n",
      "Epoch 90, current patience 30, model mean validation loss 1.099531888961792, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1003425121307373, validation loss 1.0962390899658203\n",
      "Epoch 100, current patience 29, model mean validation loss 1.098543405532837, embedding dim 2, hidden size 1024, num layers 1, train loss 1.096224308013916, validation loss 1.0923320055007935\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0978357791900635, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0918896198272705, validation loss 1.096540927886963\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0956597328186035, embedding dim 2, hidden size 1024, num layers 1, train loss 1.104963779449463, validation loss 1.0953633785247803\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0954476594924927, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0934128761291504, validation loss 1.095805287361145\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0949009656906128, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0907254219055176, validation loss 1.0935651063919067\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0947136878967285, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0967038869857788, validation loss 1.0938529968261719\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0953441858291626, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1100231409072876, validation loss 1.0990549325942993\n",
      "Epoch 170, current patience 29, model mean validation loss 1.095332384109497, embedding dim 2, hidden size 1024, num layers 1, train loss 1.104367733001709, validation loss 1.096144676208496\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0959304571151733, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0846185684204102, validation loss 1.097116231918335\n",
      "Epoch 190, current patience 27, model mean validation loss 1.0959491729736328, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0954996347427368, validation loss 1.0966901779174805\n",
      "Epoch 200, current patience 26, model mean validation loss 1.095726490020752, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0905715227127075, validation loss 1.093583106994629\n",
      "Epoch 210, current patience 25, model mean validation loss 1.095888376235962, embedding dim 2, hidden size 1024, num layers 1, train loss 1.09844970703125, validation loss 1.0971002578735352\n",
      "Epoch 220, current patience 24, model mean validation loss 1.0960090160369873, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0886287689208984, validation loss 1.0945297479629517\n",
      "Epoch 230, current patience 23, model mean validation loss 1.0962209701538086, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0980958938598633, validation loss 1.095548152923584\n",
      "Epoch 240, current patience 22, model mean validation loss 1.095800757408142, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1047255992889404, validation loss 1.095693588256836\n",
      "Epoch 250, current patience 21, model mean validation loss 1.0957502126693726, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0885324478149414, validation loss 1.095740556716919\n",
      "Epoch 260, current patience 20, model mean validation loss 1.0955333709716797, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0971332788467407, validation loss 1.095381736755371\n",
      "Epoch 270, current patience 19, model mean validation loss 1.095725655555725, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0998692512512207, validation loss 1.0982283353805542\n",
      "Epoch 280, current patience 18, model mean validation loss 1.095779299736023, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0991153717041016, validation loss 1.0940120220184326\n",
      "Epoch 290, current patience 17, model mean validation loss 1.0956134796142578, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0975611209869385, validation loss 1.0957729816436768\n",
      "Epoch 300, current patience 16, model mean validation loss 1.0955350399017334, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0994583368301392, validation loss 1.093902826309204\n",
      "Epoch 310, current patience 15, model mean validation loss 1.0951378345489502, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0933462381362915, validation loss 1.0923707485198975\n",
      "Epoch 320, current patience 14, model mean validation loss 1.0950102806091309, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0891001224517822, validation loss 1.0946733951568604\n",
      "Epoch 330, current patience 13, model mean validation loss 1.095292091369629, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0948928594589233, validation loss 1.0979945659637451\n",
      "Epoch 340, current patience 12, model mean validation loss 1.0958542823791504, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0786528587341309, validation loss 1.099879503250122\n",
      "Epoch 350, current patience 11, model mean validation loss 1.0947368144989014, embedding dim 2, hidden size 1024, num layers 1, train loss 1.085766315460205, validation loss 1.0892884731292725\n",
      "Epoch 360, current patience 10, model mean validation loss 1.0952881574630737, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1051684617996216, validation loss 1.098422646522522\n",
      "Epoch 370, current patience 9, model mean validation loss 1.094893455505371, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1013745069503784, validation loss 1.0926158428192139\n",
      "Epoch 380, current patience 8, model mean validation loss 1.0950244665145874, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0964003801345825, validation loss 1.094950556755066\n",
      "Epoch 390, current patience 7, model mean validation loss 1.095097541809082, embedding dim 2, hidden size 1024, num layers 1, train loss 1.097183346748352, validation loss 1.092955231666565\n",
      "Epoch 400, current patience 6, model mean validation loss 1.0947977304458618, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1032204627990723, validation loss 1.0922749042510986\n",
      "Epoch 410, current patience 5, model mean validation loss 1.0946638584136963, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0686490535736084, validation loss 1.0969229936599731\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0942171812057495, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0922425985336304, validation loss 1.096306324005127\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0950604677200317, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0857475996017456, validation loss 1.0960348844528198\n",
      "Epoch 440, current patience 29, model mean validation loss 1.0944242477416992, embedding dim 2, hidden size 1024, num layers 1, train loss 1.108994483947754, validation loss 1.0933330059051514\n",
      "Epoch 450, current patience 28, model mean validation loss 1.09401273727417, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0795520544052124, validation loss 1.0893237590789795\n",
      "Epoch 460, current patience 30, model mean validation loss 1.092900276184082, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1025853157043457, validation loss 1.086051344871521\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0931237936019897, embedding dim 2, hidden size 1024, num layers 1, train loss 1.080183506011963, validation loss 1.0947431325912476\n",
      "Epoch 480, current patience 29, model mean validation loss 1.0937068462371826, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0840826034545898, validation loss 1.0969396829605103\n",
      "Epoch 490, current patience 28, model mean validation loss 1.0931342840194702, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0774253606796265, validation loss 1.0923421382904053\n",
      "Epoch 500, current patience 27, model mean validation loss 1.0944855213165283, embedding dim 2, hidden size 1024, num layers 1, train loss 1.102910041809082, validation loss 1.107116460800171\n",
      "Epoch 510, current patience 26, model mean validation loss 1.0948584079742432, embedding dim 2, hidden size 1024, num layers 1, train loss 1.108034372329712, validation loss 1.09901762008667\n",
      "Epoch 520, current patience 25, model mean validation loss 1.0956623554229736, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0940037965774536, validation loss 1.0997645854949951\n",
      "Epoch 530, current patience 24, model mean validation loss 1.096834421157837, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0640718936920166, validation loss 1.0987001657485962\n",
      "Epoch 540, current patience 23, model mean validation loss 1.0976049900054932, embedding dim 2, hidden size 1024, num layers 1, train loss 1.098466157913208, validation loss 1.092215895652771\n",
      "Epoch 550, current patience 22, model mean validation loss 1.0967051982879639, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0676398277282715, validation loss 1.087545394897461\n",
      "Epoch 560, current patience 21, model mean validation loss 1.0963890552520752, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0390279293060303, validation loss 1.0944105386734009\n",
      "Epoch 570, current patience 20, model mean validation loss 1.09604811668396, embedding dim 2, hidden size 1024, num layers 1, train loss 1.053809642791748, validation loss 1.0896140336990356\n",
      "Epoch 580, current patience 19, model mean validation loss 1.0938048362731934, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0815820693969727, validation loss 1.0891706943511963\n",
      "Epoch 590, current patience 18, model mean validation loss 1.0921173095703125, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0535073280334473, validation loss 1.0855172872543335\n",
      "Epoch 600, current patience 30, model mean validation loss 1.0914682149887085, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0591119527816772, validation loss 1.0945717096328735\n",
      "Epoch 610, current patience 30, model mean validation loss 1.0899078845977783, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0947933197021484, validation loss 1.0862174034118652\n",
      "Epoch 620, current patience 30, model mean validation loss 1.0874149799346924, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0380674600601196, validation loss 1.0722719430923462\n",
      "Epoch 630, current patience 30, model mean validation loss 1.0867778062820435, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0693573951721191, validation loss 1.0824484825134277\n",
      "Epoch 640, current patience 30, model mean validation loss 1.0843048095703125, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0261356830596924, validation loss 1.07462739944458\n",
      "Epoch 650, current patience 30, model mean validation loss 1.0796959400177002, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9665080904960632, validation loss 1.052742838859558\n",
      "Epoch 660, current patience 30, model mean validation loss 1.0728373527526855, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1015048027038574, validation loss 1.0343022346496582\n",
      "Epoch 670, current patience 30, model mean validation loss 1.0680797100067139, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9868573546409607, validation loss 1.0474557876586914\n",
      "Epoch 680, current patience 30, model mean validation loss 1.0574947595596313, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0645065307617188, validation loss 1.0098918676376343\n",
      "Epoch 690, current patience 30, model mean validation loss 1.0527629852294922, embedding dim 2, hidden size 1024, num layers 1, train loss 1.1028921604156494, validation loss 1.048363447189331\n",
      "Epoch 700, current patience 30, model mean validation loss 1.0458743572235107, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9467546939849854, validation loss 1.0171629190444946\n",
      "Epoch 710, current patience 30, model mean validation loss 1.0377585887908936, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0231417417526245, validation loss 1.017521858215332\n",
      "Epoch 720, current patience 30, model mean validation loss 1.0248310565948486, embedding dim 2, hidden size 1024, num layers 1, train loss 1.0960140228271484, validation loss 0.9712080955505371\n",
      "Epoch 730, current patience 30, model mean validation loss 1.01389479637146, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9359034299850464, validation loss 0.9652518630027771\n",
      "Epoch 740, current patience 30, model mean validation loss 1.0049033164978027, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9530355930328369, validation loss 0.9623705744743347\n",
      "Epoch 750, current patience 30, model mean validation loss 0.9998801946640015, embedding dim 2, hidden size 1024, num layers 1, train loss 0.940207839012146, validation loss 1.0072709321975708\n",
      "Epoch 760, current patience 30, model mean validation loss 0.993353009223938, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9274111986160278, validation loss 0.957674503326416\n",
      "Epoch 770, current patience 30, model mean validation loss 0.9825843572616577, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9099313020706177, validation loss 0.9622147679328918\n",
      "Epoch 780, current patience 30, model mean validation loss 0.9781363010406494, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9391433000564575, validation loss 0.9815783500671387\n",
      "Epoch 790, current patience 30, model mean validation loss 0.9721627831459045, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8574345111846924, validation loss 0.9697332382202148\n",
      "Epoch 800, current patience 30, model mean validation loss 0.9682610034942627, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9898526668548584, validation loss 0.9399937987327576\n",
      "Epoch 810, current patience 30, model mean validation loss 0.9645981192588806, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8643837571144104, validation loss 0.9359484910964966\n",
      "Epoch 820, current patience 30, model mean validation loss 0.963455080986023, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7767767906188965, validation loss 0.9532264471054077\n",
      "Epoch 830, current patience 30, model mean validation loss 0.9516719579696655, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7907459735870361, validation loss 0.9130058884620667\n",
      "Epoch 840, current patience 30, model mean validation loss 0.9432584643363953, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8941407203674316, validation loss 0.8903666734695435\n",
      "Epoch 850, current patience 30, model mean validation loss 0.9391607642173767, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7754790782928467, validation loss 0.9294331073760986\n",
      "Epoch 860, current patience 30, model mean validation loss 0.9355885982513428, embedding dim 2, hidden size 1024, num layers 1, train loss 0.887747049331665, validation loss 0.9530009627342224\n",
      "Epoch 870, current patience 30, model mean validation loss 0.9293663501739502, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7323379516601562, validation loss 0.9199554324150085\n",
      "Epoch 880, current patience 30, model mean validation loss 0.9223971962928772, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8607841730117798, validation loss 0.8842405676841736\n",
      "Epoch 890, current patience 30, model mean validation loss 0.916490912437439, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8974102735519409, validation loss 0.8886985778808594\n",
      "Epoch 900, current patience 30, model mean validation loss 0.9102234840393066, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7676913738250732, validation loss 0.9030864238739014\n",
      "Epoch 910, current patience 30, model mean validation loss 0.9061571955680847, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6989092230796814, validation loss 0.8804759383201599\n",
      "Epoch 920, current patience 30, model mean validation loss 0.9065684676170349, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8928877115249634, validation loss 0.893656849861145\n",
      "Epoch 930, current patience 29, model mean validation loss 0.8972294330596924, embedding dim 2, hidden size 1024, num layers 1, train loss 0.9368159770965576, validation loss 0.8547203540802002\n",
      "Epoch 940, current patience 30, model mean validation loss 0.8910297155380249, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7328266501426697, validation loss 0.9034038186073303\n",
      "Epoch 950, current patience 30, model mean validation loss 0.8895693421363831, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8583918213844299, validation loss 0.9082724452018738\n",
      "Epoch 960, current patience 30, model mean validation loss 0.8852026462554932, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7001726627349854, validation loss 0.8493071794509888\n",
      "Epoch 970, current patience 30, model mean validation loss 0.8826812505722046, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7975195646286011, validation loss 0.8685268759727478\n",
      "Epoch 980, current patience 30, model mean validation loss 0.8795738220214844, embedding dim 2, hidden size 1024, num layers 1, train loss 0.586723804473877, validation loss 0.8782268762588501\n",
      "Epoch 990, current patience 30, model mean validation loss 0.8793249130249023, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7455763220787048, validation loss 0.8784852027893066\n",
      "Epoch 1000, current patience 30, model mean validation loss 0.872833251953125, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7981715202331543, validation loss 0.8417233228683472\n",
      "Epoch 1010, current patience 30, model mean validation loss 0.872671365737915, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7536216378211975, validation loss 0.8534252643585205\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.8643414974212646, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5723972320556641, validation loss 0.8367648124694824\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.8537828922271729, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5705912113189697, validation loss 0.8238036632537842\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.8501667976379395, embedding dim 2, hidden size 1024, num layers 1, train loss 0.8367334604263306, validation loss 0.8203781843185425\n",
      "Epoch 1050, current patience 30, model mean validation loss 0.8468567132949829, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6862685680389404, validation loss 0.8420467376708984\n",
      "Epoch 1060, current patience 30, model mean validation loss 0.8405318260192871, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7524206638336182, validation loss 0.8276276588439941\n",
      "Epoch 1070, current patience 30, model mean validation loss 0.8350344300270081, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6771740317344666, validation loss 0.8345059156417847\n",
      "Epoch 1080, current patience 30, model mean validation loss 0.8402546644210815, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7384967803955078, validation loss 0.8834847211837769\n",
      "Epoch 1090, current patience 29, model mean validation loss 0.8410253524780273, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7373790740966797, validation loss 0.8595912456512451\n",
      "Epoch 1100, current patience 28, model mean validation loss 0.8464279770851135, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6528065204620361, validation loss 0.8799857497215271\n",
      "Epoch 1110, current patience 27, model mean validation loss 0.8531551361083984, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6933495998382568, validation loss 0.8776207566261292\n",
      "Epoch 1120, current patience 26, model mean validation loss 0.8575797080993652, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6233977675437927, validation loss 0.8557751178741455\n",
      "Epoch 1130, current patience 25, model mean validation loss 0.8564271330833435, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5905712842941284, validation loss 0.8328258991241455\n",
      "Epoch 1140, current patience 24, model mean validation loss 0.8574447631835938, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6521252393722534, validation loss 0.83576899766922\n",
      "Epoch 1150, current patience 23, model mean validation loss 0.8609589338302612, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6972407102584839, validation loss 0.8626194596290588\n",
      "Epoch 1160, current patience 22, model mean validation loss 0.8559486865997314, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6829442381858826, validation loss 0.8434019088745117\n",
      "Epoch 1170, current patience 21, model mean validation loss 0.8592625856399536, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7475168704986572, validation loss 0.8861026763916016\n",
      "Epoch 1180, current patience 20, model mean validation loss 0.8547450304031372, embedding dim 2, hidden size 1024, num layers 1, train loss 0.544182538986206, validation loss 0.8438449501991272\n",
      "Epoch 1190, current patience 19, model mean validation loss 0.8516882658004761, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6924806237220764, validation loss 0.8531670570373535\n",
      "Epoch 1200, current patience 18, model mean validation loss 0.8563242554664612, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6654320359230042, validation loss 0.8928632736206055\n",
      "Epoch 1210, current patience 17, model mean validation loss 0.8643403649330139, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5418405532836914, validation loss 0.8969545364379883\n",
      "Epoch 1220, current patience 16, model mean validation loss 0.8719992637634277, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5570001602172852, validation loss 0.897040069103241\n",
      "Epoch 1230, current patience 15, model mean validation loss 0.8764613270759583, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6263152360916138, validation loss 0.898316502571106\n",
      "Epoch 1240, current patience 14, model mean validation loss 0.8840229511260986, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7877851724624634, validation loss 0.903894305229187\n",
      "Epoch 1250, current patience 13, model mean validation loss 0.8841544389724731, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6455724239349365, validation loss 0.8871543407440186\n",
      "Epoch 1260, current patience 12, model mean validation loss 0.8875628113746643, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6688024401664734, validation loss 0.8711127042770386\n",
      "Epoch 1270, current patience 11, model mean validation loss 0.8852037787437439, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5479341745376587, validation loss 0.8342947363853455\n",
      "Epoch 1280, current patience 10, model mean validation loss 0.8783830404281616, embedding dim 2, hidden size 1024, num layers 1, train loss 0.4243044853210449, validation loss 0.8382970094680786\n",
      "Epoch 1290, current patience 9, model mean validation loss 0.8733095526695251, embedding dim 2, hidden size 1024, num layers 1, train loss 0.557424783706665, validation loss 0.856366753578186\n",
      "Epoch 1300, current patience 8, model mean validation loss 0.8769165277481079, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5319476127624512, validation loss 0.9258957505226135\n",
      "Epoch 1310, current patience 7, model mean validation loss 0.8816289305686951, embedding dim 2, hidden size 1024, num layers 1, train loss 0.4966524541378021, validation loss 0.9360157251358032\n",
      "Epoch 1320, current patience 6, model mean validation loss 0.8833708763122559, embedding dim 2, hidden size 1024, num layers 1, train loss 0.687936544418335, validation loss 0.9178298711776733\n",
      "Epoch 1330, current patience 5, model mean validation loss 0.8790621757507324, embedding dim 2, hidden size 1024, num layers 1, train loss 0.7977558970451355, validation loss 0.8526849746704102\n",
      "Epoch 1340, current patience 4, model mean validation loss 0.8715440034866333, embedding dim 2, hidden size 1024, num layers 1, train loss 0.5590361952781677, validation loss 0.8109672665596008\n",
      "Epoch 1350, current patience 3, model mean validation loss 0.8824020624160767, embedding dim 2, hidden size 1024, num layers 1, train loss 0.49037158489227295, validation loss 0.9211593866348267\n",
      "Epoch 1360, current patience 2, model mean validation loss 0.8885707259178162, embedding dim 2, hidden size 1024, num layers 1, train loss 0.6891961693763733, validation loss 0.8876457214355469\n",
      "Epoch 1370, current patience 1, model mean validation loss 0.8930243849754333, embedding dim 2, hidden size 1024, num layers 1, train loss 0.4534381031990051, validation loss 0.8919965028762817\n",
      "Epoch 0, current patience 30, model mean validation loss 1.3424506187438965, embedding dim 2, hidden size 2048, num layers 1, train loss 1.101351261138916, validation loss 1.3424506187438965\n",
      "Epoch 10, current patience 30, model mean validation loss 1.2499580383300781, embedding dim 2, hidden size 2048, num layers 1, train loss 1.320022463798523, validation loss 1.1574653387069702\n",
      "Epoch 20, current patience 30, model mean validation loss 1.2019003629684448, embedding dim 2, hidden size 2048, num layers 1, train loss 1.12095308303833, validation loss 1.1057850122451782\n",
      "Epoch 30, current patience 30, model mean validation loss 1.175570011138916, embedding dim 2, hidden size 2048, num layers 1, train loss 1.3237149715423584, validation loss 1.09657883644104\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1623455286026, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0827231407165527, validation loss 1.109447956085205\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1526542901992798, embedding dim 2, hidden size 2048, num layers 1, train loss 1.101975917816162, validation loss 1.1041979789733887\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1465617418289185, embedding dim 2, hidden size 2048, num layers 1, train loss 1.095444917678833, validation loss 1.110006332397461\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1495156288146973, embedding dim 2, hidden size 2048, num layers 1, train loss 1.124913215637207, validation loss 1.1701927185058594\n",
      "Epoch 80, current patience 29, model mean validation loss 1.1356720924377441, embedding dim 2, hidden size 2048, num layers 1, train loss 1.2609493732452393, validation loss 1.231702446937561\n",
      "Epoch 90, current patience 30, model mean validation loss 1.130210518836975, embedding dim 2, hidden size 2048, num layers 1, train loss 1.2093501091003418, validation loss 1.1137726306915283\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1278724670410156, embedding dim 2, hidden size 2048, num layers 1, train loss 1.127861738204956, validation loss 1.087080478668213\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1305346488952637, embedding dim 2, hidden size 2048, num layers 1, train loss 1.127676248550415, validation loss 1.1178760528564453\n",
      "Epoch 120, current patience 29, model mean validation loss 1.1293158531188965, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1809821128845215, validation loss 1.0996983051300049\n",
      "Epoch 130, current patience 28, model mean validation loss 1.1271603107452393, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0963406562805176, validation loss 1.0869529247283936\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1253808736801147, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1219043731689453, validation loss 1.0957711935043335\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1155550479888916, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0917906761169434, validation loss 1.0915858745574951\n",
      "Epoch 160, current patience 30, model mean validation loss 1.1029850244522095, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1537740230560303, validation loss 1.1311421394348145\n",
      "Epoch 170, current patience 30, model mean validation loss 1.1024614572525024, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0708427429199219, validation loss 1.1095843315124512\n",
      "Epoch 180, current patience 30, model mean validation loss 1.1045068502426147, embedding dim 2, hidden size 2048, num layers 1, train loss 1.116572618484497, validation loss 1.1034437417984009\n",
      "Epoch 190, current patience 29, model mean validation loss 1.1013585329055786, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1789302825927734, validation loss 1.0926895141601562\n",
      "Epoch 200, current patience 30, model mean validation loss 1.1152194738388062, embedding dim 2, hidden size 2048, num layers 1, train loss 1.119147539138794, validation loss 1.2105858325958252\n",
      "Epoch 210, current patience 29, model mean validation loss 1.116783857345581, embedding dim 2, hidden size 2048, num layers 1, train loss 1.197324514389038, validation loss 1.0994672775268555\n",
      "Epoch 220, current patience 28, model mean validation loss 1.1167256832122803, embedding dim 2, hidden size 2048, num layers 1, train loss 1.092076063156128, validation loss 1.095306158065796\n",
      "Epoch 230, current patience 27, model mean validation loss 1.1191325187683105, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0319856405258179, validation loss 1.1108416318893433\n",
      "Epoch 240, current patience 26, model mean validation loss 1.1163650751113892, embedding dim 2, hidden size 2048, num layers 1, train loss 1.097325325012207, validation loss 1.1090021133422852\n",
      "Epoch 250, current patience 25, model mean validation loss 1.124324083328247, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0667753219604492, validation loss 1.173256516456604\n",
      "Epoch 260, current patience 24, model mean validation loss 1.1217079162597656, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0767931938171387, validation loss 1.0825145244598389\n",
      "Epoch 270, current patience 23, model mean validation loss 1.1204705238342285, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1027019023895264, validation loss 1.0827906131744385\n",
      "Epoch 280, current patience 22, model mean validation loss 1.11676025390625, embedding dim 2, hidden size 2048, num layers 1, train loss 1.3473916053771973, validation loss 1.1809033155441284\n",
      "Epoch 290, current patience 21, model mean validation loss 1.1478053331375122, embedding dim 2, hidden size 2048, num layers 1, train loss 1.101672887802124, validation loss 1.3478277921676636\n",
      "Epoch 300, current patience 20, model mean validation loss 1.1448928117752075, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1246931552886963, validation loss 1.0720059871673584\n",
      "Epoch 310, current patience 19, model mean validation loss 1.1502768993377686, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0876659154891968, validation loss 1.1539138555526733\n",
      "Epoch 320, current patience 18, model mean validation loss 1.1589324474334717, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0518511533737183, validation loss 1.1782476902008057\n",
      "Epoch 330, current patience 17, model mean validation loss 1.1497185230255127, embedding dim 2, hidden size 2048, num layers 1, train loss 1.3147380352020264, validation loss 1.0995440483093262\n",
      "Epoch 340, current patience 16, model mean validation loss 1.1615219116210938, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0269169807434082, validation loss 1.1769421100616455\n",
      "Epoch 350, current patience 15, model mean validation loss 1.161346197128296, embedding dim 2, hidden size 2048, num layers 1, train loss 0.990789532661438, validation loss 1.0813848972320557\n",
      "Epoch 360, current patience 14, model mean validation loss 1.146207332611084, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1875033378601074, validation loss 1.0597925186157227\n",
      "Epoch 370, current patience 13, model mean validation loss 1.1086183786392212, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9996556043624878, validation loss 1.047115683555603\n",
      "Epoch 380, current patience 12, model mean validation loss 1.1126954555511475, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1011005640029907, validation loss 1.1046221256256104\n",
      "Epoch 390, current patience 11, model mean validation loss 1.1003201007843018, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0175530910491943, validation loss 1.054911732673645\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0836238861083984, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0532217025756836, validation loss 1.044677972793579\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0796034336090088, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0967234373092651, validation loss 1.0673807859420776\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0666451454162598, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0383678674697876, validation loss 1.073275089263916\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0718302726745605, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0083324909210205, validation loss 1.122865915298462\n",
      "Epoch 440, current patience 29, model mean validation loss 1.0799096822738647, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0921307802200317, validation loss 1.1244282722473145\n",
      "Epoch 450, current patience 28, model mean validation loss 1.0819282531738281, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9641449451446533, validation loss 1.0632641315460205\n",
      "Epoch 460, current patience 27, model mean validation loss 1.0786585807800293, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0232341289520264, validation loss 1.0784645080566406\n",
      "Epoch 470, current patience 26, model mean validation loss 1.0782887935638428, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9514420628547668, validation loss 1.0519541501998901\n",
      "Epoch 480, current patience 25, model mean validation loss 1.078279733657837, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1525518894195557, validation loss 1.0446057319641113\n",
      "Epoch 490, current patience 24, model mean validation loss 1.0760117769241333, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0081820487976074, validation loss 1.0492366552352905\n",
      "Epoch 500, current patience 23, model mean validation loss 1.0710701942443848, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0280545949935913, validation loss 1.0337424278259277\n",
      "Epoch 510, current patience 22, model mean validation loss 1.0602731704711914, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0487830638885498, validation loss 1.0364902019500732\n",
      "Epoch 520, current patience 30, model mean validation loss 1.0533441305160522, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0509154796600342, validation loss 1.068995714187622\n",
      "Epoch 530, current patience 30, model mean validation loss 1.0478196144104004, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9914116859436035, validation loss 1.0190672874450684\n",
      "Epoch 540, current patience 30, model mean validation loss 1.0438660383224487, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9922224879264832, validation loss 1.0468361377716064\n",
      "Epoch 550, current patience 30, model mean validation loss 1.0431513786315918, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0132057666778564, validation loss 1.046236515045166\n",
      "Epoch 560, current patience 30, model mean validation loss 1.0448194742202759, embedding dim 2, hidden size 2048, num layers 1, train loss 1.071685791015625, validation loss 1.057950496673584\n",
      "Epoch 570, current patience 29, model mean validation loss 1.0437952280044556, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0640084743499756, validation loss 1.0410430431365967\n",
      "Epoch 580, current patience 28, model mean validation loss 1.0479626655578613, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9287369251251221, validation loss 1.0670816898345947\n",
      "Epoch 590, current patience 27, model mean validation loss 1.1809279918670654, embedding dim 2, hidden size 2048, num layers 1, train loss 1.8404173851013184, validation loss 2.1002135276794434\n",
      "Epoch 600, current patience 26, model mean validation loss 1.1966397762298584, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1136069297790527, validation loss 1.1946892738342285\n",
      "Epoch 610, current patience 25, model mean validation loss 1.2635321617126465, embedding dim 2, hidden size 2048, num layers 1, train loss 1.212386965751648, validation loss 1.554206132888794\n",
      "Epoch 620, current patience 24, model mean validation loss 1.2868632078170776, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0182945728302002, validation loss 1.2334849834442139\n",
      "Epoch 630, current patience 23, model mean validation loss 1.3173348903656006, embedding dim 2, hidden size 2048, num layers 1, train loss 1.5281375646591187, validation loss 1.2900094985961914\n",
      "Epoch 640, current patience 22, model mean validation loss 1.3443701267242432, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1354964971542358, validation loss 1.2742328643798828\n",
      "Epoch 650, current patience 21, model mean validation loss 1.3777778148651123, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1765789985656738, validation loss 1.308304786682129\n",
      "Epoch 660, current patience 20, model mean validation loss 1.3796617984771729, embedding dim 2, hidden size 2048, num layers 1, train loss 1.2208545207977295, validation loss 1.0821536779403687\n",
      "Epoch 670, current patience 19, model mean validation loss 1.2572786808013916, embedding dim 2, hidden size 2048, num layers 1, train loss 1.2778044939041138, validation loss 1.1211479902267456\n",
      "Epoch 680, current patience 18, model mean validation loss 1.2513108253479004, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9374581575393677, validation loss 1.146946668624878\n",
      "Epoch 690, current patience 17, model mean validation loss 1.1977076530456543, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0331445932388306, validation loss 1.125380516052246\n",
      "Epoch 700, current patience 16, model mean validation loss 1.173949122428894, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9492490887641907, validation loss 1.0434165000915527\n",
      "Epoch 710, current patience 15, model mean validation loss 1.1418054103851318, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9390934705734253, validation loss 1.0328601598739624\n",
      "Epoch 720, current patience 14, model mean validation loss 1.1126837730407715, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9441202878952026, validation loss 1.0412596464157104\n",
      "Epoch 730, current patience 13, model mean validation loss 1.0789542198181152, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0301774740219116, validation loss 1.038468360900879\n",
      "Epoch 740, current patience 12, model mean validation loss 1.1101043224334717, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9858406782150269, validation loss 1.3313546180725098\n",
      "Epoch 750, current patience 11, model mean validation loss 1.101860761642456, embedding dim 2, hidden size 2048, num layers 1, train loss 1.1255314350128174, validation loss 1.055199384689331\n",
      "Epoch 760, current patience 10, model mean validation loss 1.0869779586791992, embedding dim 2, hidden size 2048, num layers 1, train loss 0.987419068813324, validation loss 1.0278841257095337\n",
      "Epoch 770, current patience 9, model mean validation loss 1.0875825881958008, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9868273735046387, validation loss 1.1302177906036377\n",
      "Epoch 780, current patience 8, model mean validation loss 1.0923757553100586, embedding dim 2, hidden size 2048, num layers 1, train loss 1.18618643283844, validation loss 1.081761360168457\n",
      "Epoch 790, current patience 7, model mean validation loss 1.0921268463134766, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9338239431381226, validation loss 1.030869722366333\n",
      "Epoch 800, current patience 6, model mean validation loss 1.0889594554901123, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9289774894714355, validation loss 1.0159204006195068\n",
      "Epoch 810, current patience 5, model mean validation loss 1.087956428527832, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9992537498474121, validation loss 1.0304445028305054\n",
      "Epoch 820, current patience 4, model mean validation loss 1.0535306930541992, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9730641841888428, validation loss 1.0559487342834473\n",
      "Epoch 830, current patience 3, model mean validation loss 1.046339511871338, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9297051429748535, validation loss 0.9976696968078613\n",
      "Epoch 840, current patience 2, model mean validation loss 1.043747901916504, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9038522839546204, validation loss 1.0071502923965454\n",
      "Epoch 850, current patience 1, model mean validation loss 1.0305734872817993, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8472480773925781, validation loss 1.024823546409607\n",
      "Epoch 860, current patience 30, model mean validation loss 1.021405816078186, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9066787958145142, validation loss 1.008419394493103\n",
      "Epoch 870, current patience 30, model mean validation loss 1.0136187076568604, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8318452835083008, validation loss 0.9685736298561096\n",
      "Epoch 880, current patience 30, model mean validation loss 1.0133028030395508, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9207626581192017, validation loss 1.0133925676345825\n",
      "Epoch 890, current patience 30, model mean validation loss 1.0144063234329224, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8711273670196533, validation loss 1.0392730236053467\n",
      "Epoch 900, current patience 29, model mean validation loss 1.004894733428955, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8270379900932312, validation loss 0.9798561334609985\n",
      "Epoch 910, current patience 30, model mean validation loss 1.010169506072998, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8197342157363892, validation loss 1.0398671627044678\n",
      "Epoch 920, current patience 29, model mean validation loss 1.007934331893921, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9225723743438721, validation loss 0.9892686605453491\n",
      "Epoch 930, current patience 28, model mean validation loss 1.0053036212921143, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8104082345962524, validation loss 1.0037790536880493\n",
      "Epoch 940, current patience 27, model mean validation loss 1.0018281936645508, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8935436010360718, validation loss 0.9806150197982788\n",
      "Epoch 950, current patience 30, model mean validation loss 1.006998062133789, embedding dim 2, hidden size 2048, num layers 1, train loss 0.799863338470459, validation loss 1.0099327564239502\n",
      "Epoch 960, current patience 29, model mean validation loss 1.0039476156234741, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8900916576385498, validation loss 0.9889891147613525\n",
      "Epoch 970, current patience 28, model mean validation loss 0.9966133832931519, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9781573414802551, validation loss 0.9805995225906372\n",
      "Epoch 980, current patience 30, model mean validation loss 0.996341347694397, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7439893484115601, validation loss 0.9776799082756042\n",
      "Epoch 990, current patience 30, model mean validation loss 0.9937541484832764, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6599013209342957, validation loss 1.0191693305969238\n",
      "Epoch 1000, current patience 30, model mean validation loss 0.9948602914810181, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8060006499290466, validation loss 0.9981176853179932\n",
      "Epoch 1010, current patience 29, model mean validation loss 0.9919149279594421, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9194420576095581, validation loss 0.980216383934021\n",
      "Epoch 1020, current patience 30, model mean validation loss 0.9908689856529236, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8477043509483337, validation loss 0.9722474217414856\n",
      "Epoch 1030, current patience 30, model mean validation loss 0.9899534583091736, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9129340648651123, validation loss 1.002608299255371\n",
      "Epoch 1040, current patience 30, model mean validation loss 0.9967130422592163, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8748836517333984, validation loss 1.0430655479431152\n",
      "Epoch 1050, current patience 29, model mean validation loss 1.0159265995025635, embedding dim 2, hidden size 2048, num layers 1, train loss 0.794560432434082, validation loss 1.1343090534210205\n",
      "Epoch 1060, current patience 28, model mean validation loss 1.0226269960403442, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8332688808441162, validation loss 1.031282663345337\n",
      "Epoch 1070, current patience 27, model mean validation loss 1.0236139297485352, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8165398836135864, validation loss 1.0270650386810303\n",
      "Epoch 1080, current patience 26, model mean validation loss 1.0313565731048584, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8749001622200012, validation loss 1.0600581169128418\n",
      "Epoch 1090, current patience 25, model mean validation loss 1.0354851484298706, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9440027475357056, validation loss 1.0132454633712769\n",
      "Epoch 1100, current patience 24, model mean validation loss 1.038938045501709, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9233560562133789, validation loss 0.9998700022697449\n",
      "Epoch 1110, current patience 23, model mean validation loss 1.035508155822754, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8065853714942932, validation loss 0.9751690626144409\n",
      "Epoch 1120, current patience 22, model mean validation loss 1.0274333953857422, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6939724087715149, validation loss 0.9784675240516663\n",
      "Epoch 1130, current patience 21, model mean validation loss 1.0116088390350342, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8056812286376953, validation loss 1.0077126026153564\n",
      "Epoch 1140, current patience 20, model mean validation loss 1.0050346851348877, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7983841896057129, validation loss 0.9786901473999023\n",
      "Epoch 1150, current patience 19, model mean validation loss 1.0020416975021362, embedding dim 2, hidden size 2048, num layers 1, train loss 0.903052806854248, validation loss 1.0031208992004395\n",
      "Epoch 1160, current patience 18, model mean validation loss 0.992061972618103, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8366674184799194, validation loss 0.9802199602127075\n",
      "Epoch 1170, current patience 17, model mean validation loss 0.9913837909698486, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8651976585388184, validation loss 1.007819652557373\n",
      "Epoch 1180, current patience 16, model mean validation loss 0.9880117177963257, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8982834219932556, validation loss 0.9728939533233643\n",
      "Epoch 1190, current patience 30, model mean validation loss 0.9923591613769531, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7784639596939087, validation loss 1.0099480152130127\n",
      "Epoch 1200, current patience 29, model mean validation loss 0.9905280470848083, embedding dim 2, hidden size 2048, num layers 1, train loss 0.728420615196228, validation loss 0.9638189077377319\n",
      "Epoch 1210, current patience 28, model mean validation loss 0.99506676197052, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6023809313774109, validation loss 1.0440223217010498\n",
      "Epoch 1220, current patience 27, model mean validation loss 1.015489935874939, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7623728513717651, validation loss 1.142075538635254\n",
      "Epoch 1230, current patience 26, model mean validation loss 1.021672010421753, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9174225330352783, validation loss 1.0525777339935303\n",
      "Epoch 1240, current patience 25, model mean validation loss 1.0313551425933838, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7549737691879272, validation loss 1.0576844215393066\n",
      "Epoch 1250, current patience 24, model mean validation loss 1.0274295806884766, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7434357404708862, validation loss 0.9764161109924316\n",
      "Epoch 1260, current patience 23, model mean validation loss 1.022796630859375, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6229839324951172, validation loss 0.9358295798301697\n",
      "Epoch 1270, current patience 22, model mean validation loss 1.0198849439620972, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9029849767684937, validation loss 0.9866548776626587\n",
      "Epoch 1280, current patience 21, model mean validation loss 1.0187996625900269, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6993964314460754, validation loss 0.9551362991333008\n",
      "Epoch 1290, current patience 20, model mean validation loss 1.0114696025848389, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7568292021751404, validation loss 0.9853819608688354\n",
      "Epoch 1300, current patience 19, model mean validation loss 0.9919402599334717, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8038391470909119, validation loss 0.985840916633606\n",
      "Epoch 1310, current patience 18, model mean validation loss 0.9911390542984009, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8796519041061401, validation loss 1.046168327331543\n",
      "Epoch 1320, current patience 17, model mean validation loss 0.986003041267395, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7732546329498291, validation loss 1.0165960788726807\n",
      "Epoch 1330, current patience 30, model mean validation loss 0.9869064092636108, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8759571313858032, validation loss 0.9836434721946716\n",
      "Epoch 1340, current patience 29, model mean validation loss 1.0092480182647705, embedding dim 2, hidden size 2048, num layers 1, train loss 0.757609486579895, validation loss 1.1145625114440918\n",
      "Epoch 1350, current patience 28, model mean validation loss 1.0067709684371948, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7687077522277832, validation loss 0.966838538646698\n",
      "Epoch 1360, current patience 27, model mean validation loss 1.013975977897644, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6555199027061462, validation loss 1.0127758979797363\n",
      "Epoch 1370, current patience 26, model mean validation loss 1.0194246768951416, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8007175922393799, validation loss 1.0289719104766846\n",
      "Epoch 1380, current patience 25, model mean validation loss 1.0220667123794556, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7573632001876831, validation loss 1.0069764852523804\n",
      "Epoch 1390, current patience 24, model mean validation loss 1.0497043132781982, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7564043402671814, validation loss 1.2672690153121948\n",
      "Epoch 1400, current patience 23, model mean validation loss 1.049070119857788, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6851296424865723, validation loss 1.0115232467651367\n",
      "Epoch 1410, current patience 22, model mean validation loss 1.0524848699569702, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7120488286018372, validation loss 1.0109612941741943\n",
      "Epoch 1420, current patience 21, model mean validation loss 1.0493156909942627, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0343912839889526, validation loss 1.0892088413238525\n",
      "Epoch 1430, current patience 20, model mean validation loss 1.0562165975570679, embedding dim 2, hidden size 2048, num layers 1, train loss 0.9227708578109741, validation loss 1.0220463275909424\n",
      "Epoch 1440, current patience 19, model mean validation loss 1.0544830560684204, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6757698059082031, validation loss 0.9989078044891357\n",
      "Epoch 1450, current patience 18, model mean validation loss 1.0497568845748901, embedding dim 2, hidden size 2048, num layers 1, train loss 0.730950117111206, validation loss 0.9911626577377319\n",
      "Epoch 1460, current patience 17, model mean validation loss 1.0473309755325317, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8026045560836792, validation loss 0.9875683784484863\n",
      "Epoch 1470, current patience 16, model mean validation loss 1.0189898014068604, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7426517009735107, validation loss 1.040540099143982\n",
      "Epoch 1480, current patience 15, model mean validation loss 1.0110265016555786, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7606600522994995, validation loss 0.9478162527084351\n",
      "Epoch 1490, current patience 14, model mean validation loss 1.0111863613128662, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6907182931900024, validation loss 1.0122407674789429\n",
      "Epoch 1500, current patience 13, model mean validation loss 0.9981889724731445, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7164695262908936, validation loss 0.9852298498153687\n",
      "Epoch 1510, current patience 12, model mean validation loss 0.9899051189422607, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6787993907928467, validation loss 0.9557750821113586\n",
      "Epoch 1520, current patience 11, model mean validation loss 0.9907109141349792, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6980682611465454, validation loss 1.0053540468215942\n",
      "Epoch 1530, current patience 10, model mean validation loss 0.9876248836517334, embedding dim 2, hidden size 2048, num layers 1, train loss 0.791117250919342, validation loss 0.9664747714996338\n",
      "Epoch 1540, current patience 9, model mean validation loss 0.986952543258667, embedding dim 2, hidden size 2048, num layers 1, train loss 0.794540524482727, validation loss 0.9821892976760864\n",
      "Epoch 1550, current patience 8, model mean validation loss 0.9858100414276123, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7530497312545776, validation loss 1.031400442123413\n",
      "Epoch 1560, current patience 30, model mean validation loss 0.9889467358589172, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8513301610946655, validation loss 0.972909688949585\n",
      "Epoch 1570, current patience 29, model mean validation loss 0.980430006980896, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6495485305786133, validation loss 0.9441071152687073\n",
      "Epoch 1580, current patience 30, model mean validation loss 0.9810776114463806, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8116104602813721, validation loss 0.9904100894927979\n",
      "Epoch 1590, current patience 29, model mean validation loss 0.9761281609535217, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7994989156723022, validation loss 0.916179895401001\n",
      "Epoch 1600, current patience 30, model mean validation loss 0.980847179889679, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6126410961151123, validation loss 1.0431064367294312\n",
      "Epoch 1610, current patience 29, model mean validation loss 0.9975116848945618, embedding dim 2, hidden size 2048, num layers 1, train loss 0.5562402009963989, validation loss 1.0997905731201172\n",
      "Epoch 1620, current patience 28, model mean validation loss 0.9946846961975098, embedding dim 2, hidden size 2048, num layers 1, train loss 0.792436420917511, validation loss 0.9595734477043152\n",
      "Epoch 1630, current patience 27, model mean validation loss 0.9963135719299316, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8253552913665771, validation loss 1.0444315671920776\n",
      "Epoch 1640, current patience 26, model mean validation loss 1.0008002519607544, embedding dim 2, hidden size 2048, num layers 1, train loss 0.5669375658035278, validation loss 1.008802890777588\n",
      "Epoch 1650, current patience 25, model mean validation loss 1.0042004585266113, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7807341814041138, validation loss 0.971308171749115\n",
      "Epoch 1660, current patience 24, model mean validation loss 1.0053629875183105, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6543062925338745, validation loss 0.9997113943099976\n",
      "Epoch 1670, current patience 23, model mean validation loss 1.023993968963623, embedding dim 2, hidden size 2048, num layers 1, train loss 0.837781548500061, validation loss 1.065227746963501\n",
      "Epoch 1680, current patience 22, model mean validation loss 1.0170782804489136, embedding dim 2, hidden size 2048, num layers 1, train loss 0.622879147529602, validation loss 0.9877806901931763\n",
      "Epoch 1690, current patience 21, model mean validation loss 0.9985224008560181, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8183773159980774, validation loss 0.9513437747955322\n",
      "Epoch 1700, current patience 20, model mean validation loss 1.002583384513855, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6291722655296326, validation loss 0.9920610785484314\n",
      "Epoch 1710, current patience 19, model mean validation loss 0.9987239837646484, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6728876233100891, validation loss 1.0135562419891357\n",
      "Epoch 1720, current patience 18, model mean validation loss 0.9924616813659668, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8179681301116943, validation loss 0.9587043523788452\n",
      "Epoch 1730, current patience 17, model mean validation loss 0.9965438842773438, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6772773265838623, validation loss 1.0039653778076172\n",
      "Epoch 1740, current patience 16, model mean validation loss 0.9941719174385071, embedding dim 2, hidden size 2048, num layers 1, train loss 1.0153294801712036, validation loss 0.9807358384132385\n",
      "Epoch 1750, current patience 15, model mean validation loss 0.9908055663108826, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6867155432701111, validation loss 1.038297414779663\n",
      "Epoch 1760, current patience 14, model mean validation loss 0.9866194128990173, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6708749532699585, validation loss 0.954291582107544\n",
      "Epoch 1770, current patience 13, model mean validation loss 1.001456618309021, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7152323722839355, validation loss 1.0700411796569824\n",
      "Epoch 1780, current patience 12, model mean validation loss 0.9949324727058411, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7357140183448792, validation loss 0.9398678541183472\n",
      "Epoch 1790, current patience 11, model mean validation loss 1.0194605588912964, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7375271916389465, validation loss 1.2097809314727783\n",
      "Epoch 1800, current patience 10, model mean validation loss 1.0544227361679077, embedding dim 2, hidden size 2048, num layers 1, train loss 0.5810418128967285, validation loss 1.2384014129638672\n",
      "Epoch 1810, current patience 9, model mean validation loss 1.0690758228302002, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7045643329620361, validation loss 1.1211910247802734\n",
      "Epoch 1820, current patience 8, model mean validation loss 1.068418264389038, embedding dim 2, hidden size 2048, num layers 1, train loss 0.626057505607605, validation loss 0.975475013256073\n",
      "Epoch 1830, current patience 7, model mean validation loss 1.0633891820907593, embedding dim 2, hidden size 2048, num layers 1, train loss 0.5975446701049805, validation loss 0.9980640411376953\n",
      "Epoch 1840, current patience 6, model mean validation loss 1.0670629739761353, embedding dim 2, hidden size 2048, num layers 1, train loss 0.5814979672431946, validation loss 0.9836826324462891\n",
      "Epoch 1850, current patience 5, model mean validation loss 1.0544236898422241, embedding dim 2, hidden size 2048, num layers 1, train loss 0.8001372814178467, validation loss 0.968926191329956\n",
      "Epoch 1860, current patience 4, model mean validation loss 1.0569180250167847, embedding dim 2, hidden size 2048, num layers 1, train loss 0.7665858268737793, validation loss 0.9598228931427002\n",
      "Epoch 1870, current patience 3, model mean validation loss 1.0315146446228027, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6140620708465576, validation loss 1.006553292274475\n",
      "Epoch 1880, current patience 2, model mean validation loss 0.9981507658958435, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6394610404968262, validation loss 0.971490740776062\n",
      "Epoch 1890, current patience 1, model mean validation loss 0.988163948059082, embedding dim 2, hidden size 2048, num layers 1, train loss 0.6225665211677551, validation loss 1.0412969589233398\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1254620552062988, embedding dim 4, hidden size 1, num layers 1, train loss 1.113507866859436, validation loss 1.1254620552062988\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1208066940307617, embedding dim 4, hidden size 1, num layers 1, train loss 1.1091821193695068, validation loss 1.116151213645935\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1156905889511108, embedding dim 4, hidden size 1, num layers 1, train loss 1.0988900661468506, validation loss 1.10545814037323\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1085971593856812, embedding dim 4, hidden size 1, num layers 1, train loss 1.0860331058502197, validation loss 1.087316870689392\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1052818298339844, embedding dim 4, hidden size 1, num layers 1, train loss 1.090563178062439, validation loss 1.0920203924179077\n",
      "Epoch 50, current patience 30, model mean validation loss 1.103853702545166, embedding dim 4, hidden size 1, num layers 1, train loss 1.0949780941009521, validation loss 1.0967134237289429\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1025359630584717, embedding dim 4, hidden size 1, num layers 1, train loss 1.0948861837387085, validation loss 1.0946288108825684\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1013953685760498, embedding dim 4, hidden size 1, num layers 1, train loss 1.1079216003417969, validation loss 1.093412160873413\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0971912145614624, embedding dim 4, hidden size 1, num layers 1, train loss 1.099778413772583, validation loss 1.0918288230895996\n",
      "Epoch 90, current patience 30, model mean validation loss 1.094196081161499, embedding dim 4, hidden size 1, num layers 1, train loss 1.097910761833191, validation loss 1.0921903848648071\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0927468538284302, embedding dim 4, hidden size 1, num layers 1, train loss 1.0988914966583252, validation loss 1.0938637256622314\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0930579900741577, embedding dim 4, hidden size 1, num layers 1, train loss 1.1007816791534424, validation loss 1.0898059606552124\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0942018032073975, embedding dim 4, hidden size 1, num layers 1, train loss 1.0863358974456787, validation loss 1.1011714935302734\n",
      "Epoch 130, current patience 28, model mean validation loss 1.093910574913025, embedding dim 4, hidden size 1, num layers 1, train loss 1.0779173374176025, validation loss 1.0943830013275146\n",
      "Epoch 140, current patience 27, model mean validation loss 1.0935100317001343, embedding dim 4, hidden size 1, num layers 1, train loss 1.0757287740707397, validation loss 1.091424584388733\n",
      "Epoch 150, current patience 26, model mean validation loss 1.0926947593688965, embedding dim 4, hidden size 1, num layers 1, train loss 1.1059849262237549, validation loss 1.0868899822235107\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0919671058654785, embedding dim 4, hidden size 1, num layers 1, train loss 1.0908019542694092, validation loss 1.0860077142715454\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0917854309082031, embedding dim 4, hidden size 1, num layers 1, train loss 1.0948584079742432, validation loss 1.0907371044158936\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0908716917037964, embedding dim 4, hidden size 1, num layers 1, train loss 1.0784037113189697, validation loss 1.0865541696548462\n",
      "Epoch 190, current patience 30, model mean validation loss 1.090062141418457, embedding dim 4, hidden size 1, num layers 1, train loss 1.0970451831817627, validation loss 1.0833297967910767\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0879309177398682, embedding dim 4, hidden size 1, num layers 1, train loss 1.0954999923706055, validation loss 1.0841201543807983\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0866435766220093, embedding dim 4, hidden size 1, num layers 1, train loss 1.062150001525879, validation loss 1.0840846300125122\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0851821899414062, embedding dim 4, hidden size 1, num layers 1, train loss 1.0739502906799316, validation loss 1.07973313331604\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0841162204742432, embedding dim 4, hidden size 1, num layers 1, train loss 1.0515201091766357, validation loss 1.0783627033233643\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0819379091262817, embedding dim 4, hidden size 1, num layers 1, train loss 1.0854299068450928, validation loss 1.0685811042785645\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0804404020309448, embedding dim 4, hidden size 1, num layers 1, train loss 1.0286542177200317, validation loss 1.0787572860717773\n",
      "Epoch 260, current patience 30, model mean validation loss 1.078258991241455, embedding dim 4, hidden size 1, num layers 1, train loss 1.062505841255188, validation loss 1.0691032409667969\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0764813423156738, embedding dim 4, hidden size 1, num layers 1, train loss 1.079741358757019, validation loss 1.0691092014312744\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0745079517364502, embedding dim 4, hidden size 1, num layers 1, train loss 1.0565431118011475, validation loss 1.0683321952819824\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0723299980163574, embedding dim 4, hidden size 1, num layers 1, train loss 1.040877342224121, validation loss 1.0666611194610596\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0689637660980225, embedding dim 4, hidden size 1, num layers 1, train loss 1.077744722366333, validation loss 1.05280339717865\n",
      "Epoch 310, current patience 30, model mean validation loss 1.064843773841858, embedding dim 4, hidden size 1, num layers 1, train loss 1.0662884712219238, validation loss 1.0454026460647583\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0627270936965942, embedding dim 4, hidden size 1, num layers 1, train loss 1.03544020652771, validation loss 1.0516469478607178\n",
      "Epoch 330, current patience 30, model mean validation loss 1.059791922569275, embedding dim 4, hidden size 1, num layers 1, train loss 1.0520391464233398, validation loss 1.05527663230896\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0567691326141357, embedding dim 4, hidden size 1, num layers 1, train loss 1.0091993808746338, validation loss 1.0449203252792358\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0524736642837524, embedding dim 4, hidden size 1, num layers 1, train loss 0.993505597114563, validation loss 1.0347462892532349\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0482354164123535, embedding dim 4, hidden size 1, num layers 1, train loss 1.0497968196868896, validation loss 1.0344257354736328\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0435625314712524, embedding dim 4, hidden size 1, num layers 1, train loss 0.9989583492279053, validation loss 1.0292781591415405\n",
      "Epoch 380, current patience 30, model mean validation loss 1.040376901626587, embedding dim 4, hidden size 1, num layers 1, train loss 0.9532966017723083, validation loss 1.0273182392120361\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0358822345733643, embedding dim 4, hidden size 1, num layers 1, train loss 0.9638704061508179, validation loss 1.0094449520111084\n",
      "Epoch 400, current patience 30, model mean validation loss 1.029308557510376, embedding dim 4, hidden size 1, num layers 1, train loss 0.9421135187149048, validation loss 0.9990578889846802\n",
      "Epoch 410, current patience 30, model mean validation loss 1.021643877029419, embedding dim 4, hidden size 1, num layers 1, train loss 0.940230131149292, validation loss 0.9939600825309753\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0148720741271973, embedding dim 4, hidden size 1, num layers 1, train loss 0.9829933047294617, validation loss 0.990745484828949\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0086262226104736, embedding dim 4, hidden size 1, num layers 1, train loss 0.8948084115982056, validation loss 0.9847794771194458\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9997550249099731, embedding dim 4, hidden size 1, num layers 1, train loss 1.0185037851333618, validation loss 0.9634557962417603\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9930179119110107, embedding dim 4, hidden size 1, num layers 1, train loss 1.0163915157318115, validation loss 0.9753811359405518\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9851133823394775, embedding dim 4, hidden size 1, num layers 1, train loss 0.8544723391532898, validation loss 0.9640822410583496\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9784870743751526, embedding dim 4, hidden size 1, num layers 1, train loss 0.8785552978515625, validation loss 0.9564344882965088\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9706206321716309, embedding dim 4, hidden size 1, num layers 1, train loss 0.8947252035140991, validation loss 0.9361263513565063\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9643456339836121, embedding dim 4, hidden size 1, num layers 1, train loss 0.941696286201477, validation loss 0.9437600374221802\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9569399952888489, embedding dim 4, hidden size 1, num layers 1, train loss 0.9187242984771729, validation loss 0.9315004348754883\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9505162835121155, embedding dim 4, hidden size 1, num layers 1, train loss 0.9131174087524414, validation loss 0.9333898425102234\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9459487199783325, embedding dim 4, hidden size 1, num layers 1, train loss 0.857491135597229, validation loss 0.9269150495529175\n",
      "Epoch 530, current patience 30, model mean validation loss 0.939865231513977, embedding dim 4, hidden size 1, num layers 1, train loss 0.9287540912628174, validation loss 0.9267132878303528\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9349172115325928, embedding dim 4, hidden size 1, num layers 1, train loss 0.8168696165084839, validation loss 0.9244979619979858\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9299209117889404, embedding dim 4, hidden size 1, num layers 1, train loss 0.8323677778244019, validation loss 0.9164639711380005\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9281215667724609, embedding dim 4, hidden size 1, num layers 1, train loss 0.7784242630004883, validation loss 0.9217320084571838\n",
      "Epoch 570, current patience 30, model mean validation loss 0.924750030040741, embedding dim 4, hidden size 1, num layers 1, train loss 0.814385175704956, validation loss 0.9167877435684204\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9235949516296387, embedding dim 4, hidden size 1, num layers 1, train loss 0.8077915906906128, validation loss 0.922260046005249\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9201095104217529, embedding dim 4, hidden size 1, num layers 1, train loss 0.8293718695640564, validation loss 0.9055057168006897\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9178924560546875, embedding dim 4, hidden size 1, num layers 1, train loss 0.8531538248062134, validation loss 0.9091789722442627\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9171305298805237, embedding dim 4, hidden size 1, num layers 1, train loss 0.8652523756027222, validation loss 0.9206178188323975\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9144486784934998, embedding dim 4, hidden size 1, num layers 1, train loss 0.8632171154022217, validation loss 0.9030430316925049\n",
      "Epoch 630, current patience 30, model mean validation loss 0.9113544225692749, embedding dim 4, hidden size 1, num layers 1, train loss 0.7502174377441406, validation loss 0.8917099237442017\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9076509475708008, embedding dim 4, hidden size 1, num layers 1, train loss 0.7362358570098877, validation loss 0.892103910446167\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9033823013305664, embedding dim 4, hidden size 1, num layers 1, train loss 0.9256688952445984, validation loss 0.8826389312744141\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8982459902763367, embedding dim 4, hidden size 1, num layers 1, train loss 0.9250218272209167, validation loss 0.8811694383621216\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8980633616447449, embedding dim 4, hidden size 1, num layers 1, train loss 0.7776527404785156, validation loss 0.904045045375824\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8950678110122681, embedding dim 4, hidden size 1, num layers 1, train loss 0.8643680810928345, validation loss 0.8852147459983826\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8914757966995239, embedding dim 4, hidden size 1, num layers 1, train loss 0.7598673105239868, validation loss 0.8918808102607727\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8884745836257935, embedding dim 4, hidden size 1, num layers 1, train loss 0.8338220715522766, validation loss 0.879034161567688\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8893036842346191, embedding dim 4, hidden size 1, num layers 1, train loss 0.8817575573921204, validation loss 0.8983423709869385\n",
      "Epoch 720, current patience 29, model mean validation loss 0.8909972906112671, embedding dim 4, hidden size 1, num layers 1, train loss 0.789983332157135, validation loss 0.9056529998779297\n",
      "Epoch 730, current patience 28, model mean validation loss 0.8924815058708191, embedding dim 4, hidden size 1, num layers 1, train loss 0.7364248633384705, validation loss 0.894512414932251\n",
      "Epoch 740, current patience 27, model mean validation loss 0.8924406170845032, embedding dim 4, hidden size 1, num layers 1, train loss 0.7593833804130554, validation loss 0.8808425664901733\n",
      "Epoch 750, current patience 26, model mean validation loss 0.8913096189498901, embedding dim 4, hidden size 1, num layers 1, train loss 0.8645209074020386, validation loss 0.8949966430664062\n",
      "Epoch 760, current patience 25, model mean validation loss 0.8927491903305054, embedding dim 4, hidden size 1, num layers 1, train loss 0.7487884759902954, validation loss 0.8967313766479492\n",
      "Epoch 770, current patience 24, model mean validation loss 0.8942247629165649, embedding dim 4, hidden size 1, num layers 1, train loss 0.764148473739624, validation loss 0.903685450553894\n",
      "Epoch 780, current patience 23, model mean validation loss 0.8963810205459595, embedding dim 4, hidden size 1, num layers 1, train loss 0.73529052734375, validation loss 0.8962844610214233\n",
      "Epoch 790, current patience 22, model mean validation loss 0.897121787071228, embedding dim 4, hidden size 1, num layers 1, train loss 0.7769302129745483, validation loss 0.9042681455612183\n",
      "Epoch 800, current patience 21, model mean validation loss 0.8950238823890686, embedding dim 4, hidden size 1, num layers 1, train loss 0.7392014861106873, validation loss 0.8888696432113647\n",
      "Epoch 810, current patience 20, model mean validation loss 0.8939173817634583, embedding dim 4, hidden size 1, num layers 1, train loss 0.8612122535705566, validation loss 0.8856607675552368\n",
      "Epoch 820, current patience 19, model mean validation loss 0.8927189111709595, embedding dim 4, hidden size 1, num layers 1, train loss 0.7915821075439453, validation loss 0.8712548613548279\n",
      "Epoch 830, current patience 18, model mean validation loss 0.8914203643798828, embedding dim 4, hidden size 1, num layers 1, train loss 0.7771721482276917, validation loss 0.8846083283424377\n",
      "Epoch 840, current patience 17, model mean validation loss 0.8907727003097534, embedding dim 4, hidden size 1, num layers 1, train loss 0.6886465549468994, validation loss 0.891549825668335\n",
      "Epoch 850, current patience 16, model mean validation loss 0.8943579196929932, embedding dim 4, hidden size 1, num layers 1, train loss 0.761109471321106, validation loss 0.9323674440383911\n",
      "Epoch 860, current patience 15, model mean validation loss 0.8958277702331543, embedding dim 4, hidden size 1, num layers 1, train loss 0.6978594064712524, validation loss 0.908042848110199\n",
      "Epoch 870, current patience 14, model mean validation loss 0.8988122940063477, embedding dim 4, hidden size 1, num layers 1, train loss 0.7154779434204102, validation loss 0.928144097328186\n",
      "Epoch 880, current patience 13, model mean validation loss 0.9060831665992737, embedding dim 4, hidden size 1, num layers 1, train loss 0.7248309850692749, validation loss 0.9470375776290894\n",
      "Epoch 890, current patience 12, model mean validation loss 0.9090220332145691, embedding dim 4, hidden size 1, num layers 1, train loss 0.8987464904785156, validation loss 0.9091713428497314\n",
      "Epoch 900, current patience 11, model mean validation loss 0.9111868143081665, embedding dim 4, hidden size 1, num layers 1, train loss 0.8047465085983276, validation loss 0.8885730504989624\n",
      "Epoch 910, current patience 10, model mean validation loss 0.9131548404693604, embedding dim 4, hidden size 1, num layers 1, train loss 0.7258473634719849, validation loss 0.900352954864502\n",
      "Epoch 920, current patience 9, model mean validation loss 0.9124983549118042, embedding dim 4, hidden size 1, num layers 1, train loss 0.8141007423400879, validation loss 0.886297881603241\n",
      "Epoch 930, current patience 8, model mean validation loss 0.9040470719337463, embedding dim 4, hidden size 1, num layers 1, train loss 0.6710719466209412, validation loss 0.8647568225860596\n",
      "Epoch 940, current patience 7, model mean validation loss 0.8993351459503174, embedding dim 4, hidden size 1, num layers 1, train loss 0.7449532747268677, validation loss 0.8703476190567017\n",
      "Epoch 950, current patience 6, model mean validation loss 0.8997079730033875, embedding dim 4, hidden size 1, num layers 1, train loss 0.6842238903045654, validation loss 0.9311266541481018\n",
      "Epoch 960, current patience 5, model mean validation loss 0.8932380676269531, embedding dim 4, hidden size 1, num layers 1, train loss 0.6837674379348755, validation loss 0.8952779769897461\n",
      "Epoch 970, current patience 4, model mean validation loss 0.8939308524131775, embedding dim 4, hidden size 1, num layers 1, train loss 0.7000582218170166, validation loss 0.9147142171859741\n",
      "Epoch 980, current patience 3, model mean validation loss 0.8982744216918945, embedding dim 4, hidden size 1, num layers 1, train loss 0.6785411834716797, validation loss 0.923321008682251\n",
      "Epoch 990, current patience 2, model mean validation loss 0.9008086323738098, embedding dim 4, hidden size 1, num layers 1, train loss 0.6234166622161865, validation loss 0.9206265211105347\n",
      "Epoch 1000, current patience 1, model mean validation loss 0.907970666885376, embedding dim 4, hidden size 1, num layers 1, train loss 0.7464815974235535, validation loss 0.9435941576957703\n",
      "Epoch 0, current patience 30, model mean validation loss 1.131650686264038, embedding dim 4, hidden size 2, num layers 1, train loss 1.1467899084091187, validation loss 1.131650686264038\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1231762170791626, embedding dim 4, hidden size 2, num layers 1, train loss 1.1141870021820068, validation loss 1.114701747894287\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1160966157913208, embedding dim 4, hidden size 2, num layers 1, train loss 1.0965081453323364, validation loss 1.1019375324249268\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1115422248840332, embedding dim 4, hidden size 2, num layers 1, train loss 1.0983995199203491, validation loss 1.09787917137146\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1076037883758545, embedding dim 4, hidden size 2, num layers 1, train loss 1.1054710149765015, validation loss 1.091849446296692\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1042488813400269, embedding dim 4, hidden size 2, num layers 1, train loss 1.091722011566162, validation loss 1.0874741077423096\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1028096675872803, embedding dim 4, hidden size 2, num layers 1, train loss 1.1009087562561035, validation loss 1.0941746234893799\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1019307374954224, embedding dim 4, hidden size 2, num layers 1, train loss 1.090065598487854, validation loss 1.095778226852417\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0973689556121826, embedding dim 4, hidden size 2, num layers 1, train loss 1.1069363355636597, validation loss 1.0951571464538574\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0950264930725098, embedding dim 4, hidden size 2, num layers 1, train loss 1.092694640159607, validation loss 1.0959618091583252\n",
      "Epoch 100, current patience 30, model mean validation loss 1.09375, embedding dim 4, hidden size 2, num layers 1, train loss 1.0971457958221436, validation loss 1.0917255878448486\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0932369232177734, embedding dim 4, hidden size 2, num layers 1, train loss 1.0810120105743408, validation loss 1.0937740802764893\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0932761430740356, embedding dim 4, hidden size 2, num layers 1, train loss 1.085883617401123, validation loss 1.0921638011932373\n",
      "Epoch 130, current patience 29, model mean validation loss 1.093746542930603, embedding dim 4, hidden size 2, num layers 1, train loss 1.095574140548706, validation loss 1.0912368297576904\n",
      "Epoch 140, current patience 28, model mean validation loss 1.0932626724243164, embedding dim 4, hidden size 2, num layers 1, train loss 1.0861921310424805, validation loss 1.0903035402297974\n",
      "Epoch 150, current patience 27, model mean validation loss 1.0922038555145264, embedding dim 4, hidden size 2, num layers 1, train loss 1.098443865776062, validation loss 1.0873080492019653\n",
      "Epoch 160, current patience 30, model mean validation loss 1.09116792678833, embedding dim 4, hidden size 2, num layers 1, train loss 1.0926892757415771, validation loss 1.0868693590164185\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0897847414016724, embedding dim 4, hidden size 2, num layers 1, train loss 1.1021060943603516, validation loss 1.084896206855774\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0882478952407837, embedding dim 4, hidden size 2, num layers 1, train loss 1.0263490676879883, validation loss 1.0794306993484497\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0862914323806763, embedding dim 4, hidden size 2, num layers 1, train loss 1.1000335216522217, validation loss 1.0781229734420776\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0847704410552979, embedding dim 4, hidden size 2, num layers 1, train loss 1.0230588912963867, validation loss 1.0799965858459473\n",
      "Epoch 210, current patience 30, model mean validation loss 1.081817388534546, embedding dim 4, hidden size 2, num layers 1, train loss 1.0608766078948975, validation loss 1.0676114559173584\n",
      "Epoch 220, current patience 30, model mean validation loss 1.078523874282837, embedding dim 4, hidden size 2, num layers 1, train loss 1.044142484664917, validation loss 1.0639550685882568\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0735728740692139, embedding dim 4, hidden size 2, num layers 1, train loss 1.0296086072921753, validation loss 1.0477008819580078\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0676767826080322, embedding dim 4, hidden size 2, num layers 1, train loss 1.0936335325241089, validation loss 1.0397002696990967\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0598564147949219, embedding dim 4, hidden size 2, num layers 1, train loss 1.0364291667938232, validation loss 1.022333025932312\n",
      "Epoch 260, current patience 30, model mean validation loss 1.051240086555481, embedding dim 4, hidden size 2, num layers 1, train loss 1.0635488033294678, validation loss 1.010500431060791\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0432732105255127, embedding dim 4, hidden size 2, num layers 1, train loss 0.954230010509491, validation loss 1.0143885612487793\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0323255062103271, embedding dim 4, hidden size 2, num layers 1, train loss 0.9631036520004272, validation loss 0.9924140572547913\n",
      "Epoch 290, current patience 30, model mean validation loss 1.022881031036377, embedding dim 4, hidden size 2, num layers 1, train loss 0.9311157464981079, validation loss 0.9920558333396912\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0114421844482422, embedding dim 4, hidden size 2, num layers 1, train loss 1.0192463397979736, validation loss 0.9724440574645996\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0014264583587646, embedding dim 4, hidden size 2, num layers 1, train loss 0.9186723828315735, validation loss 0.9675750732421875\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9934855103492737, embedding dim 4, hidden size 2, num layers 1, train loss 0.958465576171875, validation loss 0.9761734008789062\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9864357113838196, embedding dim 4, hidden size 2, num layers 1, train loss 1.001671552658081, validation loss 0.9659342765808105\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9772169589996338, embedding dim 4, hidden size 2, num layers 1, train loss 0.9150079488754272, validation loss 0.9367501735687256\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9701086282730103, embedding dim 4, hidden size 2, num layers 1, train loss 1.0061804056167603, validation loss 0.9575222730636597\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9628185629844666, embedding dim 4, hidden size 2, num layers 1, train loss 0.8254024982452393, validation loss 0.9340935945510864\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9554724097251892, embedding dim 4, hidden size 2, num layers 1, train loss 0.8529739379882812, validation loss 0.9332865476608276\n",
      "Epoch 380, current patience 30, model mean validation loss 0.949858546257019, embedding dim 4, hidden size 2, num layers 1, train loss 0.8673637509346008, validation loss 0.9275330305099487\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9436909556388855, embedding dim 4, hidden size 2, num layers 1, train loss 0.8178121447563171, validation loss 0.9182343482971191\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9397533535957336, embedding dim 4, hidden size 2, num layers 1, train loss 0.9287603497505188, validation loss 0.9446724653244019\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9317699670791626, embedding dim 4, hidden size 2, num layers 1, train loss 0.9485393762588501, validation loss 0.9020673036575317\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9264730215072632, embedding dim 4, hidden size 2, num layers 1, train loss 0.8449105024337769, validation loss 0.8943741917610168\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9189035892486572, embedding dim 4, hidden size 2, num layers 1, train loss 0.8273957967758179, validation loss 0.8969676494598389\n",
      "Epoch 440, current patience 30, model mean validation loss 0.912293553352356, embedding dim 4, hidden size 2, num layers 1, train loss 0.8474847078323364, validation loss 0.8812127113342285\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9116960167884827, embedding dim 4, hidden size 2, num layers 1, train loss 0.7851958274841309, validation loss 0.9285062551498413\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9098395109176636, embedding dim 4, hidden size 2, num layers 1, train loss 0.7992509007453918, validation loss 0.9126815795898438\n",
      "Epoch 470, current patience 30, model mean validation loss 0.90604567527771, embedding dim 4, hidden size 2, num layers 1, train loss 0.7918712496757507, validation loss 0.887883186340332\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8977566957473755, embedding dim 4, hidden size 2, num layers 1, train loss 0.8087628483772278, validation loss 0.8783605098724365\n",
      "Epoch 490, current patience 30, model mean validation loss 0.893332839012146, embedding dim 4, hidden size 2, num layers 1, train loss 0.9111087918281555, validation loss 0.8666772246360779\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8939035534858704, embedding dim 4, hidden size 2, num layers 1, train loss 0.8170337677001953, validation loss 0.8989396095275879\n",
      "Epoch 510, current patience 29, model mean validation loss 0.891289234161377, embedding dim 4, hidden size 2, num layers 1, train loss 0.8199983835220337, validation loss 0.8760530948638916\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8884754776954651, embedding dim 4, hidden size 2, num layers 1, train loss 1.0051085948944092, validation loss 0.8587024211883545\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8814532160758972, embedding dim 4, hidden size 2, num layers 1, train loss 0.7837344408035278, validation loss 0.8723283410072327\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8782622814178467, embedding dim 4, hidden size 2, num layers 1, train loss 0.7195421457290649, validation loss 0.8871543407440186\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8755435347557068, embedding dim 4, hidden size 2, num layers 1, train loss 0.7729977369308472, validation loss 0.8661330342292786\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8735010027885437, embedding dim 4, hidden size 2, num layers 1, train loss 0.7391632199287415, validation loss 0.8620201945304871\n",
      "Epoch 570, current patience 30, model mean validation loss 0.877747654914856, embedding dim 4, hidden size 2, num layers 1, train loss 0.7605094909667969, validation loss 0.900650680065155\n",
      "Epoch 580, current patience 29, model mean validation loss 0.8739555478096008, embedding dim 4, hidden size 2, num layers 1, train loss 0.7475179433822632, validation loss 0.8686023950576782\n",
      "Epoch 590, current patience 28, model mean validation loss 0.8740394115447998, embedding dim 4, hidden size 2, num layers 1, train loss 0.7128407955169678, validation loss 0.8767238855361938\n",
      "Epoch 600, current patience 27, model mean validation loss 0.8736134767532349, embedding dim 4, hidden size 2, num layers 1, train loss 0.8000189661979675, validation loss 0.8552950024604797\n",
      "Epoch 610, current patience 26, model mean validation loss 0.8743764162063599, embedding dim 4, hidden size 2, num layers 1, train loss 0.8040566444396973, validation loss 0.8784315586090088\n",
      "Epoch 620, current patience 25, model mean validation loss 0.8743691444396973, embedding dim 4, hidden size 2, num layers 1, train loss 0.6918274760246277, validation loss 0.8870960474014282\n",
      "Epoch 630, current patience 24, model mean validation loss 0.8741562366485596, embedding dim 4, hidden size 2, num layers 1, train loss 0.8216238021850586, validation loss 0.8644295334815979\n",
      "Epoch 640, current patience 23, model mean validation loss 0.87477707862854, embedding dim 4, hidden size 2, num layers 1, train loss 0.7860215902328491, validation loss 0.8669872879981995\n",
      "Epoch 650, current patience 22, model mean validation loss 0.868323564529419, embedding dim 4, hidden size 2, num layers 1, train loss 0.5257266759872437, validation loss 0.8490227460861206\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8688612580299377, embedding dim 4, hidden size 2, num layers 1, train loss 0.7989456057548523, validation loss 0.8729041218757629\n",
      "Epoch 670, current patience 29, model mean validation loss 0.8648089170455933, embedding dim 4, hidden size 2, num layers 1, train loss 0.7318071722984314, validation loss 0.8443049192428589\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8683992028236389, embedding dim 4, hidden size 2, num layers 1, train loss 0.7502648830413818, validation loss 0.8840175271034241\n",
      "Epoch 690, current patience 29, model mean validation loss 0.8673849105834961, embedding dim 4, hidden size 2, num layers 1, train loss 0.7048717737197876, validation loss 0.8703171014785767\n",
      "Epoch 700, current patience 28, model mean validation loss 0.8657867312431335, embedding dim 4, hidden size 2, num layers 1, train loss 0.7474919557571411, validation loss 0.8743106126785278\n",
      "Epoch 710, current patience 27, model mean validation loss 0.8680670261383057, embedding dim 4, hidden size 2, num layers 1, train loss 0.6867092847824097, validation loss 0.8826717734336853\n",
      "Epoch 720, current patience 26, model mean validation loss 0.8681230545043945, embedding dim 4, hidden size 2, num layers 1, train loss 0.8396955132484436, validation loss 0.8674361705780029\n",
      "Epoch 730, current patience 25, model mean validation loss 0.8726560473442078, embedding dim 4, hidden size 2, num layers 1, train loss 0.6876600384712219, validation loss 0.8852862119674683\n",
      "Epoch 740, current patience 24, model mean validation loss 0.8720458745956421, embedding dim 4, hidden size 2, num layers 1, train loss 0.9775378704071045, validation loss 0.8680229783058167\n",
      "Epoch 750, current patience 23, model mean validation loss 0.8717103600502014, embedding dim 4, hidden size 2, num layers 1, train loss 0.782862663269043, validation loss 0.8416205644607544\n",
      "Epoch 760, current patience 22, model mean validation loss 0.8703520894050598, embedding dim 4, hidden size 2, num layers 1, train loss 0.6883132457733154, validation loss 0.8731516003608704\n",
      "Epoch 770, current patience 21, model mean validation loss 0.8710688352584839, embedding dim 4, hidden size 2, num layers 1, train loss 0.6223185658454895, validation loss 0.8760509490966797\n",
      "Epoch 780, current patience 20, model mean validation loss 0.873132586479187, embedding dim 4, hidden size 2, num layers 1, train loss 0.7062832117080688, validation loss 0.8908202648162842\n",
      "Epoch 790, current patience 19, model mean validation loss 0.8731749653816223, embedding dim 4, hidden size 2, num layers 1, train loss 0.6824471950531006, validation loss 0.8830112218856812\n",
      "Epoch 800, current patience 18, model mean validation loss 0.8760902285575867, embedding dim 4, hidden size 2, num layers 1, train loss 0.6081942319869995, validation loss 0.8907581567764282\n",
      "Epoch 810, current patience 17, model mean validation loss 0.8730429410934448, embedding dim 4, hidden size 2, num layers 1, train loss 0.8208706378936768, validation loss 0.8609073162078857\n",
      "Epoch 820, current patience 16, model mean validation loss 0.8725247979164124, embedding dim 4, hidden size 2, num layers 1, train loss 0.6654132008552551, validation loss 0.8638781309127808\n",
      "Epoch 830, current patience 15, model mean validation loss 0.8736210465431213, embedding dim 4, hidden size 2, num layers 1, train loss 0.6535654664039612, validation loss 0.8503905534744263\n",
      "Epoch 840, current patience 14, model mean validation loss 0.8737843036651611, embedding dim 4, hidden size 2, num layers 1, train loss 0.5409407019615173, validation loss 0.874457597732544\n",
      "Epoch 850, current patience 13, model mean validation loss 0.871456503868103, embedding dim 4, hidden size 2, num layers 1, train loss 0.6700451970100403, validation loss 0.8574285507202148\n",
      "Epoch 860, current patience 12, model mean validation loss 0.8675839900970459, embedding dim 4, hidden size 2, num layers 1, train loss 0.7828720808029175, validation loss 0.8598406314849854\n",
      "Epoch 870, current patience 11, model mean validation loss 0.8680415749549866, embedding dim 4, hidden size 2, num layers 1, train loss 0.5949305295944214, validation loss 0.8866718411445618\n",
      "Epoch 880, current patience 10, model mean validation loss 0.868087887763977, embedding dim 4, hidden size 2, num layers 1, train loss 0.705783486366272, validation loss 0.8911285996437073\n",
      "Epoch 890, current patience 9, model mean validation loss 0.8667027950286865, embedding dim 4, hidden size 2, num layers 1, train loss 0.689179539680481, validation loss 0.8498266935348511\n",
      "Epoch 900, current patience 8, model mean validation loss 0.8679376244544983, embedding dim 4, hidden size 2, num layers 1, train loss 0.6139688491821289, validation loss 0.8737566471099854\n",
      "Epoch 910, current patience 7, model mean validation loss 0.8717199563980103, embedding dim 4, hidden size 2, num layers 1, train loss 0.6910443305969238, validation loss 0.8806493878364563\n",
      "Epoch 920, current patience 6, model mean validation loss 0.8714758157730103, embedding dim 4, hidden size 2, num layers 1, train loss 0.5716972351074219, validation loss 0.872504472732544\n",
      "Epoch 930, current patience 5, model mean validation loss 0.8744381070137024, embedding dim 4, hidden size 2, num layers 1, train loss 0.7707540392875671, validation loss 0.881127119064331\n",
      "Epoch 940, current patience 4, model mean validation loss 0.876886785030365, embedding dim 4, hidden size 2, num layers 1, train loss 0.7046644687652588, validation loss 0.8794294595718384\n",
      "Epoch 950, current patience 3, model mean validation loss 0.8732963800430298, embedding dim 4, hidden size 2, num layers 1, train loss 0.6575275659561157, validation loss 0.8579485416412354\n",
      "Epoch 960, current patience 2, model mean validation loss 0.8702936172485352, embedding dim 4, hidden size 2, num layers 1, train loss 0.5711712837219238, validation loss 0.8671064376831055\n",
      "Epoch 970, current patience 1, model mean validation loss 0.875421404838562, embedding dim 4, hidden size 2, num layers 1, train loss 0.5778482556343079, validation loss 0.8908495903015137\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1257448196411133, embedding dim 4, hidden size 4, num layers 1, train loss 1.1281460523605347, validation loss 1.1257448196411133\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1136677265167236, embedding dim 4, hidden size 4, num layers 1, train loss 1.103529930114746, validation loss 1.1015907526016235\n",
      "Epoch 20, current patience 30, model mean validation loss 1.107439398765564, embedding dim 4, hidden size 4, num layers 1, train loss 1.0946502685546875, validation loss 1.0949827432632446\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1047070026397705, embedding dim 4, hidden size 4, num layers 1, train loss 1.1066815853118896, validation loss 1.0965096950531006\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1032339334487915, embedding dim 4, hidden size 4, num layers 1, train loss 1.0985195636749268, validation loss 1.097341537475586\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1019145250320435, embedding dim 4, hidden size 4, num layers 1, train loss 1.1053931713104248, validation loss 1.0953176021575928\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1005346775054932, embedding dim 4, hidden size 4, num layers 1, train loss 1.107329249382019, validation loss 1.0922558307647705\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1000224351882935, embedding dim 4, hidden size 4, num layers 1, train loss 1.1111506223678589, validation loss 1.0964361429214478\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0958749055862427, embedding dim 4, hidden size 4, num layers 1, train loss 1.0907588005065918, validation loss 1.0925647020339966\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0946521759033203, embedding dim 4, hidden size 4, num layers 1, train loss 1.0891919136047363, validation loss 1.0918093919754028\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094147801399231, embedding dim 4, hidden size 4, num layers 1, train loss 1.0905938148498535, validation loss 1.090947151184082\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0934348106384277, embedding dim 4, hidden size 4, num layers 1, train loss 1.0935449600219727, validation loss 1.090806007385254\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0921401977539062, embedding dim 4, hidden size 4, num layers 1, train loss 1.097724199295044, validation loss 1.0869853496551514\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0898995399475098, embedding dim 4, hidden size 4, num layers 1, train loss 1.0740149021148682, validation loss 1.0773918628692627\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0886074304580688, embedding dim 4, hidden size 4, num layers 1, train loss 1.0900897979736328, validation loss 1.081918716430664\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0853532552719116, embedding dim 4, hidden size 4, num layers 1, train loss 1.0510880947113037, validation loss 1.07040274143219\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0809385776519775, embedding dim 4, hidden size 4, num layers 1, train loss 1.0832908153533936, validation loss 1.0572474002838135\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0754035711288452, embedding dim 4, hidden size 4, num layers 1, train loss 1.0695090293884277, validation loss 1.0475292205810547\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0684078931808472, embedding dim 4, hidden size 4, num layers 1, train loss 1.0116162300109863, validation loss 1.0349817276000977\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0593079328536987, embedding dim 4, hidden size 4, num layers 1, train loss 0.9969883561134338, validation loss 1.0180068016052246\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0473791360855103, embedding dim 4, hidden size 4, num layers 1, train loss 1.021714448928833, validation loss 0.9915552139282227\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0364627838134766, embedding dim 4, hidden size 4, num layers 1, train loss 1.01740300655365, validation loss 0.9900606870651245\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0229251384735107, embedding dim 4, hidden size 4, num layers 1, train loss 0.9311032891273499, validation loss 0.9736170172691345\n",
      "Epoch 230, current patience 30, model mean validation loss 1.008753776550293, embedding dim 4, hidden size 4, num layers 1, train loss 0.9413361549377441, validation loss 0.9570326805114746\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9968276023864746, embedding dim 4, hidden size 4, num layers 1, train loss 0.8999334573745728, validation loss 0.9618372321128845\n",
      "Epoch 250, current patience 30, model mean validation loss 0.984522819519043, embedding dim 4, hidden size 4, num layers 1, train loss 0.864856481552124, validation loss 0.9490909576416016\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9729906320571899, embedding dim 4, hidden size 4, num layers 1, train loss 0.9691587686538696, validation loss 0.9427245259284973\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9638424515724182, embedding dim 4, hidden size 4, num layers 1, train loss 0.9053357243537903, validation loss 0.9448213577270508\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9562671184539795, embedding dim 4, hidden size 4, num layers 1, train loss 0.887018084526062, validation loss 0.9309523105621338\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9492695927619934, embedding dim 4, hidden size 4, num layers 1, train loss 0.8445176482200623, validation loss 0.9340807199478149\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9428706169128418, embedding dim 4, hidden size 4, num layers 1, train loss 0.8387355208396912, validation loss 0.9224247336387634\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9379312992095947, embedding dim 4, hidden size 4, num layers 1, train loss 0.9153826236724854, validation loss 0.9175188541412354\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9312926530838013, embedding dim 4, hidden size 4, num layers 1, train loss 0.8124390840530396, validation loss 0.9087271690368652\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9244500398635864, embedding dim 4, hidden size 4, num layers 1, train loss 0.7806416153907776, validation loss 0.8943506479263306\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9188306927680969, embedding dim 4, hidden size 4, num layers 1, train loss 0.775057315826416, validation loss 0.8977699279785156\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9137023091316223, embedding dim 4, hidden size 4, num layers 1, train loss 0.8364531993865967, validation loss 0.9037941098213196\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9073638916015625, embedding dim 4, hidden size 4, num layers 1, train loss 0.827784538269043, validation loss 0.8802449107170105\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9013519883155823, embedding dim 4, hidden size 4, num layers 1, train loss 0.8419140577316284, validation loss 0.8859851360321045\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8950237035751343, embedding dim 4, hidden size 4, num layers 1, train loss 0.760866105556488, validation loss 0.8717986941337585\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8916677236557007, embedding dim 4, hidden size 4, num layers 1, train loss 0.7667036056518555, validation loss 0.8906712532043457\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8887991905212402, embedding dim 4, hidden size 4, num layers 1, train loss 0.776207685470581, validation loss 0.8857788443565369\n",
      "Epoch 410, current patience 30, model mean validation loss 0.887133002281189, embedding dim 4, hidden size 4, num layers 1, train loss 0.6945433020591736, validation loss 0.88102126121521\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8836056590080261, embedding dim 4, hidden size 4, num layers 1, train loss 0.7697893977165222, validation loss 0.8695509433746338\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8778342008590698, embedding dim 4, hidden size 4, num layers 1, train loss 0.7332067489624023, validation loss 0.8576223254203796\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8748880624771118, embedding dim 4, hidden size 4, num layers 1, train loss 0.7848385572433472, validation loss 0.856675386428833\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8739439249038696, embedding dim 4, hidden size 4, num layers 1, train loss 0.757524847984314, validation loss 0.8784325122833252\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8733737468719482, embedding dim 4, hidden size 4, num layers 1, train loss 0.7445002198219299, validation loss 0.8672373294830322\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8692964315414429, embedding dim 4, hidden size 4, num layers 1, train loss 0.7180376052856445, validation loss 0.8580532073974609\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8650188446044922, embedding dim 4, hidden size 4, num layers 1, train loss 0.8179135322570801, validation loss 0.8515577912330627\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8603960275650024, embedding dim 4, hidden size 4, num layers 1, train loss 0.7660366296768188, validation loss 0.844038724899292\n",
      "Epoch 500, current patience 30, model mean validation loss 0.856309711933136, embedding dim 4, hidden size 4, num layers 1, train loss 0.8118323683738708, validation loss 0.8368602991104126\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8540290594100952, embedding dim 4, hidden size 4, num layers 1, train loss 0.6712273359298706, validation loss 0.8393777012825012\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8519197702407837, embedding dim 4, hidden size 4, num layers 1, train loss 0.6550433039665222, validation loss 0.8398010730743408\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8473657369613647, embedding dim 4, hidden size 4, num layers 1, train loss 0.6603683233261108, validation loss 0.8420001864433289\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8476446866989136, embedding dim 4, hidden size 4, num layers 1, train loss 0.8559750318527222, validation loss 0.8694682717323303\n",
      "Epoch 550, current patience 29, model mean validation loss 0.8478819131851196, embedding dim 4, hidden size 4, num layers 1, train loss 0.668425977230072, validation loss 0.8599514961242676\n",
      "Epoch 560, current patience 28, model mean validation loss 0.8517569899559021, embedding dim 4, hidden size 4, num layers 1, train loss 0.9520106315612793, validation loss 0.8825579881668091\n",
      "Epoch 570, current patience 27, model mean validation loss 0.8545975089073181, embedding dim 4, hidden size 4, num layers 1, train loss 0.7400780916213989, validation loss 0.8667628169059753\n",
      "Epoch 580, current patience 26, model mean validation loss 0.8554002046585083, embedding dim 4, hidden size 4, num layers 1, train loss 0.7861692309379578, validation loss 0.8432819843292236\n",
      "Epoch 590, current patience 25, model mean validation loss 0.8572126626968384, embedding dim 4, hidden size 4, num layers 1, train loss 0.6323116421699524, validation loss 0.8538778424263\n",
      "Epoch 600, current patience 24, model mean validation loss 0.858777642250061, embedding dim 4, hidden size 4, num layers 1, train loss 0.6435956954956055, validation loss 0.8523204922676086\n",
      "Epoch 610, current patience 23, model mean validation loss 0.8535882830619812, embedding dim 4, hidden size 4, num layers 1, train loss 0.8503516912460327, validation loss 0.8004855513572693\n",
      "Epoch 620, current patience 22, model mean validation loss 0.849946916103363, embedding dim 4, hidden size 4, num layers 1, train loss 0.5952939987182617, validation loss 0.8403369188308716\n",
      "Epoch 630, current patience 21, model mean validation loss 0.8461012840270996, embedding dim 4, hidden size 4, num layers 1, train loss 0.6122291088104248, validation loss 0.8291869163513184\n",
      "Epoch 640, current patience 30, model mean validation loss 0.83702552318573, embedding dim 4, hidden size 4, num layers 1, train loss 0.7407909631729126, validation loss 0.809951663017273\n",
      "Epoch 650, current patience 30, model mean validation loss 0.8327191472053528, embedding dim 4, hidden size 4, num layers 1, train loss 0.6109822988510132, validation loss 0.8323122262954712\n",
      "Epoch 660, current patience 30, model mean validation loss 0.8324375152587891, embedding dim 4, hidden size 4, num layers 1, train loss 0.8158073425292969, validation loss 0.8410288691520691\n",
      "Epoch 670, current patience 30, model mean validation loss 0.8287341594696045, embedding dim 4, hidden size 4, num layers 1, train loss 0.7485492825508118, validation loss 0.8242507576942444\n",
      "Epoch 680, current patience 30, model mean validation loss 0.8285515308380127, embedding dim 4, hidden size 4, num layers 1, train loss 0.6811091899871826, validation loss 0.850859522819519\n",
      "Epoch 690, current patience 30, model mean validation loss 0.8332049250602722, embedding dim 4, hidden size 4, num layers 1, train loss 0.610956072807312, validation loss 0.8377127647399902\n",
      "Epoch 700, current patience 29, model mean validation loss 0.8316091895103455, embedding dim 4, hidden size 4, num layers 1, train loss 0.5551501512527466, validation loss 0.8275707960128784\n",
      "Epoch 710, current patience 28, model mean validation loss 0.8294841647148132, embedding dim 4, hidden size 4, num layers 1, train loss 0.6868644952774048, validation loss 0.8121866583824158\n",
      "Epoch 720, current patience 27, model mean validation loss 0.8288875818252563, embedding dim 4, hidden size 4, num layers 1, train loss 0.6427242755889893, validation loss 0.8051791787147522\n",
      "Epoch 730, current patience 26, model mean validation loss 0.8273136019706726, embedding dim 4, hidden size 4, num layers 1, train loss 0.610966145992279, validation loss 0.8197203874588013\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8226166367530823, embedding dim 4, hidden size 4, num layers 1, train loss 0.6815881729125977, validation loss 0.8034529685974121\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8269962072372437, embedding dim 4, hidden size 4, num layers 1, train loss 0.6202927827835083, validation loss 0.8592876195907593\n",
      "Epoch 760, current patience 29, model mean validation loss 0.8229740858078003, embedding dim 4, hidden size 4, num layers 1, train loss 0.4707983136177063, validation loss 0.818682074546814\n",
      "Epoch 770, current patience 28, model mean validation loss 0.8275894522666931, embedding dim 4, hidden size 4, num layers 1, train loss 0.5767046213150024, validation loss 0.8746360540390015\n",
      "Epoch 780, current patience 27, model mean validation loss 0.8338322639465332, embedding dim 4, hidden size 4, num layers 1, train loss 0.594086229801178, validation loss 0.8775131106376648\n",
      "Epoch 790, current patience 26, model mean validation loss 0.8393062353134155, embedding dim 4, hidden size 4, num layers 1, train loss 0.7274259328842163, validation loss 0.8559785485267639\n",
      "Epoch 800, current patience 25, model mean validation loss 0.8460447788238525, embedding dim 4, hidden size 4, num layers 1, train loss 0.5674778819084167, validation loss 0.8590878248214722\n",
      "Epoch 810, current patience 24, model mean validation loss 0.8498139381408691, embedding dim 4, hidden size 4, num layers 1, train loss 0.5770497918128967, validation loss 0.849873423576355\n",
      "Epoch 820, current patience 23, model mean validation loss 0.8542259335517883, embedding dim 4, hidden size 4, num layers 1, train loss 0.6108614206314087, validation loss 0.8387486934661865\n",
      "Epoch 830, current patience 22, model mean validation loss 0.8533360362052917, embedding dim 4, hidden size 4, num layers 1, train loss 0.6127321720123291, validation loss 0.8521684408187866\n",
      "Epoch 840, current patience 21, model mean validation loss 0.8547128438949585, embedding dim 4, hidden size 4, num layers 1, train loss 0.6585416197776794, validation loss 0.8296964764595032\n",
      "Epoch 850, current patience 20, model mean validation loss 0.8502521514892578, embedding dim 4, hidden size 4, num layers 1, train loss 0.6881346106529236, validation loss 0.838950514793396\n",
      "Epoch 860, current patience 19, model mean validation loss 0.844383955001831, embedding dim 4, hidden size 4, num layers 1, train loss 0.723796010017395, validation loss 0.830567479133606\n",
      "Epoch 870, current patience 18, model mean validation loss 0.8503807783126831, embedding dim 4, hidden size 4, num layers 1, train loss 0.6291648745536804, validation loss 0.9039532542228699\n",
      "Epoch 880, current patience 17, model mean validation loss 0.8523303270339966, embedding dim 4, hidden size 4, num layers 1, train loss 0.5065710544586182, validation loss 0.87468421459198\n",
      "Epoch 890, current patience 16, model mean validation loss 0.8561718463897705, embedding dim 4, hidden size 4, num layers 1, train loss 0.5087968111038208, validation loss 0.8806052207946777\n",
      "Epoch 900, current patience 15, model mean validation loss 0.8544463515281677, embedding dim 4, hidden size 4, num layers 1, train loss 0.47699058055877686, validation loss 0.8249452114105225\n",
      "Epoch 910, current patience 14, model mean validation loss 0.8556818962097168, embedding dim 4, hidden size 4, num layers 1, train loss 0.5434666872024536, validation loss 0.8620526790618896\n",
      "Epoch 920, current patience 13, model mean validation loss 0.860136866569519, embedding dim 4, hidden size 4, num layers 1, train loss 0.5346893072128296, validation loss 0.8653364181518555\n",
      "Epoch 930, current patience 12, model mean validation loss 0.8626247048377991, embedding dim 4, hidden size 4, num layers 1, train loss 0.47046971321105957, validation loss 0.8588529825210571\n",
      "Epoch 940, current patience 11, model mean validation loss 0.8702447414398193, embedding dim 4, hidden size 4, num layers 1, train loss 0.7523515224456787, validation loss 0.8915280699729919\n",
      "Epoch 950, current patience 10, model mean validation loss 0.8611835837364197, embedding dim 4, hidden size 4, num layers 1, train loss 0.42141351103782654, validation loss 0.8314636945724487\n",
      "Epoch 960, current patience 9, model mean validation loss 0.8552230000495911, embedding dim 4, hidden size 4, num layers 1, train loss 0.536659836769104, validation loss 0.8269996643066406\n",
      "Epoch 970, current patience 8, model mean validation loss 0.8462027311325073, embedding dim 4, hidden size 4, num layers 1, train loss 0.542508602142334, validation loss 0.808443009853363\n",
      "Epoch 980, current patience 7, model mean validation loss 0.8511519432067871, embedding dim 4, hidden size 4, num layers 1, train loss 0.5503013134002686, validation loss 0.864539384841919\n",
      "Epoch 990, current patience 6, model mean validation loss 0.8473036289215088, embedding dim 4, hidden size 4, num layers 1, train loss 0.47586458921432495, validation loss 0.8312656283378601\n",
      "Epoch 1000, current patience 5, model mean validation loss 0.8466957211494446, embedding dim 4, hidden size 4, num layers 1, train loss 0.5353673696517944, validation loss 0.8604732751846313\n",
      "Epoch 1010, current patience 4, model mean validation loss 0.8420476913452148, embedding dim 4, hidden size 4, num layers 1, train loss 0.5559027791023254, validation loss 0.8216688632965088\n",
      "Epoch 1020, current patience 3, model mean validation loss 0.8376739025115967, embedding dim 4, hidden size 4, num layers 1, train loss 0.6036215424537659, validation loss 0.8565378785133362\n",
      "Epoch 1030, current patience 2, model mean validation loss 0.8390688300132751, embedding dim 4, hidden size 4, num layers 1, train loss 0.7698112726211548, validation loss 0.8426231145858765\n",
      "Epoch 1040, current patience 1, model mean validation loss 0.8469399809837341, embedding dim 4, hidden size 4, num layers 1, train loss 0.43434393405914307, validation loss 0.8899688720703125\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0974940061569214, embedding dim 4, hidden size 8, num layers 1, train loss 1.1026171445846558, validation loss 1.0974940061569214\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0976169109344482, embedding dim 4, hidden size 8, num layers 1, train loss 1.097469687461853, validation loss 1.0977399349212646\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0971421003341675, embedding dim 4, hidden size 8, num layers 1, train loss 1.0922012329101562, validation loss 1.0961922407150269\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0966341495513916, embedding dim 4, hidden size 8, num layers 1, train loss 1.0967597961425781, validation loss 1.0951101779937744\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0964463949203491, embedding dim 4, hidden size 8, num layers 1, train loss 1.0988028049468994, validation loss 1.0956954956054688\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0961183309555054, embedding dim 4, hidden size 8, num layers 1, train loss 1.1083245277404785, validation loss 1.0944777727127075\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0960004329681396, embedding dim 4, hidden size 8, num layers 1, train loss 1.0942444801330566, validation loss 1.0952929258346558\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0953032970428467, embedding dim 4, hidden size 8, num layers 1, train loss 1.0892727375030518, validation loss 1.090423345565796\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0949680805206299, embedding dim 4, hidden size 8, num layers 1, train loss 1.0932466983795166, validation loss 1.094812273979187\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0948798656463623, embedding dim 4, hidden size 8, num layers 1, train loss 1.0795127153396606, validation loss 1.097033977508545\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094895601272583, embedding dim 4, hidden size 8, num layers 1, train loss 1.094602108001709, validation loss 1.0963191986083984\n",
      "Epoch 110, current patience 29, model mean validation loss 1.0946260690689087, embedding dim 4, hidden size 8, num layers 1, train loss 1.0819447040557861, validation loss 1.0929532051086426\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0941970348358154, embedding dim 4, hidden size 8, num layers 1, train loss 1.0881366729736328, validation loss 1.092262864112854\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0934561491012573, embedding dim 4, hidden size 8, num layers 1, train loss 1.0734596252441406, validation loss 1.088551640510559\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0922443866729736, embedding dim 4, hidden size 8, num layers 1, train loss 1.053637981414795, validation loss 1.0855985879898071\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0898091793060303, embedding dim 4, hidden size 8, num layers 1, train loss 1.030954122543335, validation loss 1.0709425210952759\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0851624011993408, embedding dim 4, hidden size 8, num layers 1, train loss 1.062561273574829, validation loss 1.0576380491256714\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0808424949645996, embedding dim 4, hidden size 8, num layers 1, train loss 1.0772736072540283, validation loss 1.062474012374878\n",
      "Epoch 180, current patience 30, model mean validation loss 1.076494574546814, embedding dim 4, hidden size 8, num layers 1, train loss 1.0033587217330933, validation loss 1.0615358352661133\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0718698501586914, embedding dim 4, hidden size 8, num layers 1, train loss 1.0070916414260864, validation loss 1.0559552907943726\n",
      "Epoch 200, current patience 30, model mean validation loss 1.063952922821045, embedding dim 4, hidden size 8, num layers 1, train loss 1.0342464447021484, validation loss 1.028926968574524\n",
      "Epoch 210, current patience 30, model mean validation loss 1.057377815246582, embedding dim 4, hidden size 8, num layers 1, train loss 1.070298433303833, validation loss 1.0359519720077515\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0484864711761475, embedding dim 4, hidden size 8, num layers 1, train loss 0.9617941379547119, validation loss 1.0144667625427246\n",
      "Epoch 230, current patience 30, model mean validation loss 1.043358564376831, embedding dim 4, hidden size 8, num layers 1, train loss 0.9619930982589722, validation loss 1.0299193859100342\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0380525588989258, embedding dim 4, hidden size 8, num layers 1, train loss 0.9687953591346741, validation loss 1.015190601348877\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0317504405975342, embedding dim 4, hidden size 8, num layers 1, train loss 0.9900487065315247, validation loss 1.0120564699172974\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0224634408950806, embedding dim 4, hidden size 8, num layers 1, train loss 0.9947559833526611, validation loss 0.987240195274353\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0127601623535156, embedding dim 4, hidden size 8, num layers 1, train loss 1.1344550848007202, validation loss 0.9783295392990112\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0118242502212524, embedding dim 4, hidden size 8, num layers 1, train loss 0.9529294967651367, validation loss 1.0214391946792603\n",
      "Epoch 290, current patience 30, model mean validation loss 1.004563808441162, embedding dim 4, hidden size 8, num layers 1, train loss 0.936856210231781, validation loss 0.9778679013252258\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9977704286575317, embedding dim 4, hidden size 8, num layers 1, train loss 1.0624635219573975, validation loss 0.960120439529419\n",
      "Epoch 310, current patience 30, model mean validation loss 0.991218090057373, embedding dim 4, hidden size 8, num layers 1, train loss 1.1300816535949707, validation loss 0.9775006771087646\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9835684299468994, embedding dim 4, hidden size 8, num layers 1, train loss 0.9173132181167603, validation loss 0.9539934396743774\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9750787019729614, embedding dim 4, hidden size 8, num layers 1, train loss 0.8321661949157715, validation loss 0.9441380500793457\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9704595804214478, embedding dim 4, hidden size 8, num layers 1, train loss 0.8595811128616333, validation loss 0.9502875804901123\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9645719528198242, embedding dim 4, hidden size 8, num layers 1, train loss 0.8636881113052368, validation loss 0.9312283992767334\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9529719352722168, embedding dim 4, hidden size 8, num layers 1, train loss 0.7923265099525452, validation loss 0.9286391139030457\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9444694519042969, embedding dim 4, hidden size 8, num layers 1, train loss 0.8199174404144287, validation loss 0.9098480343818665\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9369699954986572, embedding dim 4, hidden size 8, num layers 1, train loss 0.8141250014305115, validation loss 0.9001249670982361\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9281825423240662, embedding dim 4, hidden size 8, num layers 1, train loss 0.9555906057357788, validation loss 0.9072006344795227\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9211498498916626, embedding dim 4, hidden size 8, num layers 1, train loss 0.9075040817260742, validation loss 0.897732138633728\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9133365750312805, embedding dim 4, hidden size 8, num layers 1, train loss 0.8446685075759888, validation loss 0.8816314935684204\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9102698564529419, embedding dim 4, hidden size 8, num layers 1, train loss 0.9867078065872192, validation loss 0.9257538318634033\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9071812033653259, embedding dim 4, hidden size 8, num layers 1, train loss 0.7153365612030029, validation loss 0.9065194725990295\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9020425081253052, embedding dim 4, hidden size 8, num layers 1, train loss 0.8444358706474304, validation loss 0.8875297904014587\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8977298140525818, embedding dim 4, hidden size 8, num layers 1, train loss 0.879996657371521, validation loss 0.8753461241722107\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8936257362365723, embedding dim 4, hidden size 8, num layers 1, train loss 0.8284348249435425, validation loss 0.8672928810119629\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8893293142318726, embedding dim 4, hidden size 8, num layers 1, train loss 0.7290459275245667, validation loss 0.8728287220001221\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8873577117919922, embedding dim 4, hidden size 8, num layers 1, train loss 0.72491455078125, validation loss 0.8819593191146851\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8853065371513367, embedding dim 4, hidden size 8, num layers 1, train loss 0.8308050632476807, validation loss 0.8652224540710449\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8768884539604187, embedding dim 4, hidden size 8, num layers 1, train loss 0.9246841669082642, validation loss 0.8584089875221252\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8701299428939819, embedding dim 4, hidden size 8, num layers 1, train loss 0.6580467224121094, validation loss 0.852450966835022\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8657420873641968, embedding dim 4, hidden size 8, num layers 1, train loss 0.6740495562553406, validation loss 0.8524272441864014\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8621761798858643, embedding dim 4, hidden size 8, num layers 1, train loss 0.7059036493301392, validation loss 0.8468188047409058\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8616009950637817, embedding dim 4, hidden size 8, num layers 1, train loss 0.7270464301109314, validation loss 0.8626912236213684\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8622639179229736, embedding dim 4, hidden size 8, num layers 1, train loss 0.7719640135765076, validation loss 0.8781324028968811\n",
      "Epoch 560, current patience 29, model mean validation loss 0.8590802550315857, embedding dim 4, hidden size 8, num layers 1, train loss 0.8189719915390015, validation loss 0.8564900159835815\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8547163009643555, embedding dim 4, hidden size 8, num layers 1, train loss 0.7880117893218994, validation loss 0.8303106427192688\n",
      "Epoch 580, current patience 30, model mean validation loss 0.857458770275116, embedding dim 4, hidden size 8, num layers 1, train loss 0.6529825329780579, validation loss 0.8803484439849854\n",
      "Epoch 590, current patience 29, model mean validation loss 0.857053816318512, embedding dim 4, hidden size 8, num layers 1, train loss 0.7314021587371826, validation loss 0.8492116332054138\n",
      "Epoch 600, current patience 28, model mean validation loss 0.8544661402702332, embedding dim 4, hidden size 8, num layers 1, train loss 0.5854949951171875, validation loss 0.8317257165908813\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8515317440032959, embedding dim 4, hidden size 8, num layers 1, train loss 0.7138975858688354, validation loss 0.8233438730239868\n",
      "Epoch 620, current patience 30, model mean validation loss 0.8524432182312012, embedding dim 4, hidden size 8, num layers 1, train loss 0.6659383773803711, validation loss 0.8699830174446106\n",
      "Epoch 630, current patience 29, model mean validation loss 0.8530040979385376, embedding dim 4, hidden size 8, num layers 1, train loss 0.6046528220176697, validation loss 0.8826196789741516\n",
      "Epoch 640, current patience 28, model mean validation loss 0.8556779026985168, embedding dim 4, hidden size 8, num layers 1, train loss 0.7924894094467163, validation loss 0.8778799772262573\n",
      "Epoch 650, current patience 27, model mean validation loss 0.8588340282440186, embedding dim 4, hidden size 8, num layers 1, train loss 0.7253068089485168, validation loss 0.8555597066879272\n",
      "Epoch 660, current patience 26, model mean validation loss 0.8551278710365295, embedding dim 4, hidden size 8, num layers 1, train loss 0.532294750213623, validation loss 0.8506994843482971\n",
      "Epoch 670, current patience 25, model mean validation loss 0.8532496690750122, embedding dim 4, hidden size 8, num layers 1, train loss 0.6897920370101929, validation loss 0.8341858386993408\n",
      "Epoch 680, current patience 24, model mean validation loss 0.8550002574920654, embedding dim 4, hidden size 8, num layers 1, train loss 0.6663690805435181, validation loss 0.8457305431365967\n",
      "Epoch 690, current patience 23, model mean validation loss 0.855549693107605, embedding dim 4, hidden size 8, num layers 1, train loss 0.6092333793640137, validation loss 0.8277395963668823\n",
      "Epoch 700, current patience 22, model mean validation loss 0.853920042514801, embedding dim 4, hidden size 8, num layers 1, train loss 0.5842604637145996, validation loss 0.8569455146789551\n",
      "Epoch 710, current patience 21, model mean validation loss 0.8441363573074341, embedding dim 4, hidden size 8, num layers 1, train loss 0.5681793689727783, validation loss 0.8043502569198608\n",
      "Epoch 720, current patience 30, model mean validation loss 0.8375836610794067, embedding dim 4, hidden size 8, num layers 1, train loss 0.6566214561462402, validation loss 0.8254585266113281\n",
      "Epoch 730, current patience 30, model mean validation loss 0.8315733075141907, embedding dim 4, hidden size 8, num layers 1, train loss 0.7410373687744141, validation loss 0.8074766397476196\n",
      "Epoch 740, current patience 30, model mean validation loss 0.8275779485702515, embedding dim 4, hidden size 8, num layers 1, train loss 0.6609805822372437, validation loss 0.8187364935874939\n",
      "Epoch 750, current patience 30, model mean validation loss 0.8268267512321472, embedding dim 4, hidden size 8, num layers 1, train loss 0.7238216400146484, validation loss 0.8281764984130859\n",
      "Epoch 760, current patience 30, model mean validation loss 0.8235330581665039, embedding dim 4, hidden size 8, num layers 1, train loss 0.6473670601844788, validation loss 0.8193809986114502\n",
      "Epoch 770, current patience 30, model mean validation loss 0.8269333839416504, embedding dim 4, hidden size 8, num layers 1, train loss 0.5927048921585083, validation loss 0.8549414873123169\n",
      "Epoch 780, current patience 29, model mean validation loss 0.8253470659255981, embedding dim 4, hidden size 8, num layers 1, train loss 0.6190760135650635, validation loss 0.8442558646202087\n",
      "Epoch 790, current patience 28, model mean validation loss 0.8296585083007812, embedding dim 4, hidden size 8, num layers 1, train loss 0.48379307985305786, validation loss 0.8388416767120361\n",
      "Epoch 800, current patience 27, model mean validation loss 0.8287463784217834, embedding dim 4, hidden size 8, num layers 1, train loss 0.7221657633781433, validation loss 0.8181613087654114\n",
      "Epoch 810, current patience 26, model mean validation loss 0.8290494084358215, embedding dim 4, hidden size 8, num layers 1, train loss 0.5803428888320923, validation loss 0.8099011182785034\n",
      "Epoch 820, current patience 25, model mean validation loss 0.8333383798599243, embedding dim 4, hidden size 8, num layers 1, train loss 0.7175351977348328, validation loss 0.8530476689338684\n",
      "Epoch 830, current patience 24, model mean validation loss 0.8364341259002686, embedding dim 4, hidden size 8, num layers 1, train loss 0.8884689807891846, validation loss 0.8529432415962219\n",
      "Epoch 840, current patience 23, model mean validation loss 0.8363434672355652, embedding dim 4, hidden size 8, num layers 1, train loss 0.8301562070846558, validation loss 0.8186551928520203\n",
      "Epoch 850, current patience 22, model mean validation loss 0.8304182291030884, embedding dim 4, hidden size 8, num layers 1, train loss 0.5400365591049194, validation loss 0.8075398802757263\n",
      "Epoch 860, current patience 21, model mean validation loss 0.832135021686554, embedding dim 4, hidden size 8, num layers 1, train loss 0.6468896865844727, validation loss 0.8579903841018677\n",
      "Epoch 870, current patience 20, model mean validation loss 0.8292756080627441, embedding dim 4, hidden size 8, num layers 1, train loss 0.47059106826782227, validation loss 0.8159657716751099\n",
      "Epoch 880, current patience 19, model mean validation loss 0.8347774744033813, embedding dim 4, hidden size 8, num layers 1, train loss 0.5506365299224854, validation loss 0.8621764183044434\n",
      "Epoch 890, current patience 18, model mean validation loss 0.8371634483337402, embedding dim 4, hidden size 8, num layers 1, train loss 0.698327898979187, validation loss 0.828988790512085\n",
      "Epoch 900, current patience 17, model mean validation loss 0.8330856561660767, embedding dim 4, hidden size 8, num layers 1, train loss 0.712195634841919, validation loss 0.8204256296157837\n",
      "Epoch 910, current patience 16, model mean validation loss 0.8319903612136841, embedding dim 4, hidden size 8, num layers 1, train loss 0.47629085183143616, validation loss 0.8441807627677917\n",
      "Epoch 920, current patience 15, model mean validation loss 0.8350075483322144, embedding dim 4, hidden size 8, num layers 1, train loss 0.4425498843193054, validation loss 0.8427928686141968\n",
      "Epoch 930, current patience 14, model mean validation loss 0.8408111333847046, embedding dim 4, hidden size 8, num layers 1, train loss 0.5646909475326538, validation loss 0.8539681434631348\n",
      "Epoch 940, current patience 13, model mean validation loss 0.8346877694129944, embedding dim 4, hidden size 8, num layers 1, train loss 0.5450993180274963, validation loss 0.8090037703514099\n",
      "Epoch 950, current patience 12, model mean validation loss 0.8359179496765137, embedding dim 4, hidden size 8, num layers 1, train loss 0.7659835815429688, validation loss 0.8258076906204224\n",
      "Epoch 960, current patience 11, model mean validation loss 0.8305099010467529, embedding dim 4, hidden size 8, num layers 1, train loss 0.5004827976226807, validation loss 0.8189116716384888\n",
      "Epoch 970, current patience 10, model mean validation loss 0.8325620889663696, embedding dim 4, hidden size 8, num layers 1, train loss 0.7362650632858276, validation loss 0.845406174659729\n",
      "Epoch 980, current patience 9, model mean validation loss 0.8326331377029419, embedding dim 4, hidden size 8, num layers 1, train loss 0.4352133274078369, validation loss 0.8209937214851379\n",
      "Epoch 990, current patience 8, model mean validation loss 0.8332464694976807, embedding dim 4, hidden size 8, num layers 1, train loss 0.40597468614578247, validation loss 0.8490874767303467\n",
      "Epoch 1000, current patience 7, model mean validation loss 0.8316640853881836, embedding dim 4, hidden size 8, num layers 1, train loss 0.5380770564079285, validation loss 0.8301336169242859\n",
      "Epoch 1010, current patience 6, model mean validation loss 0.8313286304473877, embedding dim 4, hidden size 8, num layers 1, train loss 0.7897810935974121, validation loss 0.8512855768203735\n",
      "Epoch 1020, current patience 5, model mean validation loss 0.8365004658699036, embedding dim 4, hidden size 8, num layers 1, train loss 0.43738043308258057, validation loss 0.8503780961036682\n",
      "Epoch 1030, current patience 4, model mean validation loss 0.8353631496429443, embedding dim 4, hidden size 8, num layers 1, train loss 0.6813677549362183, validation loss 0.8167087435722351\n",
      "Epoch 1040, current patience 3, model mean validation loss 0.8359243869781494, embedding dim 4, hidden size 8, num layers 1, train loss 0.5671688318252563, validation loss 0.8234015107154846\n",
      "Epoch 1050, current patience 2, model mean validation loss 0.8376234769821167, embedding dim 4, hidden size 8, num layers 1, train loss 0.5552686452865601, validation loss 0.8589987754821777\n",
      "Epoch 1060, current patience 1, model mean validation loss 0.8462275266647339, embedding dim 4, hidden size 8, num layers 1, train loss 0.47941267490386963, validation loss 0.8898265361785889\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0968632698059082, embedding dim 4, hidden size 16, num layers 1, train loss 1.100312352180481, validation loss 1.0968632698059082\n",
      "Epoch 10, current patience 30, model mean validation loss 1.097176194190979, embedding dim 4, hidden size 16, num layers 1, train loss 1.110525369644165, validation loss 1.0974891185760498\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0972850322723389, embedding dim 4, hidden size 16, num layers 1, train loss 1.0982120037078857, validation loss 1.0975027084350586\n",
      "Epoch 30, current patience 28, model mean validation loss 1.0968482494354248, embedding dim 4, hidden size 16, num layers 1, train loss 1.090646743774414, validation loss 1.0955379009246826\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0968072414398193, embedding dim 4, hidden size 16, num layers 1, train loss 1.1114873886108398, validation loss 1.0966436862945557\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0965272188186646, embedding dim 4, hidden size 16, num layers 1, train loss 1.1145403385162354, validation loss 1.0951271057128906\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0960588455200195, embedding dim 4, hidden size 16, num layers 1, train loss 1.087333083152771, validation loss 1.093247652053833\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0959911346435547, embedding dim 4, hidden size 16, num layers 1, train loss 1.089838981628418, validation loss 1.0955171585083008\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0964884757995605, embedding dim 4, hidden size 16, num layers 1, train loss 1.0948724746704102, validation loss 1.100842833518982\n",
      "Epoch 90, current patience 29, model mean validation loss 1.0963778495788574, embedding dim 4, hidden size 16, num layers 1, train loss 1.0915946960449219, validation loss 1.0966041088104248\n",
      "Epoch 100, current patience 28, model mean validation loss 1.095203161239624, embedding dim 4, hidden size 16, num layers 1, train loss 1.0918360948562622, validation loss 1.0881049633026123\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0948970317840576, embedding dim 4, hidden size 16, num layers 1, train loss 1.088862657546997, validation loss 1.0930886268615723\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0938224792480469, embedding dim 4, hidden size 16, num layers 1, train loss 1.102980375289917, validation loss 1.0880470275878906\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0934572219848633, embedding dim 4, hidden size 16, num layers 1, train loss 1.0903865098953247, validation loss 1.0922057628631592\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0921785831451416, embedding dim 4, hidden size 16, num layers 1, train loss 1.0582854747772217, validation loss 1.0830183029174805\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0893748998641968, embedding dim 4, hidden size 16, num layers 1, train loss 1.109987497329712, validation loss 1.073087215423584\n",
      "Epoch 160, current patience 30, model mean validation loss 1.085608720779419, embedding dim 4, hidden size 16, num layers 1, train loss 1.080155611038208, validation loss 1.0707135200500488\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0807535648345947, embedding dim 4, hidden size 16, num layers 1, train loss 1.0659661293029785, validation loss 1.0577623844146729\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0759177207946777, embedding dim 4, hidden size 16, num layers 1, train loss 1.0695438385009766, validation loss 1.0494195222854614\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0678126811981201, embedding dim 4, hidden size 16, num layers 1, train loss 1.011412262916565, validation loss 1.0282480716705322\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0572705268859863, embedding dim 4, hidden size 16, num layers 1, train loss 0.9951463937759399, validation loss 1.0037087202072144\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0443005561828613, embedding dim 4, hidden size 16, num layers 1, train loss 1.001432180404663, validation loss 0.9884463548660278\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0356452465057373, embedding dim 4, hidden size 16, num layers 1, train loss 0.9208153486251831, validation loss 1.0137758255004883\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0240952968597412, embedding dim 4, hidden size 16, num layers 1, train loss 0.8831287026405334, validation loss 0.9806877374649048\n",
      "Epoch 240, current patience 30, model mean validation loss 1.011181354522705, embedding dim 4, hidden size 16, num layers 1, train loss 0.8704548478126526, validation loss 0.9674026370048523\n",
      "Epoch 250, current patience 30, model mean validation loss 0.998677134513855, embedding dim 4, hidden size 16, num layers 1, train loss 0.8142310380935669, validation loss 0.9577282071113586\n",
      "Epoch 260, current patience 30, model mean validation loss 0.982319712638855, embedding dim 4, hidden size 16, num layers 1, train loss 0.8525211215019226, validation loss 0.9185601472854614\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9679476022720337, embedding dim 4, hidden size 16, num layers 1, train loss 0.886555552482605, validation loss 0.913271427154541\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9543554782867432, embedding dim 4, hidden size 16, num layers 1, train loss 0.7710446119308472, validation loss 0.8949719071388245\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9399948120117188, embedding dim 4, hidden size 16, num layers 1, train loss 0.9501377940177917, validation loss 0.8735603094100952\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9255625009536743, embedding dim 4, hidden size 16, num layers 1, train loss 0.7941553592681885, validation loss 0.8983175158500671\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9153289198875427, embedding dim 4, hidden size 16, num layers 1, train loss 0.7334071397781372, validation loss 0.8988189697265625\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9065777063369751, embedding dim 4, hidden size 16, num layers 1, train loss 0.7630170583724976, validation loss 0.8973931074142456\n",
      "Epoch 330, current patience 30, model mean validation loss 0.897409200668335, embedding dim 4, hidden size 16, num layers 1, train loss 0.9146100878715515, validation loss 0.8843798637390137\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8889530897140503, embedding dim 4, hidden size 16, num layers 1, train loss 0.7596707344055176, validation loss 0.8509114384651184\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8818309307098389, embedding dim 4, hidden size 16, num layers 1, train loss 0.847412109375, validation loss 0.8562940359115601\n",
      "Epoch 360, current patience 30, model mean validation loss 0.874761700630188, embedding dim 4, hidden size 16, num layers 1, train loss 0.8276641964912415, validation loss 0.8384180068969727\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8697998523712158, embedding dim 4, hidden size 16, num layers 1, train loss 0.7771156430244446, validation loss 0.8338658809661865\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8602328300476074, embedding dim 4, hidden size 16, num layers 1, train loss 0.671006441116333, validation loss 0.8217810988426208\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8501476645469666, embedding dim 4, hidden size 16, num layers 1, train loss 0.8813385963439941, validation loss 0.8181381821632385\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8411980867385864, embedding dim 4, hidden size 16, num layers 1, train loss 0.7319560050964355, validation loss 0.8257962465286255\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8336125612258911, embedding dim 4, hidden size 16, num layers 1, train loss 0.6241122484207153, validation loss 0.8236953616142273\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8330336213111877, embedding dim 4, hidden size 16, num layers 1, train loss 0.8372597098350525, validation loss 0.846280038356781\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8266611099243164, embedding dim 4, hidden size 16, num layers 1, train loss 0.7094295024871826, validation loss 0.8053140640258789\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8202822208404541, embedding dim 4, hidden size 16, num layers 1, train loss 0.607659101486206, validation loss 0.7873867750167847\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8134291172027588, embedding dim 4, hidden size 16, num layers 1, train loss 0.7198023200035095, validation loss 0.7790412902832031\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8119205236434937, embedding dim 4, hidden size 16, num layers 1, train loss 0.8872923254966736, validation loss 0.809712290763855\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8051312565803528, embedding dim 4, hidden size 16, num layers 1, train loss 0.7354884743690491, validation loss 0.7638238668441772\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8018928170204163, embedding dim 4, hidden size 16, num layers 1, train loss 0.5930629968643188, validation loss 0.7998887300491333\n",
      "Epoch 490, current patience 30, model mean validation loss 0.7987684011459351, embedding dim 4, hidden size 16, num layers 1, train loss 0.7421488761901855, validation loss 0.7987004518508911\n",
      "Epoch 500, current patience 30, model mean validation loss 0.7890512943267822, embedding dim 4, hidden size 16, num layers 1, train loss 0.5845915079116821, validation loss 0.7685426473617554\n",
      "Epoch 510, current patience 30, model mean validation loss 0.7858697175979614, embedding dim 4, hidden size 16, num layers 1, train loss 0.7777069807052612, validation loss 0.7798619270324707\n",
      "Epoch 520, current patience 30, model mean validation loss 0.7813629508018494, embedding dim 4, hidden size 16, num layers 1, train loss 0.7231992483139038, validation loss 0.7513322830200195\n",
      "Epoch 530, current patience 30, model mean validation loss 0.7791943550109863, embedding dim 4, hidden size 16, num layers 1, train loss 0.5938805937767029, validation loss 0.7616929411888123\n",
      "Epoch 540, current patience 30, model mean validation loss 0.7703827619552612, embedding dim 4, hidden size 16, num layers 1, train loss 0.5196599960327148, validation loss 0.7392191886901855\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7392191886901855_4_16_1_540.pt\n",
      "Epoch 550, current patience 30, model mean validation loss 0.7687986493110657, embedding dim 4, hidden size 16, num layers 1, train loss 0.793582558631897, validation loss 0.7511510848999023\n",
      "Epoch 560, current patience 30, model mean validation loss 0.762749433517456, embedding dim 4, hidden size 16, num layers 1, train loss 0.7484343647956848, validation loss 0.7514949440956116\n",
      "Epoch 570, current patience 30, model mean validation loss 0.7574412226676941, embedding dim 4, hidden size 16, num layers 1, train loss 0.8123946189880371, validation loss 0.7562347054481506\n",
      "Epoch 580, current patience 30, model mean validation loss 0.753097653388977, embedding dim 4, hidden size 16, num layers 1, train loss 0.5709149837493896, validation loss 0.7337943315505981\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7337943315505981_4_16_1_580.pt\n",
      "Epoch 590, current patience 30, model mean validation loss 0.7550088763237, embedding dim 4, hidden size 16, num layers 1, train loss 0.47080397605895996, validation loss 0.7951517701148987\n",
      "Epoch 600, current patience 29, model mean validation loss 0.7565320730209351, embedding dim 4, hidden size 16, num layers 1, train loss 0.7098610401153564, validation loss 0.7635179758071899\n",
      "Epoch 610, current patience 28, model mean validation loss 0.7584860920906067, embedding dim 4, hidden size 16, num layers 1, train loss 0.7044858932495117, validation loss 0.7773245573043823\n",
      "Epoch 620, current patience 27, model mean validation loss 0.7618472576141357, embedding dim 4, hidden size 16, num layers 1, train loss 0.5969446897506714, validation loss 0.7661086320877075\n",
      "Epoch 630, current patience 26, model mean validation loss 0.7652034163475037, embedding dim 4, hidden size 16, num layers 1, train loss 0.7779392600059509, validation loss 0.7780002355575562\n",
      "Epoch 640, current patience 25, model mean validation loss 0.7673428654670715, embedding dim 4, hidden size 16, num layers 1, train loss 0.738833487033844, validation loss 0.7686108350753784\n",
      "Epoch 650, current patience 24, model mean validation loss 0.7709954977035522, embedding dim 4, hidden size 16, num layers 1, train loss 0.6500964164733887, validation loss 0.7854560613632202\n",
      "Epoch 660, current patience 23, model mean validation loss 0.7777217030525208, embedding dim 4, hidden size 16, num layers 1, train loss 0.4521936774253845, validation loss 0.7876036167144775\n",
      "Epoch 670, current patience 22, model mean validation loss 0.773003339767456, embedding dim 4, hidden size 16, num layers 1, train loss 0.6790813207626343, validation loss 0.7574049234390259\n",
      "Epoch 680, current patience 21, model mean validation loss 0.7712253928184509, embedding dim 4, hidden size 16, num layers 1, train loss 0.6902466416358948, validation loss 0.7492945194244385\n",
      "Epoch 690, current patience 20, model mean validation loss 0.7672452926635742, embedding dim 4, hidden size 16, num layers 1, train loss 0.6694122552871704, validation loss 0.7454837560653687\n",
      "Epoch 700, current patience 19, model mean validation loss 0.7644356489181519, embedding dim 4, hidden size 16, num layers 1, train loss 0.48144274950027466, validation loss 0.74363112449646\n",
      "Epoch 710, current patience 18, model mean validation loss 0.7652506828308105, embedding dim 4, hidden size 16, num layers 1, train loss 0.4929484724998474, validation loss 0.7845206260681152\n",
      "Epoch 720, current patience 17, model mean validation loss 0.7626533508300781, embedding dim 4, hidden size 16, num layers 1, train loss 0.6916719079017639, validation loss 0.747832179069519\n",
      "Epoch 730, current patience 16, model mean validation loss 0.7582254409790039, embedding dim 4, hidden size 16, num layers 1, train loss 0.7702211141586304, validation loss 0.7500330209732056\n",
      "Epoch 740, current patience 15, model mean validation loss 0.7560285329818726, embedding dim 4, hidden size 16, num layers 1, train loss 0.7294528484344482, validation loss 0.7700281739234924\n",
      "Epoch 750, current patience 14, model mean validation loss 0.7551365494728088, embedding dim 4, hidden size 16, num layers 1, train loss 0.512836217880249, validation loss 0.7502689957618713\n",
      "Epoch 760, current patience 13, model mean validation loss 0.758263349533081, embedding dim 4, hidden size 16, num layers 1, train loss 0.5810058116912842, validation loss 0.7743091583251953\n",
      "Epoch 770, current patience 12, model mean validation loss 0.7630986571311951, embedding dim 4, hidden size 16, num layers 1, train loss 0.7105368375778198, validation loss 0.7841662764549255\n",
      "Epoch 780, current patience 11, model mean validation loss 0.7670271992683411, embedding dim 4, hidden size 16, num layers 1, train loss 0.7201684713363647, validation loss 0.7750590443611145\n",
      "Epoch 790, current patience 10, model mean validation loss 0.7652568817138672, embedding dim 4, hidden size 16, num layers 1, train loss 0.4804864227771759, validation loss 0.7703583240509033\n",
      "Epoch 800, current patience 9, model mean validation loss 0.7667766809463501, embedding dim 4, hidden size 16, num layers 1, train loss 0.5315056443214417, validation loss 0.7599905133247375\n",
      "Epoch 810, current patience 8, model mean validation loss 0.7680256366729736, embedding dim 4, hidden size 16, num layers 1, train loss 0.6523978114128113, validation loss 0.7600252628326416\n",
      "Epoch 820, current patience 7, model mean validation loss 0.7681847810745239, embedding dim 4, hidden size 16, num layers 1, train loss 0.5168278217315674, validation loss 0.7713007926940918\n",
      "Epoch 830, current patience 6, model mean validation loss 0.7693734169006348, embedding dim 4, hidden size 16, num layers 1, train loss 0.64451664686203, validation loss 0.7597776651382446\n",
      "Epoch 840, current patience 5, model mean validation loss 0.775302529335022, embedding dim 4, hidden size 16, num layers 1, train loss 0.5578188896179199, validation loss 0.8217423558235168\n",
      "Epoch 850, current patience 4, model mean validation loss 0.7745301723480225, embedding dim 4, hidden size 16, num layers 1, train loss 0.38757234811782837, validation loss 0.7779874801635742\n",
      "Epoch 860, current patience 3, model mean validation loss 0.7780110836029053, embedding dim 4, hidden size 16, num layers 1, train loss 0.5202966928482056, validation loss 0.8029062151908875\n",
      "Epoch 870, current patience 2, model mean validation loss 0.7816433906555176, embedding dim 4, hidden size 16, num layers 1, train loss 0.3767207860946655, validation loss 0.7994166612625122\n",
      "Epoch 880, current patience 1, model mean validation loss 0.7896829843521118, embedding dim 4, hidden size 16, num layers 1, train loss 0.45343083143234253, validation loss 0.8243073225021362\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1046867370605469, embedding dim 4, hidden size 32, num layers 1, train loss 1.0930505990982056, validation loss 1.1046867370605469\n",
      "Epoch 10, current patience 30, model mean validation loss 1.102053165435791, embedding dim 4, hidden size 32, num layers 1, train loss 1.1129088401794434, validation loss 1.0994194746017456\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0996705293655396, embedding dim 4, hidden size 32, num layers 1, train loss 1.103166103363037, validation loss 1.094905138015747\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0982179641723633, embedding dim 4, hidden size 32, num layers 1, train loss 1.0916316509246826, validation loss 1.0938606262207031\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0976585149765015, embedding dim 4, hidden size 32, num layers 1, train loss 1.0942862033843994, validation loss 1.0954203605651855\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0968705415725708, embedding dim 4, hidden size 32, num layers 1, train loss 1.087890863418579, validation loss 1.0929306745529175\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0956249237060547, embedding dim 4, hidden size 32, num layers 1, train loss 1.0743037462234497, validation loss 1.088150978088379\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0951833724975586, embedding dim 4, hidden size 32, num layers 1, train loss 1.0901347398757935, validation loss 1.0920939445495605\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0931580066680908, embedding dim 4, hidden size 32, num layers 1, train loss 1.0827656984329224, validation loss 1.08848237991333\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0923434495925903, embedding dim 4, hidden size 32, num layers 1, train loss 1.0855674743652344, validation loss 1.0929031372070312\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0909719467163086, embedding dim 4, hidden size 32, num layers 1, train loss 1.1013671159744263, validation loss 1.0839333534240723\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0895652770996094, embedding dim 4, hidden size 32, num layers 1, train loss 1.093534231185913, validation loss 1.082607626914978\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0882110595703125, embedding dim 4, hidden size 32, num layers 1, train loss 1.1086264848709106, validation loss 1.0845859050750732\n",
      "Epoch 130, current patience 30, model mean validation loss 1.08505117893219, embedding dim 4, hidden size 32, num layers 1, train loss 1.087275743484497, validation loss 1.0676515102386475\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0827531814575195, embedding dim 4, hidden size 32, num layers 1, train loss 1.0337529182434082, validation loss 1.0697672367095947\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0778803825378418, embedding dim 4, hidden size 32, num layers 1, train loss 1.017406702041626, validation loss 1.0531114339828491\n",
      "Epoch 160, current patience 30, model mean validation loss 1.071115493774414, embedding dim 4, hidden size 32, num layers 1, train loss 1.0097661018371582, validation loss 1.0343642234802246\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0647813081741333, embedding dim 4, hidden size 32, num layers 1, train loss 0.978066086769104, validation loss 1.0422289371490479\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0584512948989868, embedding dim 4, hidden size 32, num layers 1, train loss 1.0375781059265137, validation loss 1.0332934856414795\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0493476390838623, embedding dim 4, hidden size 32, num layers 1, train loss 1.0252008438110352, validation loss 1.0097788572311401\n",
      "Epoch 200, current patience 30, model mean validation loss 1.039551019668579, embedding dim 4, hidden size 32, num layers 1, train loss 1.0252046585083008, validation loss 1.0062129497528076\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0332598686218262, embedding dim 4, hidden size 32, num layers 1, train loss 0.9540925025939941, validation loss 1.0173219442367554\n",
      "Epoch 220, current patience 30, model mean validation loss 1.024477243423462, embedding dim 4, hidden size 32, num layers 1, train loss 0.9043610095977783, validation loss 0.9995063543319702\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0146052837371826, embedding dim 4, hidden size 32, num layers 1, train loss 0.9603332281112671, validation loss 0.9741350412368774\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0052785873413086, embedding dim 4, hidden size 32, num layers 1, train loss 0.8421825170516968, validation loss 0.9597512483596802\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9928809404373169, embedding dim 4, hidden size 32, num layers 1, train loss 0.9179583787918091, validation loss 0.9430476427078247\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9841892123222351, embedding dim 4, hidden size 32, num layers 1, train loss 0.9082742929458618, validation loss 0.9637596607208252\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9732567667961121, embedding dim 4, hidden size 32, num layers 1, train loss 1.0045527219772339, validation loss 0.9223192930221558\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9625846743583679, embedding dim 4, hidden size 32, num layers 1, train loss 0.8481912612915039, validation loss 0.920836329460144\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9490147829055786, embedding dim 4, hidden size 32, num layers 1, train loss 0.9168528318405151, validation loss 0.9087625741958618\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9380648136138916, embedding dim 4, hidden size 32, num layers 1, train loss 0.8335492610931396, validation loss 0.9119067192077637\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9321994781494141, embedding dim 4, hidden size 32, num layers 1, train loss 0.8288359642028809, validation loss 0.9272120594978333\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9254409074783325, embedding dim 4, hidden size 32, num layers 1, train loss 0.8364478349685669, validation loss 0.9056829214096069\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9219895005226135, embedding dim 4, hidden size 32, num layers 1, train loss 0.8053314089775085, validation loss 0.9154366254806519\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9159995317459106, embedding dim 4, hidden size 32, num layers 1, train loss 0.8264538645744324, validation loss 0.9158399105072021\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9113537073135376, embedding dim 4, hidden size 32, num layers 1, train loss 0.8305432200431824, validation loss 0.8851525783538818\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9099460244178772, embedding dim 4, hidden size 32, num layers 1, train loss 0.8191463947296143, validation loss 0.9095747470855713\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9043470621109009, embedding dim 4, hidden size 32, num layers 1, train loss 0.7158493995666504, validation loss 0.8639711737632751\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8963053822517395, embedding dim 4, hidden size 32, num layers 1, train loss 0.6604958772659302, validation loss 0.8475730419158936\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8903470039367676, embedding dim 4, hidden size 32, num layers 1, train loss 0.7984120845794678, validation loss 0.879544734954834\n",
      "Epoch 400, current patience 30, model mean validation loss 0.88606858253479, embedding dim 4, hidden size 32, num layers 1, train loss 0.874604344367981, validation loss 0.8714558482170105\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8776232600212097, embedding dim 4, hidden size 32, num layers 1, train loss 0.7240312099456787, validation loss 0.8478738069534302\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8709335327148438, embedding dim 4, hidden size 32, num layers 1, train loss 0.6696169376373291, validation loss 0.8623221516609192\n",
      "Epoch 430, current patience 30, model mean validation loss 0.865003228187561, embedding dim 4, hidden size 32, num layers 1, train loss 0.638365626335144, validation loss 0.8377106189727783\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8557306528091431, embedding dim 4, hidden size 32, num layers 1, train loss 0.7327294945716858, validation loss 0.8353942632675171\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8504674434661865, embedding dim 4, hidden size 32, num layers 1, train loss 0.8243433237075806, validation loss 0.8218652009963989\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8489639759063721, embedding dim 4, hidden size 32, num layers 1, train loss 0.8185811042785645, validation loss 0.8355451822280884\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8463712334632874, embedding dim 4, hidden size 32, num layers 1, train loss 0.5809550285339355, validation loss 0.8588031530380249\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8394836187362671, embedding dim 4, hidden size 32, num layers 1, train loss 0.57647705078125, validation loss 0.8163543343544006\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8365226984024048, embedding dim 4, hidden size 32, num layers 1, train loss 0.606879472732544, validation loss 0.8241864442825317\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8307492733001709, embedding dim 4, hidden size 32, num layers 1, train loss 0.744755744934082, validation loss 0.8161348700523376\n",
      "Epoch 510, current patience 30, model mean validation loss 0.826371967792511, embedding dim 4, hidden size 32, num layers 1, train loss 0.6384009122848511, validation loss 0.8026924729347229\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8224060535430908, embedding dim 4, hidden size 32, num layers 1, train loss 0.6624497771263123, validation loss 0.8036662340164185\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8226826786994934, embedding dim 4, hidden size 32, num layers 1, train loss 0.7093620300292969, validation loss 0.8240789175033569\n",
      "Epoch 540, current patience 29, model mean validation loss 0.8237695693969727, embedding dim 4, hidden size 32, num layers 1, train loss 0.5679901838302612, validation loss 0.8442395329475403\n",
      "Epoch 550, current patience 28, model mean validation loss 0.8219472765922546, embedding dim 4, hidden size 32, num layers 1, train loss 0.7585173845291138, validation loss 0.844225287437439\n",
      "Epoch 560, current patience 30, model mean validation loss 0.821399986743927, embedding dim 4, hidden size 32, num layers 1, train loss 0.6329001188278198, validation loss 0.8119758367538452\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8172308206558228, embedding dim 4, hidden size 32, num layers 1, train loss 0.573408842086792, validation loss 0.7908329367637634\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8128777742385864, embedding dim 4, hidden size 32, num layers 1, train loss 0.5635969042778015, validation loss 0.78131103515625\n",
      "Epoch 590, current patience 30, model mean validation loss 0.8129295110702515, embedding dim 4, hidden size 32, num layers 1, train loss 0.8452138900756836, validation loss 0.8031063675880432\n",
      "Epoch 600, current patience 29, model mean validation loss 0.8117238283157349, embedding dim 4, hidden size 32, num layers 1, train loss 0.5105557441711426, validation loss 0.7940205335617065\n",
      "Epoch 610, current patience 30, model mean validation loss 0.8056711554527283, embedding dim 4, hidden size 32, num layers 1, train loss 0.5964040756225586, validation loss 0.7756576538085938\n",
      "Epoch 620, current patience 30, model mean validation loss 0.7974778413772583, embedding dim 4, hidden size 32, num layers 1, train loss 0.6789035797119141, validation loss 0.7786930203437805\n",
      "Epoch 630, current patience 30, model mean validation loss 0.7925808429718018, embedding dim 4, hidden size 32, num layers 1, train loss 0.5201622247695923, validation loss 0.805049479007721\n",
      "Epoch 640, current patience 30, model mean validation loss 0.7892482876777649, embedding dim 4, hidden size 32, num layers 1, train loss 0.5984532833099365, validation loss 0.7853152751922607\n",
      "Epoch 650, current patience 30, model mean validation loss 0.7908402681350708, embedding dim 4, hidden size 32, num layers 1, train loss 0.580702006816864, validation loss 0.8035690784454346\n",
      "Epoch 660, current patience 29, model mean validation loss 0.7963752150535583, embedding dim 4, hidden size 32, num layers 1, train loss 0.6292170882225037, validation loss 0.8255903124809265\n",
      "Epoch 670, current patience 28, model mean validation loss 0.7940198183059692, embedding dim 4, hidden size 32, num layers 1, train loss 0.7662442922592163, validation loss 0.7842629551887512\n",
      "Epoch 680, current patience 27, model mean validation loss 0.7955463528633118, embedding dim 4, hidden size 32, num layers 1, train loss 0.8614712953567505, validation loss 0.8062331676483154\n",
      "Epoch 690, current patience 26, model mean validation loss 0.7980379462242126, embedding dim 4, hidden size 32, num layers 1, train loss 0.6223127245903015, validation loss 0.7955902814865112\n",
      "Epoch 700, current patience 25, model mean validation loss 0.8015609979629517, embedding dim 4, hidden size 32, num layers 1, train loss 0.6707043051719666, validation loss 0.8068776726722717\n",
      "Epoch 710, current patience 24, model mean validation loss 0.7997722625732422, embedding dim 4, hidden size 32, num layers 1, train loss 0.6298273205757141, validation loss 0.7907394170761108\n",
      "Epoch 720, current patience 23, model mean validation loss 0.8011457920074463, embedding dim 4, hidden size 32, num layers 1, train loss 0.668641209602356, validation loss 0.7963032722473145\n",
      "Epoch 730, current patience 22, model mean validation loss 0.797359049320221, embedding dim 4, hidden size 32, num layers 1, train loss 0.6139297485351562, validation loss 0.7732748985290527\n",
      "Epoch 740, current patience 21, model mean validation loss 0.7932839393615723, embedding dim 4, hidden size 32, num layers 1, train loss 0.5219827890396118, validation loss 0.7929897308349609\n",
      "Epoch 750, current patience 20, model mean validation loss 0.7918845415115356, embedding dim 4, hidden size 32, num layers 1, train loss 0.4573008716106415, validation loss 0.7730680108070374\n",
      "Epoch 760, current patience 19, model mean validation loss 0.7887512445449829, embedding dim 4, hidden size 32, num layers 1, train loss 0.40389370918273926, validation loss 0.7811663150787354\n",
      "Epoch 770, current patience 30, model mean validation loss 0.7873600125312805, embedding dim 4, hidden size 32, num layers 1, train loss 0.6459625363349915, validation loss 0.7844609022140503\n",
      "Epoch 780, current patience 30, model mean validation loss 0.7844681739807129, embedding dim 4, hidden size 32, num layers 1, train loss 0.5339697003364563, validation loss 0.7837430834770203\n",
      "Epoch 790, current patience 30, model mean validation loss 0.7861875295639038, embedding dim 4, hidden size 32, num layers 1, train loss 0.5329709053039551, validation loss 0.8044944405555725\n",
      "Epoch 800, current patience 29, model mean validation loss 0.7876706123352051, embedding dim 4, hidden size 32, num layers 1, train loss 0.4640668034553528, validation loss 0.8081678152084351\n",
      "Epoch 810, current patience 28, model mean validation loss 0.7833682298660278, embedding dim 4, hidden size 32, num layers 1, train loss 0.5603854656219482, validation loss 0.7388556003570557\n",
      "Epoch 820, current patience 30, model mean validation loss 0.783130407333374, embedding dim 4, hidden size 32, num layers 1, train loss 0.46692678332328796, validation loss 0.7910867929458618\n",
      "Epoch 830, current patience 30, model mean validation loss 0.7881640195846558, embedding dim 4, hidden size 32, num layers 1, train loss 0.4412260055541992, validation loss 0.8133373856544495\n",
      "Epoch 840, current patience 29, model mean validation loss 0.786821722984314, embedding dim 4, hidden size 32, num layers 1, train loss 0.5533506274223328, validation loss 0.7704275846481323\n",
      "Epoch 850, current patience 28, model mean validation loss 0.7830373644828796, embedding dim 4, hidden size 32, num layers 1, train loss 0.4927978217601776, validation loss 0.7541857957839966\n",
      "Epoch 860, current patience 30, model mean validation loss 0.7802678346633911, embedding dim 4, hidden size 32, num layers 1, train loss 0.6814658641815186, validation loss 0.7615873217582703\n",
      "Epoch 870, current patience 30, model mean validation loss 0.7797565460205078, embedding dim 4, hidden size 32, num layers 1, train loss 0.5144275426864624, validation loss 0.8004042506217957\n",
      "Epoch 880, current patience 30, model mean validation loss 0.7789989709854126, embedding dim 4, hidden size 32, num layers 1, train loss 0.4680359363555908, validation loss 0.8021072745323181\n",
      "Epoch 890, current patience 30, model mean validation loss 0.7866660356521606, embedding dim 4, hidden size 32, num layers 1, train loss 0.4050208330154419, validation loss 0.8001920580863953\n",
      "Epoch 900, current patience 29, model mean validation loss 0.7930876612663269, embedding dim 4, hidden size 32, num layers 1, train loss 0.392772912979126, validation loss 0.842460036277771\n",
      "Epoch 910, current patience 28, model mean validation loss 0.7924736738204956, embedding dim 4, hidden size 32, num layers 1, train loss 0.5034056305885315, validation loss 0.80842524766922\n",
      "Epoch 920, current patience 27, model mean validation loss 0.7983431816101074, embedding dim 4, hidden size 32, num layers 1, train loss 0.4753289818763733, validation loss 0.817383348941803\n",
      "Epoch 930, current patience 26, model mean validation loss 0.8058871030807495, embedding dim 4, hidden size 32, num layers 1, train loss 0.4967212677001953, validation loss 0.8145374059677124\n",
      "Epoch 940, current patience 25, model mean validation loss 0.8075740337371826, embedding dim 4, hidden size 32, num layers 1, train loss 0.5235793590545654, validation loss 0.7750828266143799\n",
      "Epoch 950, current patience 24, model mean validation loss 0.8008304834365845, embedding dim 4, hidden size 32, num layers 1, train loss 0.6128458976745605, validation loss 0.7464559078216553\n",
      "Epoch 960, current patience 23, model mean validation loss 0.80190110206604, embedding dim 4, hidden size 32, num layers 1, train loss 0.49389052391052246, validation loss 0.8106721043586731\n",
      "Epoch 970, current patience 22, model mean validation loss 0.8022621870040894, embedding dim 4, hidden size 32, num layers 1, train loss 0.5667728781700134, validation loss 0.8030806183815002\n",
      "Epoch 980, current patience 21, model mean validation loss 0.7915544509887695, embedding dim 4, hidden size 32, num layers 1, train loss 0.6524738669395447, validation loss 0.7567979097366333\n",
      "Epoch 990, current patience 20, model mean validation loss 0.7895166873931885, embedding dim 4, hidden size 32, num layers 1, train loss 0.5099883079528809, validation loss 0.7921229600906372\n",
      "Epoch 1000, current patience 19, model mean validation loss 0.7853571176528931, embedding dim 4, hidden size 32, num layers 1, train loss 0.5031052827835083, validation loss 0.7841066718101501\n",
      "Epoch 1010, current patience 18, model mean validation loss 0.787156879901886, embedding dim 4, hidden size 32, num layers 1, train loss 0.41474759578704834, validation loss 0.8289359211921692\n",
      "Epoch 1020, current patience 17, model mean validation loss 0.7912939786911011, embedding dim 4, hidden size 32, num layers 1, train loss 0.47209328413009644, validation loss 0.808179497718811\n",
      "Epoch 1030, current patience 16, model mean validation loss 0.7994246482849121, embedding dim 4, hidden size 32, num layers 1, train loss 0.34714558720588684, validation loss 0.811501145362854\n",
      "Epoch 1040, current patience 15, model mean validation loss 0.8013738989830017, embedding dim 4, hidden size 32, num layers 1, train loss 0.5731181502342224, validation loss 0.8262664079666138\n",
      "Epoch 1050, current patience 14, model mean validation loss 0.8054150342941284, embedding dim 4, hidden size 32, num layers 1, train loss 0.5303459167480469, validation loss 0.8354097008705139\n",
      "Epoch 1060, current patience 13, model mean validation loss 0.8258812427520752, embedding dim 4, hidden size 32, num layers 1, train loss 0.4932885468006134, validation loss 0.9205276966094971\n",
      "Epoch 1070, current patience 12, model mean validation loss 0.8305025100708008, embedding dim 4, hidden size 32, num layers 1, train loss 0.5355631113052368, validation loss 0.8290925621986389\n",
      "Epoch 1080, current patience 11, model mean validation loss 0.8363130688667297, embedding dim 4, hidden size 32, num layers 1, train loss 0.5321261882781982, validation loss 0.8305916786193848\n",
      "Epoch 1090, current patience 10, model mean validation loss 0.8435879945755005, embedding dim 4, hidden size 32, num layers 1, train loss 0.35678502917289734, validation loss 0.8871356248855591\n",
      "Epoch 1100, current patience 9, model mean validation loss 0.8451206684112549, embedding dim 4, hidden size 32, num layers 1, train loss 0.35010266304016113, validation loss 0.8204398155212402\n",
      "Epoch 1110, current patience 8, model mean validation loss 0.8475416898727417, embedding dim 4, hidden size 32, num layers 1, train loss 0.43338754773139954, validation loss 0.8308702707290649\n",
      "Epoch 1120, current patience 7, model mean validation loss 0.8489195108413696, embedding dim 4, hidden size 32, num layers 1, train loss 0.4270627200603485, validation loss 0.8372886180877686\n",
      "Epoch 1130, current patience 6, model mean validation loss 0.8621512651443481, embedding dim 4, hidden size 32, num layers 1, train loss 0.33220580220222473, validation loss 0.9412640333175659\n",
      "Epoch 1140, current patience 5, model mean validation loss 0.8580176830291748, embedding dim 4, hidden size 32, num layers 1, train loss 0.5291154980659485, validation loss 0.887458860874176\n",
      "Epoch 1150, current patience 4, model mean validation loss 0.8622171878814697, embedding dim 4, hidden size 32, num layers 1, train loss 0.39710569381713867, validation loss 0.8626883625984192\n",
      "Epoch 1160, current patience 3, model mean validation loss 0.8619884848594666, embedding dim 4, hidden size 32, num layers 1, train loss 0.4850357472896576, validation loss 0.828762412071228\n",
      "Epoch 1170, current patience 2, model mean validation loss 0.8534818887710571, embedding dim 4, hidden size 32, num layers 1, train loss 0.47631847858428955, validation loss 0.8190829157829285\n",
      "Epoch 1180, current patience 1, model mean validation loss 0.8618533611297607, embedding dim 4, hidden size 32, num layers 1, train loss 0.32355737686157227, validation loss 0.8874117136001587\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0968279838562012, embedding dim 4, hidden size 64, num layers 1, train loss 1.1029373407363892, validation loss 1.0968279838562012\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0962692499160767, embedding dim 4, hidden size 64, num layers 1, train loss 1.0758068561553955, validation loss 1.0957105159759521\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0953617095947266, embedding dim 4, hidden size 64, num layers 1, train loss 1.0903098583221436, validation loss 1.0935466289520264\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0962986946105957, embedding dim 4, hidden size 64, num layers 1, train loss 1.117532730102539, validation loss 1.0991096496582031\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0959570407867432, embedding dim 4, hidden size 64, num layers 1, train loss 1.0950617790222168, validation loss 1.094590663909912\n",
      "Epoch 50, current patience 28, model mean validation loss 1.095507025718689, embedding dim 4, hidden size 64, num layers 1, train loss 1.0780584812164307, validation loss 1.093255877494812\n",
      "Epoch 60, current patience 27, model mean validation loss 1.095999002456665, embedding dim 4, hidden size 64, num layers 1, train loss 1.0718355178833008, validation loss 1.0989511013031006\n",
      "Epoch 70, current patience 26, model mean validation loss 1.0955337285995483, embedding dim 4, hidden size 64, num layers 1, train loss 1.0747519731521606, validation loss 1.0922777652740479\n",
      "Epoch 80, current patience 25, model mean validation loss 1.0946290493011475, embedding dim 4, hidden size 64, num layers 1, train loss 1.0875132083892822, validation loss 1.0895910263061523\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0929327011108398, embedding dim 4, hidden size 64, num layers 1, train loss 1.1163051128387451, validation loss 1.082139253616333\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0922350883483887, embedding dim 4, hidden size 64, num layers 1, train loss 1.1060471534729004, validation loss 1.087965726852417\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0894761085510254, embedding dim 4, hidden size 64, num layers 1, train loss 1.0439722537994385, validation loss 1.0770379304885864\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0870963335037231, embedding dim 4, hidden size 64, num layers 1, train loss 1.0856077671051025, validation loss 1.0755518674850464\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0831809043884277, embedding dim 4, hidden size 64, num layers 1, train loss 1.0316473245620728, validation loss 1.0619323253631592\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0763391256332397, embedding dim 4, hidden size 64, num layers 1, train loss 1.0150482654571533, validation loss 1.0442171096801758\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0730900764465332, embedding dim 4, hidden size 64, num layers 1, train loss 1.0106316804885864, validation loss 1.0662853717803955\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0656459331512451, embedding dim 4, hidden size 64, num layers 1, train loss 0.9768494367599487, validation loss 1.030037522315979\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0563416481018066, embedding dim 4, hidden size 64, num layers 1, train loss 1.0193986892700195, validation loss 1.007705807685852\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0456500053405762, embedding dim 4, hidden size 64, num layers 1, train loss 1.0681297779083252, validation loss 1.0024323463439941\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0338914394378662, embedding dim 4, hidden size 64, num layers 1, train loss 0.9522484540939331, validation loss 0.9829696416854858\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0251692533493042, embedding dim 4, hidden size 64, num layers 1, train loss 0.9384644031524658, validation loss 1.005773901939392\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0153793096542358, embedding dim 4, hidden size 64, num layers 1, train loss 0.8946270942687988, validation loss 0.9836130142211914\n",
      "Epoch 220, current patience 30, model mean validation loss 1.003268837928772, embedding dim 4, hidden size 64, num layers 1, train loss 0.9879617691040039, validation loss 0.9473332166671753\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9874471426010132, embedding dim 4, hidden size 64, num layers 1, train loss 0.9991511106491089, validation loss 0.9397116899490356\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9742386341094971, embedding dim 4, hidden size 64, num layers 1, train loss 0.8572924137115479, validation loss 0.9243691563606262\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9645601511001587, embedding dim 4, hidden size 64, num layers 1, train loss 0.8214666843414307, validation loss 0.9302778840065002\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9539372324943542, embedding dim 4, hidden size 64, num layers 1, train loss 0.8445059061050415, validation loss 0.9174494743347168\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9438596963882446, embedding dim 4, hidden size 64, num layers 1, train loss 0.942356288433075, validation loss 0.9023491740226746\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9316298961639404, embedding dim 4, hidden size 64, num layers 1, train loss 0.8774702548980713, validation loss 0.9079359769821167\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9193443059921265, embedding dim 4, hidden size 64, num layers 1, train loss 0.7824686169624329, validation loss 0.8853281736373901\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9108874797821045, embedding dim 4, hidden size 64, num layers 1, train loss 0.8593190312385559, validation loss 0.8796785473823547\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9044054746627808, embedding dim 4, hidden size 64, num layers 1, train loss 0.7222625017166138, validation loss 0.887855589389801\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8966270685195923, embedding dim 4, hidden size 64, num layers 1, train loss 0.6828202605247498, validation loss 0.8621419072151184\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8886833190917969, embedding dim 4, hidden size 64, num layers 1, train loss 0.7206496000289917, validation loss 0.8667277097702026\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8829712271690369, embedding dim 4, hidden size 64, num layers 1, train loss 0.8440608382225037, validation loss 0.8717525005340576\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8783761262893677, embedding dim 4, hidden size 64, num layers 1, train loss 0.7607928514480591, validation loss 0.8655884265899658\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8684415817260742, embedding dim 4, hidden size 64, num layers 1, train loss 0.6441740989685059, validation loss 0.8284599781036377\n",
      "Epoch 370, current patience 30, model mean validation loss 0.863460898399353, embedding dim 4, hidden size 64, num layers 1, train loss 0.9155022501945496, validation loss 0.8454829454421997\n",
      "Epoch 380, current patience 30, model mean validation loss 0.858309268951416, embedding dim 4, hidden size 64, num layers 1, train loss 0.7567629814147949, validation loss 0.8384650945663452\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8544450998306274, embedding dim 4, hidden size 64, num layers 1, train loss 0.7350159287452698, validation loss 0.8569426536560059\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8523027896881104, embedding dim 4, hidden size 64, num layers 1, train loss 0.6329827308654785, validation loss 0.8450028300285339\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8486096262931824, embedding dim 4, hidden size 64, num layers 1, train loss 0.7728650569915771, validation loss 0.8371825218200684\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8412459492683411, embedding dim 4, hidden size 64, num layers 1, train loss 0.6712887287139893, validation loss 0.8128429055213928\n",
      "Epoch 430, current patience 30, model mean validation loss 0.838103175163269, embedding dim 4, hidden size 64, num layers 1, train loss 0.7121174335479736, validation loss 0.8404464721679688\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8393101692199707, embedding dim 4, hidden size 64, num layers 1, train loss 0.8245426416397095, validation loss 0.8381161689758301\n",
      "Epoch 450, current patience 29, model mean validation loss 0.8375696539878845, embedding dim 4, hidden size 64, num layers 1, train loss 0.7233796119689941, validation loss 0.831558108329773\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8319069743156433, embedding dim 4, hidden size 64, num layers 1, train loss 0.6921179294586182, validation loss 0.7931642532348633\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8234171271324158, embedding dim 4, hidden size 64, num layers 1, train loss 0.8150299787521362, validation loss 0.7890238761901855\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8148221969604492, embedding dim 4, hidden size 64, num layers 1, train loss 0.6193603277206421, validation loss 0.7762432098388672\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8096805214881897, embedding dim 4, hidden size 64, num layers 1, train loss 0.8443416357040405, validation loss 0.7960493564605713\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8102267980575562, embedding dim 4, hidden size 64, num layers 1, train loss 0.7842158079147339, validation loss 0.8172132968902588\n",
      "Epoch 510, current patience 29, model mean validation loss 0.8023232817649841, embedding dim 4, hidden size 64, num layers 1, train loss 0.6051846146583557, validation loss 0.7772178053855896\n",
      "Epoch 520, current patience 30, model mean validation loss 0.7955467700958252, embedding dim 4, hidden size 64, num layers 1, train loss 0.6951802968978882, validation loss 0.7839037775993347\n",
      "Epoch 530, current patience 30, model mean validation loss 0.790501058101654, embedding dim 4, hidden size 64, num layers 1, train loss 0.7324827909469604, validation loss 0.7911926507949829\n",
      "Epoch 540, current patience 30, model mean validation loss 0.7872256636619568, embedding dim 4, hidden size 64, num layers 1, train loss 0.6109393239021301, validation loss 0.7669612169265747\n",
      "Epoch 550, current patience 30, model mean validation loss 0.786828875541687, embedding dim 4, hidden size 64, num layers 1, train loss 0.7460776567459106, validation loss 0.7858493328094482\n",
      "Epoch 560, current patience 30, model mean validation loss 0.7898924946784973, embedding dim 4, hidden size 64, num layers 1, train loss 0.48833614587783813, validation loss 0.800752580165863\n",
      "Epoch 570, current patience 29, model mean validation loss 0.7893977165222168, embedding dim 4, hidden size 64, num layers 1, train loss 0.6535943150520325, validation loss 0.7920912504196167\n",
      "Epoch 580, current patience 28, model mean validation loss 0.7835623621940613, embedding dim 4, hidden size 64, num layers 1, train loss 0.6394475102424622, validation loss 0.7705301642417908\n",
      "Epoch 590, current patience 30, model mean validation loss 0.7829950451850891, embedding dim 4, hidden size 64, num layers 1, train loss 0.558681070804596, validation loss 0.7726794481277466\n",
      "Epoch 600, current patience 30, model mean validation loss 0.7854626774787903, embedding dim 4, hidden size 64, num layers 1, train loss 0.6032874584197998, validation loss 0.8036447167396545\n",
      "Epoch 610, current patience 29, model mean validation loss 0.7863463163375854, embedding dim 4, hidden size 64, num layers 1, train loss 0.8209649324417114, validation loss 0.7982620000839233\n",
      "Epoch 620, current patience 28, model mean validation loss 0.7919173240661621, embedding dim 4, hidden size 64, num layers 1, train loss 0.7053868174552917, validation loss 0.8115285038948059\n",
      "Epoch 630, current patience 27, model mean validation loss 0.7949503660202026, embedding dim 4, hidden size 64, num layers 1, train loss 0.5885428190231323, validation loss 0.8101141452789307\n",
      "Epoch 640, current patience 26, model mean validation loss 0.8047652244567871, embedding dim 4, hidden size 64, num layers 1, train loss 0.528969407081604, validation loss 0.8792716264724731\n",
      "Epoch 650, current patience 25, model mean validation loss 0.8011977672576904, embedding dim 4, hidden size 64, num layers 1, train loss 0.5844995975494385, validation loss 0.7635511755943298\n",
      "Epoch 660, current patience 24, model mean validation loss 0.8010189533233643, embedding dim 4, hidden size 64, num layers 1, train loss 0.6253727674484253, validation loss 0.7690998911857605\n",
      "Epoch 670, current patience 23, model mean validation loss 0.8035194873809814, embedding dim 4, hidden size 64, num layers 1, train loss 0.5052658319473267, validation loss 0.7926836609840393\n",
      "Epoch 680, current patience 22, model mean validation loss 0.8096963167190552, embedding dim 4, hidden size 64, num layers 1, train loss 0.6121741533279419, validation loss 0.8530595302581787\n",
      "Epoch 690, current patience 21, model mean validation loss 0.8070797920227051, embedding dim 4, hidden size 64, num layers 1, train loss 0.47387760877609253, validation loss 0.7773298025131226\n",
      "Epoch 700, current patience 20, model mean validation loss 0.8067299127578735, embedding dim 4, hidden size 64, num layers 1, train loss 0.7295278310775757, validation loss 0.8087292313575745\n",
      "Epoch 710, current patience 19, model mean validation loss 0.8021205067634583, embedding dim 4, hidden size 64, num layers 1, train loss 0.6140748262405396, validation loss 0.7732396125793457\n",
      "Epoch 720, current patience 18, model mean validation loss 0.794533371925354, embedding dim 4, hidden size 64, num layers 1, train loss 0.6545925140380859, validation loss 0.818574070930481\n",
      "Epoch 730, current patience 17, model mean validation loss 0.7981750965118408, embedding dim 4, hidden size 64, num layers 1, train loss 0.6366674304008484, validation loss 0.792685329914093\n",
      "Epoch 740, current patience 16, model mean validation loss 0.8026943206787109, embedding dim 4, hidden size 64, num layers 1, train loss 0.5393533706665039, validation loss 0.8052529096603394\n",
      "Epoch 750, current patience 15, model mean validation loss 0.8049789667129517, embedding dim 4, hidden size 64, num layers 1, train loss 0.5672006011009216, validation loss 0.8109614849090576\n",
      "Epoch 760, current patience 14, model mean validation loss 0.7987579107284546, embedding dim 4, hidden size 64, num layers 1, train loss 0.3991665840148926, validation loss 0.8032907247543335\n",
      "Epoch 770, current patience 13, model mean validation loss 0.7988436818122864, embedding dim 4, hidden size 64, num layers 1, train loss 0.5541529655456543, validation loss 0.7780157327651978\n",
      "Epoch 780, current patience 12, model mean validation loss 0.7953565120697021, embedding dim 4, hidden size 64, num layers 1, train loss 0.5426377058029175, validation loss 0.7808322310447693\n",
      "Epoch 790, current patience 11, model mean validation loss 0.7985600829124451, embedding dim 4, hidden size 64, num layers 1, train loss 0.46011680364608765, validation loss 0.7988680005073547\n",
      "Epoch 800, current patience 10, model mean validation loss 0.7955522537231445, embedding dim 4, hidden size 64, num layers 1, train loss 0.510326623916626, validation loss 0.7945113182067871\n",
      "Epoch 810, current patience 9, model mean validation loss 0.7902188301086426, embedding dim 4, hidden size 64, num layers 1, train loss 0.4949737787246704, validation loss 0.7500184774398804\n",
      "Epoch 820, current patience 8, model mean validation loss 0.7934712171554565, embedding dim 4, hidden size 64, num layers 1, train loss 0.5486345291137695, validation loss 0.831271767616272\n",
      "Epoch 830, current patience 7, model mean validation loss 0.8021990060806274, embedding dim 4, hidden size 64, num layers 1, train loss 0.5117518901824951, validation loss 0.88078373670578\n",
      "Epoch 840, current patience 6, model mean validation loss 0.7992230653762817, embedding dim 4, hidden size 64, num layers 1, train loss 0.5348577499389648, validation loss 0.7794833779335022\n",
      "Epoch 850, current patience 5, model mean validation loss 0.8020080327987671, embedding dim 4, hidden size 64, num layers 1, train loss 0.556233823299408, validation loss 0.8002957105636597\n",
      "Epoch 860, current patience 4, model mean validation loss 0.8078294396400452, embedding dim 4, hidden size 64, num layers 1, train loss 0.5255325436592102, validation loss 0.8274029493331909\n",
      "Epoch 870, current patience 3, model mean validation loss 0.8139380812644958, embedding dim 4, hidden size 64, num layers 1, train loss 0.459085077047348, validation loss 0.8477372527122498\n",
      "Epoch 880, current patience 2, model mean validation loss 0.8153663873672485, embedding dim 4, hidden size 64, num layers 1, train loss 0.4529438614845276, validation loss 0.8059378862380981\n",
      "Epoch 890, current patience 1, model mean validation loss 0.8224674463272095, embedding dim 4, hidden size 64, num layers 1, train loss 0.5161514282226562, validation loss 0.8068267107009888\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0983524322509766, embedding dim 4, hidden size 128, num layers 1, train loss 1.1045724153518677, validation loss 1.0983524322509766\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0968153476715088, embedding dim 4, hidden size 128, num layers 1, train loss 1.1133222579956055, validation loss 1.0952781438827515\n",
      "Epoch 20, current patience 30, model mean validation loss 1.096356749534607, embedding dim 4, hidden size 128, num layers 1, train loss 1.106221318244934, validation loss 1.0954393148422241\n",
      "Epoch 30, current patience 30, model mean validation loss 1.095703363418579, embedding dim 4, hidden size 128, num layers 1, train loss 1.0938901901245117, validation loss 1.0937433242797852\n",
      "Epoch 40, current patience 30, model mean validation loss 1.095205545425415, embedding dim 4, hidden size 128, num layers 1, train loss 1.103171467781067, validation loss 1.093214750289917\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0952626466751099, embedding dim 4, hidden size 128, num layers 1, train loss 1.0985119342803955, validation loss 1.0955479145050049\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0964635610580444, embedding dim 4, hidden size 128, num layers 1, train loss 1.0787527561187744, validation loss 1.1036686897277832\n",
      "Epoch 70, current patience 28, model mean validation loss 1.0960805416107178, embedding dim 4, hidden size 128, num layers 1, train loss 1.0723809003829956, validation loss 1.0934005975723267\n",
      "Epoch 80, current patience 27, model mean validation loss 1.0946283340454102, embedding dim 4, hidden size 128, num layers 1, train loss 1.1078667640686035, validation loss 1.0867345333099365\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0919119119644165, embedding dim 4, hidden size 128, num layers 1, train loss 1.0989267826080322, validation loss 1.0735464096069336\n",
      "Epoch 100, current patience 30, model mean validation loss 1.089431881904602, embedding dim 4, hidden size 128, num layers 1, train loss 1.0690956115722656, validation loss 1.075599193572998\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0862722396850586, embedding dim 4, hidden size 128, num layers 1, train loss 1.027437686920166, validation loss 1.0684651136398315\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0821723937988281, embedding dim 4, hidden size 128, num layers 1, train loss 1.0195975303649902, validation loss 1.0604164600372314\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0764225721359253, embedding dim 4, hidden size 128, num layers 1, train loss 1.0454461574554443, validation loss 1.0495493412017822\n",
      "Epoch 140, current patience 30, model mean validation loss 1.068986415863037, embedding dim 4, hidden size 128, num layers 1, train loss 1.0365562438964844, validation loss 1.0441789627075195\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0625993013381958, embedding dim 4, hidden size 128, num layers 1, train loss 1.031104326248169, validation loss 1.0423047542572021\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0553048849105835, embedding dim 4, hidden size 128, num layers 1, train loss 1.0286929607391357, validation loss 1.0283788442611694\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0486828088760376, embedding dim 4, hidden size 128, num layers 1, train loss 1.0435335636138916, validation loss 1.0205700397491455\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0405664443969727, embedding dim 4, hidden size 128, num layers 1, train loss 0.9706798791885376, validation loss 1.010668396949768\n",
      "Epoch 190, current patience 30, model mean validation loss 1.031236171722412, embedding dim 4, hidden size 128, num layers 1, train loss 0.9808960556983948, validation loss 0.9938231110572815\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0241992473602295, embedding dim 4, hidden size 128, num layers 1, train loss 0.933509349822998, validation loss 1.0041208267211914\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0158565044403076, embedding dim 4, hidden size 128, num layers 1, train loss 0.8995431661605835, validation loss 0.9828075170516968\n",
      "Epoch 220, current patience 30, model mean validation loss 1.007595181465149, embedding dim 4, hidden size 128, num layers 1, train loss 0.9943395853042603, validation loss 0.9780880808830261\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9994539022445679, embedding dim 4, hidden size 128, num layers 1, train loss 0.9471703767776489, validation loss 0.9771745800971985\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9888049364089966, embedding dim 4, hidden size 128, num layers 1, train loss 0.842889666557312, validation loss 0.9431870579719543\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9781023263931274, embedding dim 4, hidden size 128, num layers 1, train loss 0.882240891456604, validation loss 0.9349496364593506\n",
      "Epoch 260, current patience 30, model mean validation loss 0.964206874370575, embedding dim 4, hidden size 128, num layers 1, train loss 0.9313555359840393, validation loss 0.8995043635368347\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9534304141998291, embedding dim 4, hidden size 128, num layers 1, train loss 0.9636579751968384, validation loss 0.9076108932495117\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9387049674987793, embedding dim 4, hidden size 128, num layers 1, train loss 0.8980833292007446, validation loss 0.8863181471824646\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9263026118278503, embedding dim 4, hidden size 128, num layers 1, train loss 0.9071522951126099, validation loss 0.8835886120796204\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9113509654998779, embedding dim 4, hidden size 128, num layers 1, train loss 0.9492899775505066, validation loss 0.8584744334220886\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8989303112030029, embedding dim 4, hidden size 128, num layers 1, train loss 0.7520960569381714, validation loss 0.8778094053268433\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8903790712356567, embedding dim 4, hidden size 128, num layers 1, train loss 0.767723798751831, validation loss 0.8747769594192505\n",
      "Epoch 330, current patience 30, model mean validation loss 0.879082977771759, embedding dim 4, hidden size 128, num layers 1, train loss 0.882317304611206, validation loss 0.8445813655853271\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8716356754302979, embedding dim 4, hidden size 128, num layers 1, train loss 0.818053126335144, validation loss 0.8399255871772766\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8643933534622192, embedding dim 4, hidden size 128, num layers 1, train loss 0.6767033934593201, validation loss 0.8496724367141724\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8571016192436218, embedding dim 4, hidden size 128, num layers 1, train loss 0.8647501468658447, validation loss 0.8279843330383301\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8509357571601868, embedding dim 4, hidden size 128, num layers 1, train loss 0.6815915107727051, validation loss 0.8342617154121399\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8491814136505127, embedding dim 4, hidden size 128, num layers 1, train loss 0.6876004338264465, validation loss 0.8444398641586304\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8456040024757385, embedding dim 4, hidden size 128, num layers 1, train loss 0.7884613275527954, validation loss 0.8491901159286499\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8379817008972168, embedding dim 4, hidden size 128, num layers 1, train loss 0.8443471193313599, validation loss 0.8137983679771423\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8336893320083618, embedding dim 4, hidden size 128, num layers 1, train loss 0.6715317368507385, validation loss 0.8102421760559082\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8329061269760132, embedding dim 4, hidden size 128, num layers 1, train loss 0.7390944957733154, validation loss 0.8336600661277771\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8303347229957581, embedding dim 4, hidden size 128, num layers 1, train loss 0.6463155746459961, validation loss 0.8291013240814209\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8297144174575806, embedding dim 4, hidden size 128, num layers 1, train loss 0.8957808017730713, validation loss 0.8230218291282654\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8276979327201843, embedding dim 4, hidden size 128, num layers 1, train loss 0.8001973628997803, validation loss 0.8181296586990356\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8237340450286865, embedding dim 4, hidden size 128, num layers 1, train loss 0.6928228139877319, validation loss 0.812728762626648\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8180019855499268, embedding dim 4, hidden size 128, num layers 1, train loss 0.6643887758255005, validation loss 0.8033334016799927\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8181527853012085, embedding dim 4, hidden size 128, num layers 1, train loss 0.6873633861541748, validation loss 0.8150051832199097\n",
      "Epoch 490, current patience 29, model mean validation loss 0.8165452480316162, embedding dim 4, hidden size 128, num layers 1, train loss 0.6585717797279358, validation loss 0.7973822355270386\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8112455010414124, embedding dim 4, hidden size 128, num layers 1, train loss 0.6765562295913696, validation loss 0.7912617921829224\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8059779405593872, embedding dim 4, hidden size 128, num layers 1, train loss 0.6882812976837158, validation loss 0.7869607210159302\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8048578500747681, embedding dim 4, hidden size 128, num layers 1, train loss 0.736963152885437, validation loss 0.8140613436698914\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8070908188819885, embedding dim 4, hidden size 128, num layers 1, train loss 0.7803013324737549, validation loss 0.8359935283660889\n",
      "Epoch 540, current patience 29, model mean validation loss 0.8013294339179993, embedding dim 4, hidden size 128, num layers 1, train loss 0.6052073240280151, validation loss 0.7666372656822205\n",
      "Epoch 550, current patience 30, model mean validation loss 0.7978224754333496, embedding dim 4, hidden size 128, num layers 1, train loss 0.8884455561637878, validation loss 0.7752781510353088\n",
      "Epoch 560, current patience 30, model mean validation loss 0.7879211902618408, embedding dim 4, hidden size 128, num layers 1, train loss 0.7788577079772949, validation loss 0.7357946038246155\n",
      "Epoch 570, current patience 30, model mean validation loss 0.7857450842857361, embedding dim 4, hidden size 128, num layers 1, train loss 0.7388050556182861, validation loss 0.7799731492996216\n",
      "Epoch 580, current patience 30, model mean validation loss 0.7824550867080688, embedding dim 4, hidden size 128, num layers 1, train loss 0.528213620185852, validation loss 0.7649418711662292\n",
      "Epoch 590, current patience 30, model mean validation loss 0.7810204029083252, embedding dim 4, hidden size 128, num layers 1, train loss 0.6126643419265747, validation loss 0.7754835486412048\n",
      "Epoch 600, current patience 30, model mean validation loss 0.7789565324783325, embedding dim 4, hidden size 128, num layers 1, train loss 0.6249370574951172, validation loss 0.7975502014160156\n",
      "Epoch 610, current patience 30, model mean validation loss 0.7717550992965698, embedding dim 4, hidden size 128, num layers 1, train loss 0.4858121871948242, validation loss 0.7783820033073425\n",
      "Epoch 620, current patience 30, model mean validation loss 0.7725685834884644, embedding dim 4, hidden size 128, num layers 1, train loss 0.5468554496765137, validation loss 0.7731448411941528\n",
      "Epoch 630, current patience 29, model mean validation loss 0.7729669809341431, embedding dim 4, hidden size 128, num layers 1, train loss 0.7525755167007446, validation loss 0.7784658670425415\n",
      "Epoch 640, current patience 28, model mean validation loss 0.7714253067970276, embedding dim 4, hidden size 128, num layers 1, train loss 0.6533758044242859, validation loss 0.7234610319137573\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7234610319137573_4_128_1_640.pt\n",
      "Epoch 650, current patience 30, model mean validation loss 0.769880473613739, embedding dim 4, hidden size 128, num layers 1, train loss 0.775612473487854, validation loss 0.7676146030426025\n",
      "Epoch 660, current patience 30, model mean validation loss 0.7759984731674194, embedding dim 4, hidden size 128, num layers 1, train loss 0.5891879796981812, validation loss 0.8138856887817383\n",
      "Epoch 670, current patience 29, model mean validation loss 0.7763481736183167, embedding dim 4, hidden size 128, num layers 1, train loss 0.5405154228210449, validation loss 0.7782810926437378\n",
      "Epoch 680, current patience 28, model mean validation loss 0.7746748328208923, embedding dim 4, hidden size 128, num layers 1, train loss 0.7984170913696289, validation loss 0.7841636538505554\n",
      "Epoch 690, current patience 27, model mean validation loss 0.7729240655899048, embedding dim 4, hidden size 128, num layers 1, train loss 0.39872828125953674, validation loss 0.7643756866455078\n",
      "Epoch 700, current patience 26, model mean validation loss 0.7775352001190186, embedding dim 4, hidden size 128, num layers 1, train loss 0.48248499631881714, validation loss 0.810033917427063\n",
      "Epoch 710, current patience 25, model mean validation loss 0.7761796712875366, embedding dim 4, hidden size 128, num layers 1, train loss 0.5065056085586548, validation loss 0.767621636390686\n",
      "Epoch 720, current patience 24, model mean validation loss 0.7862638235092163, embedding dim 4, hidden size 128, num layers 1, train loss 0.7619397640228271, validation loss 0.8041343688964844\n",
      "Epoch 730, current patience 23, model mean validation loss 0.7873314619064331, embedding dim 4, hidden size 128, num layers 1, train loss 0.6319331526756287, validation loss 0.7761553525924683\n",
      "Epoch 740, current patience 22, model mean validation loss 0.7808172702789307, embedding dim 4, hidden size 128, num layers 1, train loss 0.6430593729019165, validation loss 0.7617728114128113\n",
      "Epoch 750, current patience 21, model mean validation loss 0.7777291536331177, embedding dim 4, hidden size 128, num layers 1, train loss 0.6865200996398926, validation loss 0.7535759806632996\n",
      "Epoch 760, current patience 20, model mean validation loss 0.7751468420028687, embedding dim 4, hidden size 128, num layers 1, train loss 0.4883100986480713, validation loss 0.763505220413208\n",
      "Epoch 770, current patience 19, model mean validation loss 0.7735803127288818, embedding dim 4, hidden size 128, num layers 1, train loss 0.698154866695404, validation loss 0.751843273639679\n",
      "Epoch 780, current patience 18, model mean validation loss 0.7666741609573364, embedding dim 4, hidden size 128, num layers 1, train loss 0.6078066825866699, validation loss 0.7547848224639893\n",
      "Epoch 790, current patience 30, model mean validation loss 0.7655144929885864, embedding dim 4, hidden size 128, num layers 1, train loss 0.6981843709945679, validation loss 0.7583438158035278\n",
      "Epoch 800, current patience 30, model mean validation loss 0.7618553638458252, embedding dim 4, hidden size 128, num layers 1, train loss 0.5272113084793091, validation loss 0.7748618125915527\n",
      "Epoch 810, current patience 30, model mean validation loss 0.7660281658172607, embedding dim 4, hidden size 128, num layers 1, train loss 0.48756301403045654, validation loss 0.8095372915267944\n",
      "Epoch 820, current patience 29, model mean validation loss 0.7684788703918457, embedding dim 4, hidden size 128, num layers 1, train loss 0.5329995155334473, validation loss 0.781378448009491\n",
      "Epoch 830, current patience 28, model mean validation loss 0.7699924111366272, embedding dim 4, hidden size 128, num layers 1, train loss 0.46475639939308167, validation loss 0.7656843662261963\n",
      "Epoch 840, current patience 27, model mean validation loss 0.7666190266609192, embedding dim 4, hidden size 128, num layers 1, train loss 0.5027174949645996, validation loss 0.7365185022354126\n",
      "Epoch 850, current patience 26, model mean validation loss 0.7714325189590454, embedding dim 4, hidden size 128, num layers 1, train loss 0.5159943103790283, validation loss 0.7903509140014648\n",
      "Epoch 860, current patience 25, model mean validation loss 0.7765252590179443, embedding dim 4, hidden size 128, num layers 1, train loss 0.7158629894256592, validation loss 0.7955270409584045\n",
      "Epoch 870, current patience 24, model mean validation loss 0.7799748182296753, embedding dim 4, hidden size 128, num layers 1, train loss 0.46532946825027466, validation loss 0.7859401702880859\n",
      "Epoch 880, current patience 23, model mean validation loss 0.791911244392395, embedding dim 4, hidden size 128, num layers 1, train loss 0.4178670048713684, validation loss 0.8703533411026001\n",
      "Epoch 890, current patience 22, model mean validation loss 0.7952048778533936, embedding dim 4, hidden size 128, num layers 1, train loss 0.33188796043395996, validation loss 0.8358858227729797\n",
      "Epoch 900, current patience 21, model mean validation loss 0.7946434020996094, embedding dim 4, hidden size 128, num layers 1, train loss 0.5288410782814026, validation loss 0.7768875956535339\n",
      "Epoch 910, current patience 20, model mean validation loss 0.794213593006134, embedding dim 4, hidden size 128, num layers 1, train loss 0.5622372031211853, validation loss 0.7622456550598145\n",
      "Epoch 920, current patience 19, model mean validation loss 0.8036403059959412, embedding dim 4, hidden size 128, num layers 1, train loss 0.6502683162689209, validation loss 0.8119320869445801\n",
      "Epoch 930, current patience 18, model mean validation loss 0.7988443374633789, embedding dim 4, hidden size 128, num layers 1, train loss 0.6967170238494873, validation loss 0.751983106136322\n",
      "Epoch 940, current patience 17, model mean validation loss 0.797227144241333, embedding dim 4, hidden size 128, num layers 1, train loss 0.3928234279155731, validation loss 0.782589316368103\n",
      "Epoch 950, current patience 16, model mean validation loss 0.8029637932777405, embedding dim 4, hidden size 128, num layers 1, train loss 0.39795780181884766, validation loss 0.8318333625793457\n",
      "Epoch 960, current patience 15, model mean validation loss 0.8005093336105347, embedding dim 4, hidden size 128, num layers 1, train loss 0.5894290804862976, validation loss 0.850718080997467\n",
      "Epoch 970, current patience 14, model mean validation loss 0.7992363572120667, embedding dim 4, hidden size 128, num layers 1, train loss 0.41749364137649536, validation loss 0.8257017731666565\n",
      "Epoch 980, current patience 13, model mean validation loss 0.8087005615234375, embedding dim 4, hidden size 128, num layers 1, train loss 0.5774880647659302, validation loss 0.852601170539856\n",
      "Epoch 990, current patience 12, model mean validation loss 0.8175153136253357, embedding dim 4, hidden size 128, num layers 1, train loss 0.40836602449417114, validation loss 0.832763671875\n",
      "Epoch 1000, current patience 11, model mean validation loss 0.8159908652305603, embedding dim 4, hidden size 128, num layers 1, train loss 0.34344878792762756, validation loss 0.7997364401817322\n",
      "Epoch 1010, current patience 10, model mean validation loss 0.8393478393554688, embedding dim 4, hidden size 128, num layers 1, train loss 0.3529423475265503, validation loss 0.9388391971588135\n",
      "Epoch 1020, current patience 9, model mean validation loss 0.8475818037986755, embedding dim 4, hidden size 128, num layers 1, train loss 0.5868740081787109, validation loss 0.8484604954719543\n",
      "Epoch 1030, current patience 8, model mean validation loss 0.8528251647949219, embedding dim 4, hidden size 128, num layers 1, train loss 0.4099869132041931, validation loss 0.8737801909446716\n",
      "Epoch 1040, current patience 7, model mean validation loss 0.8589869737625122, embedding dim 4, hidden size 128, num layers 1, train loss 0.2679295539855957, validation loss 0.9000126123428345\n",
      "Epoch 1050, current patience 6, model mean validation loss 0.8546404838562012, embedding dim 4, hidden size 128, num layers 1, train loss 0.3560197949409485, validation loss 0.7909297347068787\n",
      "Epoch 1060, current patience 5, model mean validation loss 0.8566722869873047, embedding dim 4, hidden size 128, num layers 1, train loss 0.554444432258606, validation loss 0.8688562512397766\n",
      "Epoch 1070, current patience 4, model mean validation loss 0.8596638441085815, embedding dim 4, hidden size 128, num layers 1, train loss 0.3183887004852295, validation loss 0.8566957116127014\n",
      "Epoch 1080, current patience 3, model mean validation loss 0.8749999403953552, embedding dim 4, hidden size 128, num layers 1, train loss 0.5021612644195557, validation loss 0.9224252700805664\n",
      "Epoch 1090, current patience 2, model mean validation loss 0.8710074424743652, embedding dim 4, hidden size 128, num layers 1, train loss 0.3218876123428345, validation loss 0.9068996906280518\n",
      "Epoch 1100, current patience 1, model mean validation loss 0.876581609249115, embedding dim 4, hidden size 128, num layers 1, train loss 0.40942907333374023, validation loss 0.8930535912513733\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0992008447647095, embedding dim 4, hidden size 256, num layers 1, train loss 1.0957483053207397, validation loss 1.0992008447647095\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0956788063049316, embedding dim 4, hidden size 256, num layers 1, train loss 1.0994505882263184, validation loss 1.0921568870544434\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0959113836288452, embedding dim 4, hidden size 256, num layers 1, train loss 1.1030359268188477, validation loss 1.096376657485962\n",
      "Epoch 30, current patience 29, model mean validation loss 1.0955755710601807, embedding dim 4, hidden size 256, num layers 1, train loss 1.0998650789260864, validation loss 1.094567894935608\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0946587324142456, embedding dim 4, hidden size 256, num layers 1, train loss 1.0972256660461426, validation loss 1.090991497039795\n",
      "Epoch 50, current patience 30, model mean validation loss 1.094855546951294, embedding dim 4, hidden size 256, num layers 1, train loss 1.0863707065582275, validation loss 1.0958399772644043\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0950367450714111, embedding dim 4, hidden size 256, num layers 1, train loss 1.0958479642868042, validation loss 1.0961229801177979\n",
      "Epoch 70, current patience 28, model mean validation loss 1.0947860479354858, embedding dim 4, hidden size 256, num layers 1, train loss 1.0987296104431152, validation loss 1.093031883239746\n",
      "Epoch 80, current patience 27, model mean validation loss 1.094085454940796, embedding dim 4, hidden size 256, num layers 1, train loss 1.0731831789016724, validation loss 1.0935959815979004\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0940971374511719, embedding dim 4, hidden size 256, num layers 1, train loss 1.100787878036499, validation loss 1.0922508239746094\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0935297012329102, embedding dim 4, hidden size 256, num layers 1, train loss 1.1117150783538818, validation loss 1.091836929321289\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0932341814041138, embedding dim 4, hidden size 256, num layers 1, train loss 1.0995006561279297, validation loss 1.0922030210494995\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0931047201156616, embedding dim 4, hidden size 256, num layers 1, train loss 1.0601379871368408, validation loss 1.0899555683135986\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0918700695037842, embedding dim 4, hidden size 256, num layers 1, train loss 1.1252506971359253, validation loss 1.0859630107879639\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0906671285629272, embedding dim 4, hidden size 256, num layers 1, train loss 1.062864065170288, validation loss 1.0864990949630737\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0900368690490723, embedding dim 4, hidden size 256, num layers 1, train loss 1.0577504634857178, validation loss 1.0879902839660645\n",
      "Epoch 160, current patience 30, model mean validation loss 1.08707594871521, embedding dim 4, hidden size 256, num layers 1, train loss 1.1005561351776123, validation loss 1.069908618927002\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0825200080871582, embedding dim 4, hidden size 256, num layers 1, train loss 1.1033730506896973, validation loss 1.0558031797409058\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0785584449768066, embedding dim 4, hidden size 256, num layers 1, train loss 1.0879244804382324, validation loss 1.060145378112793\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0736699104309082, embedding dim 4, hidden size 256, num layers 1, train loss 1.0199954509735107, validation loss 1.0530940294265747\n",
      "Epoch 200, current patience 30, model mean validation loss 1.068318247795105, embedding dim 4, hidden size 256, num layers 1, train loss 0.9804182052612305, validation loss 1.047142744064331\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0584098100662231, embedding dim 4, hidden size 256, num layers 1, train loss 1.0151978731155396, validation loss 1.0066946744918823\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0492851734161377, embedding dim 4, hidden size 256, num layers 1, train loss 1.0510969161987305, validation loss 1.0135022401809692\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0371652841567993, embedding dim 4, hidden size 256, num layers 1, train loss 0.9874284863471985, validation loss 0.9910316467285156\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0260181427001953, embedding dim 4, hidden size 256, num layers 1, train loss 0.94584059715271, validation loss 0.9807308912277222\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0162334442138672, embedding dim 4, hidden size 256, num layers 1, train loss 1.03338623046875, validation loss 0.9775258302688599\n",
      "Epoch 260, current patience 30, model mean validation loss 1.005801796913147, embedding dim 4, hidden size 256, num layers 1, train loss 1.0479555130004883, validation loss 0.9766926169395447\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9922551512718201, embedding dim 4, hidden size 256, num layers 1, train loss 0.9476748704910278, validation loss 0.9447207450866699\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9807873964309692, embedding dim 4, hidden size 256, num layers 1, train loss 0.9187719225883484, validation loss 0.9554007649421692\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9735608100891113, embedding dim 4, hidden size 256, num layers 1, train loss 0.9826275706291199, validation loss 0.9488820433616638\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9670077562332153, embedding dim 4, hidden size 256, num layers 1, train loss 0.8798903226852417, validation loss 0.9610775113105774\n",
      "Epoch 310, current patience 30, model mean validation loss 0.960883378982544, embedding dim 4, hidden size 256, num layers 1, train loss 0.8763346076011658, validation loss 0.9420365691184998\n",
      "Epoch 320, current patience 30, model mean validation loss 0.953270435333252, embedding dim 4, hidden size 256, num layers 1, train loss 0.9283421635627747, validation loss 0.9198269844055176\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9482877254486084, embedding dim 4, hidden size 256, num layers 1, train loss 0.9202913045883179, validation loss 0.9376643896102905\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9416640400886536, embedding dim 4, hidden size 256, num layers 1, train loss 0.8545893430709839, validation loss 0.9237034320831299\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9399989247322083, embedding dim 4, hidden size 256, num layers 1, train loss 0.8245251178741455, validation loss 0.9313997626304626\n",
      "Epoch 360, current patience 30, model mean validation loss 0.933993935585022, embedding dim 4, hidden size 256, num layers 1, train loss 0.8017207980155945, validation loss 0.907360851764679\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9304252862930298, embedding dim 4, hidden size 256, num layers 1, train loss 0.8743698000907898, validation loss 0.9203325510025024\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9254220724105835, embedding dim 4, hidden size 256, num layers 1, train loss 0.608973503112793, validation loss 0.9210523366928101\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9181251525878906, embedding dim 4, hidden size 256, num layers 1, train loss 0.9038099050521851, validation loss 0.8836607933044434\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9157508015632629, embedding dim 4, hidden size 256, num layers 1, train loss 0.8120980262756348, validation loss 0.9008322954177856\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9090517163276672, embedding dim 4, hidden size 256, num layers 1, train loss 0.5723482966423035, validation loss 0.8840717077255249\n",
      "Epoch 420, current patience 30, model mean validation loss 0.900994062423706, embedding dim 4, hidden size 256, num layers 1, train loss 0.7231626510620117, validation loss 0.85924232006073\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8964221477508545, embedding dim 4, hidden size 256, num layers 1, train loss 0.7758642435073853, validation loss 0.8948246836662292\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8931549191474915, embedding dim 4, hidden size 256, num layers 1, train loss 0.7486103773117065, validation loss 0.8812225461006165\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8857814073562622, embedding dim 4, hidden size 256, num layers 1, train loss 0.6192805767059326, validation loss 0.8613442778587341\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8832291960716248, embedding dim 4, hidden size 256, num layers 1, train loss 0.6350932121276855, validation loss 0.9006350040435791\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8803598284721375, embedding dim 4, hidden size 256, num layers 1, train loss 0.6587305068969727, validation loss 0.8607057332992554\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8723331689834595, embedding dim 4, hidden size 256, num layers 1, train loss 0.9756202697753906, validation loss 0.8366193771362305\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8699082732200623, embedding dim 4, hidden size 256, num layers 1, train loss 0.8895111083984375, validation loss 0.8646721243858337\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8692028522491455, embedding dim 4, hidden size 256, num layers 1, train loss 0.833055853843689, validation loss 0.8535990715026855\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8635003566741943, embedding dim 4, hidden size 256, num layers 1, train loss 0.549400806427002, validation loss 0.8492043614387512\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8606499433517456, embedding dim 4, hidden size 256, num layers 1, train loss 0.5361120700836182, validation loss 0.85841965675354\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8596400618553162, embedding dim 4, hidden size 256, num layers 1, train loss 0.6254619359970093, validation loss 0.8532649278640747\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8507089614868164, embedding dim 4, hidden size 256, num layers 1, train loss 0.5247932076454163, validation loss 0.8291866183280945\n",
      "Epoch 550, current patience 30, model mean validation loss 0.853294849395752, embedding dim 4, hidden size 256, num layers 1, train loss 0.5215417146682739, validation loss 0.8813923597335815\n",
      "Epoch 560, current patience 29, model mean validation loss 0.8539915084838867, embedding dim 4, hidden size 256, num layers 1, train loss 0.7076903581619263, validation loss 0.8421926498413086\n",
      "Epoch 570, current patience 28, model mean validation loss 0.850265383720398, embedding dim 4, hidden size 256, num layers 1, train loss 0.6346617937088013, validation loss 0.8348637819290161\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8549247980117798, embedding dim 4, hidden size 256, num layers 1, train loss 0.4643615484237671, validation loss 0.8908736705780029\n",
      "Epoch 590, current patience 29, model mean validation loss 0.8601014614105225, embedding dim 4, hidden size 256, num layers 1, train loss 0.4391442537307739, validation loss 0.8906181454658508\n",
      "Epoch 600, current patience 28, model mean validation loss 0.8601955771446228, embedding dim 4, hidden size 256, num layers 1, train loss 0.5713948011398315, validation loss 0.8591724634170532\n",
      "Epoch 610, current patience 27, model mean validation loss 0.8683738708496094, embedding dim 4, hidden size 256, num layers 1, train loss 0.4233056604862213, validation loss 0.9186910390853882\n",
      "Epoch 620, current patience 26, model mean validation loss 0.874510645866394, embedding dim 4, hidden size 256, num layers 1, train loss 0.4882357716560364, validation loss 0.8782808184623718\n",
      "Epoch 630, current patience 25, model mean validation loss 0.8757458329200745, embedding dim 4, hidden size 256, num layers 1, train loss 0.46423497796058655, validation loss 0.8912741541862488\n",
      "Epoch 640, current patience 24, model mean validation loss 0.877705454826355, embedding dim 4, hidden size 256, num layers 1, train loss 0.44206422567367554, validation loss 0.8578697443008423\n",
      "Epoch 650, current patience 23, model mean validation loss 0.8806016445159912, embedding dim 4, hidden size 256, num layers 1, train loss 0.5990276336669922, validation loss 0.8580327033996582\n",
      "Epoch 660, current patience 22, model mean validation loss 0.8792053461074829, embedding dim 4, hidden size 256, num layers 1, train loss 0.5396221876144409, validation loss 0.8797038197517395\n",
      "Epoch 670, current patience 21, model mean validation loss 0.8780449628829956, embedding dim 4, hidden size 256, num layers 1, train loss 0.5484833717346191, validation loss 0.8813351988792419\n",
      "Epoch 680, current patience 20, model mean validation loss 0.8856251239776611, embedding dim 4, hidden size 256, num layers 1, train loss 0.45810699462890625, validation loss 0.9198133945465088\n",
      "Epoch 690, current patience 19, model mean validation loss 0.8833249807357788, embedding dim 4, hidden size 256, num layers 1, train loss 0.41060370206832886, validation loss 0.9002897143363953\n",
      "Epoch 700, current patience 18, model mean validation loss 0.8847249746322632, embedding dim 4, hidden size 256, num layers 1, train loss 0.30453985929489136, validation loss 0.8894814252853394\n",
      "Epoch 710, current patience 17, model mean validation loss 0.8959370851516724, embedding dim 4, hidden size 256, num layers 1, train loss 0.507952868938446, validation loss 0.9809707403182983\n",
      "Epoch 720, current patience 16, model mean validation loss 0.9084087610244751, embedding dim 4, hidden size 256, num layers 1, train loss 0.8220148086547852, validation loss 0.9576432704925537\n",
      "Epoch 730, current patience 15, model mean validation loss 0.9053256511688232, embedding dim 4, hidden size 256, num layers 1, train loss 0.6855719089508057, validation loss 0.8333679437637329\n",
      "Epoch 740, current patience 14, model mean validation loss 0.9118724465370178, embedding dim 4, hidden size 256, num layers 1, train loss 0.39932912588119507, validation loss 0.9320778846740723\n",
      "Epoch 750, current patience 13, model mean validation loss 0.9198535680770874, embedding dim 4, hidden size 256, num layers 1, train loss 0.48545438051223755, validation loss 0.9451841711997986\n",
      "Epoch 760, current patience 12, model mean validation loss 0.9257858991622925, embedding dim 4, hidden size 256, num layers 1, train loss 0.631062388420105, validation loss 0.9672720432281494\n",
      "Epoch 770, current patience 11, model mean validation loss 0.927709698677063, embedding dim 4, hidden size 256, num layers 1, train loss 0.35754847526550293, validation loss 0.9156805872917175\n",
      "Epoch 780, current patience 10, model mean validation loss 0.9362450838088989, embedding dim 4, hidden size 256, num layers 1, train loss 0.7121440172195435, validation loss 0.9577640891075134\n",
      "Epoch 790, current patience 9, model mean validation loss 0.9311952590942383, embedding dim 4, hidden size 256, num layers 1, train loss 0.8360685110092163, validation loss 0.9405721426010132\n",
      "Epoch 800, current patience 8, model mean validation loss 0.931281328201294, embedding dim 4, hidden size 256, num layers 1, train loss 0.30508458614349365, validation loss 0.9583317041397095\n",
      "Epoch 810, current patience 7, model mean validation loss 0.9597369432449341, embedding dim 4, hidden size 256, num layers 1, train loss 0.36929795145988464, validation loss 1.061012864112854\n",
      "Epoch 820, current patience 6, model mean validation loss 0.970520555973053, embedding dim 4, hidden size 256, num layers 1, train loss 0.802666187286377, validation loss 1.018346905708313\n",
      "Epoch 830, current patience 5, model mean validation loss 0.9679415225982666, embedding dim 4, hidden size 256, num layers 1, train loss 0.40103670954704285, validation loss 0.924552321434021\n",
      "Epoch 840, current patience 4, model mean validation loss 0.9743799567222595, embedding dim 4, hidden size 256, num layers 1, train loss 0.6708397269248962, validation loss 1.0187790393829346\n",
      "Epoch 850, current patience 3, model mean validation loss 0.9780323505401611, embedding dim 4, hidden size 256, num layers 1, train loss 0.5409724712371826, validation loss 0.9448997974395752\n",
      "Epoch 860, current patience 2, model mean validation loss 0.9840328693389893, embedding dim 4, hidden size 256, num layers 1, train loss 0.2072872519493103, validation loss 1.0057681798934937\n",
      "Epoch 870, current patience 1, model mean validation loss 0.9956924915313721, embedding dim 4, hidden size 256, num layers 1, train loss 0.2727966010570526, validation loss 1.0338490009307861\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1210362911224365, embedding dim 4, hidden size 512, num layers 1, train loss 1.0975542068481445, validation loss 1.1210362911224365\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1062242984771729, embedding dim 4, hidden size 512, num layers 1, train loss 1.0727689266204834, validation loss 1.0914121866226196\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1041152477264404, embedding dim 4, hidden size 512, num layers 1, train loss 1.0962193012237549, validation loss 1.0998971462249756\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1017003059387207, embedding dim 4, hidden size 512, num layers 1, train loss 1.094660997390747, validation loss 1.0944554805755615\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1001529693603516, embedding dim 4, hidden size 512, num layers 1, train loss 1.096990942955017, validation loss 1.093963384628296\n",
      "Epoch 50, current patience 30, model mean validation loss 1.098995566368103, embedding dim 4, hidden size 512, num layers 1, train loss 1.089672327041626, validation loss 1.09320867061615\n",
      "Epoch 60, current patience 30, model mean validation loss 1.099234938621521, embedding dim 4, hidden size 512, num layers 1, train loss 1.1051095724105835, validation loss 1.1006718873977661\n",
      "Epoch 70, current patience 29, model mean validation loss 1.0985361337661743, embedding dim 4, hidden size 512, num layers 1, train loss 1.106823205947876, validation loss 1.0936439037322998\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0950393676757812, embedding dim 4, hidden size 512, num layers 1, train loss 1.0968270301818848, validation loss 1.093062162399292\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0954453945159912, embedding dim 4, hidden size 512, num layers 1, train loss 1.1026945114135742, validation loss 1.094660997390747\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0989311933517456, embedding dim 4, hidden size 512, num layers 1, train loss 1.0814346075057983, validation loss 1.127783179283142\n",
      "Epoch 110, current patience 28, model mean validation loss 1.1196660995483398, embedding dim 4, hidden size 512, num layers 1, train loss 1.290350317955017, validation loss 1.2603349685668945\n",
      "Epoch 120, current patience 27, model mean validation loss 1.135063886642456, embedding dim 4, hidden size 512, num layers 1, train loss 1.1292989253997803, validation loss 1.2171454429626465\n",
      "Epoch 130, current patience 26, model mean validation loss 1.1458629369735718, embedding dim 4, hidden size 512, num layers 1, train loss 1.2487332820892334, validation loss 1.1796011924743652\n",
      "Epoch 140, current patience 25, model mean validation loss 1.1519582271575928, embedding dim 4, hidden size 512, num layers 1, train loss 1.1683474779129028, validation loss 1.1494337320327759\n",
      "Epoch 150, current patience 24, model mean validation loss 1.1651315689086914, embedding dim 4, hidden size 512, num layers 1, train loss 1.2596967220306396, validation loss 1.1990306377410889\n",
      "Epoch 160, current patience 23, model mean validation loss 1.1725112199783325, embedding dim 4, hidden size 512, num layers 1, train loss 1.1495267152786255, validation loss 1.1520988941192627\n",
      "Epoch 170, current patience 22, model mean validation loss 1.1818408966064453, embedding dim 4, hidden size 512, num layers 1, train loss 1.2136404514312744, validation loss 1.1692988872528076\n",
      "Epoch 180, current patience 21, model mean validation loss 1.1794871091842651, embedding dim 4, hidden size 512, num layers 1, train loss 1.1657581329345703, validation loss 1.1089527606964111\n",
      "Epoch 190, current patience 20, model mean validation loss 1.1621488332748413, embedding dim 4, hidden size 512, num layers 1, train loss 1.1101375818252563, validation loss 1.121628999710083\n",
      "Epoch 200, current patience 19, model mean validation loss 1.1524077653884888, embedding dim 4, hidden size 512, num layers 1, train loss 1.1697208881378174, validation loss 1.1392171382904053\n",
      "Epoch 210, current patience 18, model mean validation loss 1.14967679977417, embedding dim 4, hidden size 512, num layers 1, train loss 1.2044252157211304, validation loss 1.157753586769104\n",
      "Epoch 220, current patience 17, model mean validation loss 1.1495568752288818, embedding dim 4, hidden size 512, num layers 1, train loss 1.1116867065429688, validation loss 1.1484744548797607\n",
      "Epoch 230, current patience 16, model mean validation loss 1.1405514478683472, embedding dim 4, hidden size 512, num layers 1, train loss 1.107505440711975, validation loss 1.1269865036010742\n",
      "Epoch 240, current patience 15, model mean validation loss 1.1372897624969482, embedding dim 4, hidden size 512, num layers 1, train loss 1.1037118434906006, validation loss 1.12600576877594\n",
      "Epoch 250, current patience 14, model mean validation loss 1.1305819749832153, embedding dim 4, hidden size 512, num layers 1, train loss 1.086932897567749, validation loss 1.115636944770813\n",
      "Epoch 260, current patience 13, model mean validation loss 1.1319024562835693, embedding dim 4, hidden size 512, num layers 1, train loss 1.114854097366333, validation loss 1.1195160150527954\n",
      "Epoch 270, current patience 12, model mean validation loss 1.1402767896652222, embedding dim 4, hidden size 512, num layers 1, train loss 1.1249268054962158, validation loss 1.1886241436004639\n",
      "Epoch 280, current patience 11, model mean validation loss 1.1464111804962158, embedding dim 4, hidden size 512, num layers 1, train loss 1.0865281820297241, validation loss 1.1882917881011963\n",
      "Epoch 290, current patience 10, model mean validation loss 1.14237642288208, embedding dim 4, hidden size 512, num layers 1, train loss 1.1073286533355713, validation loss 1.1254761219024658\n",
      "Epoch 300, current patience 9, model mean validation loss 1.1381280422210693, embedding dim 4, hidden size 512, num layers 1, train loss 1.0915310382843018, validation loss 1.1144860982894897\n",
      "Epoch 310, current patience 8, model mean validation loss 1.134741187095642, embedding dim 4, hidden size 512, num layers 1, train loss 1.0754153728485107, validation loss 1.0998923778533936\n",
      "Epoch 320, current patience 7, model mean validation loss 1.1348841190338135, embedding dim 4, hidden size 512, num layers 1, train loss 1.007908582687378, validation loss 1.1271497011184692\n",
      "Epoch 330, current patience 6, model mean validation loss 1.1321483850479126, embedding dim 4, hidden size 512, num layers 1, train loss 1.1133395433425903, validation loss 1.0937508344650269\n",
      "Epoch 340, current patience 5, model mean validation loss 1.1296249628067017, embedding dim 4, hidden size 512, num layers 1, train loss 1.0925285816192627, validation loss 1.0993285179138184\n",
      "Epoch 350, current patience 4, model mean validation loss 1.1184852123260498, embedding dim 4, hidden size 512, num layers 1, train loss 1.1239852905273438, validation loss 1.0995063781738281\n",
      "Epoch 360, current patience 3, model mean validation loss 1.1118626594543457, embedding dim 4, hidden size 512, num layers 1, train loss 1.1735215187072754, validation loss 1.135311245918274\n",
      "Epoch 370, current patience 2, model mean validation loss 1.109154462814331, embedding dim 4, hidden size 512, num layers 1, train loss 1.1293869018554688, validation loss 1.1038105487823486\n",
      "Epoch 380, current patience 1, model mean validation loss 1.112276554107666, embedding dim 4, hidden size 512, num layers 1, train loss 1.109553575515747, validation loss 1.1394625902175903\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2194366455078125, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0981318950653076, validation loss 1.2194366455078125\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1942496299743652, embedding dim 4, hidden size 1024, num layers 1, train loss 1.120758295059204, validation loss 1.169062614440918\n",
      "Epoch 20, current patience 30, model mean validation loss 1.2212824821472168, embedding dim 4, hidden size 1024, num layers 1, train loss 1.2058351039886475, validation loss 1.2753483057022095\n",
      "Epoch 30, current patience 29, model mean validation loss 1.2267255783081055, embedding dim 4, hidden size 1024, num layers 1, train loss 1.2436556816101074, validation loss 1.243054986000061\n",
      "Epoch 40, current patience 28, model mean validation loss 1.2291353940963745, embedding dim 4, hidden size 1024, num layers 1, train loss 1.145093321800232, validation loss 1.2387746572494507\n",
      "Epoch 50, current patience 27, model mean validation loss 1.219973087310791, embedding dim 4, hidden size 1024, num layers 1, train loss 1.2240660190582275, validation loss 1.1741617918014526\n",
      "Epoch 60, current patience 26, model mean validation loss 1.2072876691818237, embedding dim 4, hidden size 1024, num layers 1, train loss 1.114898443222046, validation loss 1.1311748027801514\n",
      "Epoch 70, current patience 25, model mean validation loss 1.1976802349090576, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1474156379699707, validation loss 1.1304283142089844\n",
      "Epoch 80, current patience 24, model mean validation loss 1.1894853115081787, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1907367706298828, validation loss 1.1538763046264648\n",
      "Epoch 90, current patience 30, model mean validation loss 1.189099669456482, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0786527395248413, validation loss 1.1659783124923706\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1737558841705322, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1933865547180176, validation loss 1.1525975465774536\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1595323085784912, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1358528137207031, validation loss 1.1292662620544434\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1439260244369507, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1201107501983643, validation loss 1.113924503326416\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1369295120239258, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1276884078979492, validation loss 1.1181904077529907\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1330647468566895, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1133166551589966, validation loss 1.1002558469772339\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1312259435653687, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0318586826324463, validation loss 1.1157186031341553\n",
      "Epoch 160, current patience 30, model mean validation loss 1.1230151653289795, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0806643962860107, validation loss 1.0881900787353516\n",
      "Epoch 170, current patience 30, model mean validation loss 1.1228108406066895, embedding dim 4, hidden size 1024, num layers 1, train loss 1.2132863998413086, validation loss 1.164343237876892\n",
      "Epoch 180, current patience 30, model mean validation loss 1.1163421869277954, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0865743160247803, validation loss 1.1008484363555908\n",
      "Epoch 190, current patience 30, model mean validation loss 1.112926721572876, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0726125240325928, validation loss 1.101943016052246\n",
      "Epoch 200, current patience 30, model mean validation loss 1.1109473705291748, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1254174709320068, validation loss 1.0980898141860962\n",
      "Epoch 210, current patience 30, model mean validation loss 1.1103016138076782, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1556816101074219, validation loss 1.1130237579345703\n",
      "Epoch 220, current patience 30, model mean validation loss 1.109511375427246, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0925936698913574, validation loss 1.0939345359802246\n",
      "Epoch 230, current patience 30, model mean validation loss 1.1095561981201172, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1115514039993286, validation loss 1.1160770654678345\n",
      "Epoch 240, current patience 29, model mean validation loss 1.1089266538619995, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0977599620819092, validation loss 1.083153486251831\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0999610424041748, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0957248210906982, validation loss 1.0926183462142944\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0987433195114136, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1349505186080933, validation loss 1.0911064147949219\n",
      "Epoch 270, current patience 30, model mean validation loss 1.097870111465454, embedding dim 4, hidden size 1024, num layers 1, train loss 1.081871509552002, validation loss 1.0949572324752808\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0955954790115356, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1719715595245361, validation loss 1.0798931121826172\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0920143127441406, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1176512241363525, validation loss 1.0843734741210938\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0968331098556519, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0987510681152344, validation loss 1.1324856281280518\n",
      "Epoch 310, current patience 29, model mean validation loss 1.091500163078308, embedding dim 4, hidden size 1024, num layers 1, train loss 1.096689224243164, validation loss 1.0734140872955322\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0958620309829712, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1092405319213867, validation loss 1.1180477142333984\n",
      "Epoch 330, current patience 29, model mean validation loss 1.0961755514144897, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0256452560424805, validation loss 1.0951272249221802\n",
      "Epoch 340, current patience 28, model mean validation loss 1.096274971961975, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0965828895568848, validation loss 1.0919015407562256\n",
      "Epoch 350, current patience 27, model mean validation loss 1.0976864099502563, embedding dim 4, hidden size 1024, num layers 1, train loss 1.085284948348999, validation loss 1.106248378753662\n",
      "Epoch 360, current patience 26, model mean validation loss 1.0974587202072144, embedding dim 4, hidden size 1024, num layers 1, train loss 1.075409173965454, validation loss 1.0780715942382812\n",
      "Epoch 370, current patience 25, model mean validation loss 1.1045302152633667, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0665197372436523, validation loss 1.1409450769424438\n",
      "Epoch 380, current patience 24, model mean validation loss 1.0998615026474, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1851677894592285, validation loss 1.095136046409607\n",
      "Epoch 390, current patience 23, model mean validation loss 1.102393627166748, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0772055387496948, validation loss 1.093671202659607\n",
      "Epoch 400, current patience 22, model mean validation loss 1.099840760231018, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0995646715164185, validation loss 1.0976248979568481\n",
      "Epoch 410, current patience 21, model mean validation loss 1.111440658569336, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0618263483047485, validation loss 1.187926173210144\n",
      "Epoch 420, current patience 20, model mean validation loss 1.117642879486084, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1496639251708984, validation loss 1.1415190696716309\n",
      "Epoch 430, current patience 19, model mean validation loss 1.114367127418518, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1292409896850586, validation loss 1.0800431966781616\n",
      "Epoch 440, current patience 18, model mean validation loss 1.1173648834228516, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1170333623886108, validation loss 1.1020534038543701\n",
      "Epoch 450, current patience 17, model mean validation loss 1.1115758419036865, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0694098472595215, validation loss 1.094632625579834\n",
      "Epoch 460, current patience 16, model mean validation loss 1.1115281581878662, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1115152835845947, validation loss 1.094754695892334\n",
      "Epoch 470, current patience 15, model mean validation loss 1.1101715564727783, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0902736186981201, validation loss 1.082817792892456\n",
      "Epoch 480, current patience 14, model mean validation loss 1.1116104125976562, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0622403621673584, validation loss 1.1091361045837402\n",
      "Epoch 490, current patience 13, model mean validation loss 1.0989563465118408, embedding dim 4, hidden size 1024, num layers 1, train loss 1.187166690826416, validation loss 1.0866948366165161\n",
      "Epoch 500, current patience 12, model mean validation loss 1.090003252029419, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0639643669128418, validation loss 1.0698933601379395\n",
      "Epoch 510, current patience 30, model mean validation loss 1.0906256437301636, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0152093172073364, validation loss 1.085022211074829\n",
      "Epoch 520, current patience 29, model mean validation loss 1.0899930000305176, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1254112720489502, validation loss 1.0969924926757812\n",
      "Epoch 530, current patience 30, model mean validation loss 1.0995092391967773, embedding dim 4, hidden size 1024, num layers 1, train loss 1.098459005355835, validation loss 1.170762062072754\n",
      "Epoch 540, current patience 29, model mean validation loss 1.119281530380249, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0924456119537354, validation loss 1.2529330253601074\n",
      "Epoch 550, current patience 28, model mean validation loss 1.1275464296340942, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1535887718200684, validation loss 1.148937702178955\n",
      "Epoch 560, current patience 27, model mean validation loss 1.1275250911712646, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0899534225463867, validation loss 1.108964443206787\n",
      "Epoch 570, current patience 26, model mean validation loss 1.1266976594924927, embedding dim 4, hidden size 1024, num layers 1, train loss 1.049209475517273, validation loss 1.080075979232788\n",
      "Epoch 580, current patience 25, model mean validation loss 1.1268664598464966, embedding dim 4, hidden size 1024, num layers 1, train loss 1.024681568145752, validation loss 1.0712435245513916\n",
      "Epoch 590, current patience 24, model mean validation loss 1.1332285404205322, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0427625179290771, validation loss 1.1359189748764038\n",
      "Epoch 600, current patience 23, model mean validation loss 1.1314047574996948, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0621103048324585, validation loss 1.082401990890503\n",
      "Epoch 610, current patience 22, model mean validation loss 1.1211252212524414, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1439718008041382, validation loss 1.088525652885437\n",
      "Epoch 620, current patience 21, model mean validation loss 1.101017951965332, embedding dim 4, hidden size 1024, num layers 1, train loss 0.9974287152290344, validation loss 1.0920758247375488\n",
      "Epoch 630, current patience 20, model mean validation loss 1.0924845933914185, embedding dim 4, hidden size 1024, num layers 1, train loss 1.09486985206604, validation loss 1.08066987991333\n",
      "Epoch 640, current patience 19, model mean validation loss 1.0900700092315674, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0335057973861694, validation loss 1.0896488428115845\n",
      "Epoch 650, current patience 18, model mean validation loss 1.0940886735916138, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1392288208007812, validation loss 1.1122241020202637\n",
      "Epoch 660, current patience 17, model mean validation loss 1.0983126163482666, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1212437152862549, validation loss 1.1050353050231934\n",
      "Epoch 670, current patience 16, model mean validation loss 1.0930345058441162, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0689175128936768, validation loss 1.0936942100524902\n",
      "Epoch 680, current patience 15, model mean validation loss 1.0984551906585693, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0936113595962524, validation loss 1.125767707824707\n",
      "Epoch 690, current patience 14, model mean validation loss 1.1003353595733643, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0829815864562988, validation loss 1.1035668849945068\n",
      "Epoch 700, current patience 13, model mean validation loss 1.1022592782974243, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0006524324417114, validation loss 1.1074671745300293\n",
      "Epoch 710, current patience 12, model mean validation loss 1.106055498123169, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0900723934173584, validation loss 1.111039638519287\n",
      "Epoch 720, current patience 11, model mean validation loss 1.1093711853027344, embedding dim 4, hidden size 1024, num layers 1, train loss 1.057058572769165, validation loss 1.116174340248108\n",
      "Epoch 730, current patience 10, model mean validation loss 1.1108992099761963, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0817762613296509, validation loss 1.1244490146636963\n",
      "Epoch 740, current patience 9, model mean validation loss 1.1154141426086426, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0949950218200684, validation loss 1.1411538124084473\n",
      "Epoch 750, current patience 8, model mean validation loss 1.1239187717437744, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0959181785583496, validation loss 1.1617319583892822\n",
      "Epoch 760, current patience 7, model mean validation loss 1.1214838027954102, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1596611738204956, validation loss 1.1062874794006348\n",
      "Epoch 770, current patience 6, model mean validation loss 1.120964527130127, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0962419509887695, validation loss 1.0994120836257935\n",
      "Epoch 780, current patience 5, model mean validation loss 1.116382122039795, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0247431993484497, validation loss 1.070807933807373\n",
      "Epoch 790, current patience 4, model mean validation loss 1.114567756652832, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0893415212631226, validation loss 1.0965259075164795\n",
      "Epoch 800, current patience 3, model mean validation loss 1.1145906448364258, embedding dim 4, hidden size 1024, num layers 1, train loss 1.1242343187332153, validation loss 1.1163562536239624\n",
      "Epoch 810, current patience 2, model mean validation loss 1.1154134273529053, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0878887176513672, validation loss 1.1310319900512695\n",
      "Epoch 820, current patience 1, model mean validation loss 1.1103122234344482, embedding dim 4, hidden size 1024, num layers 1, train loss 1.0807021856307983, validation loss 1.1003438234329224\n",
      "Epoch 0, current patience 30, model mean validation loss 1.7296593189239502, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1009821891784668, validation loss 1.7296593189239502\n",
      "Epoch 10, current patience 30, model mean validation loss 1.7651869058609009, embedding dim 4, hidden size 2048, num layers 1, train loss 1.7798303365707397, validation loss 1.8007144927978516\n",
      "Epoch 20, current patience 29, model mean validation loss 1.6592435836791992, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2927706241607666, validation loss 1.447356939315796\n",
      "Epoch 30, current patience 30, model mean validation loss 1.5612587928771973, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1236255168914795, validation loss 1.2673041820526123\n",
      "Epoch 40, current patience 30, model mean validation loss 1.4766600131988525, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1583889722824097, validation loss 1.1382644176483154\n",
      "Epoch 50, current patience 30, model mean validation loss 1.4185675382614136, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2536637783050537, validation loss 1.1281054019927979\n",
      "Epoch 60, current patience 30, model mean validation loss 1.3897322416305542, embedding dim 4, hidden size 2048, num layers 1, train loss 1.106798768043518, validation loss 1.2167205810546875\n",
      "Epoch 70, current patience 30, model mean validation loss 1.367813229560852, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1206088066101074, validation loss 1.2143806219100952\n",
      "Epoch 80, current patience 30, model mean validation loss 1.2936726808547974, embedding dim 4, hidden size 2048, num layers 1, train loss 1.249169111251831, validation loss 1.1365349292755127\n",
      "Epoch 90, current patience 30, model mean validation loss 1.214261770248413, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2177293300628662, validation loss 1.1654267311096191\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1714988946914673, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2586802244186401, validation loss 1.1052539348602295\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1559171676635742, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0731043815612793, validation loss 1.1426501274108887\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1655879020690918, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2161647081375122, validation loss 1.2156306505203247\n",
      "Epoch 130, current patience 29, model mean validation loss 1.191894292831421, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1451945304870605, validation loss 1.3385567665100098\n",
      "Epoch 140, current patience 28, model mean validation loss 1.1808632612228394, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2272634506225586, validation loss 1.128472089767456\n",
      "Epoch 150, current patience 27, model mean validation loss 1.1965863704681396, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2683885097503662, validation loss 1.3401658535003662\n",
      "Epoch 160, current patience 26, model mean validation loss 1.2081384658813477, embedding dim 4, hidden size 2048, num layers 1, train loss 1.4585607051849365, validation loss 1.2289512157440186\n",
      "Epoch 170, current patience 25, model mean validation loss 1.2150862216949463, embedding dim 4, hidden size 2048, num layers 1, train loss 1.113950252532959, validation loss 1.2210084199905396\n",
      "Epoch 180, current patience 24, model mean validation loss 1.2174757719039917, embedding dim 4, hidden size 2048, num layers 1, train loss 1.4738578796386719, validation loss 1.1243715286254883\n",
      "Epoch 190, current patience 23, model mean validation loss 1.2231040000915527, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0763307809829712, validation loss 1.1876754760742188\n",
      "Epoch 200, current patience 22, model mean validation loss 1.2282323837280273, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1596715450286865, validation loss 1.2566578388214111\n",
      "Epoch 210, current patience 21, model mean validation loss 1.200937032699585, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2941986322402954, validation loss 1.1201934814453125\n",
      "Epoch 220, current patience 20, model mean validation loss 1.2207412719726562, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1089664697647095, validation loss 1.2869062423706055\n",
      "Epoch 230, current patience 19, model mean validation loss 1.1958264112472534, embedding dim 4, hidden size 2048, num layers 1, train loss 1.3845772743225098, validation loss 1.1408473253250122\n",
      "Epoch 240, current patience 18, model mean validation loss 1.1835401058197021, embedding dim 4, hidden size 2048, num layers 1, train loss 1.167217493057251, validation loss 1.1306605339050293\n",
      "Epoch 250, current patience 17, model mean validation loss 1.1794352531433105, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2604169845581055, validation loss 1.1881699562072754\n",
      "Epoch 260, current patience 16, model mean validation loss 1.1840593814849854, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1521503925323486, validation loss 1.1613636016845703\n",
      "Epoch 270, current patience 15, model mean validation loss 1.1733555793762207, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0980207920074463, validation loss 1.102046251296997\n",
      "Epoch 280, current patience 14, model mean validation loss 1.154341220855713, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1766107082366943, validation loss 1.1045421361923218\n",
      "Epoch 290, current patience 30, model mean validation loss 1.1524488925933838, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1792573928833008, validation loss 1.1050543785095215\n",
      "Epoch 300, current patience 30, model mean validation loss 1.1321227550506592, embedding dim 4, hidden size 2048, num layers 1, train loss 1.041015386581421, validation loss 1.124297022819519\n",
      "Epoch 310, current patience 30, model mean validation loss 1.1377170085906982, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1135132312774658, validation loss 1.1856024265289307\n",
      "Epoch 320, current patience 29, model mean validation loss 1.1312005519866943, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1397820711135864, validation loss 1.0785291194915771\n",
      "Epoch 330, current patience 30, model mean validation loss 1.120009422302246, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1606614589691162, validation loss 1.0986400842666626\n",
      "Epoch 340, current patience 30, model mean validation loss 1.1150952577590942, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0937755107879639, validation loss 1.1220507621765137\n",
      "Epoch 350, current patience 30, model mean validation loss 1.1185365915298462, embedding dim 4, hidden size 2048, num layers 1, train loss 1.112544298171997, validation loss 1.1295771598815918\n",
      "Epoch 360, current patience 29, model mean validation loss 1.1175789833068848, embedding dim 4, hidden size 2048, num layers 1, train loss 1.444454550743103, validation loss 1.0968806743621826\n",
      "Epoch 370, current patience 28, model mean validation loss 1.1253951787948608, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1970821619033813, validation loss 1.1675840616226196\n",
      "Epoch 380, current patience 27, model mean validation loss 1.1214208602905273, embedding dim 4, hidden size 2048, num layers 1, train loss 1.095324993133545, validation loss 1.0925030708312988\n",
      "Epoch 390, current patience 26, model mean validation loss 1.1276054382324219, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1628844738006592, validation loss 1.2350788116455078\n",
      "Epoch 400, current patience 25, model mean validation loss 1.1300630569458008, embedding dim 4, hidden size 2048, num layers 1, train loss 1.111492395401001, validation loss 1.0981906652450562\n",
      "Epoch 410, current patience 24, model mean validation loss 1.1355369091033936, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1665081977844238, validation loss 1.142430067062378\n",
      "Epoch 420, current patience 23, model mean validation loss 1.1353302001953125, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1400227546691895, validation loss 1.120397686958313\n",
      "Epoch 430, current patience 22, model mean validation loss 1.1361976861953735, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1030024290084839, validation loss 1.136516809463501\n",
      "Epoch 440, current patience 21, model mean validation loss 1.1361370086669922, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1790094375610352, validation loss 1.096394658088684\n",
      "Epoch 450, current patience 20, model mean validation loss 1.1298213005065918, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0754873752593994, validation loss 1.1170588731765747\n",
      "Epoch 460, current patience 19, model mean validation loss 1.1347393989562988, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0773595571517944, validation loss 1.131847858428955\n",
      "Epoch 470, current patience 18, model mean validation loss 1.115767240524292, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1854283809661865, validation loss 1.0833015441894531\n",
      "Epoch 480, current patience 17, model mean validation loss 1.1279242038726807, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0924433469772339, validation loss 1.1954463720321655\n",
      "Epoch 490, current patience 16, model mean validation loss 1.121492862701416, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0854520797729492, validation loss 1.090978980064392\n",
      "Epoch 500, current patience 15, model mean validation loss 1.1173627376556396, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1013720035552979, validation loss 1.0873568058013916\n",
      "Epoch 510, current patience 14, model mean validation loss 1.1135213375091553, embedding dim 4, hidden size 2048, num layers 1, train loss 0.9939085245132446, validation loss 1.1057857275009155\n",
      "Epoch 520, current patience 30, model mean validation loss 1.112898588180542, embedding dim 4, hidden size 2048, num layers 1, train loss 1.105694055557251, validation loss 1.0914130210876465\n",
      "Epoch 530, current patience 30, model mean validation loss 1.1341146230697632, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0981576442718506, validation loss 1.2867869138717651\n",
      "Epoch 540, current patience 29, model mean validation loss 1.164859414100647, embedding dim 4, hidden size 2048, num layers 1, train loss 1.213974118232727, validation loss 1.377805471420288\n",
      "Epoch 550, current patience 28, model mean validation loss 1.1675742864608765, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0317515134811401, validation loss 1.1050208806991577\n",
      "Epoch 560, current patience 27, model mean validation loss 1.1622613668441772, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1241884231567383, validation loss 1.1529431343078613\n",
      "Epoch 570, current patience 26, model mean validation loss 1.1657991409301758, embedding dim 4, hidden size 2048, num layers 1, train loss 0.9843212366104126, validation loss 1.119281530380249\n",
      "Epoch 580, current patience 25, model mean validation loss 1.1682504415512085, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0902681350708008, validation loss 1.1069667339324951\n",
      "Epoch 590, current patience 24, model mean validation loss 1.1658270359039307, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0943143367767334, validation loss 1.0863986015319824\n",
      "Epoch 600, current patience 23, model mean validation loss 1.1755480766296387, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0916976928710938, validation loss 1.1691811084747314\n",
      "Epoch 610, current patience 22, model mean validation loss 1.1523960828781128, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0688636302947998, validation loss 1.1015714406967163\n",
      "Epoch 620, current patience 21, model mean validation loss 1.1215617656707764, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2163423299789429, validation loss 1.1311299800872803\n",
      "Epoch 630, current patience 20, model mean validation loss 1.1251399517059326, embedding dim 4, hidden size 2048, num layers 1, train loss 1.7532005310058594, validation loss 1.1336467266082764\n",
      "Epoch 640, current patience 19, model mean validation loss 1.1634647846221924, embedding dim 4, hidden size 2048, num layers 1, train loss 1.410048246383667, validation loss 1.4595415592193604\n",
      "Epoch 650, current patience 18, model mean validation loss 1.1655216217041016, embedding dim 4, hidden size 2048, num layers 1, train loss 1.102708339691162, validation loss 1.1357367038726807\n",
      "Epoch 660, current patience 17, model mean validation loss 1.1695942878723145, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0617977380752563, validation loss 1.1395481824874878\n",
      "Epoch 670, current patience 16, model mean validation loss 1.1914732456207275, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1084556579589844, validation loss 1.2614305019378662\n",
      "Epoch 680, current patience 15, model mean validation loss 1.2010242938995361, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1734663248062134, validation loss 1.2455893754959106\n",
      "Epoch 690, current patience 14, model mean validation loss 1.2090771198272705, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1279692649841309, validation loss 1.1659941673278809\n",
      "Epoch 700, current patience 13, model mean validation loss 1.2049131393432617, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1281603574752808, validation loss 1.0978176593780518\n",
      "Epoch 710, current patience 12, model mean validation loss 1.2040741443634033, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1741185188293457, validation loss 1.1269354820251465\n",
      "Epoch 720, current patience 11, model mean validation loss 1.1613736152648926, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2577879428863525, validation loss 1.117936611175537\n",
      "Epoch 730, current patience 10, model mean validation loss 1.1655242443084717, embedding dim 4, hidden size 2048, num layers 1, train loss 1.0428814888000488, validation loss 1.1689428091049194\n",
      "Epoch 740, current patience 9, model mean validation loss 1.162205457687378, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2344415187835693, validation loss 1.1129966974258423\n",
      "Epoch 750, current patience 8, model mean validation loss 1.1655983924865723, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2144163846969604, validation loss 1.2885745763778687\n",
      "Epoch 760, current patience 7, model mean validation loss 1.1808230876922607, embedding dim 4, hidden size 2048, num layers 1, train loss 1.117477536201477, validation loss 1.3673865795135498\n",
      "Epoch 770, current patience 6, model mean validation loss 1.1974891424179077, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2011696100234985, validation loss 1.299322485923767\n",
      "Epoch 780, current patience 5, model mean validation loss 1.2229888439178467, embedding dim 4, hidden size 2048, num layers 1, train loss 1.236138105392456, validation loss 1.301815390586853\n",
      "Epoch 790, current patience 4, model mean validation loss 1.2328734397888184, embedding dim 4, hidden size 2048, num layers 1, train loss 1.1358280181884766, validation loss 1.2060117721557617\n",
      "Epoch 800, current patience 3, model mean validation loss 1.2544583082199097, embedding dim 4, hidden size 2048, num layers 1, train loss 1.2352672815322876, validation loss 1.2906155586242676\n",
      "Epoch 810, current patience 2, model mean validation loss 1.258133888244629, embedding dim 4, hidden size 2048, num layers 1, train loss 2.312532901763916, validation loss 1.1983470916748047\n",
      "Epoch 820, current patience 1, model mean validation loss 1.268519639968872, embedding dim 4, hidden size 2048, num layers 1, train loss 1.598170280456543, validation loss 1.1960835456848145\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1737933158874512, embedding dim 8, hidden size 1, num layers 1, train loss 1.1636173725128174, validation loss 1.1737933158874512\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1592974662780762, embedding dim 8, hidden size 1, num layers 1, train loss 1.134538173675537, validation loss 1.1448014974594116\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1477605104446411, embedding dim 8, hidden size 1, num layers 1, train loss 1.113539695739746, validation loss 1.1246867179870605\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1379257440567017, embedding dim 8, hidden size 1, num layers 1, train loss 1.1225979328155518, validation loss 1.1084212064743042\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1299631595611572, embedding dim 8, hidden size 1, num layers 1, train loss 1.0958168506622314, validation loss 1.0981128215789795\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1245439052581787, embedding dim 8, hidden size 1, num layers 1, train loss 1.099421739578247, validation loss 1.0974476337432861\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1202343702316284, embedding dim 8, hidden size 1, num layers 1, train loss 1.0954151153564453, validation loss 1.094376802444458\n",
      "Epoch 70, current patience 30, model mean validation loss 1.117163896560669, embedding dim 8, hidden size 1, num layers 1, train loss 1.102906346321106, validation loss 1.0956711769104004\n",
      "Epoch 80, current patience 30, model mean validation loss 1.107568621635437, embedding dim 8, hidden size 1, num layers 1, train loss 1.1013660430908203, validation loss 1.097031593322754\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1011970043182373, embedding dim 8, hidden size 1, num layers 1, train loss 1.1028481721878052, validation loss 1.0938279628753662\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0976483821868896, embedding dim 8, hidden size 1, num layers 1, train loss 1.0825568437576294, validation loss 1.0962979793548584\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0960229635238647, embedding dim 8, hidden size 1, num layers 1, train loss 1.1066579818725586, validation loss 1.0954174995422363\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0955255031585693, embedding dim 8, hidden size 1, num layers 1, train loss 1.099172592163086, validation loss 1.0941331386566162\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0946860313415527, embedding dim 8, hidden size 1, num layers 1, train loss 1.0803718566894531, validation loss 1.0907312631607056\n",
      "Epoch 140, current patience 30, model mean validation loss 1.094435453414917, embedding dim 8, hidden size 1, num layers 1, train loss 1.096376895904541, validation loss 1.0923731327056885\n",
      "Epoch 150, current patience 30, model mean validation loss 1.093968152999878, embedding dim 8, hidden size 1, num layers 1, train loss 1.093715786933899, validation loss 1.0919326543807983\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0932835340499878, embedding dim 8, hidden size 1, num layers 1, train loss 1.0564384460449219, validation loss 1.0915541648864746\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0921880006790161, embedding dim 8, hidden size 1, num layers 1, train loss 1.0861833095550537, validation loss 1.085064172744751\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0911694765090942, embedding dim 8, hidden size 1, num layers 1, train loss 1.0884110927581787, validation loss 1.088149905204773\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0899007320404053, embedding dim 8, hidden size 1, num layers 1, train loss 1.0782008171081543, validation loss 1.0852679014205933\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0881314277648926, embedding dim 8, hidden size 1, num layers 1, train loss 1.0607035160064697, validation loss 1.079978346824646\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0858948230743408, embedding dim 8, hidden size 1, num layers 1, train loss 1.0671756267547607, validation loss 1.072838544845581\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0834546089172363, embedding dim 8, hidden size 1, num layers 1, train loss 1.0173094272613525, validation loss 1.072851538658142\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0800615549087524, embedding dim 8, hidden size 1, num layers 1, train loss 1.030444860458374, validation loss 1.0647882223129272\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0768318176269531, embedding dim 8, hidden size 1, num layers 1, train loss 1.0838068723678589, validation loss 1.0657163858413696\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0734730958938599, embedding dim 8, hidden size 1, num layers 1, train loss 1.0507736206054688, validation loss 1.0581941604614258\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0680508613586426, embedding dim 8, hidden size 1, num layers 1, train loss 1.0563617944717407, validation loss 1.0447723865509033\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0641896724700928, embedding dim 8, hidden size 1, num layers 1, train loss 0.9695546627044678, validation loss 1.0543780326843262\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0592070817947388, embedding dim 8, hidden size 1, num layers 1, train loss 0.9678575396537781, validation loss 1.0401175022125244\n",
      "Epoch 290, current patience 30, model mean validation loss 1.054273247718811, embedding dim 8, hidden size 1, num layers 1, train loss 0.9828109741210938, validation loss 1.033367395401001\n",
      "Epoch 300, current patience 30, model mean validation loss 1.048885464668274, embedding dim 8, hidden size 1, num layers 1, train loss 1.0837434530258179, validation loss 1.0297496318817139\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0459040403366089, embedding dim 8, hidden size 1, num layers 1, train loss 0.9478915929794312, validation loss 1.0409371852874756\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0417331457138062, embedding dim 8, hidden size 1, num layers 1, train loss 0.9538658261299133, validation loss 1.0323495864868164\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0384876728057861, embedding dim 8, hidden size 1, num layers 1, train loss 0.9087866544723511, validation loss 1.0322296619415283\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0362269878387451, embedding dim 8, hidden size 1, num layers 1, train loss 0.9261118769645691, validation loss 1.0266867876052856\n",
      "Epoch 350, current patience 30, model mean validation loss 1.030031442642212, embedding dim 8, hidden size 1, num layers 1, train loss 0.888804018497467, validation loss 1.00481379032135\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0285394191741943, embedding dim 8, hidden size 1, num layers 1, train loss 1.0786339044570923, validation loss 1.0281805992126465\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0231126546859741, embedding dim 8, hidden size 1, num layers 1, train loss 0.9095317125320435, validation loss 0.989953875541687\n",
      "Epoch 380, current patience 30, model mean validation loss 1.018774390220642, embedding dim 8, hidden size 1, num layers 1, train loss 0.9491705894470215, validation loss 0.995043933391571\n",
      "Epoch 390, current patience 30, model mean validation loss 1.011858582496643, embedding dim 8, hidden size 1, num layers 1, train loss 0.9199701547622681, validation loss 0.9856101274490356\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0077100992202759, embedding dim 8, hidden size 1, num layers 1, train loss 0.9065734148025513, validation loss 0.9991623759269714\n",
      "Epoch 410, current patience 30, model mean validation loss 1.001704454421997, embedding dim 8, hidden size 1, num layers 1, train loss 0.9021958112716675, validation loss 0.9841839671134949\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9958020448684692, embedding dim 8, hidden size 1, num layers 1, train loss 0.921783447265625, validation loss 0.9794678688049316\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9919750690460205, embedding dim 8, hidden size 1, num layers 1, train loss 0.9357976913452148, validation loss 0.9741973876953125\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9857938885688782, embedding dim 8, hidden size 1, num layers 1, train loss 0.9259979724884033, validation loss 0.9787313342094421\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9824225306510925, embedding dim 8, hidden size 1, num layers 1, train loss 0.8702714443206787, validation loss 0.9629830718040466\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9772974252700806, embedding dim 8, hidden size 1, num layers 1, train loss 0.8750212788581848, validation loss 0.9540430903434753\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9721770286560059, embedding dim 8, hidden size 1, num layers 1, train loss 0.8132503032684326, validation loss 0.9446468353271484\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9678635597229004, embedding dim 8, hidden size 1, num layers 1, train loss 0.9990171790122986, validation loss 0.9646550416946411\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9626628160476685, embedding dim 8, hidden size 1, num layers 1, train loss 0.8350005149841309, validation loss 0.9425778388977051\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9575302600860596, embedding dim 8, hidden size 1, num layers 1, train loss 0.8991913795471191, validation loss 0.9384075403213501\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9522285461425781, embedding dim 8, hidden size 1, num layers 1, train loss 0.761579692363739, validation loss 0.9317834973335266\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9455780386924744, embedding dim 8, hidden size 1, num layers 1, train loss 0.836378812789917, validation loss 0.9255273938179016\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9401181936264038, embedding dim 8, hidden size 1, num layers 1, train loss 0.9578967690467834, validation loss 0.9193041324615479\n",
      "Epoch 540, current patience 30, model mean validation loss 0.937897264957428, embedding dim 8, hidden size 1, num layers 1, train loss 0.8226773738861084, validation loss 0.9362757205963135\n",
      "Epoch 550, current patience 30, model mean validation loss 0.936830997467041, embedding dim 8, hidden size 1, num layers 1, train loss 0.8196568489074707, validation loss 0.9361169338226318\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9312139749526978, embedding dim 8, hidden size 1, num layers 1, train loss 0.8319336771965027, validation loss 0.9197187423706055\n",
      "Epoch 570, current patience 30, model mean validation loss 0.9291818141937256, embedding dim 8, hidden size 1, num layers 1, train loss 0.8274073600769043, validation loss 0.926320493221283\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9302655458450317, embedding dim 8, hidden size 1, num layers 1, train loss 0.7340536713600159, validation loss 0.9470772743225098\n",
      "Epoch 590, current patience 29, model mean validation loss 0.930743932723999, embedding dim 8, hidden size 1, num layers 1, train loss 0.8636751174926758, validation loss 0.9356112480163574\n",
      "Epoch 600, current patience 28, model mean validation loss 0.9282928705215454, embedding dim 8, hidden size 1, num layers 1, train loss 0.7658207416534424, validation loss 0.9059183597564697\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9283967018127441, embedding dim 8, hidden size 1, num layers 1, train loss 0.8510209321975708, validation loss 0.920134961605072\n",
      "Epoch 620, current patience 29, model mean validation loss 0.9232479929924011, embedding dim 8, hidden size 1, num layers 1, train loss 0.8218867778778076, validation loss 0.8950858116149902\n",
      "Epoch 630, current patience 30, model mean validation loss 0.9209378957748413, embedding dim 8, hidden size 1, num layers 1, train loss 0.704797625541687, validation loss 0.9176366329193115\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9195377826690674, embedding dim 8, hidden size 1, num layers 1, train loss 0.7935847640037537, validation loss 0.9085173606872559\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9189914464950562, embedding dim 8, hidden size 1, num layers 1, train loss 0.6883009672164917, validation loss 0.9219496250152588\n",
      "Epoch 660, current patience 30, model mean validation loss 0.9131761789321899, embedding dim 8, hidden size 1, num layers 1, train loss 0.760123610496521, validation loss 0.9005553126335144\n",
      "Epoch 670, current patience 30, model mean validation loss 0.9070662260055542, embedding dim 8, hidden size 1, num layers 1, train loss 0.8928154706954956, validation loss 0.8867311477661133\n",
      "Epoch 680, current patience 30, model mean validation loss 0.9050657153129578, embedding dim 8, hidden size 1, num layers 1, train loss 0.7671236991882324, validation loss 0.8899143934249878\n",
      "Epoch 690, current patience 30, model mean validation loss 0.905576765537262, embedding dim 8, hidden size 1, num layers 1, train loss 0.8779276609420776, validation loss 0.924223780632019\n",
      "Epoch 700, current patience 29, model mean validation loss 0.9101899862289429, embedding dim 8, hidden size 1, num layers 1, train loss 0.8082144260406494, validation loss 0.9319919347763062\n",
      "Epoch 710, current patience 28, model mean validation loss 0.9099694490432739, embedding dim 8, hidden size 1, num layers 1, train loss 0.6721296310424805, validation loss 0.9158719778060913\n",
      "Epoch 720, current patience 27, model mean validation loss 0.908536970615387, embedding dim 8, hidden size 1, num layers 1, train loss 1.0031852722167969, validation loss 0.8970575332641602\n",
      "Epoch 730, current patience 26, model mean validation loss 0.9045875072479248, embedding dim 8, hidden size 1, num layers 1, train loss 0.7649738788604736, validation loss 0.8903539180755615\n",
      "Epoch 740, current patience 30, model mean validation loss 0.9061856269836426, embedding dim 8, hidden size 1, num layers 1, train loss 0.6487137079238892, validation loss 0.9133403301239014\n",
      "Epoch 750, current patience 29, model mean validation loss 0.907497763633728, embedding dim 8, hidden size 1, num layers 1, train loss 0.7691316604614258, validation loss 0.8972281217575073\n",
      "Epoch 760, current patience 28, model mean validation loss 0.9081380367279053, embedding dim 8, hidden size 1, num layers 1, train loss 0.877272367477417, validation loss 0.8950366377830505\n",
      "Epoch 770, current patience 27, model mean validation loss 0.9087077975273132, embedding dim 8, hidden size 1, num layers 1, train loss 0.7654563188552856, validation loss 0.9287816286087036\n",
      "Epoch 780, current patience 26, model mean validation loss 0.9065234661102295, embedding dim 8, hidden size 1, num layers 1, train loss 0.674997091293335, validation loss 0.9145174026489258\n",
      "Epoch 790, current patience 25, model mean validation loss 0.9021776914596558, embedding dim 8, hidden size 1, num layers 1, train loss 0.6567850708961487, validation loss 0.8811053037643433\n",
      "Epoch 800, current patience 30, model mean validation loss 0.9025148153305054, embedding dim 8, hidden size 1, num layers 1, train loss 0.702890157699585, validation loss 0.8997557163238525\n",
      "Epoch 810, current patience 29, model mean validation loss 0.8998711705207825, embedding dim 8, hidden size 1, num layers 1, train loss 0.6664963960647583, validation loss 0.869204044342041\n",
      "Epoch 820, current patience 30, model mean validation loss 0.8986074328422546, embedding dim 8, hidden size 1, num layers 1, train loss 0.6303274631500244, validation loss 0.9032306671142578\n",
      "Epoch 830, current patience 30, model mean validation loss 0.8977139592170715, embedding dim 8, hidden size 1, num layers 1, train loss 0.7813667058944702, validation loss 0.8900800943374634\n",
      "Epoch 840, current patience 30, model mean validation loss 0.8983527421951294, embedding dim 8, hidden size 1, num layers 1, train loss 0.7009242177009583, validation loss 0.9001469016075134\n",
      "Epoch 850, current patience 29, model mean validation loss 0.8969844579696655, embedding dim 8, hidden size 1, num layers 1, train loss 0.6996444463729858, validation loss 0.9178357124328613\n",
      "Epoch 860, current patience 30, model mean validation loss 0.8943880200386047, embedding dim 8, hidden size 1, num layers 1, train loss 0.8458414077758789, validation loss 0.8937457799911499\n",
      "Epoch 870, current patience 30, model mean validation loss 0.895992636680603, embedding dim 8, hidden size 1, num layers 1, train loss 0.7216842174530029, validation loss 0.8939422369003296\n",
      "Epoch 880, current patience 29, model mean validation loss 0.8977846503257751, embedding dim 8, hidden size 1, num layers 1, train loss 0.7499872446060181, validation loss 0.9140915870666504\n",
      "Epoch 890, current patience 28, model mean validation loss 0.8978286981582642, embedding dim 8, hidden size 1, num layers 1, train loss 0.7031452655792236, validation loss 0.869556188583374\n",
      "Epoch 900, current patience 27, model mean validation loss 0.8984008431434631, embedding dim 8, hidden size 1, num layers 1, train loss 0.7450470924377441, validation loss 0.9078084230422974\n",
      "Epoch 910, current patience 26, model mean validation loss 0.9034873247146606, embedding dim 8, hidden size 1, num layers 1, train loss 0.6639217734336853, validation loss 0.9307714700698853\n",
      "Epoch 920, current patience 25, model mean validation loss 0.9010207056999207, embedding dim 8, hidden size 1, num layers 1, train loss 0.6866471767425537, validation loss 0.8804141283035278\n",
      "Epoch 930, current patience 24, model mean validation loss 0.8989172577857971, embedding dim 8, hidden size 1, num layers 1, train loss 0.6830359697341919, validation loss 0.9010083675384521\n",
      "Epoch 940, current patience 23, model mean validation loss 0.8984243869781494, embedding dim 8, hidden size 1, num layers 1, train loss 0.6281141042709351, validation loss 0.8898030519485474\n",
      "Epoch 950, current patience 22, model mean validation loss 0.8958734273910522, embedding dim 8, hidden size 1, num layers 1, train loss 0.6373254060745239, validation loss 0.8735344409942627\n",
      "Epoch 960, current patience 21, model mean validation loss 0.8953773379325867, embedding dim 8, hidden size 1, num layers 1, train loss 0.5937780737876892, validation loss 0.9101226329803467\n",
      "Epoch 970, current patience 20, model mean validation loss 0.9005735516548157, embedding dim 8, hidden size 1, num layers 1, train loss 0.6709440350532532, validation loss 0.911125898361206\n",
      "Epoch 980, current patience 19, model mean validation loss 0.9002286195755005, embedding dim 8, hidden size 1, num layers 1, train loss 0.6777541637420654, validation loss 0.9050492644309998\n",
      "Epoch 990, current patience 18, model mean validation loss 0.8976196646690369, embedding dim 8, hidden size 1, num layers 1, train loss 0.9589025974273682, validation loss 0.9098993539810181\n",
      "Epoch 1000, current patience 17, model mean validation loss 0.9055886268615723, embedding dim 8, hidden size 1, num layers 1, train loss 0.714863657951355, validation loss 0.9441657066345215\n",
      "Epoch 1010, current patience 16, model mean validation loss 0.9053236246109009, embedding dim 8, hidden size 1, num layers 1, train loss 0.7150439023971558, validation loss 0.8988887071609497\n",
      "Epoch 1020, current patience 15, model mean validation loss 0.905880331993103, embedding dim 8, hidden size 1, num layers 1, train loss 0.6787976622581482, validation loss 0.8942564725875854\n",
      "Epoch 1030, current patience 14, model mean validation loss 0.9109965562820435, embedding dim 8, hidden size 1, num layers 1, train loss 0.6227356195449829, validation loss 0.9144643545150757\n",
      "Epoch 1040, current patience 13, model mean validation loss 0.9103860855102539, embedding dim 8, hidden size 1, num layers 1, train loss 0.6937305331230164, validation loss 0.9052388072013855\n",
      "Epoch 1050, current patience 12, model mean validation loss 0.9116024971008301, embedding dim 8, hidden size 1, num layers 1, train loss 0.6618475914001465, validation loss 0.9208574295043945\n",
      "Epoch 1060, current patience 11, model mean validation loss 0.9115549325942993, embedding dim 8, hidden size 1, num layers 1, train loss 0.879560649394989, validation loss 0.9046684503555298\n",
      "Epoch 1070, current patience 10, model mean validation loss 0.9163108468055725, embedding dim 8, hidden size 1, num layers 1, train loss 0.6862630844116211, validation loss 0.9479465484619141\n",
      "Epoch 1080, current patience 9, model mean validation loss 0.9163143038749695, embedding dim 8, hidden size 1, num layers 1, train loss 0.6304762959480286, validation loss 0.9441937208175659\n",
      "Epoch 1090, current patience 8, model mean validation loss 0.9190024733543396, embedding dim 8, hidden size 1, num layers 1, train loss 0.5518746376037598, validation loss 0.9203938245773315\n",
      "Epoch 1100, current patience 7, model mean validation loss 0.9274373054504395, embedding dim 8, hidden size 1, num layers 1, train loss 0.6106141209602356, validation loss 0.9617353677749634\n",
      "Epoch 1110, current patience 6, model mean validation loss 0.9330338835716248, embedding dim 8, hidden size 1, num layers 1, train loss 0.6685781478881836, validation loss 0.9592365622520447\n",
      "Epoch 1120, current patience 5, model mean validation loss 0.9369990825653076, embedding dim 8, hidden size 1, num layers 1, train loss 0.6285973787307739, validation loss 0.9369605183601379\n",
      "Epoch 1130, current patience 4, model mean validation loss 0.940532922744751, embedding dim 8, hidden size 1, num layers 1, train loss 0.5910598039627075, validation loss 0.9491282105445862\n",
      "Epoch 1140, current patience 3, model mean validation loss 0.9424046277999878, embedding dim 8, hidden size 1, num layers 1, train loss 0.5994410514831543, validation loss 0.9196421504020691\n",
      "Epoch 1150, current patience 2, model mean validation loss 0.9444789290428162, embedding dim 8, hidden size 1, num layers 1, train loss 0.5836080312728882, validation loss 0.9645410180091858\n",
      "Epoch 1160, current patience 1, model mean validation loss 0.9547087550163269, embedding dim 8, hidden size 1, num layers 1, train loss 0.6188020706176758, validation loss 1.026032567024231\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1210541725158691, embedding dim 8, hidden size 2, num layers 1, train loss 1.1105700731277466, validation loss 1.1210541725158691\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1132705211639404, embedding dim 8, hidden size 2, num layers 1, train loss 1.1011079549789429, validation loss 1.1054869890213013\n",
      "Epoch 20, current patience 30, model mean validation loss 1.108928918838501, embedding dim 8, hidden size 2, num layers 1, train loss 1.1002159118652344, validation loss 1.100245714187622\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1059846878051758, embedding dim 8, hidden size 2, num layers 1, train loss 1.0967025756835938, validation loss 1.0971519947052002\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1037321090698242, embedding dim 8, hidden size 2, num layers 1, train loss 1.1010289192199707, validation loss 1.0947219133377075\n",
      "Epoch 50, current patience 30, model mean validation loss 1.102210521697998, embedding dim 8, hidden size 2, num layers 1, train loss 1.086301565170288, validation loss 1.094602346420288\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1006720066070557, embedding dim 8, hidden size 2, num layers 1, train loss 1.1101077795028687, validation loss 1.0914411544799805\n",
      "Epoch 70, current patience 30, model mean validation loss 1.100031852722168, embedding dim 8, hidden size 2, num layers 1, train loss 1.0788230895996094, validation loss 1.0955506563186646\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0965592861175537, embedding dim 8, hidden size 2, num layers 1, train loss 1.092921495437622, validation loss 1.093273401260376\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0948359966278076, embedding dim 8, hidden size 2, num layers 1, train loss 1.0991617441177368, validation loss 1.091700553894043\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094315767288208, embedding dim 8, hidden size 2, num layers 1, train loss 1.0791845321655273, validation loss 1.0960841178894043\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0943505764007568, embedding dim 8, hidden size 2, num layers 1, train loss 1.1087381839752197, validation loss 1.097430944442749\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0942691564559937, embedding dim 8, hidden size 2, num layers 1, train loss 1.0933427810668945, validation loss 1.0940704345703125\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0941091775894165, embedding dim 8, hidden size 2, num layers 1, train loss 1.1045082807540894, validation loss 1.0933215618133545\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0945109128952026, embedding dim 8, hidden size 2, num layers 1, train loss 1.1109557151794434, validation loss 1.0946552753448486\n",
      "Epoch 150, current patience 29, model mean validation loss 1.0941873788833618, embedding dim 8, hidden size 2, num layers 1, train loss 1.101905345916748, validation loss 1.0929627418518066\n",
      "Epoch 160, current patience 28, model mean validation loss 1.094421625137329, embedding dim 8, hidden size 2, num layers 1, train loss 1.0971176624298096, validation loss 1.0951476097106934\n",
      "Epoch 170, current patience 27, model mean validation loss 1.0947591066360474, embedding dim 8, hidden size 2, num layers 1, train loss 1.0817573070526123, validation loss 1.094400405883789\n",
      "Epoch 180, current patience 26, model mean validation loss 1.0945489406585693, embedding dim 8, hidden size 2, num layers 1, train loss 1.0896323919296265, validation loss 1.0944018363952637\n",
      "Epoch 190, current patience 25, model mean validation loss 1.093902587890625, embedding dim 8, hidden size 2, num layers 1, train loss 1.0993080139160156, validation loss 1.092260718345642\n",
      "Epoch 200, current patience 30, model mean validation loss 1.09354829788208, embedding dim 8, hidden size 2, num layers 1, train loss 1.101381778717041, validation loss 1.0912355184555054\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0932180881500244, embedding dim 8, hidden size 2, num layers 1, train loss 1.090956687927246, validation loss 1.0906805992126465\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0922253131866455, embedding dim 8, hidden size 2, num layers 1, train loss 1.0737500190734863, validation loss 1.0867129564285278\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0910379886627197, embedding dim 8, hidden size 2, num layers 1, train loss 1.099313497543335, validation loss 1.0834643840789795\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0888392925262451, embedding dim 8, hidden size 2, num layers 1, train loss 1.0763680934906006, validation loss 1.0775582790374756\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0851812362670898, embedding dim 8, hidden size 2, num layers 1, train loss 1.1028977632522583, validation loss 1.0651357173919678\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0781047344207764, embedding dim 8, hidden size 2, num layers 1, train loss 0.9898149967193604, validation loss 1.0377897024154663\n",
      "Epoch 270, current patience 30, model mean validation loss 1.070206642150879, embedding dim 8, hidden size 2, num layers 1, train loss 0.9872092008590698, validation loss 1.0290762186050415\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0581448078155518, embedding dim 8, hidden size 2, num layers 1, train loss 1.0863641500473022, validation loss 0.9947408437728882\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0455904006958008, embedding dim 8, hidden size 2, num layers 1, train loss 1.0759263038635254, validation loss 0.9902445673942566\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0301215648651123, embedding dim 8, hidden size 2, num layers 1, train loss 0.8994080424308777, validation loss 0.9629626870155334\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0116549730300903, embedding dim 8, hidden size 2, num layers 1, train loss 0.9373071193695068, validation loss 0.9357321262359619\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9950575828552246, embedding dim 8, hidden size 2, num layers 1, train loss 0.957787275314331, validation loss 0.9447786211967468\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9785787463188171, embedding dim 8, hidden size 2, num layers 1, train loss 0.9558204412460327, validation loss 0.9333051443099976\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9622464179992676, embedding dim 8, hidden size 2, num layers 1, train loss 0.834552526473999, validation loss 0.9071309566497803\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9496668577194214, embedding dim 8, hidden size 2, num layers 1, train loss 0.8124986290931702, validation loss 0.9284398555755615\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9375518560409546, embedding dim 8, hidden size 2, num layers 1, train loss 0.7895851135253906, validation loss 0.8978215456008911\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9248815774917603, embedding dim 8, hidden size 2, num layers 1, train loss 0.8941079378128052, validation loss 0.8888819217681885\n",
      "Epoch 380, current patience 30, model mean validation loss 0.91568922996521, embedding dim 8, hidden size 2, num layers 1, train loss 0.7226686477661133, validation loss 0.8894237875938416\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9072394371032715, embedding dim 8, hidden size 2, num layers 1, train loss 0.9355722665786743, validation loss 0.8681336641311646\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8999813795089722, embedding dim 8, hidden size 2, num layers 1, train loss 0.7844257950782776, validation loss 0.8867136240005493\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8946048021316528, embedding dim 8, hidden size 2, num layers 1, train loss 0.7253580689430237, validation loss 0.8902927041053772\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8902242183685303, embedding dim 8, hidden size 2, num layers 1, train loss 0.7962971925735474, validation loss 0.8720871210098267\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8832690715789795, embedding dim 8, hidden size 2, num layers 1, train loss 0.7243108153343201, validation loss 0.8727982044219971\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8821834325790405, embedding dim 8, hidden size 2, num layers 1, train loss 0.8318878412246704, validation loss 0.8891369104385376\n",
      "Epoch 450, current patience 30, model mean validation loss 0.874469518661499, embedding dim 8, hidden size 2, num layers 1, train loss 0.6817632913589478, validation loss 0.8271697163581848\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8703675866127014, embedding dim 8, hidden size 2, num layers 1, train loss 0.7501583099365234, validation loss 0.8566088676452637\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8660151958465576, embedding dim 8, hidden size 2, num layers 1, train loss 0.6982240676879883, validation loss 0.8333147168159485\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8610208034515381, embedding dim 8, hidden size 2, num layers 1, train loss 0.8822389841079712, validation loss 0.8467585444450378\n",
      "Epoch 490, current patience 30, model mean validation loss 0.855438232421875, embedding dim 8, hidden size 2, num layers 1, train loss 0.7400482296943665, validation loss 0.8456324934959412\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8490623831748962, embedding dim 8, hidden size 2, num layers 1, train loss 0.6468826532363892, validation loss 0.821079671382904\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8425763249397278, embedding dim 8, hidden size 2, num layers 1, train loss 0.7615890502929688, validation loss 0.8209096193313599\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8341569900512695, embedding dim 8, hidden size 2, num layers 1, train loss 0.722267746925354, validation loss 0.821782112121582\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8333643674850464, embedding dim 8, hidden size 2, num layers 1, train loss 0.7227083444595337, validation loss 0.8208285570144653\n",
      "Epoch 540, current patience 30, model mean validation loss 0.829788088798523, embedding dim 8, hidden size 2, num layers 1, train loss 0.6843106746673584, validation loss 0.8279985785484314\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8328389525413513, embedding dim 8, hidden size 2, num layers 1, train loss 0.6424196362495422, validation loss 0.8577220439910889\n",
      "Epoch 560, current patience 29, model mean validation loss 0.8316775560379028, embedding dim 8, hidden size 2, num layers 1, train loss 0.7693007588386536, validation loss 0.83746737241745\n",
      "Epoch 570, current patience 28, model mean validation loss 0.8308730125427246, embedding dim 8, hidden size 2, num layers 1, train loss 0.6662032008171082, validation loss 0.8391958475112915\n",
      "Epoch 580, current patience 27, model mean validation loss 0.8333101272583008, embedding dim 8, hidden size 2, num layers 1, train loss 0.6695189476013184, validation loss 0.8405765295028687\n",
      "Epoch 590, current patience 26, model mean validation loss 0.8313689231872559, embedding dim 8, hidden size 2, num layers 1, train loss 0.6997864246368408, validation loss 0.8053801655769348\n",
      "Epoch 600, current patience 25, model mean validation loss 0.8361661434173584, embedding dim 8, hidden size 2, num layers 1, train loss 0.683504045009613, validation loss 0.8601603507995605\n",
      "Epoch 610, current patience 24, model mean validation loss 0.838005781173706, embedding dim 8, hidden size 2, num layers 1, train loss 0.8769753575325012, validation loss 0.8355455994606018\n",
      "Epoch 620, current patience 23, model mean validation loss 0.8368744850158691, embedding dim 8, hidden size 2, num layers 1, train loss 0.7682353258132935, validation loss 0.8189476728439331\n",
      "Epoch 630, current patience 22, model mean validation loss 0.8338744640350342, embedding dim 8, hidden size 2, num layers 1, train loss 0.6445552110671997, validation loss 0.8337218165397644\n",
      "Epoch 640, current patience 21, model mean validation loss 0.8320737481117249, embedding dim 8, hidden size 2, num layers 1, train loss 0.8168256282806396, validation loss 0.8230618834495544\n",
      "Epoch 650, current patience 20, model mean validation loss 0.8326302766799927, embedding dim 8, hidden size 2, num layers 1, train loss 0.9880651235580444, validation loss 0.8436477184295654\n",
      "Epoch 660, current patience 19, model mean validation loss 0.8330543041229248, embedding dim 8, hidden size 2, num layers 1, train loss 0.7986147403717041, validation loss 0.8439695239067078\n",
      "Epoch 670, current patience 18, model mean validation loss 0.8398549556732178, embedding dim 8, hidden size 2, num layers 1, train loss 0.5769923329353333, validation loss 0.8597853183746338\n",
      "Epoch 680, current patience 17, model mean validation loss 0.8391788005828857, embedding dim 8, hidden size 2, num layers 1, train loss 0.7626450657844543, validation loss 0.8547508120536804\n",
      "Epoch 690, current patience 16, model mean validation loss 0.8391311168670654, embedding dim 8, hidden size 2, num layers 1, train loss 0.5958674550056458, validation loss 0.8351640105247498\n",
      "Epoch 700, current patience 15, model mean validation loss 0.8397181034088135, embedding dim 8, hidden size 2, num layers 1, train loss 0.5875831842422485, validation loss 0.8236434459686279\n",
      "Epoch 710, current patience 14, model mean validation loss 0.8434509038925171, embedding dim 8, hidden size 2, num layers 1, train loss 0.6646385192871094, validation loss 0.8635842800140381\n",
      "Epoch 720, current patience 13, model mean validation loss 0.844993531703949, embedding dim 8, hidden size 2, num layers 1, train loss 0.5145516991615295, validation loss 0.83540278673172\n",
      "Epoch 730, current patience 12, model mean validation loss 0.8469201326370239, embedding dim 8, hidden size 2, num layers 1, train loss 0.6559959650039673, validation loss 0.8590608835220337\n",
      "Epoch 740, current patience 11, model mean validation loss 0.8473794460296631, embedding dim 8, hidden size 2, num layers 1, train loss 0.6905543208122253, validation loss 0.8476441502571106\n",
      "Epoch 750, current patience 10, model mean validation loss 0.8436776399612427, embedding dim 8, hidden size 2, num layers 1, train loss 0.774093508720398, validation loss 0.8301711082458496\n",
      "Epoch 760, current patience 9, model mean validation loss 0.8416600227355957, embedding dim 8, hidden size 2, num layers 1, train loss 0.8418898582458496, validation loss 0.8386091589927673\n",
      "Epoch 770, current patience 8, model mean validation loss 0.8427152633666992, embedding dim 8, hidden size 2, num layers 1, train loss 0.6873242259025574, validation loss 0.8436060547828674\n",
      "Epoch 780, current patience 7, model mean validation loss 0.8479713797569275, embedding dim 8, hidden size 2, num layers 1, train loss 0.6098841428756714, validation loss 0.8656923174858093\n",
      "Epoch 790, current patience 6, model mean validation loss 0.8451998829841614, embedding dim 8, hidden size 2, num layers 1, train loss 0.6570030450820923, validation loss 0.8414124250411987\n",
      "Epoch 800, current patience 5, model mean validation loss 0.8416844010353088, embedding dim 8, hidden size 2, num layers 1, train loss 0.7815302610397339, validation loss 0.8072792291641235\n",
      "Epoch 810, current patience 4, model mean validation loss 0.840072512626648, embedding dim 8, hidden size 2, num layers 1, train loss 0.5346711874008179, validation loss 0.8461654782295227\n",
      "Epoch 820, current patience 3, model mean validation loss 0.8460165858268738, embedding dim 8, hidden size 2, num layers 1, train loss 0.7695438265800476, validation loss 0.895196795463562\n",
      "Epoch 830, current patience 2, model mean validation loss 0.8427332639694214, embedding dim 8, hidden size 2, num layers 1, train loss 0.6642511487007141, validation loss 0.80390465259552\n",
      "Epoch 840, current patience 1, model mean validation loss 0.8414105176925659, embedding dim 8, hidden size 2, num layers 1, train loss 0.6342208981513977, validation loss 0.8280270099639893\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2525509595870972, embedding dim 8, hidden size 4, num layers 1, train loss 1.2782607078552246, validation loss 1.2525509595870972\n",
      "Epoch 10, current patience 30, model mean validation loss 1.2045222520828247, embedding dim 8, hidden size 4, num layers 1, train loss 1.1702327728271484, validation loss 1.1564935445785522\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1730574369430542, embedding dim 8, hidden size 4, num layers 1, train loss 1.1113888025283813, validation loss 1.1101278066635132\n",
      "Epoch 30, current patience 30, model mean validation loss 1.153896689414978, embedding dim 8, hidden size 4, num layers 1, train loss 1.0936394929885864, validation loss 1.096414566040039\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1422053575515747, embedding dim 8, hidden size 4, num layers 1, train loss 1.1150727272033691, validation loss 1.0954396724700928\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1339980363845825, embedding dim 8, hidden size 4, num layers 1, train loss 1.081533432006836, validation loss 1.0929615497589111\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1285611391067505, embedding dim 8, hidden size 4, num layers 1, train loss 1.0833638906478882, validation loss 1.0959393978118896\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1244230270385742, embedding dim 8, hidden size 4, num layers 1, train loss 1.0943961143493652, validation loss 1.0954569578170776\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1049599647521973, embedding dim 8, hidden size 4, num layers 1, train loss 1.104525089263916, validation loss 1.0968458652496338\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0971180200576782, embedding dim 8, hidden size 4, num layers 1, train loss 1.0882529020309448, validation loss 1.0937583446502686\n",
      "Epoch 100, current patience 30, model mean validation loss 1.09537672996521, embedding dim 8, hidden size 4, num layers 1, train loss 1.0872149467468262, validation loss 1.0961978435516357\n",
      "Epoch 110, current patience 30, model mean validation loss 1.09498929977417, embedding dim 8, hidden size 4, num layers 1, train loss 1.0974647998809814, validation loss 1.0933146476745605\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0949677228927612, embedding dim 8, hidden size 4, num layers 1, train loss 1.1046946048736572, validation loss 1.0952671766281128\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0953073501586914, embedding dim 8, hidden size 4, num layers 1, train loss 1.0962072610855103, validation loss 1.0956782102584839\n",
      "Epoch 140, current patience 29, model mean validation loss 1.0951104164123535, embedding dim 8, hidden size 4, num layers 1, train loss 1.1017520427703857, validation loss 1.0943639278411865\n",
      "Epoch 150, current patience 28, model mean validation loss 1.0948865413665771, embedding dim 8, hidden size 4, num layers 1, train loss 1.0946033000946045, validation loss 1.0936665534973145\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0947024822235107, embedding dim 8, hidden size 4, num layers 1, train loss 1.0808074474334717, validation loss 1.0953738689422607\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0945955514907837, embedding dim 8, hidden size 4, num layers 1, train loss 1.0751817226409912, validation loss 1.092902421951294\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0943433046340942, embedding dim 8, hidden size 4, num layers 1, train loss 1.093578815460205, validation loss 1.0941798686981201\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0939533710479736, embedding dim 8, hidden size 4, num layers 1, train loss 1.068150520324707, validation loss 1.0901950597763062\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0933196544647217, embedding dim 8, hidden size 4, num layers 1, train loss 1.1135979890823364, validation loss 1.0901973247528076\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0925531387329102, embedding dim 8, hidden size 4, num layers 1, train loss 1.095376968383789, validation loss 1.0895462036132812\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0919935703277588, embedding dim 8, hidden size 4, num layers 1, train loss 1.0759798288345337, validation loss 1.0898873805999756\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0910708904266357, embedding dim 8, hidden size 4, num layers 1, train loss 1.0904384851455688, validation loss 1.0862852334976196\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0889596939086914, embedding dim 8, hidden size 4, num layers 1, train loss 1.1018301248550415, validation loss 1.0784837007522583\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0869214534759521, embedding dim 8, hidden size 4, num layers 1, train loss 1.088089942932129, validation loss 1.0765973329544067\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0836782455444336, embedding dim 8, hidden size 4, num layers 1, train loss 1.0320321321487427, validation loss 1.0682342052459717\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0794306993484497, embedding dim 8, hidden size 4, num layers 1, train loss 1.0742371082305908, validation loss 1.0562139749526978\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0737186670303345, embedding dim 8, hidden size 4, num layers 1, train loss 1.0274341106414795, validation loss 1.0445014238357544\n",
      "Epoch 290, current patience 30, model mean validation loss 1.066295862197876, embedding dim 8, hidden size 4, num layers 1, train loss 0.9765291213989258, validation loss 1.030163288116455\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0554144382476807, embedding dim 8, hidden size 4, num layers 1, train loss 0.9325888752937317, validation loss 1.0028369426727295\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0426063537597656, embedding dim 8, hidden size 4, num layers 1, train loss 1.0099010467529297, validation loss 0.9838200807571411\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0272469520568848, embedding dim 8, hidden size 4, num layers 1, train loss 0.8800261616706848, validation loss 0.9556077718734741\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0096014738082886, embedding dim 8, hidden size 4, num layers 1, train loss 0.8893538117408752, validation loss 0.9354343414306641\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9914608597755432, embedding dim 8, hidden size 4, num layers 1, train loss 0.8722249865531921, validation loss 0.9231094121932983\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9753356575965881, embedding dim 8, hidden size 4, num layers 1, train loss 0.8769494295120239, validation loss 0.9272122383117676\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9597906470298767, embedding dim 8, hidden size 4, num layers 1, train loss 0.9080921411514282, validation loss 0.9201414585113525\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9466717839241028, embedding dim 8, hidden size 4, num layers 1, train loss 0.8368134498596191, validation loss 0.9252119660377502\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9318568706512451, embedding dim 8, hidden size 4, num layers 1, train loss 1.004727840423584, validation loss 0.8843178749084473\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9191685914993286, embedding dim 8, hidden size 4, num layers 1, train loss 0.7456035614013672, validation loss 0.8823139071464539\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9074076414108276, embedding dim 8, hidden size 4, num layers 1, train loss 0.8202297687530518, validation loss 0.861519455909729\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8993889689445496, embedding dim 8, hidden size 4, num layers 1, train loss 0.9305978417396545, validation loss 0.8712854385375977\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8910456895828247, embedding dim 8, hidden size 4, num layers 1, train loss 0.7621167898178101, validation loss 0.85636305809021\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8812940120697021, embedding dim 8, hidden size 4, num layers 1, train loss 0.7268044948577881, validation loss 0.849199116230011\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8737257122993469, embedding dim 8, hidden size 4, num layers 1, train loss 0.7568817138671875, validation loss 0.8595951795578003\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8647152185440063, embedding dim 8, hidden size 4, num layers 1, train loss 0.8078620433807373, validation loss 0.8531277179718018\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8598848581314087, embedding dim 8, hidden size 4, num layers 1, train loss 0.7044776678085327, validation loss 0.8456748723983765\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8549950122833252, embedding dim 8, hidden size 4, num layers 1, train loss 0.7431365251541138, validation loss 0.8431949615478516\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8548778891563416, embedding dim 8, hidden size 4, num layers 1, train loss 0.8070169687271118, validation loss 0.8605829477310181\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8537649512290955, embedding dim 8, hidden size 4, num layers 1, train loss 0.6773620843887329, validation loss 0.8623816967010498\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8507591485977173, embedding dim 8, hidden size 4, num layers 1, train loss 0.788668155670166, validation loss 0.8323172330856323\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8521606922149658, embedding dim 8, hidden size 4, num layers 1, train loss 0.6089910268783569, validation loss 0.8604108095169067\n",
      "Epoch 520, current patience 29, model mean validation loss 0.8530817627906799, embedding dim 8, hidden size 4, num layers 1, train loss 0.6763744354248047, validation loss 0.8669636249542236\n",
      "Epoch 530, current patience 28, model mean validation loss 0.8509594202041626, embedding dim 8, hidden size 4, num layers 1, train loss 0.7362943887710571, validation loss 0.8361488580703735\n",
      "Epoch 540, current patience 27, model mean validation loss 0.8502009510993958, embedding dim 8, hidden size 4, num layers 1, train loss 0.6278193593025208, validation loss 0.8396072387695312\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8478302359580994, embedding dim 8, hidden size 4, num layers 1, train loss 0.6102896928787231, validation loss 0.8242294788360596\n",
      "Epoch 560, current patience 30, model mean validation loss 0.8415245413780212, embedding dim 8, hidden size 4, num layers 1, train loss 0.6915150880813599, validation loss 0.8101375102996826\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8386932611465454, embedding dim 8, hidden size 4, num layers 1, train loss 0.6998575925827026, validation loss 0.8397318124771118\n",
      "Epoch 580, current patience 30, model mean validation loss 0.8441758155822754, embedding dim 8, hidden size 4, num layers 1, train loss 0.5450152158737183, validation loss 0.8761769533157349\n",
      "Epoch 590, current patience 29, model mean validation loss 0.8433350920677185, embedding dim 8, hidden size 4, num layers 1, train loss 0.6790833473205566, validation loss 0.8536852598190308\n",
      "Epoch 600, current patience 28, model mean validation loss 0.8401104807853699, embedding dim 8, hidden size 4, num layers 1, train loss 0.7383183240890503, validation loss 0.8411667346954346\n",
      "Epoch 610, current patience 27, model mean validation loss 0.8408280611038208, embedding dim 8, hidden size 4, num layers 1, train loss 0.6552797555923462, validation loss 0.8418898582458496\n",
      "Epoch 620, current patience 26, model mean validation loss 0.8425524234771729, embedding dim 8, hidden size 4, num layers 1, train loss 0.5748286247253418, validation loss 0.8534018397331238\n",
      "Epoch 630, current patience 25, model mean validation loss 0.8453860878944397, embedding dim 8, hidden size 4, num layers 1, train loss 0.812942385673523, validation loss 0.84689861536026\n",
      "Epoch 640, current patience 24, model mean validation loss 0.8484916687011719, embedding dim 8, hidden size 4, num layers 1, train loss 0.6526420712471008, validation loss 0.8349823951721191\n",
      "Epoch 650, current patience 23, model mean validation loss 0.850597083568573, embedding dim 8, hidden size 4, num layers 1, train loss 0.7958880066871643, validation loss 0.8565750122070312\n",
      "Epoch 660, current patience 22, model mean validation loss 0.8433969020843506, embedding dim 8, hidden size 4, num layers 1, train loss 0.6149587631225586, validation loss 0.8185749650001526\n",
      "Epoch 670, current patience 21, model mean validation loss 0.8417940735816956, embedding dim 8, hidden size 4, num layers 1, train loss 0.7612330913543701, validation loss 0.8408631682395935\n",
      "Epoch 680, current patience 20, model mean validation loss 0.8432446122169495, embedding dim 8, hidden size 4, num layers 1, train loss 0.7525857090950012, validation loss 0.8527708649635315\n",
      "Epoch 690, current patience 19, model mean validation loss 0.8375645875930786, embedding dim 8, hidden size 4, num layers 1, train loss 0.6182184219360352, validation loss 0.7964493632316589\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8358653783798218, embedding dim 8, hidden size 4, num layers 1, train loss 0.505687952041626, validation loss 0.839808464050293\n",
      "Epoch 710, current patience 30, model mean validation loss 0.8377639055252075, embedding dim 8, hidden size 4, num layers 1, train loss 0.5543153285980225, validation loss 0.8620873689651489\n",
      "Epoch 720, current patience 29, model mean validation loss 0.838620662689209, embedding dim 8, hidden size 4, num layers 1, train loss 0.7445856332778931, validation loss 0.8418357372283936\n",
      "Epoch 730, current patience 28, model mean validation loss 0.8360327482223511, embedding dim 8, hidden size 4, num layers 1, train loss 0.6200449466705322, validation loss 0.8358721733093262\n",
      "Epoch 740, current patience 27, model mean validation loss 0.8419437408447266, embedding dim 8, hidden size 4, num layers 1, train loss 0.6665010452270508, validation loss 0.8658629059791565\n",
      "Epoch 750, current patience 26, model mean validation loss 0.8479176759719849, embedding dim 8, hidden size 4, num layers 1, train loss 0.5770612955093384, validation loss 0.888654887676239\n",
      "Epoch 760, current patience 25, model mean validation loss 0.8518288135528564, embedding dim 8, hidden size 4, num layers 1, train loss 0.5410430431365967, validation loss 0.8840597867965698\n",
      "Epoch 770, current patience 24, model mean validation loss 0.8606390953063965, embedding dim 8, hidden size 4, num layers 1, train loss 0.6267324686050415, validation loss 0.866931676864624\n",
      "Epoch 780, current patience 23, model mean validation loss 0.8617219924926758, embedding dim 8, hidden size 4, num layers 1, train loss 0.5801495313644409, validation loss 0.8484716415405273\n",
      "Epoch 790, current patience 22, model mean validation loss 0.8627628087997437, embedding dim 8, hidden size 4, num layers 1, train loss 0.691768229007721, validation loss 0.8704133033752441\n",
      "Epoch 800, current patience 21, model mean validation loss 0.8655330538749695, embedding dim 8, hidden size 4, num layers 1, train loss 0.6761816740036011, validation loss 0.8639981746673584\n",
      "Epoch 810, current patience 20, model mean validation loss 0.8684786558151245, embedding dim 8, hidden size 4, num layers 1, train loss 0.5534411668777466, validation loss 0.8594369888305664\n",
      "Epoch 820, current patience 19, model mean validation loss 0.8668428659439087, embedding dim 8, hidden size 4, num layers 1, train loss 0.5575443506240845, validation loss 0.852776288986206\n",
      "Epoch 830, current patience 18, model mean validation loss 0.8633256554603577, embedding dim 8, hidden size 4, num layers 1, train loss 0.7774507999420166, validation loss 0.8605174422264099\n",
      "Epoch 840, current patience 17, model mean validation loss 0.8582516312599182, embedding dim 8, hidden size 4, num layers 1, train loss 0.4288080632686615, validation loss 0.8434674739837646\n",
      "Epoch 850, current patience 16, model mean validation loss 0.8573772311210632, embedding dim 8, hidden size 4, num layers 1, train loss 0.6464896202087402, validation loss 0.8599362373352051\n",
      "Epoch 860, current patience 15, model mean validation loss 0.8639664649963379, embedding dim 8, hidden size 4, num layers 1, train loss 0.5902799367904663, validation loss 0.9011859893798828\n",
      "Epoch 870, current patience 14, model mean validation loss 0.8580858707427979, embedding dim 8, hidden size 4, num layers 1, train loss 0.6143249273300171, validation loss 0.8233684301376343\n",
      "Epoch 880, current patience 13, model mean validation loss 0.8573498725891113, embedding dim 8, hidden size 4, num layers 1, train loss 0.5406500101089478, validation loss 0.8581101894378662\n",
      "Epoch 890, current patience 12, model mean validation loss 0.863813579082489, embedding dim 8, hidden size 4, num layers 1, train loss 0.4874972403049469, validation loss 0.9111465215682983\n",
      "Epoch 900, current patience 11, model mean validation loss 0.8681890368461609, embedding dim 8, hidden size 4, num layers 1, train loss 0.5210202932357788, validation loss 0.8877802491188049\n",
      "Epoch 910, current patience 10, model mean validation loss 0.8755207061767578, embedding dim 8, hidden size 4, num layers 1, train loss 0.4905671179294586, validation loss 0.9191707372665405\n",
      "Epoch 920, current patience 9, model mean validation loss 0.8859193325042725, embedding dim 8, hidden size 4, num layers 1, train loss 0.620120108127594, validation loss 0.9266557693481445\n",
      "Epoch 930, current patience 8, model mean validation loss 0.8919264078140259, embedding dim 8, hidden size 4, num layers 1, train loss 0.4769098162651062, validation loss 0.9079936742782593\n",
      "Epoch 940, current patience 7, model mean validation loss 0.8863388895988464, embedding dim 8, hidden size 4, num layers 1, train loss 0.47356951236724854, validation loss 0.8564857244491577\n",
      "Epoch 950, current patience 6, model mean validation loss 0.8950194120407104, embedding dim 8, hidden size 4, num layers 1, train loss 0.3867166042327881, validation loss 0.8928121328353882\n",
      "Epoch 960, current patience 5, model mean validation loss 0.9024485945701599, embedding dim 8, hidden size 4, num layers 1, train loss 0.44335222244262695, validation loss 0.9175437688827515\n",
      "Epoch 970, current patience 4, model mean validation loss 0.899925172328949, embedding dim 8, hidden size 4, num layers 1, train loss 0.45590686798095703, validation loss 0.8909594416618347\n",
      "Epoch 980, current patience 3, model mean validation loss 0.9032949805259705, embedding dim 8, hidden size 4, num layers 1, train loss 0.6167242527008057, validation loss 0.9147388935089111\n",
      "Epoch 990, current patience 2, model mean validation loss 0.900572657585144, embedding dim 8, hidden size 4, num layers 1, train loss 0.3917837142944336, validation loss 0.8973921537399292\n",
      "Epoch 1000, current patience 1, model mean validation loss 0.8997576236724854, embedding dim 8, hidden size 4, num layers 1, train loss 0.4136900007724762, validation loss 0.9201350808143616\n",
      "Epoch 0, current patience 30, model mean validation loss 1.10281240940094, embedding dim 8, hidden size 8, num layers 1, train loss 1.0994329452514648, validation loss 1.10281240940094\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0991051197052002, embedding dim 8, hidden size 8, num layers 1, train loss 1.0804321765899658, validation loss 1.095397710800171\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0987287759780884, embedding dim 8, hidden size 8, num layers 1, train loss 1.0848082304000854, validation loss 1.0979763269424438\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0979989767074585, embedding dim 8, hidden size 8, num layers 1, train loss 1.0767343044281006, validation loss 1.0958093404769897\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0967823266983032, embedding dim 8, hidden size 8, num layers 1, train loss 1.0892927646636963, validation loss 1.0919153690338135\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0963863134384155, embedding dim 8, hidden size 8, num layers 1, train loss 1.099266767501831, validation loss 1.0944067239761353\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0959118604660034, embedding dim 8, hidden size 8, num layers 1, train loss 1.0731903314590454, validation loss 1.0930649042129517\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0955536365509033, embedding dim 8, hidden size 8, num layers 1, train loss 1.094689130783081, validation loss 1.0930464267730713\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0932865142822266, embedding dim 8, hidden size 8, num layers 1, train loss 1.096666693687439, validation loss 1.0846748352050781\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0896084308624268, embedding dim 8, hidden size 8, num layers 1, train loss 1.07136070728302, validation loss 1.065973162651062\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0858571529388428, embedding dim 8, hidden size 8, num layers 1, train loss 1.0444494485855103, validation loss 1.0679669380187988\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0792841911315918, embedding dim 8, hidden size 8, num layers 1, train loss 1.105940341949463, validation loss 1.0432246923446655\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0720770359039307, embedding dim 8, hidden size 8, num layers 1, train loss 1.002880573272705, validation loss 1.0342586040496826\n",
      "Epoch 130, current patience 30, model mean validation loss 1.060146689414978, embedding dim 8, hidden size 8, num layers 1, train loss 0.9763491153717041, validation loss 0.9989647269248962\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0493369102478027, embedding dim 8, hidden size 8, num layers 1, train loss 1.0565325021743774, validation loss 1.0065865516662598\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0354342460632324, embedding dim 8, hidden size 8, num layers 1, train loss 0.8966019153594971, validation loss 0.9818248748779297\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0208935737609863, embedding dim 8, hidden size 8, num layers 1, train loss 1.0228078365325928, validation loss 0.9683486223220825\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0073410272598267, embedding dim 8, hidden size 8, num layers 1, train loss 0.9839166402816772, validation loss 0.9575530290603638\n",
      "Epoch 180, current patience 30, model mean validation loss 0.992469310760498, embedding dim 8, hidden size 8, num layers 1, train loss 0.9506148099899292, validation loss 0.9489932656288147\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9795817136764526, embedding dim 8, hidden size 8, num layers 1, train loss 0.9151522517204285, validation loss 0.9401238560676575\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9670603275299072, embedding dim 8, hidden size 8, num layers 1, train loss 0.9181070327758789, validation loss 0.9340875744819641\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9568543434143066, embedding dim 8, hidden size 8, num layers 1, train loss 0.8596393465995789, validation loss 0.9173175692558289\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9441328048706055, embedding dim 8, hidden size 8, num layers 1, train loss 0.8721171617507935, validation loss 0.9048135280609131\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9362010955810547, embedding dim 8, hidden size 8, num layers 1, train loss 0.9695966839790344, validation loss 0.9183715581893921\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9269735217094421, embedding dim 8, hidden size 8, num layers 1, train loss 0.7873719930648804, validation loss 0.8945280909538269\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9175373315811157, embedding dim 8, hidden size 8, num layers 1, train loss 0.8423527479171753, validation loss 0.8820631504058838\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9072319269180298, embedding dim 8, hidden size 8, num layers 1, train loss 0.8182797431945801, validation loss 0.8665497303009033\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8985029458999634, embedding dim 8, hidden size 8, num layers 1, train loss 0.8482900857925415, validation loss 0.8702921271324158\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8927403688430786, embedding dim 8, hidden size 8, num layers 1, train loss 0.7617043852806091, validation loss 0.8879874348640442\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8864779472351074, embedding dim 8, hidden size 8, num layers 1, train loss 0.7984448671340942, validation loss 0.8672177791595459\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8807817697525024, embedding dim 8, hidden size 8, num layers 1, train loss 0.8453212380409241, validation loss 0.8592443466186523\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8744761943817139, embedding dim 8, hidden size 8, num layers 1, train loss 0.9389210939407349, validation loss 0.8679271936416626\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8685556650161743, embedding dim 8, hidden size 8, num layers 1, train loss 0.7495205998420715, validation loss 0.8471641540527344\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8650394082069397, embedding dim 8, hidden size 8, num layers 1, train loss 0.9132177829742432, validation loss 0.8539326190948486\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8627714514732361, embedding dim 8, hidden size 8, num layers 1, train loss 0.7335484027862549, validation loss 0.8484063744544983\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8590860962867737, embedding dim 8, hidden size 8, num layers 1, train loss 0.7687118649482727, validation loss 0.840808629989624\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8563590049743652, embedding dim 8, hidden size 8, num layers 1, train loss 0.8474087715148926, validation loss 0.86617112159729\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8502788543701172, embedding dim 8, hidden size 8, num layers 1, train loss 0.7994896769523621, validation loss 0.8185766935348511\n",
      "Epoch 380, current patience 30, model mean validation loss 0.845851719379425, embedding dim 8, hidden size 8, num layers 1, train loss 0.7856161594390869, validation loss 0.8238270878791809\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8458682894706726, embedding dim 8, hidden size 8, num layers 1, train loss 0.6882050037384033, validation loss 0.8680592775344849\n",
      "Epoch 400, current patience 29, model mean validation loss 0.8425620794296265, embedding dim 8, hidden size 8, num layers 1, train loss 0.6401031017303467, validation loss 0.8207147121429443\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8376704454421997, embedding dim 8, hidden size 8, num layers 1, train loss 0.6654048562049866, validation loss 0.8147991299629211\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8339976072311401, embedding dim 8, hidden size 8, num layers 1, train loss 0.6079323291778564, validation loss 0.8190235495567322\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8310391902923584, embedding dim 8, hidden size 8, num layers 1, train loss 0.7431266903877258, validation loss 0.8171418905258179\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8217490911483765, embedding dim 8, hidden size 8, num layers 1, train loss 0.6986888647079468, validation loss 0.7918504476547241\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8214937448501587, embedding dim 8, hidden size 8, num layers 1, train loss 0.7326810359954834, validation loss 0.8165339231491089\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8199348449707031, embedding dim 8, hidden size 8, num layers 1, train loss 0.7590929269790649, validation loss 0.811356246471405\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8114307522773743, embedding dim 8, hidden size 8, num layers 1, train loss 0.7586874961853027, validation loss 0.8000261187553406\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8112631440162659, embedding dim 8, hidden size 8, num layers 1, train loss 0.4873051047325134, validation loss 0.8193737864494324\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8094344735145569, embedding dim 8, hidden size 8, num layers 1, train loss 0.6193156242370605, validation loss 0.8001700639724731\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8116264343261719, embedding dim 8, hidden size 8, num layers 1, train loss 0.7011343240737915, validation loss 0.8365592956542969\n",
      "Epoch 510, current patience 29, model mean validation loss 0.8111691474914551, embedding dim 8, hidden size 8, num layers 1, train loss 0.7914577722549438, validation loss 0.8134828805923462\n",
      "Epoch 520, current patience 28, model mean validation loss 0.810223400592804, embedding dim 8, hidden size 8, num layers 1, train loss 0.5835078954696655, validation loss 0.7842849493026733\n",
      "Epoch 530, current patience 27, model mean validation loss 0.8099220991134644, embedding dim 8, hidden size 8, num layers 1, train loss 0.5707530975341797, validation loss 0.8141234517097473\n",
      "Epoch 540, current patience 26, model mean validation loss 0.8052735328674316, embedding dim 8, hidden size 8, num layers 1, train loss 0.5480419397354126, validation loss 0.7741679549217224\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8098212480545044, embedding dim 8, hidden size 8, num layers 1, train loss 0.8244760632514954, validation loss 0.8364077210426331\n",
      "Epoch 560, current patience 29, model mean validation loss 0.8099239468574524, embedding dim 8, hidden size 8, num layers 1, train loss 0.5773141384124756, validation loss 0.8201954364776611\n",
      "Epoch 570, current patience 28, model mean validation loss 0.8131744861602783, embedding dim 8, hidden size 8, num layers 1, train loss 0.8077583909034729, validation loss 0.8261736631393433\n",
      "Epoch 580, current patience 27, model mean validation loss 0.8103916049003601, embedding dim 8, hidden size 8, num layers 1, train loss 0.5206409692764282, validation loss 0.8142964243888855\n",
      "Epoch 590, current patience 26, model mean validation loss 0.8122855424880981, embedding dim 8, hidden size 8, num layers 1, train loss 0.6429122686386108, validation loss 0.8286343812942505\n",
      "Epoch 600, current patience 25, model mean validation loss 0.8214021921157837, embedding dim 8, hidden size 8, num layers 1, train loss 0.5826876163482666, validation loss 0.8572188019752502\n",
      "Epoch 610, current patience 24, model mean validation loss 0.8286147117614746, embedding dim 8, hidden size 8, num layers 1, train loss 0.5623284578323364, validation loss 0.8718231320381165\n",
      "Epoch 620, current patience 23, model mean validation loss 0.8350739479064941, embedding dim 8, hidden size 8, num layers 1, train loss 0.6548527479171753, validation loss 0.8258423209190369\n",
      "Epoch 630, current patience 22, model mean validation loss 0.8350626230239868, embedding dim 8, hidden size 8, num layers 1, train loss 0.5337704420089722, validation loss 0.8363169431686401\n",
      "Epoch 640, current patience 21, model mean validation loss 0.8348167538642883, embedding dim 8, hidden size 8, num layers 1, train loss 0.5926802158355713, validation loss 0.8182281255722046\n",
      "Epoch 650, current patience 20, model mean validation loss 0.8300710320472717, embedding dim 8, hidden size 8, num layers 1, train loss 0.7758558988571167, validation loss 0.7882081866264343\n",
      "Epoch 660, current patience 19, model mean validation loss 0.8282757997512817, embedding dim 8, hidden size 8, num layers 1, train loss 0.534319281578064, validation loss 0.7999346852302551\n",
      "Epoch 670, current patience 18, model mean validation loss 0.8287043571472168, embedding dim 8, hidden size 8, num layers 1, train loss 0.697332501411438, validation loss 0.8320630788803101\n",
      "Epoch 680, current patience 17, model mean validation loss 0.8232597708702087, embedding dim 8, hidden size 8, num layers 1, train loss 0.8538456559181213, validation loss 0.8136616349220276\n",
      "Epoch 690, current patience 16, model mean validation loss 0.8153225183486938, embedding dim 8, hidden size 8, num layers 1, train loss 0.7119467258453369, validation loss 0.8083252310752869\n",
      "Epoch 700, current patience 15, model mean validation loss 0.8116360306739807, embedding dim 8, hidden size 8, num layers 1, train loss 0.6212396621704102, validation loss 0.7963503003120422\n",
      "Epoch 710, current patience 14, model mean validation loss 0.8082773685455322, embedding dim 8, hidden size 8, num layers 1, train loss 0.6487895846366882, validation loss 0.809447705745697\n",
      "Epoch 720, current patience 13, model mean validation loss 0.8125330209732056, embedding dim 8, hidden size 8, num layers 1, train loss 0.507347583770752, validation loss 0.8522733449935913\n",
      "Epoch 730, current patience 12, model mean validation loss 0.8218820095062256, embedding dim 8, hidden size 8, num layers 1, train loss 0.4548370838165283, validation loss 0.8630001544952393\n",
      "Epoch 740, current patience 11, model mean validation loss 0.8303864002227783, embedding dim 8, hidden size 8, num layers 1, train loss 0.39849936962127686, validation loss 0.8679699301719666\n",
      "Epoch 750, current patience 10, model mean validation loss 0.8366034626960754, embedding dim 8, hidden size 8, num layers 1, train loss 0.6940131187438965, validation loss 0.8817991614341736\n",
      "Epoch 760, current patience 9, model mean validation loss 0.8398124575614929, embedding dim 8, hidden size 8, num layers 1, train loss 0.5260260105133057, validation loss 0.8393337726593018\n",
      "Epoch 770, current patience 8, model mean validation loss 0.8393056392669678, embedding dim 8, hidden size 8, num layers 1, train loss 0.5928040742874146, validation loss 0.8042709827423096\n",
      "Epoch 780, current patience 7, model mean validation loss 0.8513556122779846, embedding dim 8, hidden size 8, num layers 1, train loss 0.42675840854644775, validation loss 0.8927497863769531\n",
      "Epoch 790, current patience 6, model mean validation loss 0.8628897070884705, embedding dim 8, hidden size 8, num layers 1, train loss 0.5412710309028625, validation loss 0.9017206430435181\n",
      "Epoch 800, current patience 5, model mean validation loss 0.8680006265640259, embedding dim 8, hidden size 8, num layers 1, train loss 0.3494499921798706, validation loss 0.8931602835655212\n",
      "Epoch 810, current patience 4, model mean validation loss 0.8696563243865967, embedding dim 8, hidden size 8, num layers 1, train loss 0.29701894521713257, validation loss 0.8762461543083191\n",
      "Epoch 820, current patience 3, model mean validation loss 0.8731279373168945, embedding dim 8, hidden size 8, num layers 1, train loss 0.6460356712341309, validation loss 0.8957423567771912\n",
      "Epoch 830, current patience 2, model mean validation loss 0.8724370002746582, embedding dim 8, hidden size 8, num layers 1, train loss 0.5284737944602966, validation loss 0.876271665096283\n",
      "Epoch 840, current patience 1, model mean validation loss 0.8784074187278748, embedding dim 8, hidden size 8, num layers 1, train loss 0.7297958135604858, validation loss 0.8870973587036133\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1200170516967773, embedding dim 8, hidden size 16, num layers 1, train loss 1.1192171573638916, validation loss 1.1200170516967773\n",
      "Epoch 10, current patience 30, model mean validation loss 1.107598066329956, embedding dim 8, hidden size 16, num layers 1, train loss 1.1008273363113403, validation loss 1.0951792001724243\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1036782264709473, embedding dim 8, hidden size 16, num layers 1, train loss 1.0911191701889038, validation loss 1.0958385467529297\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1035630702972412, embedding dim 8, hidden size 16, num layers 1, train loss 1.0854694843292236, validation loss 1.103217363357544\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1016042232513428, embedding dim 8, hidden size 16, num layers 1, train loss 1.1029192209243774, validation loss 1.0937691926956177\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1005064249038696, embedding dim 8, hidden size 16, num layers 1, train loss 1.0956637859344482, validation loss 1.0950175523757935\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0998035669326782, embedding dim 8, hidden size 16, num layers 1, train loss 1.0904492139816284, validation loss 1.095585823059082\n",
      "Epoch 70, current patience 30, model mean validation loss 1.099076747894287, embedding dim 8, hidden size 16, num layers 1, train loss 1.1018954515457153, validation loss 1.093989372253418\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0957516431808472, embedding dim 8, hidden size 16, num layers 1, train loss 1.1109669208526611, validation loss 1.0934162139892578\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0944082736968994, embedding dim 8, hidden size 16, num layers 1, train loss 1.1076915264129639, validation loss 1.0844320058822632\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0923676490783691, embedding dim 8, hidden size 16, num layers 1, train loss 1.0723156929016113, validation loss 1.079514503479004\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0887458324432373, embedding dim 8, hidden size 16, num layers 1, train loss 1.1289010047912598, validation loss 1.0742417573928833\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0837831497192383, embedding dim 8, hidden size 16, num layers 1, train loss 1.0811232328414917, validation loss 1.0540685653686523\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0781135559082031, embedding dim 8, hidden size 16, num layers 1, train loss 0.987739086151123, validation loss 1.0496597290039062\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0706441402435303, embedding dim 8, hidden size 16, num layers 1, train loss 1.0015251636505127, validation loss 1.0358315706253052\n",
      "Epoch 150, current patience 30, model mean validation loss 1.062140941619873, embedding dim 8, hidden size 16, num layers 1, train loss 0.953377366065979, validation loss 1.0259628295898438\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0549713373184204, embedding dim 8, hidden size 16, num layers 1, train loss 0.9811882972717285, validation loss 1.0360596179962158\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0432820320129395, embedding dim 8, hidden size 16, num layers 1, train loss 0.8786566257476807, validation loss 0.9909183979034424\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0295703411102295, embedding dim 8, hidden size 16, num layers 1, train loss 0.9148261547088623, validation loss 0.9698206186294556\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0182468891143799, embedding dim 8, hidden size 16, num layers 1, train loss 0.8629881739616394, validation loss 0.9836540222167969\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0053069591522217, embedding dim 8, hidden size 16, num layers 1, train loss 0.8854750394821167, validation loss 0.9505490064620972\n",
      "Epoch 210, current patience 30, model mean validation loss 0.990667462348938, embedding dim 8, hidden size 16, num layers 1, train loss 0.9435805082321167, validation loss 0.9325436353683472\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9775529503822327, embedding dim 8, hidden size 16, num layers 1, train loss 0.8609185814857483, validation loss 0.9309158325195312\n",
      "Epoch 230, current patience 30, model mean validation loss 0.966252326965332, embedding dim 8, hidden size 16, num layers 1, train loss 0.9223624467849731, validation loss 0.9355575442314148\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9512219429016113, embedding dim 8, hidden size 16, num layers 1, train loss 0.947195291519165, validation loss 0.9158166646957397\n",
      "Epoch 250, current patience 30, model mean validation loss 0.943241536617279, embedding dim 8, hidden size 16, num layers 1, train loss 0.893953263759613, validation loss 0.9270749688148499\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9351385831832886, embedding dim 8, hidden size 16, num layers 1, train loss 0.8398638963699341, validation loss 0.9049971103668213\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9260122179985046, embedding dim 8, hidden size 16, num layers 1, train loss 0.7699663639068604, validation loss 0.9106428623199463\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9182653427124023, embedding dim 8, hidden size 16, num layers 1, train loss 0.7725342512130737, validation loss 0.8885740041732788\n",
      "Epoch 290, current patience 30, model mean validation loss 0.912702202796936, embedding dim 8, hidden size 16, num layers 1, train loss 0.8002278804779053, validation loss 0.8880388140678406\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9074065685272217, embedding dim 8, hidden size 16, num layers 1, train loss 0.82880038022995, validation loss 0.8885502815246582\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8987138271331787, embedding dim 8, hidden size 16, num layers 1, train loss 0.9171403050422668, validation loss 0.8660163283348083\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8914227485656738, embedding dim 8, hidden size 16, num layers 1, train loss 0.7713844776153564, validation loss 0.857487142086029\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8836073279380798, embedding dim 8, hidden size 16, num layers 1, train loss 0.7603120803833008, validation loss 0.8645517826080322\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8757888078689575, embedding dim 8, hidden size 16, num layers 1, train loss 0.7366713881492615, validation loss 0.8424489498138428\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8679768443107605, embedding dim 8, hidden size 16, num layers 1, train loss 0.669960081577301, validation loss 0.8481473326683044\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8637485504150391, embedding dim 8, hidden size 16, num layers 1, train loss 0.9562792778015137, validation loss 0.8547479510307312\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8576898574829102, embedding dim 8, hidden size 16, num layers 1, train loss 0.7109489440917969, validation loss 0.8395692110061646\n",
      "Epoch 380, current patience 30, model mean validation loss 0.855075478553772, embedding dim 8, hidden size 16, num layers 1, train loss 0.7332488298416138, validation loss 0.8676351308822632\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8501710891723633, embedding dim 8, hidden size 16, num layers 1, train loss 0.8015494346618652, validation loss 0.826781153678894\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8489178419113159, embedding dim 8, hidden size 16, num layers 1, train loss 0.7228734493255615, validation loss 0.8474617004394531\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8460869193077087, embedding dim 8, hidden size 16, num layers 1, train loss 0.6698678731918335, validation loss 0.8419040441513062\n",
      "Epoch 420, current patience 30, model mean validation loss 0.842496931552887, embedding dim 8, hidden size 16, num layers 1, train loss 0.846069872379303, validation loss 0.8137288093566895\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8372275829315186, embedding dim 8, hidden size 16, num layers 1, train loss 0.721552312374115, validation loss 0.8059924840927124\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8308775424957275, embedding dim 8, hidden size 16, num layers 1, train loss 0.7135751247406006, validation loss 0.8039471507072449\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8283536434173584, embedding dim 8, hidden size 16, num layers 1, train loss 0.6897482872009277, validation loss 0.8193783164024353\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8219996690750122, embedding dim 8, hidden size 16, num layers 1, train loss 0.6651448011398315, validation loss 0.8168036937713623\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8199669718742371, embedding dim 8, hidden size 16, num layers 1, train loss 0.6543667912483215, validation loss 0.8105192184448242\n",
      "Epoch 480, current patience 30, model mean validation loss 0.813472330570221, embedding dim 8, hidden size 16, num layers 1, train loss 0.644708514213562, validation loss 0.7955048084259033\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8061114549636841, embedding dim 8, hidden size 16, num layers 1, train loss 0.6850916743278503, validation loss 0.7830170392990112\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8050808906555176, embedding dim 8, hidden size 16, num layers 1, train loss 0.531481146812439, validation loss 0.8054841756820679\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8030719757080078, embedding dim 8, hidden size 16, num layers 1, train loss 0.7104232907295227, validation loss 0.7899210453033447\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8031607866287231, embedding dim 8, hidden size 16, num layers 1, train loss 0.6313245892524719, validation loss 0.8046575784683228\n",
      "Epoch 530, current patience 29, model mean validation loss 0.8009501695632935, embedding dim 8, hidden size 16, num layers 1, train loss 0.578943133354187, validation loss 0.8016937971115112\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8017238974571228, embedding dim 8, hidden size 16, num layers 1, train loss 0.6139461398124695, validation loss 0.8229934573173523\n",
      "Epoch 550, current patience 29, model mean validation loss 0.8018102645874023, embedding dim 8, hidden size 16, num layers 1, train loss 0.7793681621551514, validation loss 0.8112100958824158\n",
      "Epoch 560, current patience 28, model mean validation loss 0.8021479845046997, embedding dim 8, hidden size 16, num layers 1, train loss 0.5713828206062317, validation loss 0.798206627368927\n",
      "Epoch 570, current patience 27, model mean validation loss 0.8047941327095032, embedding dim 8, hidden size 16, num layers 1, train loss 0.5244846940040588, validation loss 0.8041865825653076\n",
      "Epoch 580, current patience 26, model mean validation loss 0.8078173398971558, embedding dim 8, hidden size 16, num layers 1, train loss 0.45935291051864624, validation loss 0.8296694159507751\n",
      "Epoch 590, current patience 25, model mean validation loss 0.8108742833137512, embedding dim 8, hidden size 16, num layers 1, train loss 0.5946357250213623, validation loss 0.8143768310546875\n",
      "Epoch 600, current patience 24, model mean validation loss 0.8114153742790222, embedding dim 8, hidden size 16, num layers 1, train loss 0.6409353017807007, validation loss 0.8089858293533325\n",
      "Epoch 610, current patience 23, model mean validation loss 0.8102709054946899, embedding dim 8, hidden size 16, num layers 1, train loss 0.6093426942825317, validation loss 0.7925384044647217\n",
      "Epoch 620, current patience 22, model mean validation loss 0.8087278008460999, embedding dim 8, hidden size 16, num layers 1, train loss 0.6317657232284546, validation loss 0.8106484413146973\n",
      "Epoch 630, current patience 21, model mean validation loss 0.8068891167640686, embedding dim 8, hidden size 16, num layers 1, train loss 0.41826605796813965, validation loss 0.7965006828308105\n",
      "Epoch 640, current patience 20, model mean validation loss 0.8099775910377502, embedding dim 8, hidden size 16, num layers 1, train loss 0.7309756278991699, validation loss 0.8229143619537354\n",
      "Epoch 650, current patience 19, model mean validation loss 0.8083252310752869, embedding dim 8, hidden size 16, num layers 1, train loss 0.6367002725601196, validation loss 0.7909678220748901\n",
      "Epoch 660, current patience 18, model mean validation loss 0.8026217222213745, embedding dim 8, hidden size 16, num layers 1, train loss 0.6275968551635742, validation loss 0.7840412855148315\n",
      "Epoch 670, current patience 17, model mean validation loss 0.8020180463790894, embedding dim 8, hidden size 16, num layers 1, train loss 0.7874065041542053, validation loss 0.8095471262931824\n",
      "Epoch 680, current patience 16, model mean validation loss 0.801611602306366, embedding dim 8, hidden size 16, num layers 1, train loss 0.5380741357803345, validation loss 0.8057347536087036\n",
      "Epoch 690, current patience 15, model mean validation loss 0.7994070053100586, embedding dim 8, hidden size 16, num layers 1, train loss 0.5509120225906372, validation loss 0.7749014496803284\n",
      "Epoch 700, current patience 30, model mean validation loss 0.8012863397598267, embedding dim 8, hidden size 16, num layers 1, train loss 0.4677651822566986, validation loss 0.8256831169128418\n",
      "Epoch 710, current patience 29, model mean validation loss 0.8039839267730713, embedding dim 8, hidden size 16, num layers 1, train loss 0.4431746006011963, validation loss 0.8180809020996094\n",
      "Epoch 720, current patience 28, model mean validation loss 0.8115236759185791, embedding dim 8, hidden size 16, num layers 1, train loss 0.4884348511695862, validation loss 0.883232831954956\n",
      "Epoch 730, current patience 27, model mean validation loss 0.818243145942688, embedding dim 8, hidden size 16, num layers 1, train loss 0.5314347743988037, validation loss 0.8447237014770508\n",
      "Epoch 740, current patience 26, model mean validation loss 0.8269137144088745, embedding dim 8, hidden size 16, num layers 1, train loss 0.49066248536109924, validation loss 0.8534059524536133\n",
      "Epoch 750, current patience 25, model mean validation loss 0.8306150436401367, embedding dim 8, hidden size 16, num layers 1, train loss 0.7351678609848022, validation loss 0.8391574025154114\n",
      "Epoch 760, current patience 24, model mean validation loss 0.8276926279067993, embedding dim 8, hidden size 16, num layers 1, train loss 0.700681209564209, validation loss 0.7823553085327148\n",
      "Epoch 770, current patience 23, model mean validation loss 0.8311471343040466, embedding dim 8, hidden size 16, num layers 1, train loss 0.5142520070075989, validation loss 0.8025379180908203\n",
      "Epoch 780, current patience 22, model mean validation loss 0.833419680595398, embedding dim 8, hidden size 16, num layers 1, train loss 0.6405507326126099, validation loss 0.8438636660575867\n",
      "Epoch 790, current patience 21, model mean validation loss 0.8378679752349854, embedding dim 8, hidden size 16, num layers 1, train loss 0.4750598967075348, validation loss 0.8536670207977295\n",
      "Epoch 800, current patience 20, model mean validation loss 0.8367272019386292, embedding dim 8, hidden size 16, num layers 1, train loss 0.37349557876586914, validation loss 0.8741070032119751\n",
      "Epoch 810, current patience 19, model mean validation loss 0.8310472369194031, embedding dim 8, hidden size 16, num layers 1, train loss 0.8466449975967407, validation loss 0.7992836236953735\n",
      "Epoch 820, current patience 18, model mean validation loss 0.8281341791152954, embedding dim 8, hidden size 16, num layers 1, train loss 0.5112549662590027, validation loss 0.830101728439331\n",
      "Epoch 830, current patience 17, model mean validation loss 0.8225263953208923, embedding dim 8, hidden size 16, num layers 1, train loss 0.5337458252906799, validation loss 0.7942949533462524\n",
      "Epoch 840, current patience 16, model mean validation loss 0.8298496603965759, embedding dim 8, hidden size 16, num layers 1, train loss 0.6771183013916016, validation loss 0.8409414291381836\n",
      "Epoch 850, current patience 15, model mean validation loss 0.8293862342834473, embedding dim 8, hidden size 16, num layers 1, train loss 0.42674341797828674, validation loss 0.7988303899765015\n",
      "Epoch 860, current patience 14, model mean validation loss 0.8271135091781616, embedding dim 8, hidden size 16, num layers 1, train loss 0.3999674320220947, validation loss 0.8256820440292358\n",
      "Epoch 870, current patience 13, model mean validation loss 0.827795147895813, embedding dim 8, hidden size 16, num layers 1, train loss 0.4623852074146271, validation loss 0.85912024974823\n",
      "Epoch 880, current patience 12, model mean validation loss 0.8285146951675415, embedding dim 8, hidden size 16, num layers 1, train loss 0.3954709768295288, validation loss 0.8798632621765137\n",
      "Epoch 890, current patience 11, model mean validation loss 0.8364739418029785, embedding dim 8, hidden size 16, num layers 1, train loss 0.6831168532371521, validation loss 0.8629577159881592\n",
      "Epoch 900, current patience 10, model mean validation loss 0.837329089641571, embedding dim 8, hidden size 16, num layers 1, train loss 0.34031227231025696, validation loss 0.8369427919387817\n",
      "Epoch 910, current patience 9, model mean validation loss 0.8421268463134766, embedding dim 8, hidden size 16, num layers 1, train loss 0.5156701803207397, validation loss 0.8326767683029175\n",
      "Epoch 920, current patience 8, model mean validation loss 0.8400697708129883, embedding dim 8, hidden size 16, num layers 1, train loss 0.4347500801086426, validation loss 0.8244850635528564\n",
      "Epoch 930, current patience 7, model mean validation loss 0.8528043031692505, embedding dim 8, hidden size 16, num layers 1, train loss 0.5158970355987549, validation loss 0.9007063508033752\n",
      "Epoch 940, current patience 6, model mean validation loss 0.8557727336883545, embedding dim 8, hidden size 16, num layers 1, train loss 0.5960612297058105, validation loss 0.8494300246238708\n",
      "Epoch 950, current patience 5, model mean validation loss 0.8541434407234192, embedding dim 8, hidden size 16, num layers 1, train loss 0.36395198106765747, validation loss 0.846085786819458\n",
      "Epoch 960, current patience 4, model mean validation loss 0.8535454869270325, embedding dim 8, hidden size 16, num layers 1, train loss 0.6984653472900391, validation loss 0.8750794529914856\n",
      "Epoch 970, current patience 3, model mean validation loss 0.8536015152931213, embedding dim 8, hidden size 16, num layers 1, train loss 0.6867868900299072, validation loss 0.8634060621261597\n",
      "Epoch 980, current patience 2, model mean validation loss 0.8622345924377441, embedding dim 8, hidden size 16, num layers 1, train loss 0.31122127175331116, validation loss 0.9060072898864746\n",
      "Epoch 990, current patience 1, model mean validation loss 0.8671294450759888, embedding dim 8, hidden size 16, num layers 1, train loss 0.5700485706329346, validation loss 0.8718352317810059\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1030902862548828, embedding dim 8, hidden size 32, num layers 1, train loss 1.0850673913955688, validation loss 1.1030902862548828\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0991427898406982, embedding dim 8, hidden size 32, num layers 1, train loss 1.0877552032470703, validation loss 1.0951952934265137\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0980854034423828, embedding dim 8, hidden size 32, num layers 1, train loss 1.0917930603027344, validation loss 1.095970630645752\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0969442129135132, embedding dim 8, hidden size 32, num layers 1, train loss 1.1048762798309326, validation loss 1.0935205221176147\n",
      "Epoch 40, current patience 30, model mean validation loss 1.095867395401001, embedding dim 8, hidden size 32, num layers 1, train loss 1.0875297784805298, validation loss 1.0915603637695312\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0940275192260742, embedding dim 8, hidden size 32, num layers 1, train loss 1.0986213684082031, validation loss 1.0848281383514404\n",
      "Epoch 60, current patience 30, model mean validation loss 1.091646432876587, embedding dim 8, hidden size 32, num layers 1, train loss 1.1051806211471558, validation loss 1.0773600339889526\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0881226062774658, embedding dim 8, hidden size 32, num layers 1, train loss 1.1049518585205078, validation loss 1.0634562969207764\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0822010040283203, embedding dim 8, hidden size 32, num layers 1, train loss 1.014494776725769, validation loss 1.0557162761688232\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0743533372879028, embedding dim 8, hidden size 32, num layers 1, train loss 1.0773332118988037, validation loss 1.0324146747589111\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0643703937530518, embedding dim 8, hidden size 32, num layers 1, train loss 0.9504214525222778, validation loss 1.0161066055297852\n",
      "Epoch 110, current patience 30, model mean validation loss 1.052947998046875, embedding dim 8, hidden size 32, num layers 1, train loss 0.9670687317848206, validation loss 1.0021412372589111\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0410447120666504, embedding dim 8, hidden size 32, num layers 1, train loss 0.9699923396110535, validation loss 0.9963342547416687\n",
      "Epoch 130, current patience 30, model mean validation loss 1.029704213142395, embedding dim 8, hidden size 32, num layers 1, train loss 1.0033562183380127, validation loss 0.9941040277481079\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0172690153121948, embedding dim 8, hidden size 32, num layers 1, train loss 1.0194114446640015, validation loss 0.9778786301612854\n",
      "Epoch 150, current patience 30, model mean validation loss 1.003343939781189, embedding dim 8, hidden size 32, num layers 1, train loss 0.9770412445068359, validation loss 0.9520553946495056\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9930716753005981, embedding dim 8, hidden size 32, num layers 1, train loss 0.9239140748977661, validation loss 0.9735379219055176\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9828820824623108, embedding dim 8, hidden size 32, num layers 1, train loss 0.908762514591217, validation loss 0.9508985280990601\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9714239835739136, embedding dim 8, hidden size 32, num layers 1, train loss 0.9156134128570557, validation loss 0.9244420528411865\n",
      "Epoch 190, current patience 30, model mean validation loss 0.961026132106781, embedding dim 8, hidden size 32, num layers 1, train loss 0.845413863658905, validation loss 0.9189582467079163\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9509461522102356, embedding dim 8, hidden size 32, num layers 1, train loss 0.8035357594490051, validation loss 0.9156942963600159\n",
      "Epoch 210, current patience 30, model mean validation loss 0.941139817237854, embedding dim 8, hidden size 32, num layers 1, train loss 0.8999954462051392, validation loss 0.9156538248062134\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9284592866897583, embedding dim 8, hidden size 32, num layers 1, train loss 0.9590225219726562, validation loss 0.8764339685440063\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9206462502479553, embedding dim 8, hidden size 32, num layers 1, train loss 0.9310480952262878, validation loss 0.8895509839057922\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9060274958610535, embedding dim 8, hidden size 32, num layers 1, train loss 0.8066831231117249, validation loss 0.8565879464149475\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8954773545265198, embedding dim 8, hidden size 32, num layers 1, train loss 0.8930965662002563, validation loss 0.866497278213501\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8905926942825317, embedding dim 8, hidden size 32, num layers 1, train loss 0.8058764338493347, validation loss 0.8853648900985718\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8843286633491516, embedding dim 8, hidden size 32, num layers 1, train loss 0.7459390163421631, validation loss 0.86884605884552\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8797875046730042, embedding dim 8, hidden size 32, num layers 1, train loss 0.7652627229690552, validation loss 0.8793647885322571\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8692859411239624, embedding dim 8, hidden size 32, num layers 1, train loss 0.7922451496124268, validation loss 0.831641435623169\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8657336235046387, embedding dim 8, hidden size 32, num layers 1, train loss 0.820781409740448, validation loss 0.848015308380127\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8612726330757141, embedding dim 8, hidden size 32, num layers 1, train loss 0.7111997604370117, validation loss 0.8538630604743958\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8560851812362671, embedding dim 8, hidden size 32, num layers 1, train loss 0.7961229085922241, validation loss 0.81508868932724\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8527229428291321, embedding dim 8, hidden size 32, num layers 1, train loss 0.7780070304870605, validation loss 0.8395988345146179\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8447284698486328, embedding dim 8, hidden size 32, num layers 1, train loss 0.8086681365966797, validation loss 0.8214099407196045\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8399665355682373, embedding dim 8, hidden size 32, num layers 1, train loss 0.7545508146286011, validation loss 0.8307499885559082\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8348263502120972, embedding dim 8, hidden size 32, num layers 1, train loss 0.9394667148590088, validation loss 0.8382433652877808\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8329205513000488, embedding dim 8, hidden size 32, num layers 1, train loss 0.833005964756012, validation loss 0.81639564037323\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8266191482543945, embedding dim 8, hidden size 32, num layers 1, train loss 0.8258979320526123, validation loss 0.7976036071777344\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8195215463638306, embedding dim 8, hidden size 32, num layers 1, train loss 0.6676336526870728, validation loss 0.7970824241638184\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8154221177101135, embedding dim 8, hidden size 32, num layers 1, train loss 0.738662838935852, validation loss 0.7822928428649902\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8107576370239258, embedding dim 8, hidden size 32, num layers 1, train loss 0.5549184083938599, validation loss 0.8022831082344055\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8106909990310669, embedding dim 8, hidden size 32, num layers 1, train loss 0.7105964422225952, validation loss 0.820876955986023\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8111538887023926, embedding dim 8, hidden size 32, num layers 1, train loss 0.5941264629364014, validation loss 0.8344529271125793\n",
      "Epoch 440, current patience 29, model mean validation loss 0.807443380355835, embedding dim 8, hidden size 32, num layers 1, train loss 0.6703886389732361, validation loss 0.808559775352478\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8017191886901855, embedding dim 8, hidden size 32, num layers 1, train loss 0.6450312733650208, validation loss 0.7706019282341003\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8024402260780334, embedding dim 8, hidden size 32, num layers 1, train loss 0.6510135531425476, validation loss 0.8033719062805176\n",
      "Epoch 470, current patience 29, model mean validation loss 0.8014106750488281, embedding dim 8, hidden size 32, num layers 1, train loss 0.6159419417381287, validation loss 0.7888458967208862\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8060570955276489, embedding dim 8, hidden size 32, num layers 1, train loss 0.5639446973800659, validation loss 0.8194646239280701\n",
      "Epoch 490, current patience 29, model mean validation loss 0.8066218495368958, embedding dim 8, hidden size 32, num layers 1, train loss 0.6687188148498535, validation loss 0.8068006038665771\n",
      "Epoch 500, current patience 28, model mean validation loss 0.8012897968292236, embedding dim 8, hidden size 32, num layers 1, train loss 0.5098670721054077, validation loss 0.778220534324646\n",
      "Epoch 510, current patience 30, model mean validation loss 0.7983708381652832, embedding dim 8, hidden size 32, num layers 1, train loss 0.6103290319442749, validation loss 0.8111014366149902\n",
      "Epoch 520, current patience 30, model mean validation loss 0.7995450496673584, embedding dim 8, hidden size 32, num layers 1, train loss 0.722665011882782, validation loss 0.8179531693458557\n",
      "Epoch 530, current patience 29, model mean validation loss 0.8003509044647217, embedding dim 8, hidden size 32, num layers 1, train loss 0.5115546584129333, validation loss 0.7770493626594543\n",
      "Epoch 540, current patience 28, model mean validation loss 0.8003184199333191, embedding dim 8, hidden size 32, num layers 1, train loss 0.6247260570526123, validation loss 0.8031116724014282\n",
      "Epoch 550, current patience 27, model mean validation loss 0.8025078773498535, embedding dim 8, hidden size 32, num layers 1, train loss 0.5814093351364136, validation loss 0.8063619136810303\n",
      "Epoch 560, current patience 26, model mean validation loss 0.7973558902740479, embedding dim 8, hidden size 32, num layers 1, train loss 0.5125861763954163, validation loss 0.7782490253448486\n",
      "Epoch 570, current patience 30, model mean validation loss 0.7974845170974731, embedding dim 8, hidden size 32, num layers 1, train loss 0.6468422412872314, validation loss 0.8078292608261108\n",
      "Epoch 580, current patience 29, model mean validation loss 0.7995644807815552, embedding dim 8, hidden size 32, num layers 1, train loss 0.70585036277771, validation loss 0.7948604226112366\n",
      "Epoch 590, current patience 28, model mean validation loss 0.797275722026825, embedding dim 8, hidden size 32, num layers 1, train loss 0.7271708250045776, validation loss 0.7927912473678589\n",
      "Epoch 600, current patience 30, model mean validation loss 0.7917928695678711, embedding dim 8, hidden size 32, num layers 1, train loss 0.7322998046875, validation loss 0.7740901112556458\n",
      "Epoch 610, current patience 30, model mean validation loss 0.7875316143035889, embedding dim 8, hidden size 32, num layers 1, train loss 0.39516526460647583, validation loss 0.7429593801498413\n",
      "Epoch 620, current patience 30, model mean validation loss 0.7901046276092529, embedding dim 8, hidden size 32, num layers 1, train loss 0.3879525661468506, validation loss 0.8236955404281616\n",
      "Epoch 630, current patience 29, model mean validation loss 0.7840844392776489, embedding dim 8, hidden size 32, num layers 1, train loss 0.5325428247451782, validation loss 0.7582008838653564\n",
      "Epoch 640, current patience 30, model mean validation loss 0.7837855815887451, embedding dim 8, hidden size 32, num layers 1, train loss 0.5236411094665527, validation loss 0.7758576273918152\n",
      "Epoch 650, current patience 30, model mean validation loss 0.7820347547531128, embedding dim 8, hidden size 32, num layers 1, train loss 0.45661449432373047, validation loss 0.7938231825828552\n",
      "Epoch 660, current patience 30, model mean validation loss 0.7851053476333618, embedding dim 8, hidden size 32, num layers 1, train loss 0.3376726508140564, validation loss 0.8194254636764526\n",
      "Epoch 670, current patience 29, model mean validation loss 0.7849351763725281, embedding dim 8, hidden size 32, num layers 1, train loss 0.5335062146186829, validation loss 0.7914291620254517\n",
      "Epoch 680, current patience 28, model mean validation loss 0.7901164293289185, embedding dim 8, hidden size 32, num layers 1, train loss 0.46676820516586304, validation loss 0.8155403137207031\n",
      "Epoch 690, current patience 27, model mean validation loss 0.7957776784896851, embedding dim 8, hidden size 32, num layers 1, train loss 0.5918123722076416, validation loss 0.7882489562034607\n",
      "Epoch 700, current patience 26, model mean validation loss 0.7927533388137817, embedding dim 8, hidden size 32, num layers 1, train loss 0.5042206048965454, validation loss 0.7995011806488037\n",
      "Epoch 710, current patience 25, model mean validation loss 0.7969903349876404, embedding dim 8, hidden size 32, num layers 1, train loss 0.42420294880867004, validation loss 0.7920970916748047\n",
      "Epoch 720, current patience 24, model mean validation loss 0.7951375246047974, embedding dim 8, hidden size 32, num layers 1, train loss 0.5571672916412354, validation loss 0.7610346674919128\n",
      "Epoch 730, current patience 23, model mean validation loss 0.7938732504844666, embedding dim 8, hidden size 32, num layers 1, train loss 0.42438721656799316, validation loss 0.7837090492248535\n",
      "Epoch 740, current patience 22, model mean validation loss 0.7923679947853088, embedding dim 8, hidden size 32, num layers 1, train loss 0.5706853866577148, validation loss 0.8073832392692566\n",
      "Epoch 750, current patience 21, model mean validation loss 0.7948495149612427, embedding dim 8, hidden size 32, num layers 1, train loss 0.5091345906257629, validation loss 0.8112810850143433\n",
      "Epoch 760, current patience 20, model mean validation loss 0.7979332804679871, embedding dim 8, hidden size 32, num layers 1, train loss 0.4845506548881531, validation loss 0.8402106761932373\n",
      "Epoch 770, current patience 19, model mean validation loss 0.8047362565994263, embedding dim 8, hidden size 32, num layers 1, train loss 0.40177270770072937, validation loss 0.8426729440689087\n",
      "Epoch 780, current patience 18, model mean validation loss 0.8047298192977905, embedding dim 8, hidden size 32, num layers 1, train loss 0.734157919883728, validation loss 0.7994496822357178\n",
      "Epoch 790, current patience 17, model mean validation loss 0.8021469116210938, embedding dim 8, hidden size 32, num layers 1, train loss 0.654529333114624, validation loss 0.7714336514472961\n",
      "Epoch 800, current patience 16, model mean validation loss 0.8185002207756042, embedding dim 8, hidden size 32, num layers 1, train loss 0.5305168032646179, validation loss 0.8918617963790894\n",
      "Epoch 810, current patience 15, model mean validation loss 0.821259081363678, embedding dim 8, hidden size 32, num layers 1, train loss 0.4994351267814636, validation loss 0.8057793378829956\n",
      "Epoch 820, current patience 14, model mean validation loss 0.8235064744949341, embedding dim 8, hidden size 32, num layers 1, train loss 0.5363028645515442, validation loss 0.8253624439239502\n",
      "Epoch 830, current patience 13, model mean validation loss 0.8331930637359619, embedding dim 8, hidden size 32, num layers 1, train loss 0.3586503267288208, validation loss 0.8887737989425659\n",
      "Epoch 840, current patience 12, model mean validation loss 0.8307262659072876, embedding dim 8, hidden size 32, num layers 1, train loss 0.49831995368003845, validation loss 0.8204764127731323\n",
      "Epoch 850, current patience 11, model mean validation loss 0.8348821997642517, embedding dim 8, hidden size 32, num layers 1, train loss 0.36744093894958496, validation loss 0.8759205341339111\n",
      "Epoch 860, current patience 10, model mean validation loss 0.8360139727592468, embedding dim 8, hidden size 32, num layers 1, train loss 0.4865488111972809, validation loss 0.8085039258003235\n",
      "Epoch 870, current patience 9, model mean validation loss 0.8436405658721924, embedding dim 8, hidden size 32, num layers 1, train loss 0.4129239022731781, validation loss 0.8324463367462158\n",
      "Epoch 880, current patience 8, model mean validation loss 0.8367197513580322, embedding dim 8, hidden size 32, num layers 1, train loss 0.5681337118148804, validation loss 0.8364953994750977\n",
      "Epoch 890, current patience 7, model mean validation loss 0.8326596021652222, embedding dim 8, hidden size 32, num layers 1, train loss 0.5126925110816956, validation loss 0.7732982039451599\n",
      "Epoch 900, current patience 6, model mean validation loss 0.8384483456611633, embedding dim 8, hidden size 32, num layers 1, train loss 0.34546950459480286, validation loss 0.8716723918914795\n",
      "Epoch 910, current patience 5, model mean validation loss 0.8351809978485107, embedding dim 8, hidden size 32, num layers 1, train loss 0.378722608089447, validation loss 0.8626351952552795\n",
      "Epoch 920, current patience 4, model mean validation loss 0.8455806970596313, embedding dim 8, hidden size 32, num layers 1, train loss 0.5469591617584229, validation loss 0.9036736488342285\n",
      "Epoch 930, current patience 3, model mean validation loss 0.8465738892555237, embedding dim 8, hidden size 32, num layers 1, train loss 0.3326122462749481, validation loss 0.8838658928871155\n",
      "Epoch 940, current patience 2, model mean validation loss 0.8487156629562378, embedding dim 8, hidden size 32, num layers 1, train loss 0.5445057153701782, validation loss 0.8256382346153259\n",
      "Epoch 950, current patience 1, model mean validation loss 0.8516539335250854, embedding dim 8, hidden size 32, num layers 1, train loss 0.3569301962852478, validation loss 0.8559523820877075\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0969868898391724, embedding dim 8, hidden size 64, num layers 1, train loss 1.1038743257522583, validation loss 1.0969868898391724\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0955142974853516, embedding dim 8, hidden size 64, num layers 1, train loss 1.0950201749801636, validation loss 1.0940418243408203\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0963243246078491, embedding dim 8, hidden size 64, num layers 1, train loss 1.1106276512145996, validation loss 1.0979441404342651\n",
      "Epoch 30, current patience 29, model mean validation loss 1.0958582162857056, embedding dim 8, hidden size 64, num layers 1, train loss 1.0969761610031128, validation loss 1.0944600105285645\n",
      "Epoch 40, current patience 28, model mean validation loss 1.0954972505569458, embedding dim 8, hidden size 64, num layers 1, train loss 1.1065645217895508, validation loss 1.0940533876419067\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0939546823501587, embedding dim 8, hidden size 64, num layers 1, train loss 1.0947648286819458, validation loss 1.0862418413162231\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0928714275360107, embedding dim 8, hidden size 64, num layers 1, train loss 1.0703294277191162, validation loss 1.0863720178604126\n",
      "Epoch 70, current patience 30, model mean validation loss 1.090691328048706, embedding dim 8, hidden size 64, num layers 1, train loss 1.045494794845581, validation loss 1.0754311084747314\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0859570503234863, embedding dim 8, hidden size 64, num layers 1, train loss 1.0400737524032593, validation loss 1.059112787246704\n",
      "Epoch 90, current patience 30, model mean validation loss 1.080461025238037, embedding dim 8, hidden size 64, num layers 1, train loss 1.0267846584320068, validation loss 1.0500729084014893\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0721160173416138, embedding dim 8, hidden size 64, num layers 1, train loss 1.0213685035705566, validation loss 1.0311840772628784\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0629950761795044, embedding dim 8, hidden size 64, num layers 1, train loss 0.9853291511535645, validation loss 1.0214922428131104\n",
      "Epoch 120, current patience 30, model mean validation loss 1.052506923675537, embedding dim 8, hidden size 64, num layers 1, train loss 0.9792332649230957, validation loss 1.010148286819458\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0399572849273682, embedding dim 8, hidden size 64, num layers 1, train loss 1.0298606157302856, validation loss 0.9858442544937134\n",
      "Epoch 140, current patience 30, model mean validation loss 1.030848503112793, embedding dim 8, hidden size 64, num layers 1, train loss 0.8890693187713623, validation loss 1.0135022401809692\n",
      "Epoch 150, current patience 30, model mean validation loss 1.017998218536377, embedding dim 8, hidden size 64, num layers 1, train loss 0.9388618469238281, validation loss 0.972628653049469\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0050503015518188, embedding dim 8, hidden size 64, num layers 1, train loss 0.9499608278274536, validation loss 0.9555296897888184\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9929036498069763, embedding dim 8, hidden size 64, num layers 1, train loss 0.8656989336013794, validation loss 0.952899694442749\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9816423654556274, embedding dim 8, hidden size 64, num layers 1, train loss 0.9015567302703857, validation loss 0.941093921661377\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9712918996810913, embedding dim 8, hidden size 64, num layers 1, train loss 0.8035144805908203, validation loss 0.9386888742446899\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9563603401184082, embedding dim 8, hidden size 64, num layers 1, train loss 0.7849767208099365, validation loss 0.8906950950622559\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9457632303237915, embedding dim 8, hidden size 64, num layers 1, train loss 0.8970045447349548, validation loss 0.9010677337646484\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9302663207054138, embedding dim 8, hidden size 64, num layers 1, train loss 0.9179693460464478, validation loss 0.8895267844200134\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9186100959777832, embedding dim 8, hidden size 64, num layers 1, train loss 0.9270999431610107, validation loss 0.8793788552284241\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9088926911354065, embedding dim 8, hidden size 64, num layers 1, train loss 0.9299547672271729, validation loss 0.8777905106544495\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8978922367095947, embedding dim 8, hidden size 64, num layers 1, train loss 0.5632151365280151, validation loss 0.8648958802223206\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8850380182266235, embedding dim 8, hidden size 64, num layers 1, train loss 0.699414849281311, validation loss 0.8382601737976074\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8860812187194824, embedding dim 8, hidden size 64, num layers 1, train loss 0.9449918270111084, validation loss 0.947034478187561\n",
      "Epoch 280, current patience 29, model mean validation loss 0.8840501308441162, embedding dim 8, hidden size 64, num layers 1, train loss 0.6914503574371338, validation loss 0.8744468688964844\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8801584243774414, embedding dim 8, hidden size 64, num layers 1, train loss 0.8828713297843933, validation loss 0.86993408203125\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8745924234390259, embedding dim 8, hidden size 64, num layers 1, train loss 0.7679455280303955, validation loss 0.8449986577033997\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8701336979866028, embedding dim 8, hidden size 64, num layers 1, train loss 0.8320299983024597, validation loss 0.8437087535858154\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8614166975021362, embedding dim 8, hidden size 64, num layers 1, train loss 0.5860200524330139, validation loss 0.80805504322052\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8536173105239868, embedding dim 8, hidden size 64, num layers 1, train loss 0.6195900440216064, validation loss 0.8025006055831909\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8514391779899597, embedding dim 8, hidden size 64, num layers 1, train loss 0.6736651659011841, validation loss 0.8208349347114563\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8303983211517334, embedding dim 8, hidden size 64, num layers 1, train loss 0.590027928352356, validation loss 0.7787079215049744\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8202776312828064, embedding dim 8, hidden size 64, num layers 1, train loss 0.7661718130111694, validation loss 0.7934813499450684\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8098646402359009, embedding dim 8, hidden size 64, num layers 1, train loss 0.828490674495697, validation loss 0.7866294980049133\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8061962127685547, embedding dim 8, hidden size 64, num layers 1, train loss 0.4988155961036682, validation loss 0.815650999546051\n",
      "Epoch 390, current patience 30, model mean validation loss 0.7999444007873535, embedding dim 8, hidden size 64, num layers 1, train loss 0.715455174446106, validation loss 0.7936943769454956\n",
      "Epoch 400, current patience 30, model mean validation loss 0.7972996234893799, embedding dim 8, hidden size 64, num layers 1, train loss 0.8668454885482788, validation loss 0.7868972420692444\n",
      "Epoch 410, current patience 30, model mean validation loss 0.7905420064926147, embedding dim 8, hidden size 64, num layers 1, train loss 0.7665315866470337, validation loss 0.7484398484230042\n",
      "Epoch 420, current patience 30, model mean validation loss 0.7853653430938721, embedding dim 8, hidden size 64, num layers 1, train loss 0.6841869354248047, validation loss 0.7794219851493835\n",
      "Epoch 430, current patience 30, model mean validation loss 0.7894416451454163, embedding dim 8, hidden size 64, num layers 1, train loss 0.5390288233757019, validation loss 0.8113181591033936\n",
      "Epoch 440, current patience 29, model mean validation loss 0.7882412075996399, embedding dim 8, hidden size 64, num layers 1, train loss 0.7068423628807068, validation loss 0.7838779091835022\n",
      "Epoch 450, current patience 28, model mean validation loss 0.7912731170654297, embedding dim 8, hidden size 64, num layers 1, train loss 0.5459933876991272, validation loss 0.8108847141265869\n",
      "Epoch 460, current patience 27, model mean validation loss 0.7891419529914856, embedding dim 8, hidden size 64, num layers 1, train loss 0.7605417966842651, validation loss 0.7986013293266296\n",
      "Epoch 470, current patience 26, model mean validation loss 0.7835907936096191, embedding dim 8, hidden size 64, num layers 1, train loss 0.7038811445236206, validation loss 0.7492848038673401\n",
      "Epoch 480, current patience 30, model mean validation loss 0.7797595262527466, embedding dim 8, hidden size 64, num layers 1, train loss 0.9523195028305054, validation loss 0.7562482357025146\n",
      "Epoch 490, current patience 30, model mean validation loss 0.7798494696617126, embedding dim 8, hidden size 64, num layers 1, train loss 0.6306483745574951, validation loss 0.7491591572761536\n",
      "Epoch 500, current patience 29, model mean validation loss 0.7795873880386353, embedding dim 8, hidden size 64, num layers 1, train loss 0.7078882455825806, validation loss 0.7773247957229614\n",
      "Epoch 510, current patience 30, model mean validation loss 0.7793773412704468, embedding dim 8, hidden size 64, num layers 1, train loss 0.5424737334251404, validation loss 0.8096381425857544\n",
      "Epoch 520, current patience 30, model mean validation loss 0.779532790184021, embedding dim 8, hidden size 64, num layers 1, train loss 0.7431002259254456, validation loss 0.785120964050293\n",
      "Epoch 530, current patience 29, model mean validation loss 0.776996374130249, embedding dim 8, hidden size 64, num layers 1, train loss 0.6737370491027832, validation loss 0.7905935049057007\n",
      "Epoch 540, current patience 30, model mean validation loss 0.7770882844924927, embedding dim 8, hidden size 64, num layers 1, train loss 0.5014705657958984, validation loss 0.7993365526199341\n",
      "Epoch 550, current patience 29, model mean validation loss 0.779383659362793, embedding dim 8, hidden size 64, num layers 1, train loss 0.601123571395874, validation loss 0.7676475644111633\n",
      "Epoch 560, current patience 28, model mean validation loss 0.7818622589111328, embedding dim 8, hidden size 64, num layers 1, train loss 0.6223220825195312, validation loss 0.7760770916938782\n",
      "Epoch 570, current patience 27, model mean validation loss 0.7888885736465454, embedding dim 8, hidden size 64, num layers 1, train loss 0.6227805614471436, validation loss 0.805370032787323\n",
      "Epoch 580, current patience 26, model mean validation loss 0.7909861207008362, embedding dim 8, hidden size 64, num layers 1, train loss 0.6994129419326782, validation loss 0.7941049337387085\n",
      "Epoch 590, current patience 25, model mean validation loss 0.7889099717140198, embedding dim 8, hidden size 64, num layers 1, train loss 0.4031645953655243, validation loss 0.7930294871330261\n",
      "Epoch 600, current patience 24, model mean validation loss 0.7923065423965454, embedding dim 8, hidden size 64, num layers 1, train loss 0.6307531595230103, validation loss 0.8122929334640503\n",
      "Epoch 610, current patience 23, model mean validation loss 0.7940009832382202, embedding dim 8, hidden size 64, num layers 1, train loss 0.4706929922103882, validation loss 0.8041490316390991\n",
      "Epoch 620, current patience 22, model mean validation loss 0.7933372259140015, embedding dim 8, hidden size 64, num layers 1, train loss 0.4975076913833618, validation loss 0.7940268516540527\n",
      "Epoch 630, current patience 21, model mean validation loss 0.8015984296798706, embedding dim 8, hidden size 64, num layers 1, train loss 0.46171489357948303, validation loss 0.8337371945381165\n",
      "Epoch 640, current patience 20, model mean validation loss 0.8068225383758545, embedding dim 8, hidden size 64, num layers 1, train loss 0.4964287281036377, validation loss 0.8178699016571045\n",
      "Epoch 650, current patience 19, model mean validation loss 0.7991229295730591, embedding dim 8, hidden size 64, num layers 1, train loss 0.5568380355834961, validation loss 0.743773341178894\n",
      "Epoch 660, current patience 18, model mean validation loss 0.8021369576454163, embedding dim 8, hidden size 64, num layers 1, train loss 0.3641090393066406, validation loss 0.8182171583175659\n",
      "Epoch 670, current patience 17, model mean validation loss 0.8014551401138306, embedding dim 8, hidden size 64, num layers 1, train loss 0.2989104986190796, validation loss 0.7875746488571167\n",
      "Epoch 680, current patience 16, model mean validation loss 0.7985230684280396, embedding dim 8, hidden size 64, num layers 1, train loss 0.5381984710693359, validation loss 0.7888365983963013\n",
      "Epoch 690, current patience 15, model mean validation loss 0.8039430975914001, embedding dim 8, hidden size 64, num layers 1, train loss 0.4239112138748169, validation loss 0.8475090265274048\n",
      "Epoch 700, current patience 14, model mean validation loss 0.8063044548034668, embedding dim 8, hidden size 64, num layers 1, train loss 0.5801773071289062, validation loss 0.8129176497459412\n",
      "Epoch 710, current patience 13, model mean validation loss 0.80567467212677, embedding dim 8, hidden size 64, num layers 1, train loss 0.3989110589027405, validation loss 0.82869952917099\n",
      "Epoch 720, current patience 12, model mean validation loss 0.8117319941520691, embedding dim 8, hidden size 64, num layers 1, train loss 0.5326168537139893, validation loss 0.8663281798362732\n",
      "Epoch 730, current patience 11, model mean validation loss 0.8186116814613342, embedding dim 8, hidden size 64, num layers 1, train loss 0.2915235161781311, validation loss 0.7988109588623047\n",
      "Epoch 740, current patience 10, model mean validation loss 0.8149131536483765, embedding dim 8, hidden size 64, num layers 1, train loss 0.28022557497024536, validation loss 0.7886284589767456\n",
      "Epoch 750, current patience 9, model mean validation loss 0.8288772106170654, embedding dim 8, hidden size 64, num layers 1, train loss 0.3572928011417389, validation loss 0.8992875814437866\n",
      "Epoch 760, current patience 8, model mean validation loss 0.8360852003097534, embedding dim 8, hidden size 64, num layers 1, train loss 0.4408224821090698, validation loss 0.8465002775192261\n",
      "Epoch 770, current patience 7, model mean validation loss 0.8364983797073364, embedding dim 8, hidden size 64, num layers 1, train loss 0.3273274302482605, validation loss 0.850814700126648\n",
      "Epoch 780, current patience 6, model mean validation loss 0.8406779766082764, embedding dim 8, hidden size 64, num layers 1, train loss 0.4180389642715454, validation loss 0.8463538885116577\n",
      "Epoch 790, current patience 5, model mean validation loss 0.8439732193946838, embedding dim 8, hidden size 64, num layers 1, train loss 0.6771888136863708, validation loss 0.8550616502761841\n",
      "Epoch 800, current patience 4, model mean validation loss 0.844203770160675, embedding dim 8, hidden size 64, num layers 1, train loss 0.5086567997932434, validation loss 0.8681726455688477\n",
      "Epoch 810, current patience 3, model mean validation loss 0.8490962386131287, embedding dim 8, hidden size 64, num layers 1, train loss 0.3997840881347656, validation loss 0.8379507660865784\n",
      "Epoch 820, current patience 2, model mean validation loss 0.8594025373458862, embedding dim 8, hidden size 64, num layers 1, train loss 0.4751189947128296, validation loss 0.8710788488388062\n",
      "Epoch 830, current patience 1, model mean validation loss 0.8579460382461548, embedding dim 8, hidden size 64, num layers 1, train loss 0.6011930704116821, validation loss 0.8876349925994873\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1096973419189453, embedding dim 8, hidden size 128, num layers 1, train loss 1.0984212160110474, validation loss 1.1096973419189453\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1025115251541138, embedding dim 8, hidden size 128, num layers 1, train loss 1.0863707065582275, validation loss 1.0953257083892822\n",
      "Epoch 20, current patience 30, model mean validation loss 1.099312424659729, embedding dim 8, hidden size 128, num layers 1, train loss 1.090942621231079, validation loss 1.092914342880249\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0983483791351318, embedding dim 8, hidden size 128, num layers 1, train loss 1.0959489345550537, validation loss 1.0954558849334717\n",
      "Epoch 40, current patience 30, model mean validation loss 1.099294662475586, embedding dim 8, hidden size 128, num layers 1, train loss 1.0711619853973389, validation loss 1.10308039188385\n",
      "Epoch 50, current patience 29, model mean validation loss 1.098420262336731, embedding dim 8, hidden size 128, num layers 1, train loss 1.099156141281128, validation loss 1.0940473079681396\n",
      "Epoch 60, current patience 28, model mean validation loss 1.0947633981704712, embedding dim 8, hidden size 128, num layers 1, train loss 1.071854591369629, validation loss 1.072821855545044\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0935275554656982, embedding dim 8, hidden size 128, num layers 1, train loss 1.0558029413223267, validation loss 1.0848772525787354\n",
      "Epoch 80, current patience 30, model mean validation loss 1.087652325630188, embedding dim 8, hidden size 128, num layers 1, train loss 1.1181703805923462, validation loss 1.062695860862732\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0811368227005005, embedding dim 8, hidden size 128, num layers 1, train loss 1.027599573135376, validation loss 1.0432018041610718\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0733519792556763, embedding dim 8, hidden size 128, num layers 1, train loss 1.0969094038009644, validation loss 1.0306357145309448\n",
      "Epoch 110, current patience 30, model mean validation loss 1.063327431678772, embedding dim 8, hidden size 128, num layers 1, train loss 1.0399631261825562, validation loss 1.0152597427368164\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0500036478042603, embedding dim 8, hidden size 128, num layers 1, train loss 1.0323004722595215, validation loss 0.9964900016784668\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0343877077102661, embedding dim 8, hidden size 128, num layers 1, train loss 0.8676781058311462, validation loss 0.9691194295883179\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0202710628509521, embedding dim 8, hidden size 128, num layers 1, train loss 0.945736289024353, validation loss 0.9598886370658875\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0037885904312134, embedding dim 8, hidden size 128, num layers 1, train loss 0.9111833572387695, validation loss 0.953016996383667\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9901783466339111, embedding dim 8, hidden size 128, num layers 1, train loss 0.86908358335495, validation loss 0.9538142681121826\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9788427352905273, embedding dim 8, hidden size 128, num layers 1, train loss 0.936734676361084, validation loss 0.9525174498558044\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9658516645431519, embedding dim 8, hidden size 128, num layers 1, train loss 0.9782084226608276, validation loss 0.9267069697380066\n",
      "Epoch 190, current patience 30, model mean validation loss 0.954746663570404, embedding dim 8, hidden size 128, num layers 1, train loss 0.8054124116897583, validation loss 0.9264194965362549\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9440826773643494, embedding dim 8, hidden size 128, num layers 1, train loss 1.0338914394378662, validation loss 0.911178469657898\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9346375465393066, embedding dim 8, hidden size 128, num layers 1, train loss 0.8056590557098389, validation loss 0.8935579061508179\n",
      "Epoch 220, current patience 30, model mean validation loss 0.925439715385437, embedding dim 8, hidden size 128, num layers 1, train loss 0.7578507661819458, validation loss 0.88630610704422\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9158705472946167, embedding dim 8, hidden size 128, num layers 1, train loss 0.8003844618797302, validation loss 0.8764637112617493\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9064317941665649, embedding dim 8, hidden size 128, num layers 1, train loss 0.8627676963806152, validation loss 0.8783048391342163\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8930027484893799, embedding dim 8, hidden size 128, num layers 1, train loss 0.7537626028060913, validation loss 0.845084547996521\n",
      "Epoch 260, current patience 30, model mean validation loss 0.886400043964386, embedding dim 8, hidden size 128, num layers 1, train loss 0.7475911974906921, validation loss 0.8738853931427002\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8764300346374512, embedding dim 8, hidden size 128, num layers 1, train loss 0.7477262020111084, validation loss 0.8466590642929077\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8681718111038208, embedding dim 8, hidden size 128, num layers 1, train loss 0.5788695812225342, validation loss 0.8451129198074341\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8596451282501221, embedding dim 8, hidden size 128, num layers 1, train loss 0.8050658702850342, validation loss 0.8253449201583862\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8527946472167969, embedding dim 8, hidden size 128, num layers 1, train loss 0.7509534358978271, validation loss 0.8315014839172363\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8432706594467163, embedding dim 8, hidden size 128, num layers 1, train loss 0.8084537982940674, validation loss 0.8002720475196838\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8347241282463074, embedding dim 8, hidden size 128, num layers 1, train loss 0.6595956087112427, validation loss 0.8099327087402344\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8299267292022705, embedding dim 8, hidden size 128, num layers 1, train loss 0.7327309846878052, validation loss 0.806705117225647\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8232105374336243, embedding dim 8, hidden size 128, num layers 1, train loss 0.7479938268661499, validation loss 0.8201559782028198\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8198720216751099, embedding dim 8, hidden size 128, num layers 1, train loss 0.5980727076530457, validation loss 0.8199508786201477\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8157193660736084, embedding dim 8, hidden size 128, num layers 1, train loss 0.8077254891395569, validation loss 0.8118915557861328\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8112249374389648, embedding dim 8, hidden size 128, num layers 1, train loss 0.7577099204063416, validation loss 0.7893899083137512\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8084527254104614, embedding dim 8, hidden size 128, num layers 1, train loss 0.6502977013587952, validation loss 0.809323251247406\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8088338375091553, embedding dim 8, hidden size 128, num layers 1, train loss 0.6501399874687195, validation loss 0.8033213019371033\n",
      "Epoch 400, current patience 29, model mean validation loss 0.7997771501541138, embedding dim 8, hidden size 128, num layers 1, train loss 0.5643035173416138, validation loss 0.7374792098999023\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8012316823005676, embedding dim 8, hidden size 128, num layers 1, train loss 0.8441118001937866, validation loss 0.8183414936065674\n",
      "Epoch 420, current patience 29, model mean validation loss 0.7940259575843811, embedding dim 8, hidden size 128, num layers 1, train loss 0.6685438752174377, validation loss 0.762509822845459\n",
      "Epoch 430, current patience 30, model mean validation loss 0.7893801927566528, embedding dim 8, hidden size 128, num layers 1, train loss 0.6854100227355957, validation loss 0.7827850580215454\n",
      "Epoch 440, current patience 30, model mean validation loss 0.7838149666786194, embedding dim 8, hidden size 128, num layers 1, train loss 0.6663064956665039, validation loss 0.7673698663711548\n",
      "Epoch 450, current patience 30, model mean validation loss 0.7820189595222473, embedding dim 8, hidden size 128, num layers 1, train loss 0.6307604312896729, validation loss 0.7750219106674194\n",
      "Epoch 460, current patience 30, model mean validation loss 0.7768784165382385, embedding dim 8, hidden size 128, num layers 1, train loss 0.44649744033813477, validation loss 0.7681989073753357\n",
      "Epoch 470, current patience 30, model mean validation loss 0.776174783706665, embedding dim 8, hidden size 128, num layers 1, train loss 0.627032458782196, validation loss 0.797691822052002\n",
      "Epoch 480, current patience 30, model mean validation loss 0.777102530002594, embedding dim 8, hidden size 128, num layers 1, train loss 0.7488570213317871, validation loss 0.7449016571044922\n",
      "Epoch 490, current patience 29, model mean validation loss 0.7695212364196777, embedding dim 8, hidden size 128, num layers 1, train loss 0.6628681421279907, validation loss 0.7576909065246582\n",
      "Epoch 500, current patience 30, model mean validation loss 0.7750207185745239, embedding dim 8, hidden size 128, num layers 1, train loss 0.6090905666351318, validation loss 0.8065059781074524\n",
      "Epoch 510, current patience 29, model mean validation loss 0.7713363170623779, embedding dim 8, hidden size 128, num layers 1, train loss 0.5553911924362183, validation loss 0.7533094882965088\n",
      "Epoch 520, current patience 28, model mean validation loss 0.7751564979553223, embedding dim 8, hidden size 128, num layers 1, train loss 0.5337011814117432, validation loss 0.797931432723999\n",
      "Epoch 530, current patience 27, model mean validation loss 0.7798115611076355, embedding dim 8, hidden size 128, num layers 1, train loss 0.6446112394332886, validation loss 0.8122624158859253\n",
      "Epoch 540, current patience 26, model mean validation loss 0.7863094806671143, embedding dim 8, hidden size 128, num layers 1, train loss 0.6122312545776367, validation loss 0.8201819658279419\n",
      "Epoch 550, current patience 25, model mean validation loss 0.7835099697113037, embedding dim 8, hidden size 128, num layers 1, train loss 0.5679107308387756, validation loss 0.7752960920333862\n",
      "Epoch 560, current patience 24, model mean validation loss 0.7849851846694946, embedding dim 8, hidden size 128, num layers 1, train loss 0.45340660214424133, validation loss 0.7567028999328613\n",
      "Epoch 570, current patience 23, model mean validation loss 0.7925752997398376, embedding dim 8, hidden size 128, num layers 1, train loss 0.6183524131774902, validation loss 0.8184123039245605\n",
      "Epoch 580, current patience 22, model mean validation loss 0.7995588779449463, embedding dim 8, hidden size 128, num layers 1, train loss 0.45389944314956665, validation loss 0.862373948097229\n",
      "Epoch 590, current patience 21, model mean validation loss 0.8033790588378906, embedding dim 8, hidden size 128, num layers 1, train loss 0.8039801120758057, validation loss 0.783871591091156\n",
      "Epoch 600, current patience 20, model mean validation loss 0.8057689666748047, embedding dim 8, hidden size 128, num layers 1, train loss 0.5474115610122681, validation loss 0.8170505166053772\n",
      "Epoch 610, current patience 19, model mean validation loss 0.8054354786872864, embedding dim 8, hidden size 128, num layers 1, train loss 0.4571516513824463, validation loss 0.8095946311950684\n",
      "Epoch 620, current patience 18, model mean validation loss 0.8094039559364319, embedding dim 8, hidden size 128, num layers 1, train loss 0.6799449324607849, validation loss 0.8519295454025269\n",
      "Epoch 630, current patience 17, model mean validation loss 0.8233076333999634, embedding dim 8, hidden size 128, num layers 1, train loss 0.6892235279083252, validation loss 0.8865256309509277\n",
      "Epoch 640, current patience 16, model mean validation loss 0.8290464282035828, embedding dim 8, hidden size 128, num layers 1, train loss 0.6519284844398499, validation loss 0.8026132583618164\n",
      "Epoch 650, current patience 15, model mean validation loss 0.8334788680076599, embedding dim 8, hidden size 128, num layers 1, train loss 0.3344604969024658, validation loss 0.8538718223571777\n",
      "Epoch 660, current patience 14, model mean validation loss 0.8307636380195618, embedding dim 8, hidden size 128, num layers 1, train loss 0.4083631634712219, validation loss 0.8406522274017334\n",
      "Epoch 670, current patience 13, model mean validation loss 0.8328345417976379, embedding dim 8, hidden size 128, num layers 1, train loss 0.5560043454170227, validation loss 0.8004388809204102\n",
      "Epoch 680, current patience 12, model mean validation loss 0.8306347131729126, embedding dim 8, hidden size 128, num layers 1, train loss 0.475231796503067, validation loss 0.7994520664215088\n",
      "Epoch 690, current patience 11, model mean validation loss 0.8319301605224609, embedding dim 8, hidden size 128, num layers 1, train loss 0.5920028686523438, validation loss 0.8199580311775208\n",
      "Epoch 700, current patience 10, model mean validation loss 0.8316200375556946, embedding dim 8, hidden size 128, num layers 1, train loss 0.3058876395225525, validation loss 0.8494484424591064\n",
      "Epoch 710, current patience 9, model mean validation loss 0.8202429413795471, embedding dim 8, hidden size 128, num layers 1, train loss 0.32323968410491943, validation loss 0.795508861541748\n",
      "Epoch 720, current patience 8, model mean validation loss 0.836054265499115, embedding dim 8, hidden size 128, num layers 1, train loss 0.2908480763435364, validation loss 0.9291040897369385\n",
      "Epoch 730, current patience 7, model mean validation loss 0.8451322317123413, embedding dim 8, hidden size 128, num layers 1, train loss 0.43872109055519104, validation loss 0.9264951944351196\n",
      "Epoch 740, current patience 6, model mean validation loss 0.8458896279335022, embedding dim 8, hidden size 128, num layers 1, train loss 0.5054113864898682, validation loss 0.8467113375663757\n",
      "Epoch 750, current patience 5, model mean validation loss 0.8529014587402344, embedding dim 8, hidden size 128, num layers 1, train loss 0.6105261445045471, validation loss 0.856533408164978\n",
      "Epoch 760, current patience 4, model mean validation loss 0.8636839389801025, embedding dim 8, hidden size 128, num layers 1, train loss 0.36586371064186096, validation loss 0.8857121467590332\n",
      "Epoch 770, current patience 3, model mean validation loss 0.8701730966567993, embedding dim 8, hidden size 128, num layers 1, train loss 0.4448736310005188, validation loss 0.871871292591095\n",
      "Epoch 780, current patience 2, model mean validation loss 0.8721029162406921, embedding dim 8, hidden size 128, num layers 1, train loss 0.3559517562389374, validation loss 0.864886999130249\n",
      "Epoch 790, current patience 1, model mean validation loss 0.877264142036438, embedding dim 8, hidden size 128, num layers 1, train loss 0.5967216491699219, validation loss 0.8367984294891357\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0961377620697021, embedding dim 8, hidden size 256, num layers 1, train loss 1.103124976158142, validation loss 1.0961377620697021\n",
      "Epoch 10, current patience 30, model mean validation loss 1.09543776512146, embedding dim 8, hidden size 256, num layers 1, train loss 1.0930085182189941, validation loss 1.0947378873825073\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0949739217758179, embedding dim 8, hidden size 256, num layers 1, train loss 1.0971444845199585, validation loss 1.0940463542938232\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0927783250808716, embedding dim 8, hidden size 256, num layers 1, train loss 1.0739392042160034, validation loss 1.0861914157867432\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0928815603256226, embedding dim 8, hidden size 256, num layers 1, train loss 1.1018624305725098, validation loss 1.0932948589324951\n",
      "Epoch 50, current patience 29, model mean validation loss 1.0925620794296265, embedding dim 8, hidden size 256, num layers 1, train loss 1.0698294639587402, validation loss 1.0909640789031982\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0915461778640747, embedding dim 8, hidden size 256, num layers 1, train loss 1.1071557998657227, validation loss 1.085451364517212\n",
      "Epoch 70, current patience 30, model mean validation loss 1.091945767402649, embedding dim 8, hidden size 256, num layers 1, train loss 1.1004607677459717, validation loss 1.0947425365447998\n",
      "Epoch 80, current patience 29, model mean validation loss 1.0899213552474976, embedding dim 8, hidden size 256, num layers 1, train loss 1.0675303936004639, validation loss 1.079942226409912\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0899548530578613, embedding dim 8, hidden size 256, num layers 1, train loss 1.0946180820465088, validation loss 1.0950064659118652\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0889394283294678, embedding dim 8, hidden size 256, num layers 1, train loss 1.08902907371521, validation loss 1.085923433303833\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0908353328704834, embedding dim 8, hidden size 256, num layers 1, train loss 1.1231167316436768, validation loss 1.1013579368591309\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0907740592956543, embedding dim 8, hidden size 256, num layers 1, train loss 1.0840091705322266, validation loss 1.092803955078125\n",
      "Epoch 130, current patience 28, model mean validation loss 1.0918500423431396, embedding dim 8, hidden size 256, num layers 1, train loss 1.1056150197982788, validation loss 1.0995715856552124\n",
      "Epoch 140, current patience 27, model mean validation loss 1.0885608196258545, embedding dim 8, hidden size 256, num layers 1, train loss 1.0530307292938232, validation loss 1.0591375827789307\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0868936777114868, embedding dim 8, hidden size 256, num layers 1, train loss 1.0502026081085205, validation loss 1.0814063549041748\n",
      "Epoch 160, current patience 30, model mean validation loss 1.086758017539978, embedding dim 8, hidden size 256, num layers 1, train loss 1.0217368602752686, validation loss 1.0788565874099731\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0810915231704712, embedding dim 8, hidden size 256, num layers 1, train loss 1.040567398071289, validation loss 1.0496745109558105\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0727357864379883, embedding dim 8, hidden size 256, num layers 1, train loss 1.0545268058776855, validation loss 1.0190775394439697\n",
      "Epoch 190, current patience 30, model mean validation loss 1.059584140777588, embedding dim 8, hidden size 256, num layers 1, train loss 0.9883269667625427, validation loss 0.9961450695991516\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0551435947418213, embedding dim 8, hidden size 256, num layers 1, train loss 0.9829992055892944, validation loss 1.0572798252105713\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0497397184371948, embedding dim 8, hidden size 256, num layers 1, train loss 1.0808451175689697, validation loss 1.056340217590332\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0407614707946777, embedding dim 8, hidden size 256, num layers 1, train loss 0.8527395129203796, validation loss 0.987311601638794\n",
      "Epoch 230, current patience 30, model mean validation loss 1.025476336479187, embedding dim 8, hidden size 256, num layers 1, train loss 0.9627887010574341, validation loss 0.9591251015663147\n",
      "Epoch 240, current patience 30, model mean validation loss 1.009958028793335, embedding dim 8, hidden size 256, num layers 1, train loss 0.9575172662734985, validation loss 0.9547103643417358\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9954773783683777, embedding dim 8, hidden size 256, num layers 1, train loss 0.7456473112106323, validation loss 0.9338292479515076\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9815284609794617, embedding dim 8, hidden size 256, num layers 1, train loss 0.8696908950805664, validation loss 0.907486081123352\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9703963994979858, embedding dim 8, hidden size 256, num layers 1, train loss 0.8899160027503967, validation loss 0.9070889949798584\n",
      "Epoch 280, current patience 30, model mean validation loss 0.948785126209259, embedding dim 8, hidden size 256, num layers 1, train loss 0.8544996380805969, validation loss 0.8843889236450195\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9306497573852539, embedding dim 8, hidden size 256, num layers 1, train loss 0.7343593835830688, validation loss 0.9112578630447388\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9159141778945923, embedding dim 8, hidden size 256, num layers 1, train loss 0.8706176280975342, validation loss 0.8694270253181458\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9059712886810303, embedding dim 8, hidden size 256, num layers 1, train loss 0.8591427803039551, validation loss 0.8795814514160156\n",
      "Epoch 320, current patience 30, model mean validation loss 0.892012357711792, embedding dim 8, hidden size 256, num layers 1, train loss 0.7276228070259094, validation loss 0.8430392742156982\n",
      "Epoch 330, current patience 30, model mean validation loss 0.883609414100647, embedding dim 8, hidden size 256, num layers 1, train loss 0.7702906727790833, validation loss 0.8666059374809265\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8743165731430054, embedding dim 8, hidden size 256, num layers 1, train loss 0.8094826936721802, validation loss 0.8331426382064819\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8625982999801636, embedding dim 8, hidden size 256, num layers 1, train loss 0.6427568197250366, validation loss 0.8133431673049927\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8573150038719177, embedding dim 8, hidden size 256, num layers 1, train loss 0.7489976286888123, validation loss 0.8421226739883423\n",
      "Epoch 370, current patience 30, model mean validation loss 0.849227786064148, embedding dim 8, hidden size 256, num layers 1, train loss 0.6781198978424072, validation loss 0.8465596437454224\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8460662364959717, embedding dim 8, hidden size 256, num layers 1, train loss 0.8349494338035583, validation loss 0.8441351056098938\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8376970291137695, embedding dim 8, hidden size 256, num layers 1, train loss 0.7392005324363708, validation loss 0.8126279711723328\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8350332975387573, embedding dim 8, hidden size 256, num layers 1, train loss 0.669604480266571, validation loss 0.8217289447784424\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8288684487342834, embedding dim 8, hidden size 256, num layers 1, train loss 0.5359636545181274, validation loss 0.8172873258590698\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8260502219200134, embedding dim 8, hidden size 256, num layers 1, train loss 0.695176899433136, validation loss 0.8105970621109009\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8278200626373291, embedding dim 8, hidden size 256, num layers 1, train loss 0.49131059646606445, validation loss 0.8275018334388733\n",
      "Epoch 440, current patience 29, model mean validation loss 0.8262416124343872, embedding dim 8, hidden size 256, num layers 1, train loss 0.626702070236206, validation loss 0.8294950127601624\n",
      "Epoch 450, current patience 28, model mean validation loss 0.8225933313369751, embedding dim 8, hidden size 256, num layers 1, train loss 0.7117916941642761, validation loss 0.8173734545707703\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8159802556037903, embedding dim 8, hidden size 256, num layers 1, train loss 0.5351462364196777, validation loss 0.7912305593490601\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8186740279197693, embedding dim 8, hidden size 256, num layers 1, train loss 0.6066374778747559, validation loss 0.8341779708862305\n",
      "Epoch 480, current patience 29, model mean validation loss 0.8183884620666504, embedding dim 8, hidden size 256, num layers 1, train loss 0.8389884233474731, validation loss 0.8194442987442017\n",
      "Epoch 490, current patience 28, model mean validation loss 0.8166199326515198, embedding dim 8, hidden size 256, num layers 1, train loss 0.5235053300857544, validation loss 0.8031389713287354\n",
      "Epoch 500, current patience 27, model mean validation loss 0.8220133781433105, embedding dim 8, hidden size 256, num layers 1, train loss 0.6072952747344971, validation loss 0.8537450432777405\n",
      "Epoch 510, current patience 26, model mean validation loss 0.8174004554748535, embedding dim 8, hidden size 256, num layers 1, train loss 0.7055314779281616, validation loss 0.7905977964401245\n",
      "Epoch 520, current patience 25, model mean validation loss 0.8147236704826355, embedding dim 8, hidden size 256, num layers 1, train loss 0.6145755052566528, validation loss 0.8080810308456421\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8132710456848145, embedding dim 8, hidden size 256, num layers 1, train loss 0.4777255058288574, validation loss 0.8057523369789124\n",
      "Epoch 540, current patience 30, model mean validation loss 0.8214179277420044, embedding dim 8, hidden size 256, num layers 1, train loss 0.8109488487243652, validation loss 0.8564053773880005\n",
      "Epoch 550, current patience 29, model mean validation loss 0.8174084424972534, embedding dim 8, hidden size 256, num layers 1, train loss 0.6062890887260437, validation loss 0.8021026849746704\n",
      "Epoch 560, current patience 28, model mean validation loss 0.8201981782913208, embedding dim 8, hidden size 256, num layers 1, train loss 0.47344931960105896, validation loss 0.8417620062828064\n",
      "Epoch 570, current patience 27, model mean validation loss 0.8236974477767944, embedding dim 8, hidden size 256, num layers 1, train loss 0.6325187683105469, validation loss 0.8311331272125244\n",
      "Epoch 580, current patience 26, model mean validation loss 0.8234646916389465, embedding dim 8, hidden size 256, num layers 1, train loss 0.43878304958343506, validation loss 0.8518832921981812\n",
      "Epoch 590, current patience 25, model mean validation loss 0.8283261060714722, embedding dim 8, hidden size 256, num layers 1, train loss 0.47761261463165283, validation loss 0.8294890522956848\n",
      "Epoch 600, current patience 24, model mean validation loss 0.8290410041809082, embedding dim 8, hidden size 256, num layers 1, train loss 0.42739731073379517, validation loss 0.8138005137443542\n",
      "Epoch 610, current patience 23, model mean validation loss 0.8383749723434448, embedding dim 8, hidden size 256, num layers 1, train loss 0.5319008827209473, validation loss 0.8804237842559814\n",
      "Epoch 620, current patience 22, model mean validation loss 0.8339658975601196, embedding dim 8, hidden size 256, num layers 1, train loss 0.5518901944160461, validation loss 0.8211329579353333\n",
      "Epoch 630, current patience 21, model mean validation loss 0.8349179029464722, embedding dim 8, hidden size 256, num layers 1, train loss 0.40676984190940857, validation loss 0.8097188472747803\n",
      "Epoch 640, current patience 20, model mean validation loss 0.8362432718276978, embedding dim 8, hidden size 256, num layers 1, train loss 0.46173813939094543, validation loss 0.8523650169372559\n",
      "Epoch 650, current patience 19, model mean validation loss 0.8448992967605591, embedding dim 8, hidden size 256, num layers 1, train loss 0.5785926580429077, validation loss 0.9003806114196777\n",
      "Epoch 660, current patience 18, model mean validation loss 0.8439332246780396, embedding dim 8, hidden size 256, num layers 1, train loss 0.392539918422699, validation loss 0.8441553115844727\n",
      "Epoch 670, current patience 17, model mean validation loss 0.8427748680114746, embedding dim 8, hidden size 256, num layers 1, train loss 0.4019641876220703, validation loss 0.820222020149231\n",
      "Epoch 680, current patience 16, model mean validation loss 0.8639065027236938, embedding dim 8, hidden size 256, num layers 1, train loss 0.3768553137779236, validation loss 0.9828531742095947\n",
      "Epoch 690, current patience 15, model mean validation loss 0.8626897931098938, embedding dim 8, hidden size 256, num layers 1, train loss 0.5667866468429565, validation loss 0.8706903457641602\n",
      "Epoch 700, current patience 14, model mean validation loss 0.8688085079193115, embedding dim 8, hidden size 256, num layers 1, train loss 0.4548683762550354, validation loss 0.8700828552246094\n",
      "Epoch 710, current patience 13, model mean validation loss 0.8811594247817993, embedding dim 8, hidden size 256, num layers 1, train loss 0.33814647793769836, validation loss 0.9085263013839722\n",
      "Epoch 720, current patience 12, model mean validation loss 0.8878216743469238, embedding dim 8, hidden size 256, num layers 1, train loss 0.7417728900909424, validation loss 0.9056626558303833\n",
      "Epoch 730, current patience 11, model mean validation loss 0.8827735185623169, embedding dim 8, hidden size 256, num layers 1, train loss 0.3465675115585327, validation loss 0.859995424747467\n",
      "Epoch 740, current patience 10, model mean validation loss 0.8863232731819153, embedding dim 8, hidden size 256, num layers 1, train loss 0.32520073652267456, validation loss 0.872553288936615\n",
      "Epoch 750, current patience 9, model mean validation loss 0.9019824266433716, embedding dim 8, hidden size 256, num layers 1, train loss 0.24457193911075592, validation loss 0.9454954266548157\n",
      "Epoch 760, current patience 8, model mean validation loss 0.8929644823074341, embedding dim 8, hidden size 256, num layers 1, train loss 0.2377139925956726, validation loss 0.910709023475647\n",
      "Epoch 770, current patience 7, model mean validation loss 0.8959227800369263, embedding dim 8, hidden size 256, num layers 1, train loss 0.4094378650188446, validation loss 0.8943573832511902\n",
      "Epoch 780, current patience 6, model mean validation loss 0.9061288237571716, embedding dim 8, hidden size 256, num layers 1, train loss 0.2528640627861023, validation loss 0.9517308473587036\n",
      "Epoch 790, current patience 5, model mean validation loss 0.913022518157959, embedding dim 8, hidden size 256, num layers 1, train loss 0.38576775789260864, validation loss 0.9636762738227844\n",
      "Epoch 800, current patience 4, model mean validation loss 0.9147101640701294, embedding dim 8, hidden size 256, num layers 1, train loss 0.22794866561889648, validation loss 0.9191635847091675\n",
      "Epoch 810, current patience 3, model mean validation loss 0.923758864402771, embedding dim 8, hidden size 256, num layers 1, train loss 0.32261568307876587, validation loss 0.932385265827179\n",
      "Epoch 820, current patience 2, model mean validation loss 0.9387059807777405, embedding dim 8, hidden size 256, num layers 1, train loss 0.20282380282878876, validation loss 0.9921302795410156\n",
      "Epoch 830, current patience 1, model mean validation loss 0.9390523433685303, embedding dim 8, hidden size 256, num layers 1, train loss 0.20495906472206116, validation loss 0.9482660889625549\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1125071048736572, embedding dim 8, hidden size 512, num layers 1, train loss 1.1012954711914062, validation loss 1.1125071048736572\n",
      "Epoch 10, current patience 30, model mean validation loss 1.104853630065918, embedding dim 8, hidden size 512, num layers 1, train loss 1.09702730178833, validation loss 1.0972002744674683\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1034778356552124, embedding dim 8, hidden size 512, num layers 1, train loss 1.1148288249969482, validation loss 1.1007262468338013\n",
      "Epoch 30, current patience 30, model mean validation loss 1.101582407951355, embedding dim 8, hidden size 512, num layers 1, train loss 1.0954790115356445, validation loss 1.0958962440490723\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1005793809890747, embedding dim 8, hidden size 512, num layers 1, train loss 1.0946769714355469, validation loss 1.0965667963027954\n",
      "Epoch 50, current patience 30, model mean validation loss 1.099331259727478, embedding dim 8, hidden size 512, num layers 1, train loss 1.094860553741455, validation loss 1.0930914878845215\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0985745191574097, embedding dim 8, hidden size 512, num layers 1, train loss 1.0981409549713135, validation loss 1.0940335988998413\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0973106622695923, embedding dim 8, hidden size 512, num layers 1, train loss 1.0905518531799316, validation loss 1.088463544845581\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0941931009292603, embedding dim 8, hidden size 512, num layers 1, train loss 1.1036577224731445, validation loss 1.0875669717788696\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0941309928894043, embedding dim 8, hidden size 512, num layers 1, train loss 1.1017379760742188, validation loss 1.096703052520752\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0927817821502686, embedding dim 8, hidden size 512, num layers 1, train loss 1.1174062490463257, validation loss 1.0899327993392944\n",
      "Epoch 110, current patience 30, model mean validation loss 1.091262936592102, embedding dim 8, hidden size 512, num layers 1, train loss 1.0819017887115479, validation loss 1.0837452411651611\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0867207050323486, embedding dim 8, hidden size 512, num layers 1, train loss 1.069968581199646, validation loss 1.0602281093597412\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0820374488830566, embedding dim 8, hidden size 512, num layers 1, train loss 0.9730631113052368, validation loss 1.055626392364502\n",
      "Epoch 140, current patience 30, model mean validation loss 1.072780966758728, embedding dim 8, hidden size 512, num layers 1, train loss 1.0097477436065674, validation loss 1.0199813842773438\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0618022680282593, embedding dim 8, hidden size 512, num layers 1, train loss 0.9503182768821716, validation loss 1.0006341934204102\n",
      "Epoch 160, current patience 30, model mean validation loss 1.049782156944275, embedding dim 8, hidden size 512, num layers 1, train loss 0.9836084842681885, validation loss 0.9914054870605469\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0358784198760986, embedding dim 8, hidden size 512, num layers 1, train loss 0.9379189014434814, validation loss 0.9854727983474731\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0218642950057983, embedding dim 8, hidden size 512, num layers 1, train loss 0.9312254190444946, validation loss 0.9778211712837219\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0063753128051758, embedding dim 8, hidden size 512, num layers 1, train loss 0.8348839282989502, validation loss 0.959833025932312\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9911679029464722, embedding dim 8, hidden size 512, num layers 1, train loss 0.8835632801055908, validation loss 0.9385693073272705\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9772153496742249, embedding dim 8, hidden size 512, num layers 1, train loss 0.9435139894485474, validation loss 0.9440052509307861\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9657137393951416, embedding dim 8, hidden size 512, num layers 1, train loss 0.8354523181915283, validation loss 0.9279686212539673\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9565658569335938, embedding dim 8, hidden size 512, num layers 1, train loss 0.9869397878646851, validation loss 0.9274511337280273\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9494354128837585, embedding dim 8, hidden size 512, num layers 1, train loss 0.8283201456069946, validation loss 0.9343615770339966\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9438908100128174, embedding dim 8, hidden size 512, num layers 1, train loss 1.0677305459976196, validation loss 0.9411159753799438\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9334132075309753, embedding dim 8, hidden size 512, num layers 1, train loss 0.7445063591003418, validation loss 0.8940008878707886\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9246670007705688, embedding dim 8, hidden size 512, num layers 1, train loss 0.7981157302856445, validation loss 0.8898628950119019\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9190813302993774, embedding dim 8, hidden size 512, num layers 1, train loss 0.8948686122894287, validation loss 0.8938841223716736\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9122111201286316, embedding dim 8, hidden size 512, num layers 1, train loss 0.6750762462615967, validation loss 0.8890438079833984\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9042700529098511, embedding dim 8, hidden size 512, num layers 1, train loss 0.8991419076919556, validation loss 0.8644403219223022\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8934746384620667, embedding dim 8, hidden size 512, num layers 1, train loss 0.8129231333732605, validation loss 0.841087818145752\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8935060501098633, embedding dim 8, hidden size 512, num layers 1, train loss 0.7112934589385986, validation loss 0.9346123933792114\n",
      "Epoch 330, current patience 29, model mean validation loss 0.8873142004013062, embedding dim 8, hidden size 512, num layers 1, train loss 0.6795496940612793, validation loss 0.8915818333625793\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8815048933029175, embedding dim 8, hidden size 512, num layers 1, train loss 0.8995051980018616, validation loss 0.8475260734558105\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8768696188926697, embedding dim 8, hidden size 512, num layers 1, train loss 0.7807773351669312, validation loss 0.8527808785438538\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8686083555221558, embedding dim 8, hidden size 512, num layers 1, train loss 0.7291437387466431, validation loss 0.8277939558029175\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8652098178863525, embedding dim 8, hidden size 512, num layers 1, train loss 0.5320539474487305, validation loss 0.8618553280830383\n",
      "Epoch 380, current patience 30, model mean validation loss 0.866042971611023, embedding dim 8, hidden size 512, num layers 1, train loss 0.5060511827468872, validation loss 0.8711057305335999\n",
      "Epoch 390, current patience 29, model mean validation loss 0.8685206770896912, embedding dim 8, hidden size 512, num layers 1, train loss 0.5981607437133789, validation loss 0.8609094023704529\n",
      "Epoch 400, current patience 28, model mean validation loss 0.8598650693893433, embedding dim 8, hidden size 512, num layers 1, train loss 0.7179067134857178, validation loss 0.8653674125671387\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8591505289077759, embedding dim 8, hidden size 512, num layers 1, train loss 0.656875729560852, validation loss 0.8858656883239746\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8643932938575745, embedding dim 8, hidden size 512, num layers 1, train loss 0.5665032863616943, validation loss 0.8894681930541992\n",
      "Epoch 430, current patience 29, model mean validation loss 0.8665214776992798, embedding dim 8, hidden size 512, num layers 1, train loss 0.7306473255157471, validation loss 0.8698062896728516\n",
      "Epoch 440, current patience 28, model mean validation loss 0.8807961940765381, embedding dim 8, hidden size 512, num layers 1, train loss 0.43039822578430176, validation loss 0.9419913291931152\n",
      "Epoch 450, current patience 27, model mean validation loss 0.8939382433891296, embedding dim 8, hidden size 512, num layers 1, train loss 0.5286544561386108, validation loss 0.9669917821884155\n",
      "Epoch 460, current patience 26, model mean validation loss 0.8905600309371948, embedding dim 8, hidden size 512, num layers 1, train loss 0.7923264503479004, validation loss 0.8440799713134766\n",
      "Epoch 470, current patience 25, model mean validation loss 0.8908572196960449, embedding dim 8, hidden size 512, num layers 1, train loss 0.7669219970703125, validation loss 0.8632866740226746\n",
      "Epoch 480, current patience 24, model mean validation loss 0.8849765062332153, embedding dim 8, hidden size 512, num layers 1, train loss 0.6376771926879883, validation loss 0.8183215856552124\n",
      "Epoch 490, current patience 23, model mean validation loss 0.8802810907363892, embedding dim 8, hidden size 512, num layers 1, train loss 0.7527785897254944, validation loss 0.8483029007911682\n",
      "Epoch 500, current patience 22, model mean validation loss 0.8809123039245605, embedding dim 8, hidden size 512, num layers 1, train loss 0.5218371152877808, validation loss 0.894517719745636\n",
      "Epoch 510, current patience 21, model mean validation loss 0.8911334872245789, embedding dim 8, hidden size 512, num layers 1, train loss 0.6120004653930664, validation loss 0.9515761137008667\n",
      "Epoch 520, current patience 20, model mean validation loss 0.8827123045921326, embedding dim 8, hidden size 512, num layers 1, train loss 0.46125927567481995, validation loss 0.8746215105056763\n",
      "Epoch 530, current patience 19, model mean validation loss 0.8718803524971008, embedding dim 8, hidden size 512, num layers 1, train loss 0.48456189036369324, validation loss 0.8803362250328064\n",
      "Epoch 540, current patience 18, model mean validation loss 0.8820890784263611, embedding dim 8, hidden size 512, num layers 1, train loss 0.17126378417015076, validation loss 0.9257500171661377\n",
      "Epoch 550, current patience 17, model mean validation loss 0.8858642578125, embedding dim 8, hidden size 512, num layers 1, train loss 0.6365603804588318, validation loss 0.8934881687164307\n",
      "Epoch 560, current patience 16, model mean validation loss 0.9042133092880249, embedding dim 8, hidden size 512, num layers 1, train loss 0.693401038646698, validation loss 0.9651139974594116\n",
      "Epoch 570, current patience 15, model mean validation loss 0.9192580580711365, embedding dim 8, hidden size 512, num layers 1, train loss 0.5468662977218628, validation loss 0.968660831451416\n",
      "Epoch 580, current patience 14, model mean validation loss 0.9188765287399292, embedding dim 8, hidden size 512, num layers 1, train loss 0.4805442988872528, validation loss 0.8914651870727539\n",
      "Epoch 590, current patience 13, model mean validation loss 0.9221183657646179, embedding dim 8, hidden size 512, num layers 1, train loss 0.2544414699077606, validation loss 0.9775105714797974\n",
      "Epoch 600, current patience 12, model mean validation loss 0.9323486089706421, embedding dim 8, hidden size 512, num layers 1, train loss 0.780863881111145, validation loss 0.9564636945724487\n",
      "Epoch 610, current patience 11, model mean validation loss 0.9364702701568604, embedding dim 8, hidden size 512, num layers 1, train loss 0.6436294317245483, validation loss 0.9133093357086182\n",
      "Epoch 620, current patience 10, model mean validation loss 0.9527966976165771, embedding dim 8, hidden size 512, num layers 1, train loss 0.346958190202713, validation loss 1.056362271308899\n",
      "Epoch 630, current patience 9, model mean validation loss 0.9700944423675537, embedding dim 8, hidden size 512, num layers 1, train loss 0.5821617841720581, validation loss 1.031869888305664\n",
      "Epoch 640, current patience 8, model mean validation loss 0.9708552360534668, embedding dim 8, hidden size 512, num layers 1, train loss 0.3047868609428406, validation loss 0.9712002277374268\n",
      "Epoch 650, current patience 7, model mean validation loss 0.9761531352996826, embedding dim 8, hidden size 512, num layers 1, train loss 0.3695647716522217, validation loss 1.0110442638397217\n",
      "Epoch 660, current patience 6, model mean validation loss 0.9907217025756836, embedding dim 8, hidden size 512, num layers 1, train loss 0.38777101039886475, validation loss 1.0080134868621826\n",
      "Epoch 670, current patience 5, model mean validation loss 0.9936071634292603, embedding dim 8, hidden size 512, num layers 1, train loss 0.5705498456954956, validation loss 1.0005940198898315\n",
      "Epoch 680, current patience 4, model mean validation loss 0.9940743446350098, embedding dim 8, hidden size 512, num layers 1, train loss 0.5003050565719604, validation loss 0.9602012634277344\n",
      "Epoch 690, current patience 3, model mean validation loss 1.000376582145691, embedding dim 8, hidden size 512, num layers 1, train loss 0.36241769790649414, validation loss 0.9637271761894226\n",
      "Epoch 700, current patience 2, model mean validation loss 0.9962062835693359, embedding dim 8, hidden size 512, num layers 1, train loss 0.2873237729072571, validation loss 1.0229997634887695\n",
      "Epoch 710, current patience 1, model mean validation loss 0.9915004372596741, embedding dim 8, hidden size 512, num layers 1, train loss 0.7144646048545837, validation loss 0.9942231178283691\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2782890796661377, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0990574359893799, validation loss 1.2782890796661377\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1897820234298706, embedding dim 8, hidden size 1024, num layers 1, train loss 1.1015615463256836, validation loss 1.1012749671936035\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1597851514816284, embedding dim 8, hidden size 1024, num layers 1, train loss 1.136439561843872, validation loss 1.0997912883758545\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1449979543685913, embedding dim 8, hidden size 1024, num layers 1, train loss 1.1029434204101562, validation loss 1.1006364822387695\n",
      "Epoch 40, current patience 30, model mean validation loss 1.135770559310913, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0937409400939941, validation loss 1.0988612174987793\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1290308237075806, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0890552997589111, validation loss 1.0953316688537598\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1239444017410278, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0925458669662476, validation loss 1.0934264659881592\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1207125186920166, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0908724069595337, validation loss 1.0980885028839111\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0978996753692627, embedding dim 8, hidden size 1024, num layers 1, train loss 1.109565019607544, validation loss 1.0957868099212646\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0960315465927124, embedding dim 8, hidden size 1024, num layers 1, train loss 1.1067456007003784, validation loss 1.0863300561904907\n",
      "Epoch 100, current patience 30, model mean validation loss 1.095667839050293, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0781956911087036, validation loss 1.0968821048736572\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0950195789337158, embedding dim 8, hidden size 1024, num layers 1, train loss 1.1136953830718994, validation loss 1.095449686050415\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0944414138793945, embedding dim 8, hidden size 1024, num layers 1, train loss 1.090548038482666, validation loss 1.0942366123199463\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0936123132705688, embedding dim 8, hidden size 1024, num layers 1, train loss 1.086275577545166, validation loss 1.0886982679367065\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0930407047271729, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0842556953430176, validation loss 1.0888538360595703\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0921523571014404, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0721399784088135, validation loss 1.0909814834594727\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0915899276733398, embedding dim 8, hidden size 1024, num layers 1, train loss 1.161351203918457, validation loss 1.0912878513336182\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0939260721206665, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0860463380813599, validation loss 1.1050188541412354\n",
      "Epoch 180, current patience 29, model mean validation loss 1.0901944637298584, embedding dim 8, hidden size 1024, num layers 1, train loss 1.068289875984192, validation loss 1.0670284032821655\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0860629081726074, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0517537593841553, validation loss 1.0623977184295654\n",
      "Epoch 200, current patience 30, model mean validation loss 1.082399845123291, embedding dim 8, hidden size 1024, num layers 1, train loss 0.9844257831573486, validation loss 1.0649330615997314\n",
      "Epoch 210, current patience 30, model mean validation loss 1.074599266052246, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0830695629119873, validation loss 1.0262928009033203\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0667753219604492, embedding dim 8, hidden size 1024, num layers 1, train loss 0.9771831631660461, validation loss 1.0262632369995117\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0595065355300903, embedding dim 8, hidden size 1024, num layers 1, train loss 0.928460955619812, validation loss 1.0328301191329956\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0470960140228271, embedding dim 8, hidden size 1024, num layers 1, train loss 0.9186348915100098, validation loss 0.9920032024383545\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0309914350509644, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8841693997383118, validation loss 0.9761829972267151\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0236279964447021, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8987300395965576, validation loss 1.0081204175949097\n",
      "Epoch 270, current patience 30, model mean validation loss 1.01926851272583, embedding dim 8, hidden size 1024, num layers 1, train loss 1.0178375244140625, validation loss 1.027522087097168\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0063551664352417, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8138131499290466, validation loss 0.9616259932518005\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9963129758834839, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8463703989982605, validation loss 0.9459551572799683\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9826949834823608, embedding dim 8, hidden size 1024, num layers 1, train loss 0.9187912344932556, validation loss 0.9173194169998169\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9702208638191223, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8046879172325134, validation loss 0.933037281036377\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9558591246604919, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7722948789596558, validation loss 0.8771094679832458\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9441568851470947, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8469554781913757, validation loss 0.8825648427009583\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9278035163879395, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7166479825973511, validation loss 0.8772932291030884\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9102474451065063, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8454415798187256, validation loss 0.8870738744735718\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8967927694320679, embedding dim 8, hidden size 1024, num layers 1, train loss 0.6852965354919434, validation loss 0.853988766670227\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8855630159378052, embedding dim 8, hidden size 1024, num layers 1, train loss 0.9150509238243103, validation loss 0.8561171293258667\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8766237497329712, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7372699975967407, validation loss 0.845805287361145\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8647571206092834, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7566370964050293, validation loss 0.8381043672561646\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8627545833587646, embedding dim 8, hidden size 1024, num layers 1, train loss 0.830832839012146, validation loss 0.8610891103744507\n",
      "Epoch 410, current patience 30, model mean validation loss 0.855962336063385, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7201341390609741, validation loss 0.8282266855239868\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8529560565948486, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8295252323150635, validation loss 0.8532431125640869\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8431926965713501, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7890944480895996, validation loss 0.8089668154716492\n",
      "Epoch 440, current patience 30, model mean validation loss 0.836326539516449, embedding dim 8, hidden size 1024, num layers 1, train loss 0.74224853515625, validation loss 0.7990598678588867\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8348574638366699, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5833388566970825, validation loss 0.8443643450737\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8299927711486816, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7923908233642578, validation loss 0.8068885803222656\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8260118365287781, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7899389266967773, validation loss 0.8062565922737122\n",
      "Epoch 480, current patience 30, model mean validation loss 0.8200570344924927, embedding dim 8, hidden size 1024, num layers 1, train loss 0.729561984539032, validation loss 0.813450038433075\n",
      "Epoch 490, current patience 30, model mean validation loss 0.8206813931465149, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5753582715988159, validation loss 0.8332218527793884\n",
      "Epoch 500, current patience 29, model mean validation loss 0.8181612491607666, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5905141830444336, validation loss 0.8330819010734558\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8184393048286438, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5060312747955322, validation loss 0.8111908435821533\n",
      "Epoch 520, current patience 29, model mean validation loss 0.8149561882019043, embedding dim 8, hidden size 1024, num layers 1, train loss 0.7831234931945801, validation loss 0.7711951732635498\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8094292879104614, embedding dim 8, hidden size 1024, num layers 1, train loss 0.6176563501358032, validation loss 0.8001492023468018\n",
      "Epoch 540, current patience 30, model mean validation loss 0.807295560836792, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5610367059707642, validation loss 0.7898193597793579\n",
      "Epoch 550, current patience 30, model mean validation loss 0.8076382279396057, embedding dim 8, hidden size 1024, num layers 1, train loss 0.6417579650878906, validation loss 0.808997392654419\n",
      "Epoch 560, current patience 29, model mean validation loss 0.8061960935592651, embedding dim 8, hidden size 1024, num layers 1, train loss 0.4113544225692749, validation loss 0.8019132614135742\n",
      "Epoch 570, current patience 30, model mean validation loss 0.8052039742469788, embedding dim 8, hidden size 1024, num layers 1, train loss 0.4881931245326996, validation loss 0.8252846002578735\n",
      "Epoch 580, current patience 30, model mean validation loss 0.7984497547149658, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8029297590255737, validation loss 0.7790484428405762\n",
      "Epoch 590, current patience 30, model mean validation loss 0.7997128367424011, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5724829435348511, validation loss 0.821295440196991\n",
      "Epoch 600, current patience 29, model mean validation loss 0.807309627532959, embedding dim 8, hidden size 1024, num layers 1, train loss 0.43622997403144836, validation loss 0.8319693803787231\n",
      "Epoch 610, current patience 28, model mean validation loss 0.8067927360534668, embedding dim 8, hidden size 1024, num layers 1, train loss 0.6570595502853394, validation loss 0.7960140705108643\n",
      "Epoch 620, current patience 27, model mean validation loss 0.8062757253646851, embedding dim 8, hidden size 1024, num layers 1, train loss 0.531046450138092, validation loss 0.7856830358505249\n",
      "Epoch 630, current patience 26, model mean validation loss 0.8081554174423218, embedding dim 8, hidden size 1024, num layers 1, train loss 0.502443790435791, validation loss 0.8240347504615784\n",
      "Epoch 640, current patience 25, model mean validation loss 0.8091164827346802, embedding dim 8, hidden size 1024, num layers 1, train loss 0.6603521108627319, validation loss 0.809601902961731\n",
      "Epoch 650, current patience 24, model mean validation loss 0.809679388999939, embedding dim 8, hidden size 1024, num layers 1, train loss 0.8152707815170288, validation loss 0.8297877311706543\n",
      "Epoch 660, current patience 23, model mean validation loss 0.8110753297805786, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3330579996109009, validation loss 0.7902160882949829\n",
      "Epoch 670, current patience 22, model mean validation loss 0.8146873712539673, embedding dim 8, hidden size 1024, num layers 1, train loss 0.5781864523887634, validation loss 0.8501923084259033\n",
      "Epoch 680, current patience 21, model mean validation loss 0.8106240630149841, embedding dim 8, hidden size 1024, num layers 1, train loss 0.34583961963653564, validation loss 0.7994625568389893\n",
      "Epoch 690, current patience 20, model mean validation loss 0.8157464265823364, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3780888617038727, validation loss 0.8369934558868408\n",
      "Epoch 700, current patience 19, model mean validation loss 0.8185742497444153, embedding dim 8, hidden size 1024, num layers 1, train loss 0.40637779235839844, validation loss 0.8083057403564453\n",
      "Epoch 710, current patience 18, model mean validation loss 0.8190170526504517, embedding dim 8, hidden size 1024, num layers 1, train loss 0.44011664390563965, validation loss 0.8275769352912903\n",
      "Epoch 720, current patience 17, model mean validation loss 0.822543740272522, embedding dim 8, hidden size 1024, num layers 1, train loss 0.36507701873779297, validation loss 0.8378148078918457\n",
      "Epoch 730, current patience 16, model mean validation loss 0.826472282409668, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3095228374004364, validation loss 0.8612163066864014\n",
      "Epoch 740, current patience 15, model mean validation loss 0.8387641906738281, embedding dim 8, hidden size 1024, num layers 1, train loss 0.2977547347545624, validation loss 0.888551652431488\n",
      "Epoch 750, current patience 14, model mean validation loss 0.8404564261436462, embedding dim 8, hidden size 1024, num layers 1, train loss 0.20315124094486237, validation loss 0.8637295365333557\n",
      "Epoch 760, current patience 13, model mean validation loss 0.8495105504989624, embedding dim 8, hidden size 1024, num layers 1, train loss 0.569475531578064, validation loss 0.8718960881233215\n",
      "Epoch 770, current patience 12, model mean validation loss 0.8563413619995117, embedding dim 8, hidden size 1024, num layers 1, train loss 0.4861818253993988, validation loss 0.8916400671005249\n",
      "Epoch 780, current patience 11, model mean validation loss 0.8745468258857727, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3707607388496399, validation loss 0.9539494514465332\n",
      "Epoch 790, current patience 10, model mean validation loss 0.878696084022522, embedding dim 8, hidden size 1024, num layers 1, train loss 0.43459978699684143, validation loss 0.8607708811759949\n",
      "Epoch 800, current patience 9, model mean validation loss 0.890906572341919, embedding dim 8, hidden size 1024, num layers 1, train loss 0.39867451786994934, validation loss 0.9354987144470215\n",
      "Epoch 810, current patience 8, model mean validation loss 0.8953497409820557, embedding dim 8, hidden size 1024, num layers 1, train loss 0.28675708174705505, validation loss 0.8967614769935608\n",
      "Epoch 820, current patience 7, model mean validation loss 0.8912047147750854, embedding dim 8, hidden size 1024, num layers 1, train loss 0.4190719723701477, validation loss 0.8553917407989502\n",
      "Epoch 830, current patience 6, model mean validation loss 0.8946518898010254, embedding dim 8, hidden size 1024, num layers 1, train loss 0.65479576587677, validation loss 0.8913064002990723\n",
      "Epoch 840, current patience 5, model mean validation loss 0.8936202526092529, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3340631127357483, validation loss 0.8636434078216553\n",
      "Epoch 850, current patience 4, model mean validation loss 0.8918055295944214, embedding dim 8, hidden size 1024, num layers 1, train loss 0.4165126085281372, validation loss 0.8771226406097412\n",
      "Epoch 860, current patience 3, model mean validation loss 0.8809434175491333, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3740253746509552, validation loss 0.8670516610145569\n",
      "Epoch 870, current patience 2, model mean validation loss 0.8933463096618652, embedding dim 8, hidden size 1024, num layers 1, train loss 0.29637929797172546, validation loss 0.9599946737289429\n",
      "Epoch 880, current patience 1, model mean validation loss 0.886474609375, embedding dim 8, hidden size 1024, num layers 1, train loss 0.3916512727737427, validation loss 0.8805250525474548\n",
      "Epoch 0, current patience 30, model mean validation loss 1.6728606224060059, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1020689010620117, validation loss 1.6728606224060059\n",
      "Epoch 10, current patience 30, model mean validation loss 1.714980125427246, embedding dim 8, hidden size 2048, num layers 1, train loss 1.479007601737976, validation loss 1.7570997476577759\n",
      "Epoch 20, current patience 29, model mean validation loss 1.547082543373108, embedding dim 8, hidden size 2048, num layers 1, train loss 1.3261783123016357, validation loss 1.211287498474121\n",
      "Epoch 30, current patience 30, model mean validation loss 1.4614295959472656, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1387836933135986, validation loss 1.2044706344604492\n",
      "Epoch 40, current patience 30, model mean validation loss 1.4057543277740479, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2342214584350586, validation loss 1.1830536127090454\n",
      "Epoch 50, current patience 30, model mean validation loss 1.3690909147262573, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2819571495056152, validation loss 1.1857733726501465\n",
      "Epoch 60, current patience 30, model mean validation loss 1.347467303276062, embedding dim 8, hidden size 2048, num layers 1, train loss 1.277531385421753, validation loss 1.217726469039917\n",
      "Epoch 70, current patience 30, model mean validation loss 1.3231908082962036, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2169878482818604, validation loss 1.1532542705535889\n",
      "Epoch 80, current patience 30, model mean validation loss 1.252509593963623, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2959861755371094, validation loss 1.1074113845825195\n",
      "Epoch 90, current patience 30, model mean validation loss 1.17138671875, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1704823970794678, validation loss 1.108116865158081\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1633801460266113, embedding dim 8, hidden size 2048, num layers 1, train loss 1.0920391082763672, validation loss 1.1472346782684326\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1574440002441406, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1329163312911987, validation loss 1.1569815874099731\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1481603384017944, embedding dim 8, hidden size 2048, num layers 1, train loss 1.110377311706543, validation loss 1.108783483505249\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1440980434417725, embedding dim 8, hidden size 2048, num layers 1, train loss 1.094751238822937, validation loss 1.1532762050628662\n",
      "Epoch 140, current patience 30, model mean validation loss 1.133650779724121, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1231484413146973, validation loss 1.1341478824615479\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1400444507598877, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1081074476242065, validation loss 1.2044038772583008\n",
      "Epoch 160, current patience 29, model mean validation loss 1.1392673254013062, embedding dim 8, hidden size 2048, num layers 1, train loss 1.0989158153533936, validation loss 1.1011943817138672\n",
      "Epoch 170, current patience 28, model mean validation loss 1.1401779651641846, embedding dim 8, hidden size 2048, num layers 1, train loss 1.0855712890625, validation loss 1.1154015064239502\n",
      "Epoch 180, current patience 27, model mean validation loss 1.1385822296142578, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1205873489379883, validation loss 1.1344692707061768\n",
      "Epoch 190, current patience 26, model mean validation loss 1.1342201232910156, embedding dim 8, hidden size 2048, num layers 1, train loss 1.094589352607727, validation loss 1.1220839023590088\n",
      "Epoch 200, current patience 25, model mean validation loss 1.1420197486877441, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1080820560455322, validation loss 1.1711809635162354\n",
      "Epoch 210, current patience 24, model mean validation loss 1.1367484331130981, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1576380729675293, validation loss 1.1111055612564087\n",
      "Epoch 220, current patience 23, model mean validation loss 1.1375060081481934, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1848728656768799, validation loss 1.1402087211608887\n",
      "Epoch 230, current patience 22, model mean validation loss 1.1337995529174805, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1440703868865967, validation loss 1.1747517585754395\n",
      "Epoch 240, current patience 21, model mean validation loss 1.1382092237472534, embedding dim 8, hidden size 2048, num layers 1, train loss 1.0806955099105835, validation loss 1.1364717483520508\n",
      "Epoch 250, current patience 20, model mean validation loss 1.1538922786712646, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1114823818206787, validation loss 1.2408661842346191\n",
      "Epoch 260, current patience 19, model mean validation loss 1.164335012435913, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2175666093826294, validation loss 1.2180109024047852\n",
      "Epoch 270, current patience 18, model mean validation loss 1.1797206401824951, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2706444263458252, validation loss 1.245169997215271\n",
      "Epoch 280, current patience 17, model mean validation loss 1.2254512310028076, embedding dim 8, hidden size 2048, num layers 1, train loss 1.4564342498779297, validation loss 1.5370255708694458\n",
      "Epoch 290, current patience 16, model mean validation loss 1.2455885410308838, embedding dim 8, hidden size 2048, num layers 1, train loss 1.4858336448669434, validation loss 1.272203803062439\n",
      "Epoch 300, current patience 15, model mean validation loss 1.2530287504196167, embedding dim 8, hidden size 2048, num layers 1, train loss 1.3544154167175293, validation loss 1.1997298002243042\n",
      "Epoch 310, current patience 14, model mean validation loss 1.2714577913284302, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1828162670135498, validation loss 1.3221843242645264\n",
      "Epoch 320, current patience 13, model mean validation loss 1.3057830333709717, embedding dim 8, hidden size 2048, num layers 1, train loss 1.3530491590499878, validation loss 1.411074161529541\n",
      "Epoch 330, current patience 12, model mean validation loss 1.315683126449585, embedding dim 8, hidden size 2048, num layers 1, train loss 1.3215491771697998, validation loss 1.320066213607788\n",
      "Epoch 340, current patience 11, model mean validation loss 1.3294836282730103, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1627123355865479, validation loss 1.3284159898757935\n",
      "Epoch 350, current patience 10, model mean validation loss 1.3286573886871338, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1168889999389648, validation loss 1.2385585308074951\n",
      "Epoch 360, current patience 9, model mean validation loss 1.2811800241470337, embedding dim 8, hidden size 2048, num layers 1, train loss 1.3471765518188477, validation loss 1.1572073698043823\n",
      "Epoch 370, current patience 8, model mean validation loss 1.2615008354187012, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1079745292663574, validation loss 1.114769697189331\n",
      "Epoch 380, current patience 7, model mean validation loss 1.2592509984970093, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2260977029800415, validation loss 1.1817314624786377\n",
      "Epoch 390, current patience 6, model mean validation loss 1.2434457540512085, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1520532369613647, validation loss 1.1957426071166992\n",
      "Epoch 400, current patience 5, model mean validation loss 1.2119182348251343, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1172142028808594, validation loss 1.1588534116744995\n",
      "Epoch 410, current patience 4, model mean validation loss 1.1982948780059814, embedding dim 8, hidden size 2048, num layers 1, train loss 1.2127530574798584, validation loss 1.2110792398452759\n",
      "Epoch 420, current patience 3, model mean validation loss 1.1809537410736084, embedding dim 8, hidden size 2048, num layers 1, train loss 1.156768798828125, validation loss 1.1896876096725464\n",
      "Epoch 430, current patience 2, model mean validation loss 1.166595220565796, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1616798639297485, validation loss 1.1236908435821533\n",
      "Epoch 440, current patience 1, model mean validation loss 1.178371787071228, embedding dim 8, hidden size 2048, num layers 1, train loss 1.1761890649795532, validation loss 1.251418948173523\n",
      "Epoch 0, current patience 30, model mean validation loss 1.4563863277435303, embedding dim 16, hidden size 1, num layers 1, train loss 1.6057546138763428, validation loss 1.4563863277435303\n",
      "Epoch 10, current patience 30, model mean validation loss 1.4014904499053955, embedding dim 16, hidden size 1, num layers 1, train loss 1.384292483329773, validation loss 1.3465944528579712\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3697525262832642, embedding dim 16, hidden size 1, num layers 1, train loss 1.414733648300171, validation loss 1.3062770366668701\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3503199815750122, embedding dim 16, hidden size 1, num layers 1, train loss 1.2507500648498535, validation loss 1.2920222282409668\n",
      "Epoch 40, current patience 30, model mean validation loss 1.329833745956421, embedding dim 16, hidden size 1, num layers 1, train loss 1.2518688440322876, validation loss 1.2478888034820557\n",
      "Epoch 50, current patience 30, model mean validation loss 1.309984564781189, embedding dim 16, hidden size 1, num layers 1, train loss 1.189164161682129, validation loss 1.2107387781143188\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2907979488372803, embedding dim 16, hidden size 1, num layers 1, train loss 1.1888651847839355, validation loss 1.1756784915924072\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2745308876037598, embedding dim 16, hidden size 1, num layers 1, train loss 1.1217284202575684, validation loss 1.1606614589691162\n",
      "Epoch 80, current patience 30, model mean validation loss 1.2366697788238525, embedding dim 16, hidden size 1, num layers 1, train loss 1.165472149848938, validation loss 1.1534976959228516\n",
      "Epoch 90, current patience 30, model mean validation loss 1.2107070684432983, embedding dim 16, hidden size 1, num layers 1, train loss 1.1530925035476685, validation loss 1.1388927698135376\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1876215934753418, embedding dim 16, hidden size 1, num layers 1, train loss 1.1279194355010986, validation loss 1.1215925216674805\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1648766994476318, embedding dim 16, hidden size 1, num layers 1, train loss 1.1090333461761475, validation loss 1.110062599182129\n",
      "Epoch 120, current patience 30, model mean validation loss 1.146630048751831, embedding dim 16, hidden size 1, num layers 1, train loss 1.096540927886963, validation loss 1.1019160747528076\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1325368881225586, embedding dim 16, hidden size 1, num layers 1, train loss 1.0989447832107544, validation loss 1.0979928970336914\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1221928596496582, embedding dim 16, hidden size 1, num layers 1, train loss 1.101728916168213, validation loss 1.0929267406463623\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1131961345672607, embedding dim 16, hidden size 1, num layers 1, train loss 1.089378833770752, validation loss 1.0886882543563843\n",
      "Epoch 160, current patience 30, model mean validation loss 1.1044254302978516, embedding dim 16, hidden size 1, num layers 1, train loss 1.1018973588943481, validation loss 1.0833324193954468\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0980474948883057, embedding dim 16, hidden size 1, num layers 1, train loss 1.1003834009170532, validation loss 1.087868571281433\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0935719013214111, embedding dim 16, hidden size 1, num layers 1, train loss 1.102879524230957, validation loss 1.0857869386672974\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0902820825576782, embedding dim 16, hidden size 1, num layers 1, train loss 1.1035387516021729, validation loss 1.0837448835372925\n",
      "Epoch 200, current patience 30, model mean validation loss 1.087857723236084, embedding dim 16, hidden size 1, num layers 1, train loss 1.1073899269104004, validation loss 1.0825213193893433\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0861953496932983, embedding dim 16, hidden size 1, num layers 1, train loss 1.0709969997406006, validation loss 1.0846941471099854\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0849299430847168, embedding dim 16, hidden size 1, num layers 1, train loss 1.0550315380096436, validation loss 1.082803726196289\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0838351249694824, embedding dim 16, hidden size 1, num layers 1, train loss 1.0923130512237549, validation loss 1.079930067062378\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0833640098571777, embedding dim 16, hidden size 1, num layers 1, train loss 1.0784306526184082, validation loss 1.0795631408691406\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0819458961486816, embedding dim 16, hidden size 1, num layers 1, train loss 1.0688186883926392, validation loss 1.0765225887298584\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0799603462219238, embedding dim 16, hidden size 1, num layers 1, train loss 0.9316118955612183, validation loss 1.0699026584625244\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0787153244018555, embedding dim 16, hidden size 1, num layers 1, train loss 1.0384013652801514, validation loss 1.0737850666046143\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0772669315338135, embedding dim 16, hidden size 1, num layers 1, train loss 1.0323272943496704, validation loss 1.0709338188171387\n",
      "Epoch 290, current patience 30, model mean validation loss 1.075138807296753, embedding dim 16, hidden size 1, num layers 1, train loss 1.041852355003357, validation loss 1.06766939163208\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0733065605163574, embedding dim 16, hidden size 1, num layers 1, train loss 0.9339984059333801, validation loss 1.0681452751159668\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0713036060333252, embedding dim 16, hidden size 1, num layers 1, train loss 1.0647408962249756, validation loss 1.0639066696166992\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0682826042175293, embedding dim 16, hidden size 1, num layers 1, train loss 0.9614088535308838, validation loss 1.0553950071334839\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0663695335388184, embedding dim 16, hidden size 1, num layers 1, train loss 1.107458472251892, validation loss 1.0612177848815918\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0638344287872314, embedding dim 16, hidden size 1, num layers 1, train loss 1.0097225904464722, validation loss 1.0496220588684082\n",
      "Epoch 350, current patience 30, model mean validation loss 1.059909462928772, embedding dim 16, hidden size 1, num layers 1, train loss 1.0605264902114868, validation loss 1.0423856973648071\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0560247898101807, embedding dim 16, hidden size 1, num layers 1, train loss 1.0280721187591553, validation loss 1.0398564338684082\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0526217222213745, embedding dim 16, hidden size 1, num layers 1, train loss 0.9610492587089539, validation loss 1.0404446125030518\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0482308864593506, embedding dim 16, hidden size 1, num layers 1, train loss 0.9065693020820618, validation loss 1.0330183506011963\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0440644025802612, embedding dim 16, hidden size 1, num layers 1, train loss 0.9055370688438416, validation loss 1.0305750370025635\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0393482446670532, embedding dim 16, hidden size 1, num layers 1, train loss 0.9060280323028564, validation loss 1.0176656246185303\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0330474376678467, embedding dim 16, hidden size 1, num layers 1, train loss 0.9614539742469788, validation loss 1.0108110904693604\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0278117656707764, embedding dim 16, hidden size 1, num layers 1, train loss 0.9000612497329712, validation loss 1.0077378749847412\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0227923393249512, embedding dim 16, hidden size 1, num layers 1, train loss 0.9635624885559082, validation loss 1.0022296905517578\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0167510509490967, embedding dim 16, hidden size 1, num layers 1, train loss 0.9458550214767456, validation loss 0.991525411605835\n",
      "Epoch 450, current patience 30, model mean validation loss 1.010532259941101, embedding dim 16, hidden size 1, num layers 1, train loss 0.8872414231300354, validation loss 0.9906954765319824\n",
      "Epoch 460, current patience 30, model mean validation loss 1.0065710544586182, embedding dim 16, hidden size 1, num layers 1, train loss 0.8419010639190674, validation loss 1.0013277530670166\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0030009746551514, embedding dim 16, hidden size 1, num layers 1, train loss 0.8457492589950562, validation loss 1.002015471458435\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9986080527305603, embedding dim 16, hidden size 1, num layers 1, train loss 0.8577002286911011, validation loss 0.9825212955474854\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9963738918304443, embedding dim 16, hidden size 1, num layers 1, train loss 0.9225761890411377, validation loss 0.9929380416870117\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9940633177757263, embedding dim 16, hidden size 1, num layers 1, train loss 0.8201561570167542, validation loss 0.9892534017562866\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9946203231811523, embedding dim 16, hidden size 1, num layers 1, train loss 0.9162342548370361, validation loss 1.006685733795166\n",
      "Epoch 520, current patience 29, model mean validation loss 0.9949111938476562, embedding dim 16, hidden size 1, num layers 1, train loss 0.8628958463668823, validation loss 0.9938521981239319\n",
      "Epoch 530, current patience 28, model mean validation loss 0.9956847429275513, embedding dim 16, hidden size 1, num layers 1, train loss 0.9612833261489868, validation loss 0.9968843460083008\n",
      "Epoch 540, current patience 27, model mean validation loss 0.9932215809822083, embedding dim 16, hidden size 1, num layers 1, train loss 0.8711589574813843, validation loss 0.9816218614578247\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9916621446609497, embedding dim 16, hidden size 1, num layers 1, train loss 0.7764772176742554, validation loss 0.989540696144104\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9889814257621765, embedding dim 16, hidden size 1, num layers 1, train loss 0.9111149311065674, validation loss 0.9610752463340759\n",
      "Epoch 570, current patience 30, model mean validation loss 0.987533688545227, embedding dim 16, hidden size 1, num layers 1, train loss 0.7523037195205688, validation loss 0.9813562631607056\n",
      "Epoch 580, current patience 30, model mean validation loss 0.98722243309021, embedding dim 16, hidden size 1, num layers 1, train loss 0.9230945110321045, validation loss 0.9867631196975708\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9830874800682068, embedding dim 16, hidden size 1, num layers 1, train loss 0.8686910271644592, validation loss 0.9736059904098511\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9786539077758789, embedding dim 16, hidden size 1, num layers 1, train loss 0.8081377744674683, validation loss 0.9583836793899536\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9795248508453369, embedding dim 16, hidden size 1, num layers 1, train loss 0.8581986427307129, validation loss 1.0038522481918335\n",
      "Epoch 620, current patience 29, model mean validation loss 0.9792288541793823, embedding dim 16, hidden size 1, num layers 1, train loss 0.8030946254730225, validation loss 0.9792534112930298\n",
      "Epoch 630, current patience 28, model mean validation loss 0.9744261503219604, embedding dim 16, hidden size 1, num layers 1, train loss 0.8976117968559265, validation loss 0.9511194229125977\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9792758822441101, embedding dim 16, hidden size 1, num layers 1, train loss 0.8273361325263977, validation loss 0.9998729228973389\n",
      "Epoch 650, current patience 29, model mean validation loss 0.9791529774665833, embedding dim 16, hidden size 1, num layers 1, train loss 0.8031459450721741, validation loss 0.9803730845451355\n",
      "Epoch 660, current patience 28, model mean validation loss 0.9752732515335083, embedding dim 16, hidden size 1, num layers 1, train loss 0.7300699949264526, validation loss 0.9557250142097473\n",
      "Epoch 670, current patience 27, model mean validation loss 0.9736744165420532, embedding dim 16, hidden size 1, num layers 1, train loss 0.8505404591560364, validation loss 0.9608156085014343\n",
      "Epoch 680, current patience 30, model mean validation loss 0.9740157723426819, embedding dim 16, hidden size 1, num layers 1, train loss 0.8333534002304077, validation loss 0.9611146450042725\n",
      "Epoch 690, current patience 29, model mean validation loss 0.9668176174163818, embedding dim 16, hidden size 1, num layers 1, train loss 0.9575154185295105, validation loss 0.9462662935256958\n",
      "Epoch 700, current patience 30, model mean validation loss 0.964084267616272, embedding dim 16, hidden size 1, num layers 1, train loss 0.8306962251663208, validation loss 0.9573873281478882\n",
      "Epoch 710, current patience 30, model mean validation loss 0.9674383401870728, embedding dim 16, hidden size 1, num layers 1, train loss 0.7686970829963684, validation loss 0.9779515862464905\n",
      "Epoch 720, current patience 29, model mean validation loss 0.9626376628875732, embedding dim 16, hidden size 1, num layers 1, train loss 0.7993303537368774, validation loss 0.9614677429199219\n",
      "Epoch 730, current patience 30, model mean validation loss 0.9594370722770691, embedding dim 16, hidden size 1, num layers 1, train loss 0.7324446439743042, validation loss 0.9547686576843262\n",
      "Epoch 740, current patience 30, model mean validation loss 0.95982426404953, embedding dim 16, hidden size 1, num layers 1, train loss 0.7458535432815552, validation loss 0.9588223695755005\n",
      "Epoch 750, current patience 29, model mean validation loss 0.9596350193023682, embedding dim 16, hidden size 1, num layers 1, train loss 0.7742294073104858, validation loss 0.9593012928962708\n",
      "Epoch 760, current patience 28, model mean validation loss 0.9561984539031982, embedding dim 16, hidden size 1, num layers 1, train loss 0.8143601417541504, validation loss 0.9336220622062683\n",
      "Epoch 770, current patience 30, model mean validation loss 0.9584945440292358, embedding dim 16, hidden size 1, num layers 1, train loss 0.6828573942184448, validation loss 0.9646353125572205\n",
      "Epoch 780, current patience 29, model mean validation loss 0.9597262144088745, embedding dim 16, hidden size 1, num layers 1, train loss 0.6932368278503418, validation loss 0.9672406315803528\n",
      "Epoch 790, current patience 28, model mean validation loss 0.9628736972808838, embedding dim 16, hidden size 1, num layers 1, train loss 0.7665176391601562, validation loss 1.00313138961792\n",
      "Epoch 800, current patience 27, model mean validation loss 0.9629894495010376, embedding dim 16, hidden size 1, num layers 1, train loss 0.6923116445541382, validation loss 0.962394118309021\n",
      "Epoch 810, current patience 26, model mean validation loss 0.9603967666625977, embedding dim 16, hidden size 1, num layers 1, train loss 0.7058971524238586, validation loss 0.934027373790741\n",
      "Epoch 820, current patience 25, model mean validation loss 0.9659005999565125, embedding dim 16, hidden size 1, num layers 1, train loss 0.7806711792945862, validation loss 1.0028525590896606\n",
      "Epoch 830, current patience 24, model mean validation loss 0.9674322009086609, embedding dim 16, hidden size 1, num layers 1, train loss 0.7090697288513184, validation loss 0.9715543985366821\n",
      "Epoch 840, current patience 23, model mean validation loss 0.9717311859130859, embedding dim 16, hidden size 1, num layers 1, train loss 0.6779964566230774, validation loss 0.9680137634277344\n",
      "Epoch 850, current patience 22, model mean validation loss 0.969473123550415, embedding dim 16, hidden size 1, num layers 1, train loss 0.7394536137580872, validation loss 0.9465703964233398\n",
      "Epoch 860, current patience 21, model mean validation loss 0.9709933996200562, embedding dim 16, hidden size 1, num layers 1, train loss 0.6877924203872681, validation loss 0.9794036149978638\n",
      "Epoch 870, current patience 20, model mean validation loss 0.9663840532302856, embedding dim 16, hidden size 1, num layers 1, train loss 0.8271147608757019, validation loss 0.9662563800811768\n",
      "Epoch 880, current patience 19, model mean validation loss 0.9664941430091858, embedding dim 16, hidden size 1, num layers 1, train loss 0.682977557182312, validation loss 0.963274359703064\n",
      "Epoch 890, current patience 18, model mean validation loss 0.970103919506073, embedding dim 16, hidden size 1, num layers 1, train loss 0.7324694395065308, validation loss 0.962905764579773\n",
      "Epoch 900, current patience 17, model mean validation loss 0.9677834510803223, embedding dim 16, hidden size 1, num layers 1, train loss 0.6808029413223267, validation loss 0.9842889904975891\n",
      "Epoch 910, current patience 16, model mean validation loss 0.9650974273681641, embedding dim 16, hidden size 1, num layers 1, train loss 0.6773637533187866, validation loss 0.9500664472579956\n",
      "Epoch 920, current patience 15, model mean validation loss 0.9653064012527466, embedding dim 16, hidden size 1, num layers 1, train loss 0.7120380401611328, validation loss 0.969685435295105\n",
      "Epoch 930, current patience 14, model mean validation loss 0.9723425507545471, embedding dim 16, hidden size 1, num layers 1, train loss 0.6122373342514038, validation loss 1.0028595924377441\n",
      "Epoch 940, current patience 13, model mean validation loss 0.9760164022445679, embedding dim 16, hidden size 1, num layers 1, train loss 0.7026811838150024, validation loss 1.0087943077087402\n",
      "Epoch 950, current patience 12, model mean validation loss 0.9839326739311218, embedding dim 16, hidden size 1, num layers 1, train loss 0.9051316976547241, validation loss 1.0295863151550293\n",
      "Epoch 960, current patience 11, model mean validation loss 0.9873037338256836, embedding dim 16, hidden size 1, num layers 1, train loss 0.626618504524231, validation loss 0.9902430176734924\n",
      "Epoch 970, current patience 10, model mean validation loss 0.993663489818573, embedding dim 16, hidden size 1, num layers 1, train loss 0.7068034410476685, validation loss 1.0137838125228882\n",
      "Epoch 980, current patience 9, model mean validation loss 0.9954355955123901, embedding dim 16, hidden size 1, num layers 1, train loss 0.6719605922698975, validation loss 0.9984658360481262\n",
      "Epoch 990, current patience 8, model mean validation loss 0.9989962577819824, embedding dim 16, hidden size 1, num layers 1, train loss 0.6628801226615906, validation loss 0.9785512685775757\n",
      "Epoch 1000, current patience 7, model mean validation loss 1.0013089179992676, embedding dim 16, hidden size 1, num layers 1, train loss 0.8007650375366211, validation loss 0.9881867170333862\n",
      "Epoch 1010, current patience 6, model mean validation loss 1.0015873908996582, embedding dim 16, hidden size 1, num layers 1, train loss 0.7882367372512817, validation loss 1.0050878524780273\n",
      "Epoch 1020, current patience 5, model mean validation loss 0.9982869625091553, embedding dim 16, hidden size 1, num layers 1, train loss 0.5402774810791016, validation loss 0.9823905825614929\n",
      "Epoch 1030, current patience 4, model mean validation loss 0.9921561479568481, embedding dim 16, hidden size 1, num layers 1, train loss 0.7264330387115479, validation loss 0.9805396795272827\n",
      "Epoch 1040, current patience 3, model mean validation loss 0.9923460483551025, embedding dim 16, hidden size 1, num layers 1, train loss 0.7777994871139526, validation loss 0.9917623400688171\n",
      "Epoch 1050, current patience 2, model mean validation loss 0.9893003106117249, embedding dim 16, hidden size 1, num layers 1, train loss 0.6786467432975769, validation loss 0.9894183874130249\n",
      "Epoch 1060, current patience 1, model mean validation loss 0.9858388900756836, embedding dim 16, hidden size 1, num layers 1, train loss 0.638620913028717, validation loss 0.970774233341217\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1454042196273804, embedding dim 16, hidden size 2, num layers 1, train loss 1.1849366426467896, validation loss 1.1454042196273804\n",
      "Epoch 10, current patience 30, model mean validation loss 1.133849859237671, embedding dim 16, hidden size 2, num layers 1, train loss 1.1168546676635742, validation loss 1.122295618057251\n",
      "Epoch 20, current patience 30, model mean validation loss 1.123927116394043, embedding dim 16, hidden size 2, num layers 1, train loss 1.1049582958221436, validation loss 1.1040815114974976\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1173264980316162, embedding dim 16, hidden size 2, num layers 1, train loss 1.0902833938598633, validation loss 1.097524881362915\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1128568649291992, embedding dim 16, hidden size 2, num layers 1, train loss 1.0886414051055908, validation loss 1.094977855682373\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1101025342941284, embedding dim 16, hidden size 2, num layers 1, train loss 1.0925368070602417, validation loss 1.0963307619094849\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1076467037200928, embedding dim 16, hidden size 2, num layers 1, train loss 1.110727310180664, validation loss 1.092911720275879\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1060700416564941, embedding dim 16, hidden size 2, num layers 1, train loss 1.0892049074172974, validation loss 1.0950337648391724\n",
      "Epoch 80, current patience 30, model mean validation loss 1.099655270576477, embedding dim 16, hidden size 2, num layers 1, train loss 1.0916869640350342, validation loss 1.094085454940796\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0962200164794922, embedding dim 16, hidden size 2, num layers 1, train loss 1.1102325916290283, validation loss 1.0948147773742676\n",
      "Epoch 100, current patience 30, model mean validation loss 1.094531774520874, embedding dim 16, hidden size 2, num layers 1, train loss 1.0933263301849365, validation loss 1.0905743837356567\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0938048362731934, embedding dim 16, hidden size 2, num layers 1, train loss 1.110718846321106, validation loss 1.0917096138000488\n",
      "Epoch 120, current patience 30, model mean validation loss 1.092902660369873, embedding dim 16, hidden size 2, num layers 1, train loss 1.0707083940505981, validation loss 1.0877611637115479\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0918735265731812, embedding dim 16, hidden size 2, num layers 1, train loss 1.0874239206314087, validation loss 1.0880978107452393\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0905702114105225, embedding dim 16, hidden size 2, num layers 1, train loss 1.0910866260528564, validation loss 1.0824847221374512\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0883733034133911, embedding dim 16, hidden size 2, num layers 1, train loss 1.0627765655517578, validation loss 1.077458381652832\n",
      "Epoch 160, current patience 30, model mean validation loss 1.085039496421814, embedding dim 16, hidden size 2, num layers 1, train loss 1.0213141441345215, validation loss 1.0674152374267578\n",
      "Epoch 170, current patience 30, model mean validation loss 1.079628825187683, embedding dim 16, hidden size 2, num layers 1, train loss 1.0205068588256836, validation loss 1.0515294075012207\n",
      "Epoch 180, current patience 30, model mean validation loss 1.072995901107788, embedding dim 16, hidden size 2, num layers 1, train loss 1.0039470195770264, validation loss 1.037510871887207\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0634207725524902, embedding dim 16, hidden size 2, num layers 1, train loss 1.0012081861495972, validation loss 1.0151090621948242\n",
      "Epoch 200, current patience 30, model mean validation loss 1.052960991859436, embedding dim 16, hidden size 2, num layers 1, train loss 0.9939719438552856, validation loss 1.004082441329956\n",
      "Epoch 210, current patience 30, model mean validation loss 1.040447473526001, embedding dim 16, hidden size 2, num layers 1, train loss 0.9410547018051147, validation loss 0.9879904985427856\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0252233743667603, embedding dim 16, hidden size 2, num layers 1, train loss 0.9345240592956543, validation loss 0.9606908559799194\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0103185176849365, embedding dim 16, hidden size 2, num layers 1, train loss 0.9541956186294556, validation loss 0.9582195281982422\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9964009523391724, embedding dim 16, hidden size 2, num layers 1, train loss 0.9182946681976318, validation loss 0.9560752511024475\n",
      "Epoch 250, current patience 30, model mean validation loss 0.983763575553894, embedding dim 16, hidden size 2, num layers 1, train loss 0.8134981393814087, validation loss 0.9504299163818359\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9701140522956848, embedding dim 16, hidden size 2, num layers 1, train loss 0.8678871989250183, validation loss 0.9283146858215332\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9573582410812378, embedding dim 16, hidden size 2, num layers 1, train loss 0.9148014783859253, validation loss 0.913062572479248\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9458302855491638, embedding dim 16, hidden size 2, num layers 1, train loss 0.9264816641807556, validation loss 0.9118589162826538\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9344051480293274, embedding dim 16, hidden size 2, num layers 1, train loss 0.9809290170669556, validation loss 0.8965893983840942\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9266951680183411, embedding dim 16, hidden size 2, num layers 1, train loss 0.7934236526489258, validation loss 0.8990110158920288\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9172810912132263, embedding dim 16, hidden size 2, num layers 1, train loss 0.9286787509918213, validation loss 0.8829067945480347\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9090545177459717, embedding dim 16, hidden size 2, num layers 1, train loss 0.8345245122909546, validation loss 0.8902624845504761\n",
      "Epoch 330, current patience 30, model mean validation loss 0.902198076248169, embedding dim 16, hidden size 2, num layers 1, train loss 0.89154452085495, validation loss 0.8955789804458618\n",
      "Epoch 340, current patience 30, model mean validation loss 0.896493673324585, embedding dim 16, hidden size 2, num layers 1, train loss 0.846062421798706, validation loss 0.8826797008514404\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8920097351074219, embedding dim 16, hidden size 2, num layers 1, train loss 0.7351676225662231, validation loss 0.8771904706954956\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8847881555557251, embedding dim 16, hidden size 2, num layers 1, train loss 0.8192273378372192, validation loss 0.85408616065979\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8832664489746094, embedding dim 16, hidden size 2, num layers 1, train loss 0.7226060628890991, validation loss 0.8844159841537476\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8818278312683105, embedding dim 16, hidden size 2, num layers 1, train loss 0.7681310176849365, validation loss 0.8875021934509277\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8794941902160645, embedding dim 16, hidden size 2, num layers 1, train loss 0.7050934433937073, validation loss 0.8642380237579346\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8761616945266724, embedding dim 16, hidden size 2, num layers 1, train loss 0.9176092743873596, validation loss 0.863601803779602\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8746857047080994, embedding dim 16, hidden size 2, num layers 1, train loss 0.7092880010604858, validation loss 0.8837709426879883\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8742884993553162, embedding dim 16, hidden size 2, num layers 1, train loss 0.7535257339477539, validation loss 0.8795022964477539\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8732748031616211, embedding dim 16, hidden size 2, num layers 1, train loss 0.641636848449707, validation loss 0.8690811991691589\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8757472038269043, embedding dim 16, hidden size 2, num layers 1, train loss 0.6788553595542908, validation loss 0.8738651871681213\n",
      "Epoch 450, current patience 29, model mean validation loss 0.8728112578392029, embedding dim 16, hidden size 2, num layers 1, train loss 0.7998709678649902, validation loss 0.8609281778335571\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8723279237747192, embedding dim 16, hidden size 2, num layers 1, train loss 0.6164950132369995, validation loss 0.883635401725769\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8762627840042114, embedding dim 16, hidden size 2, num layers 1, train loss 0.6456583738327026, validation loss 0.8957167267799377\n",
      "Epoch 480, current patience 29, model mean validation loss 0.8773015737533569, embedding dim 16, hidden size 2, num layers 1, train loss 0.7220152616500854, validation loss 0.8719131946563721\n",
      "Epoch 490, current patience 28, model mean validation loss 0.8756817579269409, embedding dim 16, hidden size 2, num layers 1, train loss 0.6030302047729492, validation loss 0.8708120584487915\n",
      "Epoch 500, current patience 27, model mean validation loss 0.8822505474090576, embedding dim 16, hidden size 2, num layers 1, train loss 0.6555795669555664, validation loss 0.9320527911186218\n",
      "Epoch 510, current patience 26, model mean validation loss 0.8821464776992798, embedding dim 16, hidden size 2, num layers 1, train loss 0.7356964349746704, validation loss 0.8682482838630676\n",
      "Epoch 520, current patience 25, model mean validation loss 0.8860530257225037, embedding dim 16, hidden size 2, num layers 1, train loss 0.7052006721496582, validation loss 0.9051176309585571\n",
      "Epoch 530, current patience 24, model mean validation loss 0.8842418193817139, embedding dim 16, hidden size 2, num layers 1, train loss 0.7316573858261108, validation loss 0.8464385271072388\n",
      "Epoch 540, current patience 23, model mean validation loss 0.8818798661231995, embedding dim 16, hidden size 2, num layers 1, train loss 0.8013330698013306, validation loss 0.8647396564483643\n",
      "Epoch 550, current patience 22, model mean validation loss 0.8773923516273499, embedding dim 16, hidden size 2, num layers 1, train loss 0.7377399206161499, validation loss 0.85981684923172\n",
      "Epoch 560, current patience 21, model mean validation loss 0.8810240030288696, embedding dim 16, hidden size 2, num layers 1, train loss 0.6549203991889954, validation loss 0.900966227054596\n",
      "Epoch 570, current patience 20, model mean validation loss 0.8846755623817444, embedding dim 16, hidden size 2, num layers 1, train loss 0.7820817232131958, validation loss 0.9000246524810791\n",
      "Epoch 580, current patience 19, model mean validation loss 0.8755391836166382, embedding dim 16, hidden size 2, num layers 1, train loss 0.734042763710022, validation loss 0.8589613437652588\n",
      "Epoch 590, current patience 18, model mean validation loss 0.8800102472305298, embedding dim 16, hidden size 2, num layers 1, train loss 0.6838672757148743, validation loss 0.9040173292160034\n",
      "Epoch 600, current patience 17, model mean validation loss 0.8821625709533691, embedding dim 16, hidden size 2, num layers 1, train loss 0.6490792632102966, validation loss 0.9223357439041138\n",
      "Epoch 610, current patience 16, model mean validation loss 0.8867347240447998, embedding dim 16, hidden size 2, num layers 1, train loss 0.644881010055542, validation loss 0.8830159306526184\n",
      "Epoch 620, current patience 15, model mean validation loss 0.8904222846031189, embedding dim 16, hidden size 2, num layers 1, train loss 0.8810915946960449, validation loss 0.894240140914917\n",
      "Epoch 630, current patience 14, model mean validation loss 0.8917814493179321, embedding dim 16, hidden size 2, num layers 1, train loss 0.5751458406448364, validation loss 0.8706904649734497\n",
      "Epoch 640, current patience 13, model mean validation loss 0.8892619013786316, embedding dim 16, hidden size 2, num layers 1, train loss 0.5779439806938171, validation loss 0.8808096051216125\n",
      "Epoch 650, current patience 12, model mean validation loss 0.8913215398788452, embedding dim 16, hidden size 2, num layers 1, train loss 0.7101445198059082, validation loss 0.916501522064209\n",
      "Epoch 660, current patience 11, model mean validation loss 0.8946506977081299, embedding dim 16, hidden size 2, num layers 1, train loss 0.5562999248504639, validation loss 0.8855947256088257\n",
      "Epoch 670, current patience 10, model mean validation loss 0.8967533111572266, embedding dim 16, hidden size 2, num layers 1, train loss 0.869769275188446, validation loss 0.9208384156227112\n",
      "Epoch 680, current patience 9, model mean validation loss 0.8961085081100464, embedding dim 16, hidden size 2, num layers 1, train loss 0.5898700952529907, validation loss 0.9171770811080933\n",
      "Epoch 690, current patience 8, model mean validation loss 0.8995327949523926, embedding dim 16, hidden size 2, num layers 1, train loss 0.6477582454681396, validation loss 0.9104102253913879\n",
      "Epoch 700, current patience 7, model mean validation loss 0.8980176448822021, embedding dim 16, hidden size 2, num layers 1, train loss 0.7017472386360168, validation loss 0.8821185827255249\n",
      "Epoch 710, current patience 6, model mean validation loss 0.9016873836517334, embedding dim 16, hidden size 2, num layers 1, train loss 0.7066605091094971, validation loss 0.9000493288040161\n",
      "Epoch 720, current patience 5, model mean validation loss 0.9093655347824097, embedding dim 16, hidden size 2, num layers 1, train loss 0.5579652786254883, validation loss 0.9422340393066406\n",
      "Epoch 730, current patience 4, model mean validation loss 0.9091488122940063, embedding dim 16, hidden size 2, num layers 1, train loss 0.47555065155029297, validation loss 0.9147678017616272\n",
      "Epoch 740, current patience 3, model mean validation loss 0.9182636737823486, embedding dim 16, hidden size 2, num layers 1, train loss 0.7583243250846863, validation loss 0.9585140347480774\n",
      "Epoch 750, current patience 2, model mean validation loss 0.9166683554649353, embedding dim 16, hidden size 2, num layers 1, train loss 0.569191575050354, validation loss 0.9080755710601807\n",
      "Epoch 760, current patience 1, model mean validation loss 0.9163521528244019, embedding dim 16, hidden size 2, num layers 1, train loss 0.5279169082641602, validation loss 0.9146474599838257\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0974828004837036, embedding dim 16, hidden size 4, num layers 1, train loss 1.101791262626648, validation loss 1.0974828004837036\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0967915058135986, embedding dim 16, hidden size 4, num layers 1, train loss 1.0883517265319824, validation loss 1.0961002111434937\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0961352586746216, embedding dim 16, hidden size 4, num layers 1, train loss 1.0874457359313965, validation loss 1.094822645187378\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0955861806869507, embedding dim 16, hidden size 4, num layers 1, train loss 1.1093430519104004, validation loss 1.0939390659332275\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0954787731170654, embedding dim 16, hidden size 4, num layers 1, train loss 1.0977883338928223, validation loss 1.0950497388839722\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0946851968765259, embedding dim 16, hidden size 4, num layers 1, train loss 1.0917402505874634, validation loss 1.0907167196273804\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0946251153945923, embedding dim 16, hidden size 4, num layers 1, train loss 1.0901484489440918, validation loss 1.0942647457122803\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0947225093841553, embedding dim 16, hidden size 4, num layers 1, train loss 1.1176838874816895, validation loss 1.0954034328460693\n",
      "Epoch 80, current patience 29, model mean validation loss 1.0936294794082642, embedding dim 16, hidden size 4, num layers 1, train loss 1.1052294969558716, validation loss 1.0887393951416016\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0937390327453613, embedding dim 16, hidden size 4, num layers 1, train loss 1.0966498851776123, validation loss 1.0969767570495605\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0937449932098389, embedding dim 16, hidden size 4, num layers 1, train loss 1.0925885438919067, validation loss 1.0948700904846191\n",
      "Epoch 110, current patience 28, model mean validation loss 1.094207763671875, embedding dim 16, hidden size 4, num layers 1, train loss 1.0898675918579102, validation loss 1.0976412296295166\n",
      "Epoch 120, current patience 27, model mean validation loss 1.0942797660827637, embedding dim 16, hidden size 4, num layers 1, train loss 1.095696210861206, validation loss 1.0956262350082397\n",
      "Epoch 130, current patience 26, model mean validation loss 1.0943799018859863, embedding dim 16, hidden size 4, num layers 1, train loss 1.1010692119598389, validation loss 1.091517448425293\n",
      "Epoch 140, current patience 25, model mean validation loss 1.0939768552780151, embedding dim 16, hidden size 4, num layers 1, train loss 1.0885752439498901, validation loss 1.0910402536392212\n",
      "Epoch 150, current patience 24, model mean validation loss 1.0932538509368896, embedding dim 16, hidden size 4, num layers 1, train loss 1.1026567220687866, validation loss 1.0896196365356445\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0931947231292725, embedding dim 16, hidden size 4, num layers 1, train loss 1.0797837972640991, validation loss 1.0882658958435059\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0915966033935547, embedding dim 16, hidden size 4, num layers 1, train loss 1.0837544202804565, validation loss 1.0841927528381348\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0897860527038574, embedding dim 16, hidden size 4, num layers 1, train loss 1.116494059562683, validation loss 1.0803849697113037\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0880842208862305, embedding dim 16, hidden size 4, num layers 1, train loss 1.0497825145721436, validation loss 1.0840269327163696\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0855989456176758, embedding dim 16, hidden size 4, num layers 1, train loss 1.070317268371582, validation loss 1.0757441520690918\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0833487510681152, embedding dim 16, hidden size 4, num layers 1, train loss 1.0602734088897705, validation loss 1.0735150575637817\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0809721946716309, embedding dim 16, hidden size 4, num layers 1, train loss 1.0748753547668457, validation loss 1.0720287561416626\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0777437686920166, embedding dim 16, hidden size 4, num layers 1, train loss 1.0554332733154297, validation loss 1.0637915134429932\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0753810405731201, embedding dim 16, hidden size 4, num layers 1, train loss 1.070387601852417, validation loss 1.069364070892334\n",
      "Epoch 250, current patience 30, model mean validation loss 1.073394536972046, embedding dim 16, hidden size 4, num layers 1, train loss 0.9885371327400208, validation loss 1.0683008432388306\n",
      "Epoch 260, current patience 30, model mean validation loss 1.070076584815979, embedding dim 16, hidden size 4, num layers 1, train loss 0.9609085917472839, validation loss 1.0538408756256104\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0630130767822266, embedding dim 16, hidden size 4, num layers 1, train loss 1.0602686405181885, validation loss 1.0275194644927979\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0600165128707886, embedding dim 16, hidden size 4, num layers 1, train loss 1.0140559673309326, validation loss 1.0517714023590088\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0562107563018799, embedding dim 16, hidden size 4, num layers 1, train loss 1.0740231275558472, validation loss 1.0430693626403809\n",
      "Epoch 300, current patience 30, model mean validation loss 1.052697777748108, embedding dim 16, hidden size 4, num layers 1, train loss 1.0254685878753662, validation loss 1.0439252853393555\n",
      "Epoch 310, current patience 30, model mean validation loss 1.045337200164795, embedding dim 16, hidden size 4, num layers 1, train loss 1.022705316543579, validation loss 1.0049062967300415\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0357494354248047, embedding dim 16, hidden size 4, num layers 1, train loss 0.9587452411651611, validation loss 0.9926624298095703\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0279852151870728, embedding dim 16, hidden size 4, num layers 1, train loss 1.0717170238494873, validation loss 1.0061872005462646\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0222101211547852, embedding dim 16, hidden size 4, num layers 1, train loss 1.0125856399536133, validation loss 1.00764000415802\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0179215669631958, embedding dim 16, hidden size 4, num layers 1, train loss 0.9406241178512573, validation loss 0.9932108521461487\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0075633525848389, embedding dim 16, hidden size 4, num layers 1, train loss 0.9401979446411133, validation loss 0.9689050912857056\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0007998943328857, embedding dim 16, hidden size 4, num layers 1, train loss 0.8833780288696289, validation loss 0.988961935043335\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9910415410995483, embedding dim 16, hidden size 4, num layers 1, train loss 0.9083309173583984, validation loss 0.9658583998680115\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9845383167266846, embedding dim 16, hidden size 4, num layers 1, train loss 1.0077495574951172, validation loss 0.9528809189796448\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9836476445198059, embedding dim 16, hidden size 4, num layers 1, train loss 0.9698002338409424, validation loss 0.9855369925498962\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9756410121917725, embedding dim 16, hidden size 4, num layers 1, train loss 0.8882472515106201, validation loss 0.9421341419219971\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9685147404670715, embedding dim 16, hidden size 4, num layers 1, train loss 0.8801249861717224, validation loss 0.9506296515464783\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9632378816604614, embedding dim 16, hidden size 4, num layers 1, train loss 0.7925736308097839, validation loss 0.9509959816932678\n",
      "Epoch 440, current patience 30, model mean validation loss 0.960956335067749, embedding dim 16, hidden size 4, num layers 1, train loss 0.9103864431381226, validation loss 0.9506524801254272\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9559868574142456, embedding dim 16, hidden size 4, num layers 1, train loss 0.739197850227356, validation loss 0.9492058753967285\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9541032314300537, embedding dim 16, hidden size 4, num layers 1, train loss 0.8838890790939331, validation loss 0.9507899880409241\n",
      "Epoch 470, current patience 30, model mean validation loss 0.954538106918335, embedding dim 16, hidden size 4, num layers 1, train loss 0.6956278681755066, validation loss 0.9563596844673157\n",
      "Epoch 480, current patience 29, model mean validation loss 0.9491888284683228, embedding dim 16, hidden size 4, num layers 1, train loss 0.6863787770271301, validation loss 0.9427429437637329\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9514759182929993, embedding dim 16, hidden size 4, num layers 1, train loss 0.7141287922859192, validation loss 0.9604307413101196\n",
      "Epoch 500, current patience 29, model mean validation loss 0.9467791318893433, embedding dim 16, hidden size 4, num layers 1, train loss 0.7812062501907349, validation loss 0.913055419921875\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9452290534973145, embedding dim 16, hidden size 4, num layers 1, train loss 0.7236680388450623, validation loss 0.9385953545570374\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9427464008331299, embedding dim 16, hidden size 4, num layers 1, train loss 0.6913596987724304, validation loss 0.9307909607887268\n",
      "Epoch 530, current patience 30, model mean validation loss 0.9397997856140137, embedding dim 16, hidden size 4, num layers 1, train loss 0.7583597898483276, validation loss 0.9256329536437988\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9414438009262085, embedding dim 16, hidden size 4, num layers 1, train loss 0.5472350120544434, validation loss 0.9639424085617065\n",
      "Epoch 550, current patience 29, model mean validation loss 0.9489201307296753, embedding dim 16, hidden size 4, num layers 1, train loss 0.8613560795783997, validation loss 1.0161702632904053\n",
      "Epoch 560, current patience 28, model mean validation loss 0.9525483846664429, embedding dim 16, hidden size 4, num layers 1, train loss 0.7671668529510498, validation loss 0.9717691540718079\n",
      "Epoch 570, current patience 27, model mean validation loss 0.950181245803833, embedding dim 16, hidden size 4, num layers 1, train loss 0.719472348690033, validation loss 0.9414933919906616\n",
      "Epoch 580, current patience 26, model mean validation loss 0.9542505145072937, embedding dim 16, hidden size 4, num layers 1, train loss 0.813187837600708, validation loss 0.9456096887588501\n",
      "Epoch 590, current patience 25, model mean validation loss 0.9503794312477112, embedding dim 16, hidden size 4, num layers 1, train loss 0.732988715171814, validation loss 0.9076269865036011\n",
      "Epoch 600, current patience 24, model mean validation loss 0.9530200362205505, embedding dim 16, hidden size 4, num layers 1, train loss 0.6524494290351868, validation loss 0.9519153237342834\n",
      "Epoch 610, current patience 23, model mean validation loss 0.9582047462463379, embedding dim 16, hidden size 4, num layers 1, train loss 0.5294228792190552, validation loss 0.9671108722686768\n",
      "Epoch 620, current patience 22, model mean validation loss 0.9568371772766113, embedding dim 16, hidden size 4, num layers 1, train loss 0.5846229195594788, validation loss 0.9530019760131836\n",
      "Epoch 630, current patience 21, model mean validation loss 0.9526761770248413, embedding dim 16, hidden size 4, num layers 1, train loss 0.6557697653770447, validation loss 0.9828821420669556\n",
      "Epoch 640, current patience 20, model mean validation loss 0.9532655477523804, embedding dim 16, hidden size 4, num layers 1, train loss 0.7732076048851013, validation loss 0.9764837026596069\n",
      "Epoch 650, current patience 19, model mean validation loss 0.956659197807312, embedding dim 16, hidden size 4, num layers 1, train loss 0.6051654815673828, validation loss 0.968643069267273\n",
      "Epoch 660, current patience 18, model mean validation loss 0.9583472013473511, embedding dim 16, hidden size 4, num layers 1, train loss 0.6342847347259521, validation loss 0.9591134786605835\n",
      "Epoch 670, current patience 17, model mean validation loss 0.9642259478569031, embedding dim 16, hidden size 4, num layers 1, train loss 0.6085612773895264, validation loss 0.9546568989753723\n",
      "Epoch 680, current patience 16, model mean validation loss 0.9636421203613281, embedding dim 16, hidden size 4, num layers 1, train loss 0.624179482460022, validation loss 0.9472446441650391\n",
      "Epoch 690, current patience 15, model mean validation loss 0.9633820056915283, embedding dim 16, hidden size 4, num layers 1, train loss 0.602352499961853, validation loss 0.9650298953056335\n",
      "Epoch 700, current patience 14, model mean validation loss 0.9617970585823059, embedding dim 16, hidden size 4, num layers 1, train loss 0.9228515625, validation loss 0.9403224587440491\n",
      "Epoch 710, current patience 13, model mean validation loss 0.9601930975914001, embedding dim 16, hidden size 4, num layers 1, train loss 0.5509040355682373, validation loss 0.9700503945350647\n",
      "Epoch 720, current patience 12, model mean validation loss 0.959007978439331, embedding dim 16, hidden size 4, num layers 1, train loss 0.7776520848274231, validation loss 0.967002809047699\n",
      "Epoch 730, current patience 11, model mean validation loss 0.9610779285430908, embedding dim 16, hidden size 4, num layers 1, train loss 0.6846169233322144, validation loss 0.9852027893066406\n",
      "Epoch 740, current patience 10, model mean validation loss 0.9600582122802734, embedding dim 16, hidden size 4, num layers 1, train loss 0.7143521308898926, validation loss 0.9509561061859131\n",
      "Epoch 750, current patience 9, model mean validation loss 0.9598237872123718, embedding dim 16, hidden size 4, num layers 1, train loss 0.534460186958313, validation loss 0.9527811408042908\n",
      "Epoch 760, current patience 8, model mean validation loss 0.9640255570411682, embedding dim 16, hidden size 4, num layers 1, train loss 0.7278985977172852, validation loss 0.9808587431907654\n",
      "Epoch 770, current patience 7, model mean validation loss 0.9650547504425049, embedding dim 16, hidden size 4, num layers 1, train loss 0.6150034666061401, validation loss 0.9732640385627747\n",
      "Epoch 780, current patience 6, model mean validation loss 0.9682381749153137, embedding dim 16, hidden size 4, num layers 1, train loss 0.6301172971725464, validation loss 0.9657896161079407\n",
      "Epoch 790, current patience 5, model mean validation loss 0.9700698256492615, embedding dim 16, hidden size 4, num layers 1, train loss 0.7161131501197815, validation loss 0.9847036004066467\n",
      "Epoch 800, current patience 4, model mean validation loss 0.9654347896575928, embedding dim 16, hidden size 4, num layers 1, train loss 0.5202711224555969, validation loss 0.9299222826957703\n",
      "Epoch 810, current patience 3, model mean validation loss 0.9610130786895752, embedding dim 16, hidden size 4, num layers 1, train loss 0.5226284265518188, validation loss 0.9498291015625\n",
      "Epoch 820, current patience 2, model mean validation loss 0.9639623165130615, embedding dim 16, hidden size 4, num layers 1, train loss 0.5773755311965942, validation loss 0.9745502471923828\n",
      "Epoch 830, current patience 1, model mean validation loss 0.9693262577056885, embedding dim 16, hidden size 4, num layers 1, train loss 0.6172073483467102, validation loss 0.9956924915313721\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1543211936950684, embedding dim 16, hidden size 8, num layers 1, train loss 1.1852773427963257, validation loss 1.1543211936950684\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1283766031265259, embedding dim 16, hidden size 8, num layers 1, train loss 1.1001163721084595, validation loss 1.1024320125579834\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1165083646774292, embedding dim 16, hidden size 8, num layers 1, train loss 1.1176488399505615, validation loss 1.0927716493606567\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1092493534088135, embedding dim 16, hidden size 8, num layers 1, train loss 1.091617465019226, validation loss 1.0874722003936768\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1055095195770264, embedding dim 16, hidden size 8, num layers 1, train loss 1.0799846649169922, validation loss 1.0905510187149048\n",
      "Epoch 50, current patience 30, model mean validation loss 1.103293776512146, embedding dim 16, hidden size 8, num layers 1, train loss 1.089766502380371, validation loss 1.0922149419784546\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1012588739395142, embedding dim 16, hidden size 8, num layers 1, train loss 1.062739372253418, validation loss 1.0890486240386963\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0990204811096191, embedding dim 16, hidden size 8, num layers 1, train loss 1.0945167541503906, validation loss 1.0833523273468018\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0903961658477783, embedding dim 16, hidden size 8, num layers 1, train loss 1.0542871952056885, validation loss 1.085326075553894\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0852769613265991, embedding dim 16, hidden size 8, num layers 1, train loss 1.0234829187393188, validation loss 1.061478614807129\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0795608758926392, embedding dim 16, hidden size 8, num layers 1, train loss 0.9394991397857666, validation loss 1.0470428466796875\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0731663703918457, embedding dim 16, hidden size 8, num layers 1, train loss 0.9850848913192749, validation loss 1.0363168716430664\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0657439231872559, embedding dim 16, hidden size 8, num layers 1, train loss 0.9391162991523743, validation loss 1.0311706066131592\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0551214218139648, embedding dim 16, hidden size 8, num layers 1, train loss 0.9453320503234863, validation loss 1.0072360038757324\n",
      "Epoch 140, current patience 30, model mean validation loss 1.042033314704895, embedding dim 16, hidden size 8, num layers 1, train loss 0.9127966165542603, validation loss 0.9843432307243347\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0315719842910767, embedding dim 16, hidden size 8, num layers 1, train loss 0.977837324142456, validation loss 0.9996613264083862\n",
      "Epoch 160, current patience 30, model mean validation loss 1.016819953918457, embedding dim 16, hidden size 8, num layers 1, train loss 0.9863132238388062, validation loss 0.9673098921775818\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0026601552963257, embedding dim 16, hidden size 8, num layers 1, train loss 0.8753656148910522, validation loss 0.9481996297836304\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9898926615715027, embedding dim 16, hidden size 8, num layers 1, train loss 0.9141823053359985, validation loss 0.9449032545089722\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9756323099136353, embedding dim 16, hidden size 8, num layers 1, train loss 0.8500843048095703, validation loss 0.9222349524497986\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9630160331726074, embedding dim 16, hidden size 8, num layers 1, train loss 0.8574720025062561, validation loss 0.9302395582199097\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9504005312919617, embedding dim 16, hidden size 8, num layers 1, train loss 0.8257770538330078, validation loss 0.9063127040863037\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9401211142539978, embedding dim 16, hidden size 8, num layers 1, train loss 0.807102620601654, validation loss 0.9021077752113342\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9261714816093445, embedding dim 16, hidden size 8, num layers 1, train loss 0.8482352495193481, validation loss 0.8880640864372253\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9163713455200195, embedding dim 16, hidden size 8, num layers 1, train loss 0.7846209406852722, validation loss 0.8889091610908508\n",
      "Epoch 250, current patience 30, model mean validation loss 0.907418966293335, embedding dim 16, hidden size 8, num layers 1, train loss 0.8505045175552368, validation loss 0.8765807151794434\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8985447883605957, embedding dim 16, hidden size 8, num layers 1, train loss 0.7588313817977905, validation loss 0.8739092350006104\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8915332555770874, embedding dim 16, hidden size 8, num layers 1, train loss 0.8166161775588989, validation loss 0.8661423921585083\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8840777277946472, embedding dim 16, hidden size 8, num layers 1, train loss 0.7834685444831848, validation loss 0.8705955743789673\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8759315609931946, embedding dim 16, hidden size 8, num layers 1, train loss 0.8188927173614502, validation loss 0.8411436080932617\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8683308362960815, embedding dim 16, hidden size 8, num layers 1, train loss 0.7127214670181274, validation loss 0.8413019180297852\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8619007468223572, embedding dim 16, hidden size 8, num layers 1, train loss 0.9092704653739929, validation loss 0.8366235494613647\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8599839210510254, embedding dim 16, hidden size 8, num layers 1, train loss 0.7309086918830872, validation loss 0.8735748529434204\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8563815355300903, embedding dim 16, hidden size 8, num layers 1, train loss 0.6474605202674866, validation loss 0.8477609157562256\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8550893068313599, embedding dim 16, hidden size 8, num layers 1, train loss 0.752497673034668, validation loss 0.8635717630386353\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8515182733535767, embedding dim 16, hidden size 8, num layers 1, train loss 0.6318462491035461, validation loss 0.8375743627548218\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8453245759010315, embedding dim 16, hidden size 8, num layers 1, train loss 0.6799795627593994, validation loss 0.8210457563400269\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8452025055885315, embedding dim 16, hidden size 8, num layers 1, train loss 0.7821915745735168, validation loss 0.8401666879653931\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8475617170333862, embedding dim 16, hidden size 8, num layers 1, train loss 0.5801618099212646, validation loss 0.8601758480072021\n",
      "Epoch 390, current patience 29, model mean validation loss 0.84706711769104, embedding dim 16, hidden size 8, num layers 1, train loss 0.9391313791275024, validation loss 0.8326663374900818\n",
      "Epoch 400, current patience 28, model mean validation loss 0.8416662812232971, embedding dim 16, hidden size 8, num layers 1, train loss 0.6463292837142944, validation loss 0.8303685784339905\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8433059453964233, embedding dim 16, hidden size 8, num layers 1, train loss 0.5406326651573181, validation loss 0.8608782887458801\n",
      "Epoch 420, current patience 29, model mean validation loss 0.8387689590454102, embedding dim 16, hidden size 8, num layers 1, train loss 0.882774293422699, validation loss 0.8272754549980164\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8366211652755737, embedding dim 16, hidden size 8, num layers 1, train loss 0.6289184093475342, validation loss 0.8203924894332886\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8385511636734009, embedding dim 16, hidden size 8, num layers 1, train loss 0.8045830130577087, validation loss 0.8364853858947754\n",
      "Epoch 450, current patience 29, model mean validation loss 0.8376315832138062, embedding dim 16, hidden size 8, num layers 1, train loss 0.6470620632171631, validation loss 0.8328101634979248\n",
      "Epoch 460, current patience 28, model mean validation loss 0.8315879106521606, embedding dim 16, hidden size 8, num layers 1, train loss 0.5492932796478271, validation loss 0.8118268251419067\n",
      "Epoch 470, current patience 30, model mean validation loss 0.8322716951370239, embedding dim 16, hidden size 8, num layers 1, train loss 0.5948626399040222, validation loss 0.8381370306015015\n",
      "Epoch 480, current patience 29, model mean validation loss 0.832119882106781, embedding dim 16, hidden size 8, num layers 1, train loss 0.5998899936676025, validation loss 0.8291534781455994\n",
      "Epoch 490, current patience 28, model mean validation loss 0.8288631439208984, embedding dim 16, hidden size 8, num layers 1, train loss 0.538267195224762, validation loss 0.8348241448402405\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8331505656242371, embedding dim 16, hidden size 8, num layers 1, train loss 0.7723318934440613, validation loss 0.8615751266479492\n",
      "Epoch 510, current patience 29, model mean validation loss 0.8321467041969299, embedding dim 16, hidden size 8, num layers 1, train loss 0.5864235162734985, validation loss 0.8123614192008972\n",
      "Epoch 520, current patience 28, model mean validation loss 0.8354631066322327, embedding dim 16, hidden size 8, num layers 1, train loss 0.5234454870223999, validation loss 0.8630165457725525\n",
      "Epoch 530, current patience 27, model mean validation loss 0.83553147315979, embedding dim 16, hidden size 8, num layers 1, train loss 0.5489845275878906, validation loss 0.8333569765090942\n",
      "Epoch 540, current patience 26, model mean validation loss 0.844481348991394, embedding dim 16, hidden size 8, num layers 1, train loss 0.6216493844985962, validation loss 0.8834258317947388\n",
      "Epoch 550, current patience 25, model mean validation loss 0.8462708592414856, embedding dim 16, hidden size 8, num layers 1, train loss 0.5536395311355591, validation loss 0.8524536490440369\n",
      "Epoch 560, current patience 24, model mean validation loss 0.8490632176399231, embedding dim 16, hidden size 8, num layers 1, train loss 0.5047545433044434, validation loss 0.8514919281005859\n",
      "Epoch 570, current patience 23, model mean validation loss 0.8537098169326782, embedding dim 16, hidden size 8, num layers 1, train loss 0.6203246116638184, validation loss 0.8719968199729919\n",
      "Epoch 580, current patience 22, model mean validation loss 0.8547154664993286, embedding dim 16, hidden size 8, num layers 1, train loss 0.569682776927948, validation loss 0.8696204423904419\n",
      "Epoch 590, current patience 21, model mean validation loss 0.8569085597991943, embedding dim 16, hidden size 8, num layers 1, train loss 0.6270381212234497, validation loss 0.8299059867858887\n",
      "Epoch 600, current patience 20, model mean validation loss 0.8513321876525879, embedding dim 16, hidden size 8, num layers 1, train loss 0.5408702492713928, validation loss 0.8184064030647278\n",
      "Epoch 610, current patience 19, model mean validation loss 0.8512455821037292, embedding dim 16, hidden size 8, num layers 1, train loss 0.5233062505722046, validation loss 0.8326634764671326\n",
      "Epoch 620, current patience 18, model mean validation loss 0.8445439338684082, embedding dim 16, hidden size 8, num layers 1, train loss 0.6620861887931824, validation loss 0.8298128247261047\n",
      "Epoch 630, current patience 17, model mean validation loss 0.8416620492935181, embedding dim 16, hidden size 8, num layers 1, train loss 0.4634668827056885, validation loss 0.8293986320495605\n",
      "Epoch 640, current patience 16, model mean validation loss 0.8413352966308594, embedding dim 16, hidden size 8, num layers 1, train loss 0.368604838848114, validation loss 0.8488777875900269\n",
      "Epoch 650, current patience 15, model mean validation loss 0.8375498056411743, embedding dim 16, hidden size 8, num layers 1, train loss 0.5527990460395813, validation loss 0.8417127132415771\n",
      "Epoch 660, current patience 14, model mean validation loss 0.835532546043396, embedding dim 16, hidden size 8, num layers 1, train loss 0.5433768033981323, validation loss 0.8534823656082153\n",
      "Epoch 670, current patience 13, model mean validation loss 0.8414332866668701, embedding dim 16, hidden size 8, num layers 1, train loss 0.4698319137096405, validation loss 0.8771117925643921\n",
      "Epoch 680, current patience 12, model mean validation loss 0.8476446270942688, embedding dim 16, hidden size 8, num layers 1, train loss 0.49808478355407715, validation loss 0.8680974245071411\n",
      "Epoch 690, current patience 11, model mean validation loss 0.8560645580291748, embedding dim 16, hidden size 8, num layers 1, train loss 0.5804283618927002, validation loss 0.9000228047370911\n",
      "Epoch 700, current patience 10, model mean validation loss 0.862471342086792, embedding dim 16, hidden size 8, num layers 1, train loss 0.4054858684539795, validation loss 0.8810673952102661\n",
      "Epoch 710, current patience 9, model mean validation loss 0.869957685470581, embedding dim 16, hidden size 8, num layers 1, train loss 0.4842265546321869, validation loss 0.8892897367477417\n",
      "Epoch 720, current patience 8, model mean validation loss 0.8805792927742004, embedding dim 16, hidden size 8, num layers 1, train loss 0.37265920639038086, validation loss 0.9338500499725342\n",
      "Epoch 730, current patience 7, model mean validation loss 0.8892205357551575, embedding dim 16, hidden size 8, num layers 1, train loss 0.3943883180618286, validation loss 0.9108425974845886\n",
      "Epoch 740, current patience 6, model mean validation loss 0.8889135718345642, embedding dim 16, hidden size 8, num layers 1, train loss 0.5582263469696045, validation loss 0.8510268926620483\n",
      "Epoch 750, current patience 5, model mean validation loss 0.8873957991600037, embedding dim 16, hidden size 8, num layers 1, train loss 0.41512584686279297, validation loss 0.8649693131446838\n",
      "Epoch 760, current patience 4, model mean validation loss 0.8930769562721252, embedding dim 16, hidden size 8, num layers 1, train loss 0.6650708913803101, validation loss 0.9135469198226929\n",
      "Epoch 770, current patience 3, model mean validation loss 0.9061973690986633, embedding dim 16, hidden size 8, num layers 1, train loss 0.7080101370811462, validation loss 1.004986047744751\n",
      "Epoch 780, current patience 2, model mean validation loss 0.909166693687439, embedding dim 16, hidden size 8, num layers 1, train loss 0.5173001289367676, validation loss 0.9048219919204712\n",
      "Epoch 790, current patience 1, model mean validation loss 0.9112659692764282, embedding dim 16, hidden size 8, num layers 1, train loss 0.6613930463790894, validation loss 0.9060839414596558\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1094179153442383, embedding dim 16, hidden size 16, num layers 1, train loss 1.1080937385559082, validation loss 1.1094179153442383\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1013765335083008, embedding dim 16, hidden size 16, num layers 1, train loss 1.0989258289337158, validation loss 1.0933352708816528\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0995508432388306, embedding dim 16, hidden size 16, num layers 1, train loss 1.0761245489120483, validation loss 1.0958995819091797\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0983641147613525, embedding dim 16, hidden size 16, num layers 1, train loss 1.10196053981781, validation loss 1.094803810119629\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0968807935714722, embedding dim 16, hidden size 16, num layers 1, train loss 1.100470781326294, validation loss 1.0909476280212402\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0958726406097412, embedding dim 16, hidden size 16, num layers 1, train loss 1.0899428129196167, validation loss 1.0908317565917969\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0955017805099487, embedding dim 16, hidden size 16, num layers 1, train loss 1.1119587421417236, validation loss 1.0932767391204834\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0943939685821533, embedding dim 16, hidden size 16, num layers 1, train loss 1.0818688869476318, validation loss 1.086639165878296\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0904030799865723, embedding dim 16, hidden size 16, num layers 1, train loss 1.0778377056121826, validation loss 1.0774900913238525\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0869946479797363, embedding dim 16, hidden size 16, num layers 1, train loss 1.1050410270690918, validation loss 1.0660688877105713\n",
      "Epoch 100, current patience 30, model mean validation loss 1.080521583557129, embedding dim 16, hidden size 16, num layers 1, train loss 1.0886116027832031, validation loss 1.0441138744354248\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0744363069534302, embedding dim 16, hidden size 16, num layers 1, train loss 1.0925687551498413, validation loss 1.0461220741271973\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0653066635131836, embedding dim 16, hidden size 16, num layers 1, train loss 0.9560985565185547, validation loss 1.017910122871399\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0502089262008667, embedding dim 16, hidden size 16, num layers 1, train loss 0.8767557740211487, validation loss 0.9700498580932617\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0335259437561035, embedding dim 16, hidden size 16, num layers 1, train loss 0.8740502595901489, validation loss 0.9598127603530884\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0161179304122925, embedding dim 16, hidden size 16, num layers 1, train loss 0.8641147613525391, validation loss 0.9473754167556763\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9972236156463623, embedding dim 16, hidden size 16, num layers 1, train loss 0.864757239818573, validation loss 0.9263355731964111\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9785158634185791, embedding dim 16, hidden size 16, num layers 1, train loss 1.0326306819915771, validation loss 0.9164071679115295\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9626408815383911, embedding dim 16, hidden size 16, num layers 1, train loss 0.8355078101158142, validation loss 0.9171140789985657\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9419781565666199, embedding dim 16, hidden size 16, num layers 1, train loss 0.8660162687301636, validation loss 0.8808200359344482\n",
      "Epoch 200, current patience 30, model mean validation loss 0.924639880657196, embedding dim 16, hidden size 16, num layers 1, train loss 0.8227987885475159, validation loss 0.8792039155960083\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9088470339775085, embedding dim 16, hidden size 16, num layers 1, train loss 0.9354966878890991, validation loss 0.8437069654464722\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8962686061859131, embedding dim 16, hidden size 16, num layers 1, train loss 0.7073880434036255, validation loss 0.8591850996017456\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8848327994346619, embedding dim 16, hidden size 16, num layers 1, train loss 0.8608222007751465, validation loss 0.8558891415596008\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8719633221626282, embedding dim 16, hidden size 16, num layers 1, train loss 0.7613584399223328, validation loss 0.8233798742294312\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8597881197929382, embedding dim 16, hidden size 16, num layers 1, train loss 0.7183185815811157, validation loss 0.81900554895401\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8484286665916443, embedding dim 16, hidden size 16, num layers 1, train loss 0.6603537201881409, validation loss 0.8262388110160828\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8391287922859192, embedding dim 16, hidden size 16, num layers 1, train loss 0.8034764528274536, validation loss 0.8064210414886475\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8278601169586182, embedding dim 16, hidden size 16, num layers 1, train loss 0.7464934587478638, validation loss 0.7890547513961792\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8194091320037842, embedding dim 16, hidden size 16, num layers 1, train loss 0.5654485821723938, validation loss 0.7760987281799316\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8104591965675354, embedding dim 16, hidden size 16, num layers 1, train loss 0.6919518709182739, validation loss 0.7875856161117554\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8047524690628052, embedding dim 16, hidden size 16, num layers 1, train loss 0.6289836168289185, validation loss 0.8102350234985352\n",
      "Epoch 320, current patience 30, model mean validation loss 0.7989474534988403, embedding dim 16, hidden size 16, num layers 1, train loss 0.7561598420143127, validation loss 0.7769407033920288\n",
      "Epoch 330, current patience 30, model mean validation loss 0.7973207235336304, embedding dim 16, hidden size 16, num layers 1, train loss 0.7184797525405884, validation loss 0.8059913516044617\n",
      "Epoch 340, current patience 30, model mean validation loss 0.7923451066017151, embedding dim 16, hidden size 16, num layers 1, train loss 0.609422504901886, validation loss 0.7864333391189575\n",
      "Epoch 350, current patience 30, model mean validation loss 0.7885140776634216, embedding dim 16, hidden size 16, num layers 1, train loss 0.7558653950691223, validation loss 0.7757729291915894\n",
      "Epoch 360, current patience 30, model mean validation loss 0.788078784942627, embedding dim 16, hidden size 16, num layers 1, train loss 0.697827935218811, validation loss 0.7855727672576904\n",
      "Epoch 370, current patience 30, model mean validation loss 0.7924752235412598, embedding dim 16, hidden size 16, num layers 1, train loss 0.8399295210838318, validation loss 0.8112703561782837\n",
      "Epoch 380, current patience 29, model mean validation loss 0.7907330989837646, embedding dim 16, hidden size 16, num layers 1, train loss 0.6858048439025879, validation loss 0.7736482620239258\n",
      "Epoch 390, current patience 28, model mean validation loss 0.7838602662086487, embedding dim 16, hidden size 16, num layers 1, train loss 0.9732589721679688, validation loss 0.7552525997161865\n",
      "Epoch 400, current patience 30, model mean validation loss 0.7851181626319885, embedding dim 16, hidden size 16, num layers 1, train loss 0.6854570508003235, validation loss 0.7870036959648132\n",
      "Epoch 410, current patience 29, model mean validation loss 0.7835580110549927, embedding dim 16, hidden size 16, num layers 1, train loss 0.7632009983062744, validation loss 0.7935096621513367\n",
      "Epoch 420, current patience 30, model mean validation loss 0.7831723093986511, embedding dim 16, hidden size 16, num layers 1, train loss 0.6034923791885376, validation loss 0.7833485007286072\n",
      "Epoch 430, current patience 30, model mean validation loss 0.7858363389968872, embedding dim 16, hidden size 16, num layers 1, train loss 0.6621595025062561, validation loss 0.7970848083496094\n",
      "Epoch 440, current patience 29, model mean validation loss 0.7895812392234802, embedding dim 16, hidden size 16, num layers 1, train loss 0.6239364147186279, validation loss 0.8155320286750793\n",
      "Epoch 450, current patience 28, model mean validation loss 0.7839730978012085, embedding dim 16, hidden size 16, num layers 1, train loss 0.640676736831665, validation loss 0.7664051651954651\n",
      "Epoch 460, current patience 27, model mean validation loss 0.7822462320327759, embedding dim 16, hidden size 16, num layers 1, train loss 0.4946914315223694, validation loss 0.759833574295044\n",
      "Epoch 470, current patience 30, model mean validation loss 0.786260187625885, embedding dim 16, hidden size 16, num layers 1, train loss 0.6179503202438354, validation loss 0.7873640060424805\n",
      "Epoch 480, current patience 29, model mean validation loss 0.7868654131889343, embedding dim 16, hidden size 16, num layers 1, train loss 0.503056526184082, validation loss 0.7918456196784973\n",
      "Epoch 490, current patience 28, model mean validation loss 0.7858350276947021, embedding dim 16, hidden size 16, num layers 1, train loss 0.8922508955001831, validation loss 0.7852662801742554\n",
      "Epoch 500, current patience 27, model mean validation loss 0.787643551826477, embedding dim 16, hidden size 16, num layers 1, train loss 0.8531786203384399, validation loss 0.7978167533874512\n",
      "Epoch 510, current patience 26, model mean validation loss 0.7902200222015381, embedding dim 16, hidden size 16, num layers 1, train loss 0.6935192346572876, validation loss 0.8176964521408081\n",
      "Epoch 520, current patience 25, model mean validation loss 0.7856308221817017, embedding dim 16, hidden size 16, num layers 1, train loss 0.5215145945549011, validation loss 0.7788189649581909\n",
      "Epoch 530, current patience 24, model mean validation loss 0.7941428422927856, embedding dim 16, hidden size 16, num layers 1, train loss 0.5945740938186646, validation loss 0.8345006704330444\n",
      "Epoch 540, current patience 23, model mean validation loss 0.7982617616653442, embedding dim 16, hidden size 16, num layers 1, train loss 0.5041807889938354, validation loss 0.7927854061126709\n",
      "Epoch 550, current patience 22, model mean validation loss 0.7997026443481445, embedding dim 16, hidden size 16, num layers 1, train loss 0.687030017375946, validation loss 0.7988913059234619\n",
      "Epoch 560, current patience 21, model mean validation loss 0.8010141849517822, embedding dim 16, hidden size 16, num layers 1, train loss 0.47638267278671265, validation loss 0.802337646484375\n",
      "Epoch 570, current patience 20, model mean validation loss 0.7985727787017822, embedding dim 16, hidden size 16, num layers 1, train loss 0.679526150226593, validation loss 0.7657349705696106\n",
      "Epoch 580, current patience 19, model mean validation loss 0.796589732170105, embedding dim 16, hidden size 16, num layers 1, train loss 0.5579959154129028, validation loss 0.7819519639015198\n",
      "Epoch 590, current patience 18, model mean validation loss 0.8010114431381226, embedding dim 16, hidden size 16, num layers 1, train loss 0.5286707878112793, validation loss 0.8530707359313965\n",
      "Epoch 600, current patience 17, model mean validation loss 0.8076837658882141, embedding dim 16, hidden size 16, num layers 1, train loss 0.4109479784965515, validation loss 0.8321976661682129\n",
      "Epoch 610, current patience 16, model mean validation loss 0.8042681813240051, embedding dim 16, hidden size 16, num layers 1, train loss 0.5653538703918457, validation loss 0.807175874710083\n",
      "Epoch 620, current patience 15, model mean validation loss 0.8063549995422363, embedding dim 16, hidden size 16, num layers 1, train loss 0.4480370879173279, validation loss 0.8094797134399414\n",
      "Epoch 630, current patience 14, model mean validation loss 0.8097044825553894, embedding dim 16, hidden size 16, num layers 1, train loss 0.49468541145324707, validation loss 0.8256874084472656\n",
      "Epoch 640, current patience 13, model mean validation loss 0.8164992332458496, embedding dim 16, hidden size 16, num layers 1, train loss 0.7830770015716553, validation loss 0.8566953539848328\n",
      "Epoch 650, current patience 12, model mean validation loss 0.820374608039856, embedding dim 16, hidden size 16, num layers 1, train loss 0.275073379278183, validation loss 0.7967382669448853\n",
      "Epoch 660, current patience 11, model mean validation loss 0.8224747776985168, embedding dim 16, hidden size 16, num layers 1, train loss 0.4702301025390625, validation loss 0.7987531423568726\n",
      "Epoch 670, current patience 10, model mean validation loss 0.817564845085144, embedding dim 16, hidden size 16, num layers 1, train loss 0.4446375370025635, validation loss 0.8137914538383484\n",
      "Epoch 680, current patience 9, model mean validation loss 0.8153128623962402, embedding dim 16, hidden size 16, num layers 1, train loss 0.401860773563385, validation loss 0.8141815662384033\n",
      "Epoch 690, current patience 8, model mean validation loss 0.8187803626060486, embedding dim 16, hidden size 16, num layers 1, train loss 0.6462188959121704, validation loss 0.8349159359931946\n",
      "Epoch 700, current patience 7, model mean validation loss 0.8213868737220764, embedding dim 16, hidden size 16, num layers 1, train loss 0.4518119990825653, validation loss 0.8303319215774536\n",
      "Epoch 710, current patience 6, model mean validation loss 0.823036789894104, embedding dim 16, hidden size 16, num layers 1, train loss 0.42656296491622925, validation loss 0.8388864398002625\n",
      "Epoch 720, current patience 5, model mean validation loss 0.8218129873275757, embedding dim 16, hidden size 16, num layers 1, train loss 0.4274006485939026, validation loss 0.8469052314758301\n",
      "Epoch 730, current patience 4, model mean validation loss 0.8269782662391663, embedding dim 16, hidden size 16, num layers 1, train loss 0.5652022957801819, validation loss 0.8380600214004517\n",
      "Epoch 740, current patience 3, model mean validation loss 0.8321887254714966, embedding dim 16, hidden size 16, num layers 1, train loss 0.38668251037597656, validation loss 0.8404372930526733\n",
      "Epoch 750, current patience 2, model mean validation loss 0.835610032081604, embedding dim 16, hidden size 16, num layers 1, train loss 0.49126705527305603, validation loss 0.8411614298820496\n",
      "Epoch 760, current patience 1, model mean validation loss 0.8409540057182312, embedding dim 16, hidden size 16, num layers 1, train loss 0.3313550055027008, validation loss 0.8569334745407104\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0986530780792236, embedding dim 16, hidden size 32, num layers 1, train loss 1.093455195426941, validation loss 1.0986530780792236\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0966548919677734, embedding dim 16, hidden size 32, num layers 1, train loss 1.0866904258728027, validation loss 1.0946567058563232\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0950840711593628, embedding dim 16, hidden size 32, num layers 1, train loss 1.0974113941192627, validation loss 1.091942310333252\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0950093269348145, embedding dim 16, hidden size 32, num layers 1, train loss 1.0892436504364014, validation loss 1.0947850942611694\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0942766666412354, embedding dim 16, hidden size 32, num layers 1, train loss 1.0815107822418213, validation loss 1.091346025466919\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0941214561462402, embedding dim 16, hidden size 32, num layers 1, train loss 1.0911883115768433, validation loss 1.0933454036712646\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0930637121200562, embedding dim 16, hidden size 32, num layers 1, train loss 1.0752500295639038, validation loss 1.086717128753662\n",
      "Epoch 70, current patience 30, model mean validation loss 1.09089994430542, embedding dim 16, hidden size 32, num layers 1, train loss 1.0785107612609863, validation loss 1.0757540464401245\n",
      "Epoch 80, current patience 30, model mean validation loss 1.085264801979065, embedding dim 16, hidden size 32, num layers 1, train loss 1.0592498779296875, validation loss 1.0535712242126465\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0817633867263794, embedding dim 16, hidden size 32, num layers 1, train loss 1.1102120876312256, validation loss 1.0666460990905762\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0744166374206543, embedding dim 16, hidden size 32, num layers 1, train loss 0.9825631380081177, validation loss 1.0331687927246094\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0629851818084717, embedding dim 16, hidden size 32, num layers 1, train loss 0.9774970412254333, validation loss 1.0033327341079712\n",
      "Epoch 120, current patience 30, model mean validation loss 1.053635835647583, embedding dim 16, hidden size 32, num layers 1, train loss 1.0532114505767822, validation loss 1.0165510177612305\n",
      "Epoch 130, current patience 30, model mean validation loss 1.037687063217163, embedding dim 16, hidden size 32, num layers 1, train loss 0.9567760229110718, validation loss 0.9657554030418396\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0176246166229248, embedding dim 16, hidden size 32, num layers 1, train loss 0.9111557602882385, validation loss 0.9262171983718872\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9991117119789124, embedding dim 16, hidden size 32, num layers 1, train loss 0.8693665266036987, validation loss 0.9276512265205383\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9790250062942505, embedding dim 16, hidden size 32, num layers 1, train loss 0.8760924339294434, validation loss 0.8928776979446411\n",
      "Epoch 170, current patience 30, model mean validation loss 0.957351803779602, embedding dim 16, hidden size 32, num layers 1, train loss 0.7844065427780151, validation loss 0.8932602405548096\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9385683536529541, embedding dim 16, hidden size 32, num layers 1, train loss 0.8590635657310486, validation loss 0.882901132106781\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9236403107643127, embedding dim 16, hidden size 32, num layers 1, train loss 0.7566037774085999, validation loss 0.8839085102081299\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9129945635795593, embedding dim 16, hidden size 32, num layers 1, train loss 0.7615373134613037, validation loss 0.9313853979110718\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8976095914840698, embedding dim 16, hidden size 32, num layers 1, train loss 0.8157064914703369, validation loss 0.8426751494407654\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8879129886627197, embedding dim 16, hidden size 32, num layers 1, train loss 0.7914655208587646, validation loss 0.8486442565917969\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8754688501358032, embedding dim 16, hidden size 32, num layers 1, train loss 0.9446594715118408, validation loss 0.8280979990959167\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8660781383514404, embedding dim 16, hidden size 32, num layers 1, train loss 0.6768755316734314, validation loss 0.8177522420883179\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8579850196838379, embedding dim 16, hidden size 32, num layers 1, train loss 0.809158980846405, validation loss 0.828515350818634\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8513098955154419, embedding dim 16, hidden size 32, num layers 1, train loss 0.8088266253471375, validation loss 0.8295001983642578\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8424431681632996, embedding dim 16, hidden size 32, num layers 1, train loss 0.6787101626396179, validation loss 0.8129746913909912\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8221675157546997, embedding dim 16, hidden size 32, num layers 1, train loss 0.5691574811935425, validation loss 0.7691797018051147\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8165246248245239, embedding dim 16, hidden size 32, num layers 1, train loss 0.5637625455856323, validation loss 0.7975327968597412\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8096506595611572, embedding dim 16, hidden size 32, num layers 1, train loss 0.6340646743774414, validation loss 0.7936527729034424\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8066564798355103, embedding dim 16, hidden size 32, num layers 1, train loss 0.8326684236526489, validation loss 0.8041442632675171\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8045388460159302, embedding dim 16, hidden size 32, num layers 1, train loss 0.8707618117332458, validation loss 0.8008111715316772\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8014765977859497, embedding dim 16, hidden size 32, num layers 1, train loss 0.7852095365524292, validation loss 0.8040175437927246\n",
      "Epoch 340, current patience 30, model mean validation loss 0.7995404005050659, embedding dim 16, hidden size 32, num layers 1, train loss 0.6807140111923218, validation loss 0.8140102624893188\n",
      "Epoch 350, current patience 30, model mean validation loss 0.7971460819244385, embedding dim 16, hidden size 32, num layers 1, train loss 0.700137734413147, validation loss 0.793820321559906\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8015600442886353, embedding dim 16, hidden size 32, num layers 1, train loss 0.6574059724807739, validation loss 0.8044917583465576\n",
      "Epoch 370, current patience 29, model mean validation loss 0.7981587648391724, embedding dim 16, hidden size 32, num layers 1, train loss 0.5657732486724854, validation loss 0.770322322845459\n",
      "Epoch 380, current patience 28, model mean validation loss 0.7953881621360779, embedding dim 16, hidden size 32, num layers 1, train loss 0.5663743019104004, validation loss 0.7714875340461731\n",
      "Epoch 390, current patience 30, model mean validation loss 0.7933984994888306, embedding dim 16, hidden size 32, num layers 1, train loss 0.5606937408447266, validation loss 0.7882271409034729\n",
      "Epoch 400, current patience 30, model mean validation loss 0.7908282279968262, embedding dim 16, hidden size 32, num layers 1, train loss 0.46845725178718567, validation loss 0.7802486419677734\n",
      "Epoch 410, current patience 30, model mean validation loss 0.79306960105896, embedding dim 16, hidden size 32, num layers 1, train loss 0.6933457851409912, validation loss 0.8219486474990845\n",
      "Epoch 420, current patience 29, model mean validation loss 0.7919477224349976, embedding dim 16, hidden size 32, num layers 1, train loss 0.5144583582878113, validation loss 0.8050354719161987\n",
      "Epoch 430, current patience 28, model mean validation loss 0.7944213151931763, embedding dim 16, hidden size 32, num layers 1, train loss 0.751930832862854, validation loss 0.8136093020439148\n",
      "Epoch 440, current patience 27, model mean validation loss 0.7918245792388916, embedding dim 16, hidden size 32, num layers 1, train loss 0.6000087261199951, validation loss 0.7837169170379639\n",
      "Epoch 450, current patience 26, model mean validation loss 0.7903144359588623, embedding dim 16, hidden size 32, num layers 1, train loss 0.6074663400650024, validation loss 0.7582419514656067\n",
      "Epoch 460, current patience 30, model mean validation loss 0.7937523126602173, embedding dim 16, hidden size 32, num layers 1, train loss 0.7244056463241577, validation loss 0.7989903688430786\n",
      "Epoch 470, current patience 29, model mean validation loss 0.7945700883865356, embedding dim 16, hidden size 32, num layers 1, train loss 0.5244905948638916, validation loss 0.7947694063186646\n",
      "Epoch 480, current patience 28, model mean validation loss 0.7966463565826416, embedding dim 16, hidden size 32, num layers 1, train loss 0.48959195613861084, validation loss 0.7968591451644897\n",
      "Epoch 490, current patience 27, model mean validation loss 0.7983081340789795, embedding dim 16, hidden size 32, num layers 1, train loss 0.34774118661880493, validation loss 0.835242748260498\n",
      "Epoch 500, current patience 26, model mean validation loss 0.7958369255065918, embedding dim 16, hidden size 32, num layers 1, train loss 0.5380240678787231, validation loss 0.7852658033370972\n",
      "Epoch 510, current patience 25, model mean validation loss 0.7916280627250671, embedding dim 16, hidden size 32, num layers 1, train loss 0.4619288742542267, validation loss 0.7799379825592041\n",
      "Epoch 520, current patience 24, model mean validation loss 0.7969557046890259, embedding dim 16, hidden size 32, num layers 1, train loss 0.5095620155334473, validation loss 0.8263382911682129\n",
      "Epoch 530, current patience 23, model mean validation loss 0.8035902976989746, embedding dim 16, hidden size 32, num layers 1, train loss 0.4780700206756592, validation loss 0.8113184571266174\n",
      "Epoch 540, current patience 22, model mean validation loss 0.8004692792892456, embedding dim 16, hidden size 32, num layers 1, train loss 0.724205493927002, validation loss 0.7740222811698914\n",
      "Epoch 550, current patience 21, model mean validation loss 0.8081157803535461, embedding dim 16, hidden size 32, num layers 1, train loss 0.6524731516838074, validation loss 0.8559414148330688\n",
      "Epoch 560, current patience 20, model mean validation loss 0.8135902285575867, embedding dim 16, hidden size 32, num layers 1, train loss 0.43976593017578125, validation loss 0.840654730796814\n",
      "Epoch 570, current patience 19, model mean validation loss 0.8091498613357544, embedding dim 16, hidden size 32, num layers 1, train loss 0.5862346887588501, validation loss 0.7997197508811951\n",
      "Epoch 580, current patience 18, model mean validation loss 0.8072290420532227, embedding dim 16, hidden size 32, num layers 1, train loss 0.7815251350402832, validation loss 0.7698994874954224\n",
      "Epoch 590, current patience 17, model mean validation loss 0.8116956949234009, embedding dim 16, hidden size 32, num layers 1, train loss 0.505627453327179, validation loss 0.8156713843345642\n",
      "Epoch 600, current patience 16, model mean validation loss 0.8060648441314697, embedding dim 16, hidden size 32, num layers 1, train loss 0.5560888648033142, validation loss 0.7812913656234741\n",
      "Epoch 610, current patience 15, model mean validation loss 0.8088541030883789, embedding dim 16, hidden size 32, num layers 1, train loss 0.46843141317367554, validation loss 0.8336323499679565\n",
      "Epoch 620, current patience 14, model mean validation loss 0.8177218437194824, embedding dim 16, hidden size 32, num layers 1, train loss 0.47869622707366943, validation loss 0.8449644446372986\n",
      "Epoch 630, current patience 13, model mean validation loss 0.8192012310028076, embedding dim 16, hidden size 32, num layers 1, train loss 0.45958995819091797, validation loss 0.8677762746810913\n",
      "Epoch 640, current patience 12, model mean validation loss 0.8208498954772949, embedding dim 16, hidden size 32, num layers 1, train loss 0.34724438190460205, validation loss 0.853844404220581\n",
      "Epoch 650, current patience 11, model mean validation loss 0.8281282782554626, embedding dim 16, hidden size 32, num layers 1, train loss 0.37345027923583984, validation loss 0.8579466342926025\n",
      "Epoch 660, current patience 10, model mean validation loss 0.8406668901443481, embedding dim 16, hidden size 32, num layers 1, train loss 0.556606650352478, validation loss 0.8702085018157959\n",
      "Epoch 670, current patience 9, model mean validation loss 0.852810263633728, embedding dim 16, hidden size 32, num layers 1, train loss 0.3530879318714142, validation loss 0.9128180742263794\n",
      "Epoch 680, current patience 8, model mean validation loss 0.8620996475219727, embedding dim 16, hidden size 32, num layers 1, train loss 0.40931856632232666, validation loss 0.8556060791015625\n",
      "Epoch 690, current patience 7, model mean validation loss 0.8647092580795288, embedding dim 16, hidden size 32, num layers 1, train loss 0.3794119954109192, validation loss 0.854509711265564\n",
      "Epoch 700, current patience 6, model mean validation loss 0.8697277307510376, embedding dim 16, hidden size 32, num layers 1, train loss 0.42030030488967896, validation loss 0.8851120471954346\n",
      "Epoch 710, current patience 5, model mean validation loss 0.869627058506012, embedding dim 16, hidden size 32, num layers 1, train loss 0.33503440022468567, validation loss 0.8669708967208862\n",
      "Epoch 720, current patience 4, model mean validation loss 0.8736140727996826, embedding dim 16, hidden size 32, num layers 1, train loss 0.4050945043563843, validation loss 0.8857407569885254\n",
      "Epoch 730, current patience 3, model mean validation loss 0.8734497427940369, embedding dim 16, hidden size 32, num layers 1, train loss 0.45850297808647156, validation loss 0.8566317558288574\n",
      "Epoch 740, current patience 2, model mean validation loss 0.8876489400863647, embedding dim 16, hidden size 32, num layers 1, train loss 0.4338234066963196, validation loss 0.9838017821311951\n",
      "Epoch 750, current patience 1, model mean validation loss 0.8910073041915894, embedding dim 16, hidden size 32, num layers 1, train loss 0.4535525143146515, validation loss 0.9396848082542419\n",
      "Epoch 0, current patience 30, model mean validation loss 1.10280442237854, embedding dim 16, hidden size 64, num layers 1, train loss 1.11484694480896, validation loss 1.10280442237854\n",
      "Epoch 10, current patience 30, model mean validation loss 1.097153663635254, embedding dim 16, hidden size 64, num layers 1, train loss 1.1061547994613647, validation loss 1.0915030241012573\n",
      "Epoch 20, current patience 30, model mean validation loss 1.096356749534607, embedding dim 16, hidden size 64, num layers 1, train loss 1.1011989116668701, validation loss 1.0947630405426025\n",
      "Epoch 30, current patience 30, model mean validation loss 1.095839500427246, embedding dim 16, hidden size 64, num layers 1, train loss 1.1021614074707031, validation loss 1.0942878723144531\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0922771692276, embedding dim 16, hidden size 64, num layers 1, train loss 1.073728322982788, validation loss 1.0780274868011475\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0887842178344727, embedding dim 16, hidden size 64, num layers 1, train loss 1.1138420104980469, validation loss 1.0713196992874146\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0850759744644165, embedding dim 16, hidden size 64, num layers 1, train loss 1.0341246128082275, validation loss 1.062826156616211\n",
      "Epoch 70, current patience 30, model mean validation loss 1.07974112033844, embedding dim 16, hidden size 64, num layers 1, train loss 1.013307809829712, validation loss 1.0423974990844727\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0721410512924194, embedding dim 16, hidden size 64, num layers 1, train loss 0.9921497106552124, validation loss 1.0420036315917969\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0612077713012695, embedding dim 16, hidden size 64, num layers 1, train loss 0.9530224800109863, validation loss 1.0040372610092163\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0488594770431519, embedding dim 16, hidden size 64, num layers 1, train loss 1.0198743343353271, validation loss 0.9959758520126343\n",
      "Epoch 110, current patience 30, model mean validation loss 1.032940149307251, embedding dim 16, hidden size 64, num layers 1, train loss 1.0212759971618652, validation loss 0.966934084892273\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0207501649856567, embedding dim 16, hidden size 64, num layers 1, train loss 0.9663186073303223, validation loss 0.980506956577301\n",
      "Epoch 130, current patience 30, model mean validation loss 1.00440514087677, embedding dim 16, hidden size 64, num layers 1, train loss 0.9545556306838989, validation loss 0.9405596256256104\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9906810522079468, embedding dim 16, hidden size 64, num layers 1, train loss 0.8730137348175049, validation loss 0.953033447265625\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9771550893783569, embedding dim 16, hidden size 64, num layers 1, train loss 0.8537547588348389, validation loss 0.9341901540756226\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9606918096542358, embedding dim 16, hidden size 64, num layers 1, train loss 0.9541662931442261, validation loss 0.9102972745895386\n",
      "Epoch 170, current patience 30, model mean validation loss 0.945314884185791, embedding dim 16, hidden size 64, num layers 1, train loss 0.8822647333145142, validation loss 0.8810216784477234\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9344959855079651, embedding dim 16, hidden size 64, num layers 1, train loss 0.8036322593688965, validation loss 0.9094241857528687\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9220870733261108, embedding dim 16, hidden size 64, num layers 1, train loss 0.7813786864280701, validation loss 0.8676629662513733\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9089810848236084, embedding dim 16, hidden size 64, num layers 1, train loss 0.7624735832214355, validation loss 0.8756589293479919\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8978551626205444, embedding dim 16, hidden size 64, num layers 1, train loss 0.7589553594589233, validation loss 0.8515526652336121\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8860800266265869, embedding dim 16, hidden size 64, num layers 1, train loss 0.715681791305542, validation loss 0.8588324785232544\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8777790069580078, embedding dim 16, hidden size 64, num layers 1, train loss 0.8889193534851074, validation loss 0.8677820563316345\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8684970140457153, embedding dim 16, hidden size 64, num layers 1, train loss 0.783004105091095, validation loss 0.836040735244751\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8666042685508728, embedding dim 16, hidden size 64, num layers 1, train loss 0.8491127490997314, validation loss 0.8658798933029175\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8542488813400269, embedding dim 16, hidden size 64, num layers 1, train loss 0.7524490356445312, validation loss 0.810581386089325\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8491783142089844, embedding dim 16, hidden size 64, num layers 1, train loss 0.8205717206001282, validation loss 0.8270981907844543\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8376801013946533, embedding dim 16, hidden size 64, num layers 1, train loss 0.6802469491958618, validation loss 0.7836737632751465\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8309815526008606, embedding dim 16, hidden size 64, num layers 1, train loss 0.7413203120231628, validation loss 0.7979636192321777\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8231282234191895, embedding dim 16, hidden size 64, num layers 1, train loss 0.7116605639457703, validation loss 0.7960060834884644\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8130937814712524, embedding dim 16, hidden size 64, num layers 1, train loss 0.877906858921051, validation loss 0.7875070571899414\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8091588020324707, embedding dim 16, hidden size 64, num layers 1, train loss 0.5664056539535522, validation loss 0.8045604825019836\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8052053451538086, embedding dim 16, hidden size 64, num layers 1, train loss 0.6972766518592834, validation loss 0.8342523574829102\n",
      "Epoch 340, current patience 30, model mean validation loss 0.801904022693634, embedding dim 16, hidden size 64, num layers 1, train loss 0.630611777305603, validation loss 0.7841706871986389\n",
      "Epoch 350, current patience 30, model mean validation loss 0.7999587059020996, embedding dim 16, hidden size 64, num layers 1, train loss 0.5494234561920166, validation loss 0.8115358352661133\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8048709630966187, embedding dim 16, hidden size 64, num layers 1, train loss 0.722346842288971, validation loss 0.8229717016220093\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8026519417762756, embedding dim 16, hidden size 64, num layers 1, train loss 0.5815654993057251, validation loss 0.7802109718322754\n",
      "Epoch 380, current patience 28, model mean validation loss 0.8002416491508484, embedding dim 16, hidden size 64, num layers 1, train loss 0.6070257425308228, validation loss 0.7767238020896912\n",
      "Epoch 390, current patience 27, model mean validation loss 0.8000510334968567, embedding dim 16, hidden size 64, num layers 1, train loss 0.5067314505577087, validation loss 0.785982608795166\n",
      "Epoch 400, current patience 26, model mean validation loss 0.80645751953125, embedding dim 16, hidden size 64, num layers 1, train loss 0.555066704750061, validation loss 0.8558122515678406\n",
      "Epoch 410, current patience 25, model mean validation loss 0.8040977716445923, embedding dim 16, hidden size 64, num layers 1, train loss 0.5392470955848694, validation loss 0.8153744339942932\n",
      "Epoch 420, current patience 24, model mean validation loss 0.8066169023513794, embedding dim 16, hidden size 64, num layers 1, train loss 0.5567619800567627, validation loss 0.8043240308761597\n",
      "Epoch 430, current patience 23, model mean validation loss 0.8008280992507935, embedding dim 16, hidden size 64, num layers 1, train loss 0.5745623111724854, validation loss 0.765224814414978\n",
      "Epoch 440, current patience 22, model mean validation loss 0.8074535131454468, embedding dim 16, hidden size 64, num layers 1, train loss 0.5927886962890625, validation loss 0.8759757280349731\n",
      "Epoch 450, current patience 21, model mean validation loss 0.8069075345993042, embedding dim 16, hidden size 64, num layers 1, train loss 0.45466524362564087, validation loss 0.7758423089981079\n",
      "Epoch 460, current patience 20, model mean validation loss 0.8080894947052002, embedding dim 16, hidden size 64, num layers 1, train loss 0.48519033193588257, validation loss 0.7861795425415039\n",
      "Epoch 470, current patience 19, model mean validation loss 0.8105245232582092, embedding dim 16, hidden size 64, num layers 1, train loss 0.8820546269416809, validation loss 0.8054628968238831\n",
      "Epoch 480, current patience 18, model mean validation loss 0.8020430207252502, embedding dim 16, hidden size 64, num layers 1, train loss 0.6896886229515076, validation loss 0.787960410118103\n",
      "Epoch 490, current patience 17, model mean validation loss 0.7957785129547119, embedding dim 16, hidden size 64, num layers 1, train loss 0.39493897557258606, validation loss 0.7652583122253418\n",
      "Epoch 500, current patience 30, model mean validation loss 0.7959244847297668, embedding dim 16, hidden size 64, num layers 1, train loss 0.6499669551849365, validation loss 0.8054918646812439\n",
      "Epoch 510, current patience 29, model mean validation loss 0.810895562171936, embedding dim 16, hidden size 64, num layers 1, train loss 0.6072032451629639, validation loss 0.8849937319755554\n",
      "Epoch 520, current patience 28, model mean validation loss 0.8006186485290527, embedding dim 16, hidden size 64, num layers 1, train loss 0.5247061252593994, validation loss 0.793759822845459\n",
      "Epoch 530, current patience 27, model mean validation loss 0.8108192682266235, embedding dim 16, hidden size 64, num layers 1, train loss 0.46387922763824463, validation loss 0.857447624206543\n",
      "Epoch 540, current patience 26, model mean validation loss 0.8158524036407471, embedding dim 16, hidden size 64, num layers 1, train loss 0.6486145257949829, validation loss 0.8264447450637817\n",
      "Epoch 550, current patience 25, model mean validation loss 0.8174228668212891, embedding dim 16, hidden size 64, num layers 1, train loss 0.41113054752349854, validation loss 0.8180263042449951\n",
      "Epoch 560, current patience 24, model mean validation loss 0.8214199542999268, embedding dim 16, hidden size 64, num layers 1, train loss 0.7470563054084778, validation loss 0.8199370503425598\n",
      "Epoch 570, current patience 23, model mean validation loss 0.8304338455200195, embedding dim 16, hidden size 64, num layers 1, train loss 0.46793055534362793, validation loss 0.8373700380325317\n",
      "Epoch 580, current patience 22, model mean validation loss 0.8395341634750366, embedding dim 16, hidden size 64, num layers 1, train loss 0.5125032663345337, validation loss 0.8782939314842224\n",
      "Epoch 590, current patience 21, model mean validation loss 0.8246043920516968, embedding dim 16, hidden size 64, num layers 1, train loss 0.6144965887069702, validation loss 0.7655557990074158\n",
      "Epoch 600, current patience 20, model mean validation loss 0.8269301652908325, embedding dim 16, hidden size 64, num layers 1, train loss 0.5137046575546265, validation loss 0.8123661279678345\n",
      "Epoch 610, current patience 19, model mean validation loss 0.8271164894104004, embedding dim 16, hidden size 64, num layers 1, train loss 0.49370241165161133, validation loss 0.8589377999305725\n",
      "Epoch 620, current patience 18, model mean validation loss 0.830967366695404, embedding dim 16, hidden size 64, num layers 1, train loss 0.47417598962783813, validation loss 0.8572516441345215\n",
      "Epoch 630, current patience 17, model mean validation loss 0.8352493643760681, embedding dim 16, hidden size 64, num layers 1, train loss 0.5438100099563599, validation loss 0.8522824645042419\n",
      "Epoch 640, current patience 16, model mean validation loss 0.8316357135772705, embedding dim 16, hidden size 64, num layers 1, train loss 0.380245566368103, validation loss 0.7910277843475342\n",
      "Epoch 650, current patience 15, model mean validation loss 0.8365567922592163, embedding dim 16, hidden size 64, num layers 1, train loss 0.36048388481140137, validation loss 0.8767383098602295\n",
      "Epoch 660, current patience 14, model mean validation loss 0.836410641670227, embedding dim 16, hidden size 64, num layers 1, train loss 0.33699434995651245, validation loss 0.8771254420280457\n",
      "Epoch 670, current patience 13, model mean validation loss 0.8536678552627563, embedding dim 16, hidden size 64, num layers 1, train loss 0.5828362703323364, validation loss 0.903613269329071\n",
      "Epoch 680, current patience 12, model mean validation loss 0.8755748271942139, embedding dim 16, hidden size 64, num layers 1, train loss 0.304949015378952, validation loss 0.9876219034194946\n",
      "Epoch 690, current patience 11, model mean validation loss 0.8824582099914551, embedding dim 16, hidden size 64, num layers 1, train loss 0.4000871181488037, validation loss 0.9140046834945679\n",
      "Epoch 700, current patience 10, model mean validation loss 0.8888379335403442, embedding dim 16, hidden size 64, num layers 1, train loss 0.3726120591163635, validation loss 0.9082895517349243\n",
      "Epoch 710, current patience 9, model mean validation loss 0.898909330368042, embedding dim 16, hidden size 64, num layers 1, train loss 0.33093172311782837, validation loss 0.9328532814979553\n",
      "Epoch 720, current patience 8, model mean validation loss 0.9178524017333984, embedding dim 16, hidden size 64, num layers 1, train loss 0.558707058429718, validation loss 0.9425727128982544\n",
      "Epoch 730, current patience 7, model mean validation loss 0.926063060760498, embedding dim 16, hidden size 64, num layers 1, train loss 0.34836700558662415, validation loss 0.9424237012863159\n",
      "Epoch 740, current patience 6, model mean validation loss 0.9242538213729858, embedding dim 16, hidden size 64, num layers 1, train loss 0.4836968183517456, validation loss 0.8626514673233032\n",
      "Epoch 750, current patience 5, model mean validation loss 0.9307560920715332, embedding dim 16, hidden size 64, num layers 1, train loss 0.3460872769355774, validation loss 0.9556316137313843\n",
      "Epoch 760, current patience 4, model mean validation loss 0.9187377691268921, embedding dim 16, hidden size 64, num layers 1, train loss 0.5622373819351196, validation loss 0.8914751410484314\n",
      "Epoch 770, current patience 3, model mean validation loss 0.9124318361282349, embedding dim 16, hidden size 64, num layers 1, train loss 0.3892623484134674, validation loss 0.8635571599006653\n",
      "Epoch 780, current patience 2, model mean validation loss 0.9107284545898438, embedding dim 16, hidden size 64, num layers 1, train loss 0.23056326806545258, validation loss 0.8946622610092163\n",
      "Epoch 790, current patience 1, model mean validation loss 0.9120243191719055, embedding dim 16, hidden size 64, num layers 1, train loss 0.2050047367811203, validation loss 0.9432201385498047\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1012766361236572, embedding dim 16, hidden size 128, num layers 1, train loss 1.102400779724121, validation loss 1.1012766361236572\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0983846187591553, embedding dim 16, hidden size 128, num layers 1, train loss 1.1008691787719727, validation loss 1.0954924821853638\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0982189178466797, embedding dim 16, hidden size 128, num layers 1, train loss 1.0974608659744263, validation loss 1.0978875160217285\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0940111875534058, embedding dim 16, hidden size 128, num layers 1, train loss 1.0561418533325195, validation loss 1.081387996673584\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0920473337173462, embedding dim 16, hidden size 128, num layers 1, train loss 1.09989333152771, validation loss 1.084192156791687\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0882035493850708, embedding dim 16, hidden size 128, num layers 1, train loss 1.105679988861084, validation loss 1.0689847469329834\n",
      "Epoch 60, current patience 30, model mean validation loss 1.08432137966156, embedding dim 16, hidden size 128, num layers 1, train loss 1.0916593074798584, validation loss 1.0610289573669434\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0777652263641357, embedding dim 16, hidden size 128, num layers 1, train loss 1.0555577278137207, validation loss 1.0318715572357178\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0677520036697388, embedding dim 16, hidden size 128, num layers 1, train loss 1.0443183183670044, validation loss 1.0211708545684814\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0541713237762451, embedding dim 16, hidden size 128, num layers 1, train loss 1.2190124988555908, validation loss 0.9868466854095459\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0475666522979736, embedding dim 16, hidden size 128, num layers 1, train loss 0.9784802198410034, validation loss 1.045050024986267\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0390150547027588, embedding dim 16, hidden size 128, num layers 1, train loss 1.0524739027023315, validation loss 1.0129748582839966\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0268759727478027, embedding dim 16, hidden size 128, num layers 1, train loss 1.0081284046173096, validation loss 0.987080454826355\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0134433507919312, embedding dim 16, hidden size 128, num layers 1, train loss 0.9805208444595337, validation loss 0.9615229368209839\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9984074234962463, embedding dim 16, hidden size 128, num layers 1, train loss 0.8361840844154358, validation loss 0.9407422542572021\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9861447811126709, embedding dim 16, hidden size 128, num layers 1, train loss 0.9427629709243774, validation loss 0.9337706565856934\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9732382297515869, embedding dim 16, hidden size 128, num layers 1, train loss 0.8514267206192017, validation loss 0.9179176688194275\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9619473218917847, embedding dim 16, hidden size 128, num layers 1, train loss 0.8461923599243164, validation loss 0.8965198993682861\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9451894760131836, embedding dim 16, hidden size 128, num layers 1, train loss 0.7855022549629211, validation loss 0.9109869003295898\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9301967620849609, embedding dim 16, hidden size 128, num layers 1, train loss 1.002433180809021, validation loss 0.893033504486084\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9149773120880127, embedding dim 16, hidden size 128, num layers 1, train loss 0.7164067029953003, validation loss 0.8653246164321899\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9012579917907715, embedding dim 16, hidden size 128, num layers 1, train loss 0.8675106167793274, validation loss 0.8517683744430542\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8939064145088196, embedding dim 16, hidden size 128, num layers 1, train loss 0.8194538950920105, validation loss 0.8819297552108765\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8884308338165283, embedding dim 16, hidden size 128, num layers 1, train loss 0.9254423379898071, validation loss 0.8899662494659424\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8801822066307068, embedding dim 16, hidden size 128, num layers 1, train loss 0.8363627195358276, validation loss 0.8519285321235657\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8726961612701416, embedding dim 16, hidden size 128, num layers 1, train loss 0.8150331974029541, validation loss 0.8366315364837646\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8639962673187256, embedding dim 16, hidden size 128, num layers 1, train loss 0.6928134560585022, validation loss 0.8413872122764587\n",
      "Epoch 270, current patience 30, model mean validation loss 0.856174886226654, embedding dim 16, hidden size 128, num layers 1, train loss 0.7253265380859375, validation loss 0.8304627537727356\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8491851687431335, embedding dim 16, hidden size 128, num layers 1, train loss 0.8877654671669006, validation loss 0.8094068765640259\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8422110080718994, embedding dim 16, hidden size 128, num layers 1, train loss 0.5989798307418823, validation loss 0.7959749698638916\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8330299854278564, embedding dim 16, hidden size 128, num layers 1, train loss 0.7254379987716675, validation loss 0.8084814548492432\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8261368870735168, embedding dim 16, hidden size 128, num layers 1, train loss 0.5256685018539429, validation loss 0.8348219394683838\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8233139514923096, embedding dim 16, hidden size 128, num layers 1, train loss 0.9184868335723877, validation loss 0.8293451070785522\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8169267177581787, embedding dim 16, hidden size 128, num layers 1, train loss 0.6819332242012024, validation loss 0.7855337262153625\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8130673170089722, embedding dim 16, hidden size 128, num layers 1, train loss 0.5727059245109558, validation loss 0.8105120658874512\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8085517883300781, embedding dim 16, hidden size 128, num layers 1, train loss 0.611879289150238, validation loss 0.794338047504425\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8102586269378662, embedding dim 16, hidden size 128, num layers 1, train loss 0.6513344049453735, validation loss 0.8230615258216858\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8112853765487671, embedding dim 16, hidden size 128, num layers 1, train loss 0.8757508993148804, validation loss 0.80418860912323\n",
      "Epoch 380, current patience 28, model mean validation loss 0.8044971823692322, embedding dim 16, hidden size 128, num layers 1, train loss 0.770332396030426, validation loss 0.754176139831543\n",
      "Epoch 390, current patience 30, model mean validation loss 0.7981960773468018, embedding dim 16, hidden size 128, num layers 1, train loss 0.543274998664856, validation loss 0.7844133377075195\n",
      "Epoch 400, current patience 30, model mean validation loss 0.7928646802902222, embedding dim 16, hidden size 128, num layers 1, train loss 0.6202540397644043, validation loss 0.7866936922073364\n",
      "Epoch 410, current patience 30, model mean validation loss 0.7922190427780151, embedding dim 16, hidden size 128, num layers 1, train loss 0.44031959772109985, validation loss 0.7803690433502197\n",
      "Epoch 420, current patience 30, model mean validation loss 0.7919013500213623, embedding dim 16, hidden size 128, num layers 1, train loss 0.6769274473190308, validation loss 0.8079705238342285\n",
      "Epoch 430, current patience 30, model mean validation loss 0.788011908531189, embedding dim 16, hidden size 128, num layers 1, train loss 0.429604709148407, validation loss 0.7632222771644592\n",
      "Epoch 440, current patience 30, model mean validation loss 0.7848371267318726, embedding dim 16, hidden size 128, num layers 1, train loss 0.7254679799079895, validation loss 0.7976633310317993\n",
      "Epoch 450, current patience 30, model mean validation loss 0.7818090915679932, embedding dim 16, hidden size 128, num layers 1, train loss 0.49297666549682617, validation loss 0.7799640893936157\n",
      "Epoch 460, current patience 30, model mean validation loss 0.7860261797904968, embedding dim 16, hidden size 128, num layers 1, train loss 0.6885899305343628, validation loss 0.7879132628440857\n",
      "Epoch 470, current patience 29, model mean validation loss 0.7952502965927124, embedding dim 16, hidden size 128, num layers 1, train loss 0.5121203064918518, validation loss 0.8582062721252441\n",
      "Epoch 480, current patience 28, model mean validation loss 0.7932965159416199, embedding dim 16, hidden size 128, num layers 1, train loss 0.5533270239830017, validation loss 0.7710630893707275\n",
      "Epoch 490, current patience 27, model mean validation loss 0.7889817953109741, embedding dim 16, hidden size 128, num layers 1, train loss 0.8044416904449463, validation loss 0.7458511590957642\n",
      "Epoch 500, current patience 26, model mean validation loss 0.793104887008667, embedding dim 16, hidden size 128, num layers 1, train loss 0.4212576746940613, validation loss 0.8409558534622192\n",
      "Epoch 510, current patience 25, model mean validation loss 0.7998009324073792, embedding dim 16, hidden size 128, num layers 1, train loss 0.47530579566955566, validation loss 0.8167906999588013\n",
      "Epoch 520, current patience 24, model mean validation loss 0.8005532622337341, embedding dim 16, hidden size 128, num layers 1, train loss 0.538156270980835, validation loss 0.803681492805481\n",
      "Epoch 530, current patience 23, model mean validation loss 0.8052860498428345, embedding dim 16, hidden size 128, num layers 1, train loss 0.44920670986175537, validation loss 0.8178266286849976\n",
      "Epoch 540, current patience 22, model mean validation loss 0.8177400231361389, embedding dim 16, hidden size 128, num layers 1, train loss 0.40679532289505005, validation loss 0.8875449895858765\n",
      "Epoch 550, current patience 21, model mean validation loss 0.8115391731262207, embedding dim 16, hidden size 128, num layers 1, train loss 0.5721250772476196, validation loss 0.808599591255188\n",
      "Epoch 560, current patience 20, model mean validation loss 0.8139004707336426, embedding dim 16, hidden size 128, num layers 1, train loss 0.5577753186225891, validation loss 0.78995281457901\n",
      "Epoch 570, current patience 19, model mean validation loss 0.8341057896614075, embedding dim 16, hidden size 128, num layers 1, train loss 0.7194644212722778, validation loss 0.907494068145752\n",
      "Epoch 580, current patience 18, model mean validation loss 0.834033727645874, embedding dim 16, hidden size 128, num layers 1, train loss 0.5214583277702332, validation loss 0.8403792381286621\n",
      "Epoch 590, current patience 17, model mean validation loss 0.8349512815475464, embedding dim 16, hidden size 128, num layers 1, train loss 0.5543385744094849, validation loss 0.8241314888000488\n",
      "Epoch 600, current patience 16, model mean validation loss 0.8342790603637695, embedding dim 16, hidden size 128, num layers 1, train loss 0.788018524646759, validation loss 0.7983032464981079\n",
      "Epoch 610, current patience 15, model mean validation loss 0.8319818377494812, embedding dim 16, hidden size 128, num layers 1, train loss 0.355806827545166, validation loss 0.7994489669799805\n",
      "Epoch 620, current patience 14, model mean validation loss 0.8333496451377869, embedding dim 16, hidden size 128, num layers 1, train loss 0.282223105430603, validation loss 0.8984876871109009\n",
      "Epoch 630, current patience 13, model mean validation loss 0.8367600440979004, embedding dim 16, hidden size 128, num layers 1, train loss 0.25986868143081665, validation loss 0.8358829617500305\n",
      "Epoch 640, current patience 12, model mean validation loss 0.8434141874313354, embedding dim 16, hidden size 128, num layers 1, train loss 0.33972063660621643, validation loss 0.8431854844093323\n",
      "Epoch 650, current patience 11, model mean validation loss 0.8407154679298401, embedding dim 16, hidden size 128, num layers 1, train loss 0.4554523229598999, validation loss 0.8859046697616577\n",
      "Epoch 660, current patience 10, model mean validation loss 0.8422478437423706, embedding dim 16, hidden size 128, num layers 1, train loss 0.5833516120910645, validation loss 0.8526378870010376\n",
      "Epoch 670, current patience 9, model mean validation loss 0.854167103767395, embedding dim 16, hidden size 128, num layers 1, train loss 0.37415194511413574, validation loss 0.9194861054420471\n",
      "Epoch 680, current patience 8, model mean validation loss 0.8658440113067627, embedding dim 16, hidden size 128, num layers 1, train loss 0.6197066307067871, validation loss 0.8917184472084045\n",
      "Epoch 690, current patience 7, model mean validation loss 0.8828843832015991, embedding dim 16, hidden size 128, num layers 1, train loss 0.39809900522232056, validation loss 0.9357717633247375\n",
      "Epoch 700, current patience 6, model mean validation loss 0.8793832063674927, embedding dim 16, hidden size 128, num layers 1, train loss 0.3486604690551758, validation loss 0.8704777956008911\n",
      "Epoch 710, current patience 5, model mean validation loss 0.8852894306182861, embedding dim 16, hidden size 128, num layers 1, train loss 0.5650830268859863, validation loss 0.883133053779602\n",
      "Epoch 720, current patience 4, model mean validation loss 0.8868701457977295, embedding dim 16, hidden size 128, num layers 1, train loss 0.49969369173049927, validation loss 0.8558316230773926\n",
      "Epoch 730, current patience 3, model mean validation loss 0.8964511156082153, embedding dim 16, hidden size 128, num layers 1, train loss 0.4448452889919281, validation loss 0.9625523090362549\n",
      "Epoch 740, current patience 2, model mean validation loss 0.907750129699707, embedding dim 16, hidden size 128, num layers 1, train loss 0.37774965167045593, validation loss 0.9430303573608398\n",
      "Epoch 750, current patience 1, model mean validation loss 0.9082778692245483, embedding dim 16, hidden size 128, num layers 1, train loss 0.241709366440773, validation loss 0.9237076044082642\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0989503860473633, embedding dim 16, hidden size 256, num layers 1, train loss 1.0986454486846924, validation loss 1.0989503860473633\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0961800813674927, embedding dim 16, hidden size 256, num layers 1, train loss 1.090157151222229, validation loss 1.093409776687622\n",
      "Epoch 20, current patience 30, model mean validation loss 1.094117283821106, embedding dim 16, hidden size 256, num layers 1, train loss 1.18668532371521, validation loss 1.0899916887283325\n",
      "Epoch 30, current patience 30, model mean validation loss 1.094020128250122, embedding dim 16, hidden size 256, num layers 1, train loss 1.0714024305343628, validation loss 1.0937283039093018\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0929489135742188, embedding dim 16, hidden size 256, num layers 1, train loss 1.0963754653930664, validation loss 1.0886646509170532\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0931404829025269, embedding dim 16, hidden size 256, num layers 1, train loss 1.096105933189392, validation loss 1.0940983295440674\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0933219194412231, embedding dim 16, hidden size 256, num layers 1, train loss 1.0854356288909912, validation loss 1.0944106578826904\n",
      "Epoch 70, current patience 28, model mean validation loss 1.0927261114120483, embedding dim 16, hidden size 256, num layers 1, train loss 1.0939605236053467, validation loss 1.088554859161377\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0922057628631592, embedding dim 16, hidden size 256, num layers 1, train loss 1.0825237035751343, validation loss 1.0947885513305664\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0921754837036133, embedding dim 16, hidden size 256, num layers 1, train loss 1.0877394676208496, validation loss 1.0931668281555176\n",
      "Epoch 100, current patience 30, model mean validation loss 1.092164158821106, embedding dim 16, hidden size 256, num layers 1, train loss 1.0674248933792114, validation loss 1.0899014472961426\n",
      "Epoch 110, current patience 30, model mean validation loss 1.089347004890442, embedding dim 16, hidden size 256, num layers 1, train loss 1.0522804260253906, validation loss 1.0711913108825684\n",
      "Epoch 120, current patience 30, model mean validation loss 1.086338758468628, embedding dim 16, hidden size 256, num layers 1, train loss 1.0256178379058838, validation loss 1.0645976066589355\n",
      "Epoch 130, current patience 30, model mean validation loss 1.081186294555664, embedding dim 16, hidden size 256, num layers 1, train loss 1.055782675743103, validation loss 1.0528793334960938\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0730654001235962, embedding dim 16, hidden size 256, num layers 1, train loss 1.073630928993225, validation loss 1.0294435024261475\n",
      "Epoch 150, current patience 30, model mean validation loss 1.063667893409729, embedding dim 16, hidden size 256, num layers 1, train loss 1.0262036323547363, validation loss 1.0133748054504395\n",
      "Epoch 160, current patience 30, model mean validation loss 1.050825595855713, embedding dim 16, hidden size 256, num layers 1, train loss 1.0875115394592285, validation loss 0.9920491576194763\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0360404253005981, embedding dim 16, hidden size 256, num layers 1, train loss 0.957102358341217, validation loss 0.9748862981796265\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0216909646987915, embedding dim 16, hidden size 256, num layers 1, train loss 0.9070149064064026, validation loss 0.9751057624816895\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0073037147521973, embedding dim 16, hidden size 256, num layers 1, train loss 0.9347898960113525, validation loss 0.956092894077301\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9902247190475464, embedding dim 16, hidden size 256, num layers 1, train loss 0.8747822046279907, validation loss 0.9279659986495972\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9769987463951111, embedding dim 16, hidden size 256, num layers 1, train loss 0.8956418037414551, validation loss 0.9470716118812561\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9615601301193237, embedding dim 16, hidden size 256, num layers 1, train loss 0.8281760811805725, validation loss 0.9059349894523621\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9472233057022095, embedding dim 16, hidden size 256, num layers 1, train loss 1.0819274187088013, validation loss 0.8986796140670776\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9359560012817383, embedding dim 16, hidden size 256, num layers 1, train loss 0.7848470211029053, validation loss 0.9019108414649963\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9411818981170654, embedding dim 16, hidden size 256, num layers 1, train loss 0.7201076745986938, validation loss 1.0166935920715332\n",
      "Epoch 260, current patience 29, model mean validation loss 0.9283953905105591, embedding dim 16, hidden size 256, num layers 1, train loss 0.8117493987083435, validation loss 0.8728134632110596\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9173009991645813, embedding dim 16, hidden size 256, num layers 1, train loss 0.7381572723388672, validation loss 0.8673377633094788\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9063248038291931, embedding dim 16, hidden size 256, num layers 1, train loss 0.7300040125846863, validation loss 0.8401564359664917\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8924634456634521, embedding dim 16, hidden size 256, num layers 1, train loss 0.553725004196167, validation loss 0.8361808061599731\n",
      "Epoch 300, current patience 30, model mean validation loss 0.884992241859436, embedding dim 16, hidden size 256, num layers 1, train loss 0.6500123739242554, validation loss 0.8461655974388123\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8786400556564331, embedding dim 16, hidden size 256, num layers 1, train loss 0.9023693799972534, validation loss 0.8478620052337646\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8729078769683838, embedding dim 16, hidden size 256, num layers 1, train loss 0.660685122013092, validation loss 0.8560532331466675\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8480527997016907, embedding dim 16, hidden size 256, num layers 1, train loss 0.6831201314926147, validation loss 0.8178533315658569\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8460886478424072, embedding dim 16, hidden size 256, num layers 1, train loss 0.687570333480835, validation loss 0.857100248336792\n",
      "Epoch 350, current patience 30, model mean validation loss 0.842637300491333, embedding dim 16, hidden size 256, num layers 1, train loss 0.8857349157333374, validation loss 0.8397265672683716\n",
      "Epoch 360, current patience 30, model mean validation loss 0.843497633934021, embedding dim 16, hidden size 256, num layers 1, train loss 0.5992246866226196, validation loss 0.8470392227172852\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8390995860099792, embedding dim 16, hidden size 256, num layers 1, train loss 0.7303183078765869, validation loss 0.8009965419769287\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8372648358345032, embedding dim 16, hidden size 256, num layers 1, train loss 0.5636128187179565, validation loss 0.8314873576164246\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8350184559822083, embedding dim 16, hidden size 256, num layers 1, train loss 0.6359606981277466, validation loss 0.8298912048339844\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8309354186058044, embedding dim 16, hidden size 256, num layers 1, train loss 0.7460841536521912, validation loss 0.8233891725540161\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8330676555633545, embedding dim 16, hidden size 256, num layers 1, train loss 0.7962111234664917, validation loss 0.8349109888076782\n",
      "Epoch 420, current patience 29, model mean validation loss 0.8327733278274536, embedding dim 16, hidden size 256, num layers 1, train loss 0.5793413519859314, validation loss 0.8547454476356506\n",
      "Epoch 430, current patience 28, model mean validation loss 0.8293260335922241, embedding dim 16, hidden size 256, num layers 1, train loss 0.7051423788070679, validation loss 0.8121482133865356\n",
      "Epoch 440, current patience 30, model mean validation loss 0.8244469165802002, embedding dim 16, hidden size 256, num layers 1, train loss 0.5328772068023682, validation loss 0.8080066442489624\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8219364881515503, embedding dim 16, hidden size 256, num layers 1, train loss 0.5185673832893372, validation loss 0.7809130549430847\n",
      "Epoch 460, current patience 30, model mean validation loss 0.8229334354400635, embedding dim 16, hidden size 256, num layers 1, train loss 0.4504775404930115, validation loss 0.8394629955291748\n",
      "Epoch 470, current patience 29, model mean validation loss 0.826708197593689, embedding dim 16, hidden size 256, num layers 1, train loss 0.5292371511459351, validation loss 0.8600894212722778\n",
      "Epoch 480, current patience 28, model mean validation loss 0.8306259512901306, embedding dim 16, hidden size 256, num layers 1, train loss 0.33311599493026733, validation loss 0.8547308444976807\n",
      "Epoch 490, current patience 27, model mean validation loss 0.8376541137695312, embedding dim 16, hidden size 256, num layers 1, train loss 0.4240083694458008, validation loss 0.8911365270614624\n",
      "Epoch 500, current patience 26, model mean validation loss 0.8467122316360474, embedding dim 16, hidden size 256, num layers 1, train loss 0.4491948187351227, validation loss 0.9272099733352661\n",
      "Epoch 510, current patience 25, model mean validation loss 0.85163813829422, embedding dim 16, hidden size 256, num layers 1, train loss 0.35437557101249695, validation loss 0.851555585861206\n",
      "Epoch 520, current patience 24, model mean validation loss 0.8555018901824951, embedding dim 16, hidden size 256, num layers 1, train loss 0.6163336038589478, validation loss 0.8389164805412292\n",
      "Epoch 530, current patience 23, model mean validation loss 0.8595870733261108, embedding dim 16, hidden size 256, num layers 1, train loss 0.3728708326816559, validation loss 0.8135945796966553\n",
      "Epoch 540, current patience 22, model mean validation loss 0.8643296957015991, embedding dim 16, hidden size 256, num layers 1, train loss 0.41988757252693176, validation loss 0.8774042129516602\n",
      "Epoch 550, current patience 21, model mean validation loss 0.8614305257797241, embedding dim 16, hidden size 256, num layers 1, train loss 0.46417999267578125, validation loss 0.8368962407112122\n",
      "Epoch 560, current patience 20, model mean validation loss 0.865077018737793, embedding dim 16, hidden size 256, num layers 1, train loss 0.26936429738998413, validation loss 0.8839026689529419\n",
      "Epoch 570, current patience 19, model mean validation loss 0.858849048614502, embedding dim 16, hidden size 256, num layers 1, train loss 0.26462751626968384, validation loss 0.8413127660751343\n",
      "Epoch 580, current patience 18, model mean validation loss 0.8513504266738892, embedding dim 16, hidden size 256, num layers 1, train loss 0.4081490635871887, validation loss 0.8672205805778503\n",
      "Epoch 590, current patience 17, model mean validation loss 0.8663896918296814, embedding dim 16, hidden size 256, num layers 1, train loss 0.33516210317611694, validation loss 0.9718695282936096\n",
      "Epoch 600, current patience 16, model mean validation loss 0.8913468718528748, embedding dim 16, hidden size 256, num layers 1, train loss 0.20024555921554565, validation loss 1.03857421875\n",
      "Epoch 610, current patience 15, model mean validation loss 0.9032220840454102, embedding dim 16, hidden size 256, num layers 1, train loss 0.5043503642082214, validation loss 0.9085966348648071\n",
      "Epoch 620, current patience 14, model mean validation loss 0.9059410691261292, embedding dim 16, hidden size 256, num layers 1, train loss 0.46865642070770264, validation loss 0.8991557955741882\n",
      "Epoch 630, current patience 13, model mean validation loss 0.9251059889793396, embedding dim 16, hidden size 256, num layers 1, train loss 0.3716905117034912, validation loss 0.9902156591415405\n",
      "Epoch 640, current patience 12, model mean validation loss 0.9301894903182983, embedding dim 16, hidden size 256, num layers 1, train loss 0.7247992753982544, validation loss 0.924570620059967\n",
      "Epoch 650, current patience 11, model mean validation loss 0.9307626485824585, embedding dim 16, hidden size 256, num layers 1, train loss 0.7011405229568481, validation loss 0.8458977937698364\n",
      "Epoch 660, current patience 10, model mean validation loss 0.9339451789855957, embedding dim 16, hidden size 256, num layers 1, train loss 0.5305175185203552, validation loss 0.8926810026168823\n",
      "Epoch 670, current patience 9, model mean validation loss 0.9299922585487366, embedding dim 16, hidden size 256, num layers 1, train loss 0.1556919813156128, validation loss 0.9402466416358948\n",
      "Epoch 680, current patience 8, model mean validation loss 0.9184821844100952, embedding dim 16, hidden size 256, num layers 1, train loss 0.6823319792747498, validation loss 0.9464938640594482\n",
      "Epoch 690, current patience 7, model mean validation loss 0.9290225505828857, embedding dim 16, hidden size 256, num layers 1, train loss 0.29198625683784485, validation loss 0.9929191470146179\n",
      "Epoch 700, current patience 6, model mean validation loss 0.9362655878067017, embedding dim 16, hidden size 256, num layers 1, train loss 0.3289456367492676, validation loss 0.9570999145507812\n",
      "Epoch 710, current patience 5, model mean validation loss 0.9278503656387329, embedding dim 16, hidden size 256, num layers 1, train loss 0.2976362407207489, validation loss 0.9228938817977905\n",
      "Epoch 720, current patience 4, model mean validation loss 0.926432728767395, embedding dim 16, hidden size 256, num layers 1, train loss 0.18063221871852875, validation loss 0.9132298231124878\n",
      "Epoch 730, current patience 3, model mean validation loss 0.94577956199646, embedding dim 16, hidden size 256, num layers 1, train loss 0.46290886402130127, validation loss 1.0006718635559082\n",
      "Epoch 740, current patience 2, model mean validation loss 0.9626795053482056, embedding dim 16, hidden size 256, num layers 1, train loss 0.3139115273952484, validation loss 1.0278809070587158\n",
      "Epoch 750, current patience 1, model mean validation loss 0.9845409393310547, embedding dim 16, hidden size 256, num layers 1, train loss 0.24083387851715088, validation loss 1.1151378154754639\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1132972240447998, embedding dim 16, hidden size 512, num layers 1, train loss 1.1041643619537354, validation loss 1.1132972240447998\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1032617092132568, embedding dim 16, hidden size 512, num layers 1, train loss 1.092505693435669, validation loss 1.0932261943817139\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1028733253479004, embedding dim 16, hidden size 512, num layers 1, train loss 1.1002062559127808, validation loss 1.102096676826477\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1017638444900513, embedding dim 16, hidden size 512, num layers 1, train loss 1.1030503511428833, validation loss 1.0984352827072144\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1004265546798706, embedding dim 16, hidden size 512, num layers 1, train loss 1.1104094982147217, validation loss 1.0950772762298584\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0991781949996948, embedding dim 16, hidden size 512, num layers 1, train loss 1.1013319492340088, validation loss 1.0929360389709473\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0970760583877563, embedding dim 16, hidden size 512, num layers 1, train loss 1.1212108135223389, validation loss 1.0844628810882568\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0954118967056274, embedding dim 16, hidden size 512, num layers 1, train loss 1.0588372945785522, validation loss 1.0837633609771729\n",
      "Epoch 80, current patience 30, model mean validation loss 1.09197199344635, embedding dim 16, hidden size 512, num layers 1, train loss 1.0784986019134521, validation loss 1.0857782363891602\n",
      "Epoch 90, current patience 30, model mean validation loss 1.088626742362976, embedding dim 16, hidden size 512, num layers 1, train loss 1.0798753499984741, validation loss 1.0664639472961426\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0798946619033813, embedding dim 16, hidden size 512, num layers 1, train loss 1.066017985343933, validation loss 1.0322399139404297\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0722136497497559, embedding dim 16, hidden size 512, num layers 1, train loss 0.94612056016922, validation loss 1.0369864702224731\n",
      "Epoch 120, current patience 30, model mean validation loss 1.062039852142334, embedding dim 16, hidden size 512, num layers 1, train loss 1.091713547706604, validation loss 1.0136878490447998\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0498113632202148, embedding dim 16, hidden size 512, num layers 1, train loss 0.935253918170929, validation loss 0.9951087236404419\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0359355211257935, embedding dim 16, hidden size 512, num layers 1, train loss 0.9578850269317627, validation loss 0.9734559059143066\n",
      "Epoch 150, current patience 30, model mean validation loss 1.017935872077942, embedding dim 16, hidden size 512, num layers 1, train loss 0.9464694261550903, validation loss 0.939766526222229\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9980581998825073, embedding dim 16, hidden size 512, num layers 1, train loss 0.8894668817520142, validation loss 0.9267560839653015\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9795831441879272, embedding dim 16, hidden size 512, num layers 1, train loss 0.8805312514305115, validation loss 0.9186641573905945\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9665532112121582, embedding dim 16, hidden size 512, num layers 1, train loss 0.9023435115814209, validation loss 0.9279997944831848\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9506278038024902, embedding dim 16, hidden size 512, num layers 1, train loss 0.856838583946228, validation loss 0.9095834493637085\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9359797835350037, embedding dim 16, hidden size 512, num layers 1, train loss 0.6535282731056213, validation loss 0.8965036869049072\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9195890426635742, embedding dim 16, hidden size 512, num layers 1, train loss 0.8161360025405884, validation loss 0.8639829158782959\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9021749496459961, embedding dim 16, hidden size 512, num layers 1, train loss 0.7739187479019165, validation loss 0.8341425657272339\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8880126476287842, embedding dim 16, hidden size 512, num layers 1, train loss 0.6791771650314331, validation loss 0.8264683485031128\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8772649765014648, embedding dim 16, hidden size 512, num layers 1, train loss 0.6473898887634277, validation loss 0.8407748937606812\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8659330606460571, embedding dim 16, hidden size 512, num layers 1, train loss 0.7847631573677063, validation loss 0.8280086517333984\n",
      "Epoch 260, current patience 30, model mean validation loss 0.849769115447998, embedding dim 16, hidden size 512, num layers 1, train loss 0.6713209748268127, validation loss 0.7986878156661987\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8432813882827759, embedding dim 16, hidden size 512, num layers 1, train loss 0.5882453918457031, validation loss 0.8576823472976685\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8366376161575317, embedding dim 16, hidden size 512, num layers 1, train loss 0.8996930122375488, validation loss 0.8433533906936646\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8317026495933533, embedding dim 16, hidden size 512, num layers 1, train loss 0.727429986000061, validation loss 0.824503481388092\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8303096294403076, embedding dim 16, hidden size 512, num layers 1, train loss 0.6855193376541138, validation loss 0.8229982852935791\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8260080814361572, embedding dim 16, hidden size 512, num layers 1, train loss 0.708518922328949, validation loss 0.7920557260513306\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8234423995018005, embedding dim 16, hidden size 512, num layers 1, train loss 0.46463847160339355, validation loss 0.8202498555183411\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8384567499160767, embedding dim 16, hidden size 512, num layers 1, train loss 0.5292595624923706, validation loss 0.9481229782104492\n",
      "Epoch 340, current patience 29, model mean validation loss 0.8431761860847473, embedding dim 16, hidden size 512, num layers 1, train loss 0.5964837670326233, validation loss 0.8364432454109192\n",
      "Epoch 350, current patience 28, model mean validation loss 0.8352164030075073, embedding dim 16, hidden size 512, num layers 1, train loss 0.7946298122406006, validation loss 0.7940043210983276\n",
      "Epoch 360, current patience 27, model mean validation loss 0.8301116228103638, embedding dim 16, hidden size 512, num layers 1, train loss 0.6297652721405029, validation loss 0.8025150895118713\n",
      "Epoch 370, current patience 26, model mean validation loss 0.8320913910865784, embedding dim 16, hidden size 512, num layers 1, train loss 0.2830083966255188, validation loss 0.8403414487838745\n",
      "Epoch 380, current patience 25, model mean validation loss 0.8273493051528931, embedding dim 16, hidden size 512, num layers 1, train loss 0.4594031274318695, validation loss 0.7850614786148071\n",
      "Epoch 390, current patience 24, model mean validation loss 0.8311790227890015, embedding dim 16, hidden size 512, num layers 1, train loss 0.8678364753723145, validation loss 0.8226940631866455\n",
      "Epoch 400, current patience 23, model mean validation loss 0.8292708396911621, embedding dim 16, hidden size 512, num layers 1, train loss 0.5807149410247803, validation loss 0.8049840331077576\n",
      "Epoch 410, current patience 22, model mean validation loss 0.8166399002075195, embedding dim 16, hidden size 512, num layers 1, train loss 0.527383029460907, validation loss 0.8470758199691772\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8152684569358826, embedding dim 16, hidden size 512, num layers 1, train loss 0.43635839223861694, validation loss 0.8254716396331787\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8179527521133423, embedding dim 16, hidden size 512, num layers 1, train loss 0.5074777603149414, validation loss 0.8154786825180054\n",
      "Epoch 440, current patience 29, model mean validation loss 0.8249008655548096, embedding dim 16, hidden size 512, num layers 1, train loss 0.4761379659175873, validation loss 0.858100175857544\n",
      "Epoch 450, current patience 28, model mean validation loss 0.8247212171554565, embedding dim 16, hidden size 512, num layers 1, train loss 0.4796837270259857, validation loss 0.8389040231704712\n",
      "Epoch 460, current patience 27, model mean validation loss 0.8398796319961548, embedding dim 16, hidden size 512, num layers 1, train loss 0.2810403108596802, validation loss 0.9063282012939453\n",
      "Epoch 470, current patience 26, model mean validation loss 0.8507269620895386, embedding dim 16, hidden size 512, num layers 1, train loss 0.5009949803352356, validation loss 0.9094730615615845\n",
      "Epoch 480, current patience 25, model mean validation loss 0.8593007326126099, embedding dim 16, hidden size 512, num layers 1, train loss 0.22954878211021423, validation loss 0.8735743165016174\n",
      "Epoch 490, current patience 24, model mean validation loss 0.8662534356117249, embedding dim 16, hidden size 512, num layers 1, train loss 0.6854613423347473, validation loss 0.9026974439620972\n",
      "Epoch 500, current patience 23, model mean validation loss 0.8670812249183655, embedding dim 16, hidden size 512, num layers 1, train loss 0.6021721363067627, validation loss 0.8320937752723694\n",
      "Epoch 510, current patience 22, model mean validation loss 0.8739487528800964, embedding dim 16, hidden size 512, num layers 1, train loss 0.42175382375717163, validation loss 0.8704192638397217\n",
      "Epoch 520, current patience 21, model mean validation loss 0.8770490884780884, embedding dim 16, hidden size 512, num layers 1, train loss 0.36335474252700806, validation loss 0.8829023241996765\n",
      "Epoch 530, current patience 20, model mean validation loss 0.8806298971176147, embedding dim 16, hidden size 512, num layers 1, train loss 0.43587207794189453, validation loss 0.867550790309906\n",
      "Epoch 540, current patience 19, model mean validation loss 0.8756470680236816, embedding dim 16, hidden size 512, num layers 1, train loss 0.28068047761917114, validation loss 0.8664661645889282\n",
      "Epoch 550, current patience 18, model mean validation loss 0.8773608207702637, embedding dim 16, hidden size 512, num layers 1, train loss 0.2314898520708084, validation loss 0.9231829643249512\n",
      "Epoch 560, current patience 17, model mean validation loss 0.8812005519866943, embedding dim 16, hidden size 512, num layers 1, train loss 0.14812317490577698, validation loss 0.9042917490005493\n",
      "Epoch 570, current patience 16, model mean validation loss 0.889256477355957, embedding dim 16, hidden size 512, num layers 1, train loss 0.3188413977622986, validation loss 0.9671452641487122\n",
      "Epoch 580, current patience 15, model mean validation loss 0.909375786781311, embedding dim 16, hidden size 512, num layers 1, train loss 0.36197400093078613, validation loss 0.9930483102798462\n",
      "Epoch 590, current patience 14, model mean validation loss 0.9176797270774841, embedding dim 16, hidden size 512, num layers 1, train loss 0.35068362951278687, validation loss 0.9368506669998169\n",
      "Epoch 600, current patience 13, model mean validation loss 0.9255393743515015, embedding dim 16, hidden size 512, num layers 1, train loss 0.5507678985595703, validation loss 0.945779025554657\n",
      "Epoch 610, current patience 12, model mean validation loss 0.9428310394287109, embedding dim 16, hidden size 512, num layers 1, train loss 0.16232261061668396, validation loss 1.0058836936950684\n",
      "Epoch 620, current patience 11, model mean validation loss 0.9620394706726074, embedding dim 16, hidden size 512, num layers 1, train loss 0.2608500123023987, validation loss 1.0201342105865479\n",
      "Epoch 630, current patience 10, model mean validation loss 0.9703230857849121, embedding dim 16, hidden size 512, num layers 1, train loss 0.4088507294654846, validation loss 0.9894516468048096\n",
      "Epoch 640, current patience 9, model mean validation loss 0.9738730192184448, embedding dim 16, hidden size 512, num layers 1, train loss 0.45302486419677734, validation loss 0.9326911568641663\n",
      "Epoch 650, current patience 8, model mean validation loss 0.9775946140289307, embedding dim 16, hidden size 512, num layers 1, train loss 0.8477860689163208, validation loss 0.9969182014465332\n",
      "Epoch 660, current patience 7, model mean validation loss 0.9701579809188843, embedding dim 16, hidden size 512, num layers 1, train loss 0.3887462019920349, validation loss 0.9335554242134094\n",
      "Epoch 670, current patience 6, model mean validation loss 0.9693668484687805, embedding dim 16, hidden size 512, num layers 1, train loss 0.15652737021446228, validation loss 0.9305211305618286\n",
      "Epoch 680, current patience 5, model mean validation loss 0.9697238802909851, embedding dim 16, hidden size 512, num layers 1, train loss 0.44970810413360596, validation loss 0.9486355781555176\n",
      "Epoch 690, current patience 4, model mean validation loss 0.9746073484420776, embedding dim 16, hidden size 512, num layers 1, train loss 0.38720226287841797, validation loss 1.0449516773223877\n",
      "Epoch 700, current patience 3, model mean validation loss 0.9712347388267517, embedding dim 16, hidden size 512, num layers 1, train loss 0.29577112197875977, validation loss 0.9931532740592957\n",
      "Epoch 710, current patience 2, model mean validation loss 0.9740653038024902, embedding dim 16, hidden size 512, num layers 1, train loss 0.170547753572464, validation loss 1.0120965242385864\n",
      "Epoch 720, current patience 1, model mean validation loss 0.984809398651123, embedding dim 16, hidden size 512, num layers 1, train loss 0.23391121625900269, validation loss 1.0186432600021362\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1938254833221436, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0987861156463623, validation loss 1.1938254833221436\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1457931995391846, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0965356826782227, validation loss 1.0977609157562256\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1319648027420044, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1176494359970093, validation loss 1.1043081283569336\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1225792169570923, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0929276943206787, validation loss 1.0944223403930664\n",
      "Epoch 40, current patience 30, model mean validation loss 1.117248773574829, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0909852981567383, validation loss 1.0959270000457764\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1144565343856812, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0917716026306152, validation loss 1.1004952192306519\n",
      "Epoch 60, current patience 30, model mean validation loss 1.113355040550232, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0905728340148926, validation loss 1.1067463159561157\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1113617420196533, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1087801456451416, validation loss 1.0974082946777344\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0991668701171875, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1126670837402344, validation loss 1.096267580986023\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1020424365997314, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0578358173370361, validation loss 1.1207647323608398\n",
      "Epoch 100, current patience 29, model mean validation loss 1.2682523727416992, embedding dim 16, hidden size 1024, num layers 1, train loss 1.526532769203186, validation loss 2.433987855911255\n",
      "Epoch 110, current patience 28, model mean validation loss 1.3896634578704834, embedding dim 16, hidden size 1024, num layers 1, train loss 1.9016897678375244, validation loss 2.0657100677490234\n",
      "Epoch 120, current patience 27, model mean validation loss 1.468336582183838, embedding dim 16, hidden size 1024, num layers 1, train loss 1.5025033950805664, validation loss 1.7253127098083496\n",
      "Epoch 130, current patience 26, model mean validation loss 1.4699082374572754, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1198792457580566, validation loss 1.1130685806274414\n",
      "Epoch 140, current patience 25, model mean validation loss 1.4810975790023804, embedding dim 16, hidden size 1024, num layers 1, train loss 1.163468599319458, validation loss 1.1962604522705078\n",
      "Epoch 150, current patience 24, model mean validation loss 1.487982153892517, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1869124174118042, validation loss 1.152484655380249\n",
      "Epoch 160, current patience 23, model mean validation loss 1.4900894165039062, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0965156555175781, validation loss 1.1131268739700317\n",
      "Epoch 170, current patience 22, model mean validation loss 1.4874058961868286, embedding dim 16, hidden size 1024, num layers 1, train loss 1.05233633518219, validation loss 1.0992963314056396\n",
      "Epoch 180, current patience 21, model mean validation loss 1.3228451013565063, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1114890575408936, validation loss 1.1175014972686768\n",
      "Epoch 190, current patience 20, model mean validation loss 1.2013921737670898, embedding dim 16, hidden size 1024, num layers 1, train loss 1.139981985092163, validation loss 1.0940864086151123\n",
      "Epoch 200, current patience 19, model mean validation loss 1.122992992401123, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0866138935089111, validation loss 1.098118543624878\n",
      "Epoch 210, current patience 18, model mean validation loss 1.1211659908294678, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1336568593978882, validation loss 1.0984532833099365\n",
      "Epoch 220, current patience 17, model mean validation loss 1.1087106466293335, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0923062562942505, validation loss 1.0966174602508545\n",
      "Epoch 230, current patience 16, model mean validation loss 1.1014388799667358, embedding dim 16, hidden size 1024, num layers 1, train loss 1.074843168258667, validation loss 1.0943107604980469\n",
      "Epoch 240, current patience 15, model mean validation loss 1.1065088510513306, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1726815700531006, validation loss 1.153686761856079\n",
      "Epoch 250, current patience 14, model mean validation loss 1.1120749711990356, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1066138744354248, validation loss 1.1438250541687012\n",
      "Epoch 260, current patience 13, model mean validation loss 1.1145398616790771, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0692557096481323, validation loss 1.1372205018997192\n",
      "Epoch 270, current patience 12, model mean validation loss 1.114575982093811, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0642626285552979, validation loss 1.0943753719329834\n",
      "Epoch 280, current patience 11, model mean validation loss 1.1132915019989014, embedding dim 16, hidden size 1024, num layers 1, train loss 1.061692714691162, validation loss 1.0878429412841797\n",
      "Epoch 290, current patience 10, model mean validation loss 1.1142942905426025, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1180858612060547, validation loss 1.1064748764038086\n",
      "Epoch 300, current patience 9, model mean validation loss 1.1140730381011963, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1057920455932617, validation loss 1.0948481559753418\n",
      "Epoch 310, current patience 8, model mean validation loss 1.115170955657959, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0760347843170166, validation loss 1.1030941009521484\n",
      "Epoch 320, current patience 7, model mean validation loss 1.1160928010940552, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0378754138946533, validation loss 1.161061406135559\n",
      "Epoch 330, current patience 6, model mean validation loss 1.1209766864776611, embedding dim 16, hidden size 1024, num layers 1, train loss 1.1152021884918213, validation loss 1.1828970909118652\n",
      "Epoch 340, current patience 5, model mean validation loss 1.113849401473999, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0818418264389038, validation loss 1.080201506614685\n",
      "Epoch 350, current patience 4, model mean validation loss 1.1150214672088623, embedding dim 16, hidden size 1024, num layers 1, train loss 1.029431700706482, validation loss 1.1037510633468628\n",
      "Epoch 360, current patience 3, model mean validation loss 1.115524172782898, embedding dim 16, hidden size 1024, num layers 1, train loss 0.9866929054260254, validation loss 1.091864824295044\n",
      "Epoch 370, current patience 2, model mean validation loss 1.1162590980529785, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0534882545471191, validation loss 1.1123542785644531\n",
      "Epoch 380, current patience 1, model mean validation loss 1.1172385215759277, embedding dim 16, hidden size 1024, num layers 1, train loss 1.0988194942474365, validation loss 1.1026835441589355\n",
      "Epoch 0, current patience 30, model mean validation loss 1.3935621976852417, embedding dim 16, hidden size 2048, num layers 1, train loss 1.100183129310608, validation loss 1.3935621976852417\n",
      "Epoch 10, current patience 30, model mean validation loss 1.401294231414795, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3976054191589355, validation loss 1.4090263843536377\n",
      "Epoch 20, current patience 29, model mean validation loss 1.365087628364563, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2958266735076904, validation loss 1.2926746606826782\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3358960151672363, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3100923299789429, validation loss 1.248321294784546\n",
      "Epoch 40, current patience 30, model mean validation loss 1.312119483947754, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2040072679519653, validation loss 1.2170135974884033\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2956866025924683, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1290595531463623, validation loss 1.2135212421417236\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2716741561889648, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1654733419418335, validation loss 1.1275999546051025\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2612526416778564, embedding dim 16, hidden size 2048, num layers 1, train loss 1.143326759338379, validation loss 1.1883022785186768\n",
      "Epoch 80, current patience 30, model mean validation loss 1.2420654296875, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1551027297973633, validation loss 1.2400639057159424\n",
      "Epoch 90, current patience 30, model mean validation loss 1.2077500820159912, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1481205224990845, validation loss 1.1345036029815674\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1882210969924927, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1564991474151611, validation loss 1.1364431381225586\n",
      "Epoch 110, current patience 30, model mean validation loss 1.181172251701355, embedding dim 16, hidden size 2048, num layers 1, train loss 1.140669584274292, validation loss 1.1919306516647339\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1712911128997803, embedding dim 16, hidden size 2048, num layers 1, train loss 1.17465341091156, validation loss 1.1379644870758057\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1709976196289062, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1322649717330933, validation loss 1.2111735343933105\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1958343982696533, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2520415782928467, validation loss 1.326293706893921\n",
      "Epoch 150, current patience 29, model mean validation loss 1.1912695169448853, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1247503757476807, validation loss 1.1517832279205322\n",
      "Epoch 160, current patience 28, model mean validation loss 1.179900884628296, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2274863719940186, validation loss 1.1491146087646484\n",
      "Epoch 170, current patience 27, model mean validation loss 1.1817675828933716, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1240272521972656, validation loss 1.1494373083114624\n",
      "Epoch 180, current patience 26, model mean validation loss 1.1820271015167236, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1389695405960083, validation loss 1.1385189294815063\n",
      "Epoch 190, current patience 25, model mean validation loss 1.177730917930603, embedding dim 16, hidden size 2048, num layers 1, train loss 1.095083475112915, validation loss 1.1575613021850586\n",
      "Epoch 200, current patience 24, model mean validation loss 1.1773065328598022, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1334679126739502, validation loss 1.1345689296722412\n",
      "Epoch 210, current patience 23, model mean validation loss 1.1692568063735962, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2382838726043701, validation loss 1.1467756032943726\n",
      "Epoch 220, current patience 30, model mean validation loss 1.1538054943084717, embedding dim 16, hidden size 2048, num layers 1, train loss 1.0819165706634521, validation loss 1.202683448791504\n",
      "Epoch 230, current patience 30, model mean validation loss 1.1514296531677246, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1420128345489502, validation loss 1.132777452468872\n",
      "Epoch 240, current patience 30, model mean validation loss 1.152619481086731, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1259472370147705, validation loss 1.1586335897445679\n",
      "Epoch 250, current patience 29, model mean validation loss 1.1606327295303345, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2051517963409424, validation loss 1.2135424613952637\n",
      "Epoch 260, current patience 28, model mean validation loss 1.1592836380004883, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1899089813232422, validation loss 1.1277269124984741\n",
      "Epoch 270, current patience 27, model mean validation loss 1.1584515571594238, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1796869039535522, validation loss 1.1509045362472534\n",
      "Epoch 280, current patience 26, model mean validation loss 1.1770038604736328, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2623264789581299, validation loss 1.2829864025115967\n",
      "Epoch 290, current patience 25, model mean validation loss 1.1829200983047485, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3544820547103882, validation loss 1.1941062211990356\n",
      "Epoch 300, current patience 24, model mean validation loss 1.176351547241211, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1645370721817017, validation loss 1.1501357555389404\n",
      "Epoch 310, current patience 23, model mean validation loss 1.1833723783493042, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2048181295394897, validation loss 1.18894362449646\n",
      "Epoch 320, current patience 22, model mean validation loss 1.1854279041290283, embedding dim 16, hidden size 2048, num layers 1, train loss 1.155210018157959, validation loss 1.1750779151916504\n",
      "Epoch 330, current patience 21, model mean validation loss 1.198965072631836, embedding dim 16, hidden size 2048, num layers 1, train loss 1.22823965549469, validation loss 1.3218398094177246\n",
      "Epoch 340, current patience 20, model mean validation loss 1.2141897678375244, embedding dim 16, hidden size 2048, num layers 1, train loss 1.294769287109375, validation loss 1.2495238780975342\n",
      "Epoch 350, current patience 19, model mean validation loss 1.243620753288269, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1260671615600586, validation loss 1.386352300643921\n",
      "Epoch 360, current patience 18, model mean validation loss 1.2301476001739502, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3109025955200195, validation loss 1.1752009391784668\n",
      "Epoch 370, current patience 17, model mean validation loss 1.2443933486938477, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1883903741836548, validation loss 1.3080719709396362\n",
      "Epoch 380, current patience 16, model mean validation loss 1.275658369064331, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2248057126998901, validation loss 1.400256872177124\n",
      "Epoch 390, current patience 15, model mean validation loss 1.3129546642303467, embedding dim 16, hidden size 2048, num layers 1, train loss 2.108991861343384, validation loss 1.487313151359558\n",
      "Epoch 400, current patience 14, model mean validation loss 1.4932889938354492, embedding dim 16, hidden size 2048, num layers 1, train loss 2.352069854736328, validation loss 2.6177523136138916\n",
      "Epoch 410, current patience 13, model mean validation loss 1.5306799411773682, embedding dim 16, hidden size 2048, num layers 1, train loss 1.790846586227417, validation loss 1.6209681034088135\n",
      "Epoch 420, current patience 12, model mean validation loss 1.6070940494537354, embedding dim 16, hidden size 2048, num layers 1, train loss 1.4450520277023315, validation loss 1.8608367443084717\n",
      "Epoch 430, current patience 11, model mean validation loss 1.6301460266113281, embedding dim 16, hidden size 2048, num layers 1, train loss 1.7689560651779175, validation loss 1.5707674026489258\n",
      "Epoch 440, current patience 10, model mean validation loss 1.6549124717712402, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3904820680618286, validation loss 1.3733329772949219\n",
      "Epoch 450, current patience 9, model mean validation loss 1.6559826135635376, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2300293445587158, validation loss 1.3166332244873047\n",
      "Epoch 460, current patience 8, model mean validation loss 1.6657214164733887, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3624205589294434, validation loss 1.4781676530838013\n",
      "Epoch 470, current patience 7, model mean validation loss 1.6386680603027344, embedding dim 16, hidden size 2048, num layers 1, train loss 1.1713664531707764, validation loss 1.2708866596221924\n",
      "Epoch 480, current patience 6, model mean validation loss 1.5319831371307373, embedding dim 16, hidden size 2048, num layers 1, train loss 1.9084501266479492, validation loss 1.764272689819336\n",
      "Epoch 490, current patience 5, model mean validation loss 1.496150255203247, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2409299612045288, validation loss 1.3343042135238647\n",
      "Epoch 500, current patience 4, model mean validation loss 1.4685955047607422, embedding dim 16, hidden size 2048, num layers 1, train loss 1.7339363098144531, validation loss 1.6403985023498535\n",
      "Epoch 510, current patience 3, model mean validation loss 1.4514379501342773, embedding dim 16, hidden size 2048, num layers 1, train loss 1.264391541481018, validation loss 1.4335075616836548\n",
      "Epoch 520, current patience 2, model mean validation loss 1.4272047281265259, embedding dim 16, hidden size 2048, num layers 1, train loss 1.3126442432403564, validation loss 1.1794672012329102\n",
      "Epoch 530, current patience 1, model mean validation loss 1.452669382095337, embedding dim 16, hidden size 2048, num layers 1, train loss 1.2495923042297363, validation loss 1.520350456237793\n",
      "Epoch 0, current patience 30, model mean validation loss 1.4740204811096191, embedding dim 32, hidden size 1, num layers 1, train loss 1.4356991052627563, validation loss 1.4740204811096191\n",
      "Epoch 10, current patience 30, model mean validation loss 1.4182556867599487, embedding dim 32, hidden size 1, num layers 1, train loss 1.4060107469558716, validation loss 1.3624908924102783\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3700127601623535, embedding dim 32, hidden size 1, num layers 1, train loss 1.2724252939224243, validation loss 1.273526906967163\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3344380855560303, embedding dim 32, hidden size 1, num layers 1, train loss 1.2002677917480469, validation loss 1.227713942527771\n",
      "Epoch 40, current patience 30, model mean validation loss 1.302280306816101, embedding dim 32, hidden size 1, num layers 1, train loss 1.16609525680542, validation loss 1.173649549484253\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2777448892593384, embedding dim 32, hidden size 1, num layers 1, train loss 1.1702258586883545, validation loss 1.1550666093826294\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2581976652145386, embedding dim 32, hidden size 1, num layers 1, train loss 1.1669635772705078, validation loss 1.1409153938293457\n",
      "Epoch 70, current patience 30, model mean validation loss 1.24125337600708, embedding dim 32, hidden size 1, num layers 1, train loss 1.1118090152740479, validation loss 1.1226427555084229\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1967236995697021, embedding dim 32, hidden size 1, num layers 1, train loss 1.1020399332046509, validation loss 1.117783546447754\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1656875610351562, embedding dim 32, hidden size 1, num layers 1, train loss 1.0981862545013428, validation loss 1.1142017841339111\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1449739933013916, embedding dim 32, hidden size 1, num layers 1, train loss 1.110166072845459, validation loss 1.1078181266784668\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1293385028839111, embedding dim 32, hidden size 1, num layers 1, train loss 1.1161960363388062, validation loss 1.102630615234375\n",
      "Epoch 120, current patience 30, model mean validation loss 1.120534896850586, embedding dim 32, hidden size 1, num layers 1, train loss 1.1078376770019531, validation loss 1.1032201051712036\n",
      "Epoch 130, current patience 30, model mean validation loss 1.113542079925537, embedding dim 32, hidden size 1, num layers 1, train loss 1.0979965925216675, validation loss 1.0991246700286865\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1082574129104614, embedding dim 32, hidden size 1, num layers 1, train loss 1.0926766395568848, validation loss 1.0986382961273193\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1048223972320557, embedding dim 32, hidden size 1, num layers 1, train loss 1.0987577438354492, validation loss 1.09516179561615\n",
      "Epoch 160, current patience 30, model mean validation loss 1.1019097566604614, embedding dim 32, hidden size 1, num layers 1, train loss 1.0912669897079468, validation loss 1.094482660293579\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0993146896362305, embedding dim 32, hidden size 1, num layers 1, train loss 1.0988718271255493, validation loss 1.0934404134750366\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0975075960159302, embedding dim 32, hidden size 1, num layers 1, train loss 1.09656822681427, validation loss 1.0933623313903809\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0962728261947632, embedding dim 32, hidden size 1, num layers 1, train loss 1.0940523147583008, validation loss 1.0927523374557495\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0945537090301514, embedding dim 32, hidden size 1, num layers 1, train loss 1.0942668914794922, validation loss 1.089468240737915\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0929007530212402, embedding dim 32, hidden size 1, num layers 1, train loss 1.0877673625946045, validation loss 1.0859001874923706\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0916104316711426, embedding dim 32, hidden size 1, num layers 1, train loss 1.093395709991455, validation loss 1.0883159637451172\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0909740924835205, embedding dim 32, hidden size 1, num layers 1, train loss 1.074432134628296, validation loss 1.0900704860687256\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0893839597702026, embedding dim 32, hidden size 1, num layers 1, train loss 1.0953106880187988, validation loss 1.0817617177963257\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0862865447998047, embedding dim 32, hidden size 1, num layers 1, train loss 1.0842076539993286, validation loss 1.0686607360839844\n",
      "Epoch 260, current patience 30, model mean validation loss 1.082829236984253, embedding dim 32, hidden size 1, num layers 1, train loss 1.081282138824463, validation loss 1.0657038688659668\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0785331726074219, embedding dim 32, hidden size 1, num layers 1, train loss 0.9766832590103149, validation loss 1.0583842992782593\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0732004642486572, embedding dim 32, hidden size 1, num layers 1, train loss 1.0737273693084717, validation loss 1.0468058586120605\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0683945417404175, embedding dim 32, hidden size 1, num layers 1, train loss 0.9928247928619385, validation loss 1.0474536418914795\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0626728534698486, embedding dim 32, hidden size 1, num layers 1, train loss 0.9024131894111633, validation loss 1.042542576789856\n",
      "Epoch 310, current patience 30, model mean validation loss 1.055599331855774, embedding dim 32, hidden size 1, num layers 1, train loss 0.9055631160736084, validation loss 1.0334818363189697\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0469005107879639, embedding dim 32, hidden size 1, num layers 1, train loss 0.9631621837615967, validation loss 1.012171745300293\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0391570329666138, embedding dim 32, hidden size 1, num layers 1, train loss 0.9223554134368896, validation loss 1.0067129135131836\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0290800333023071, embedding dim 32, hidden size 1, num layers 1, train loss 0.9092121124267578, validation loss 0.9850871562957764\n",
      "Epoch 350, current patience 30, model mean validation loss 1.021880865097046, embedding dim 32, hidden size 1, num layers 1, train loss 0.9618477821350098, validation loss 1.0007909536361694\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0172665119171143, embedding dim 32, hidden size 1, num layers 1, train loss 0.9313655495643616, validation loss 1.0098910331726074\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0096949338912964, embedding dim 32, hidden size 1, num layers 1, train loss 0.9358723759651184, validation loss 0.986880898475647\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0023809671401978, embedding dim 32, hidden size 1, num layers 1, train loss 1.0499467849731445, validation loss 0.984031081199646\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9952589273452759, embedding dim 32, hidden size 1, num layers 1, train loss 0.8795033693313599, validation loss 0.9765061736106873\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9887980222702026, embedding dim 32, hidden size 1, num layers 1, train loss 0.8159906268119812, validation loss 0.9604841470718384\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9842797517776489, embedding dim 32, hidden size 1, num layers 1, train loss 0.813955545425415, validation loss 0.9705666303634644\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9811022877693176, embedding dim 32, hidden size 1, num layers 1, train loss 0.8312889337539673, validation loss 0.9596672058105469\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9749951362609863, embedding dim 32, hidden size 1, num layers 1, train loss 0.8727582097053528, validation loss 0.9519339203834534\n",
      "Epoch 440, current patience 30, model mean validation loss 0.967308759689331, embedding dim 32, hidden size 1, num layers 1, train loss 0.9103369116783142, validation loss 0.94840008020401\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9640612602233887, embedding dim 32, hidden size 1, num layers 1, train loss 0.7909879088401794, validation loss 0.9609002470970154\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9585506319999695, embedding dim 32, hidden size 1, num layers 1, train loss 0.8224289417266846, validation loss 0.9399466514587402\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9564412832260132, embedding dim 32, hidden size 1, num layers 1, train loss 0.9165363311767578, validation loss 0.9596311450004578\n",
      "Epoch 480, current patience 30, model mean validation loss 0.956708550453186, embedding dim 32, hidden size 1, num layers 1, train loss 0.7806688547134399, validation loss 0.9626224040985107\n",
      "Epoch 490, current patience 29, model mean validation loss 0.9535061120986938, embedding dim 32, hidden size 1, num layers 1, train loss 0.7735376358032227, validation loss 0.9449470043182373\n",
      "Epoch 500, current patience 30, model mean validation loss 0.9515706300735474, embedding dim 32, hidden size 1, num layers 1, train loss 0.9092699289321899, validation loss 0.9441835880279541\n",
      "Epoch 510, current patience 30, model mean validation loss 0.949000358581543, embedding dim 32, hidden size 1, num layers 1, train loss 0.872758150100708, validation loss 0.931371808052063\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9514306783676147, embedding dim 32, hidden size 1, num layers 1, train loss 0.7693273425102234, validation loss 0.9678423404693604\n",
      "Epoch 530, current patience 29, model mean validation loss 0.9516249895095825, embedding dim 32, hidden size 1, num layers 1, train loss 0.8998829126358032, validation loss 0.9624549150466919\n",
      "Epoch 540, current patience 28, model mean validation loss 0.9516145586967468, embedding dim 32, hidden size 1, num layers 1, train loss 0.8232821822166443, validation loss 0.9398635625839233\n",
      "Epoch 550, current patience 27, model mean validation loss 0.948032557964325, embedding dim 32, hidden size 1, num layers 1, train loss 0.7655819654464722, validation loss 0.9309749007225037\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9458482265472412, embedding dim 32, hidden size 1, num layers 1, train loss 0.8916184902191162, validation loss 0.9451477527618408\n",
      "Epoch 570, current patience 30, model mean validation loss 0.9423511028289795, embedding dim 32, hidden size 1, num layers 1, train loss 0.83452308177948, validation loss 0.9169700145721436\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9422163367271423, embedding dim 32, hidden size 1, num layers 1, train loss 0.7630585432052612, validation loss 0.9431054592132568\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9463911056518555, embedding dim 32, hidden size 1, num layers 1, train loss 0.8083227872848511, validation loss 0.9647701382637024\n",
      "Epoch 600, current patience 29, model mean validation loss 0.9429125189781189, embedding dim 32, hidden size 1, num layers 1, train loss 0.8275916576385498, validation loss 0.9400131702423096\n",
      "Epoch 610, current patience 28, model mean validation loss 0.9389793276786804, embedding dim 32, hidden size 1, num layers 1, train loss 0.8183541893959045, validation loss 0.9309893846511841\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9391042590141296, embedding dim 32, hidden size 1, num layers 1, train loss 0.8733882904052734, validation loss 0.9408633708953857\n",
      "Epoch 630, current patience 29, model mean validation loss 0.9411388635635376, embedding dim 32, hidden size 1, num layers 1, train loss 0.7473596930503845, validation loss 0.9472513794898987\n",
      "Epoch 640, current patience 28, model mean validation loss 0.9386553764343262, embedding dim 32, hidden size 1, num layers 1, train loss 0.7453280687332153, validation loss 0.9252800941467285\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9425312280654907, embedding dim 32, hidden size 1, num layers 1, train loss 0.720533013343811, validation loss 0.9479767680168152\n",
      "Epoch 660, current patience 29, model mean validation loss 0.9441146850585938, embedding dim 32, hidden size 1, num layers 1, train loss 0.8637154698371887, validation loss 0.9557733535766602\n",
      "Epoch 670, current patience 28, model mean validation loss 0.9416710138320923, embedding dim 32, hidden size 1, num layers 1, train loss 0.6884915828704834, validation loss 0.9452206492424011\n",
      "Epoch 680, current patience 27, model mean validation loss 0.9432375431060791, embedding dim 32, hidden size 1, num layers 1, train loss 0.7715215086936951, validation loss 0.9525454044342041\n",
      "Epoch 690, current patience 26, model mean validation loss 0.9399611949920654, embedding dim 32, hidden size 1, num layers 1, train loss 0.7088968753814697, validation loss 0.9047788381576538\n",
      "Epoch 700, current patience 25, model mean validation loss 0.938292920589447, embedding dim 32, hidden size 1, num layers 1, train loss 0.6702855825424194, validation loss 0.9275168180465698\n",
      "Epoch 710, current patience 30, model mean validation loss 0.9392207860946655, embedding dim 32, hidden size 1, num layers 1, train loss 0.8262330293655396, validation loss 0.9546743631362915\n",
      "Epoch 720, current patience 29, model mean validation loss 0.9386518597602844, embedding dim 32, hidden size 1, num layers 1, train loss 0.9699575304985046, validation loss 0.9207289218902588\n",
      "Epoch 730, current patience 28, model mean validation loss 0.9331958293914795, embedding dim 32, hidden size 1, num layers 1, train loss 0.6987097263336182, validation loss 0.9043287038803101\n",
      "Epoch 740, current patience 30, model mean validation loss 0.9264291524887085, embedding dim 32, hidden size 1, num layers 1, train loss 0.7500479221343994, validation loss 0.9016393423080444\n",
      "Epoch 750, current patience 30, model mean validation loss 0.9210162162780762, embedding dim 32, hidden size 1, num layers 1, train loss 0.8181374669075012, validation loss 0.9019174575805664\n",
      "Epoch 760, current patience 30, model mean validation loss 0.921959638595581, embedding dim 32, hidden size 1, num layers 1, train loss 0.6821438074111938, validation loss 0.9600927829742432\n",
      "Epoch 770, current patience 29, model mean validation loss 0.9257832765579224, embedding dim 32, hidden size 1, num layers 1, train loss 0.8238707184791565, validation loss 0.9353677034378052\n",
      "Epoch 780, current patience 28, model mean validation loss 0.9233784079551697, embedding dim 32, hidden size 1, num layers 1, train loss 0.7393472790718079, validation loss 0.9082779884338379\n",
      "Epoch 790, current patience 27, model mean validation loss 0.9178954362869263, embedding dim 32, hidden size 1, num layers 1, train loss 0.6770907640457153, validation loss 0.9108107089996338\n",
      "Epoch 800, current patience 30, model mean validation loss 0.9189426302909851, embedding dim 32, hidden size 1, num layers 1, train loss 0.6306031942367554, validation loss 0.9291060566902161\n",
      "Epoch 810, current patience 29, model mean validation loss 0.9199684858322144, embedding dim 32, hidden size 1, num layers 1, train loss 0.7347052097320557, validation loss 0.9125362634658813\n",
      "Epoch 820, current patience 28, model mean validation loss 0.9257720708847046, embedding dim 32, hidden size 1, num layers 1, train loss 0.8200030326843262, validation loss 0.9480677843093872\n",
      "Epoch 830, current patience 27, model mean validation loss 0.9307187795639038, embedding dim 32, hidden size 1, num layers 1, train loss 0.7580317258834839, validation loss 0.941490888595581\n",
      "Epoch 840, current patience 26, model mean validation loss 0.9285933971405029, embedding dim 32, hidden size 1, num layers 1, train loss 0.6382585167884827, validation loss 0.9430897235870361\n",
      "Epoch 850, current patience 25, model mean validation loss 0.9311459064483643, embedding dim 32, hidden size 1, num layers 1, train loss 0.7072409987449646, validation loss 0.9557880759239197\n",
      "Epoch 860, current patience 24, model mean validation loss 0.9358623623847961, embedding dim 32, hidden size 1, num layers 1, train loss 0.8087762594223022, validation loss 0.9460095167160034\n",
      "Epoch 870, current patience 23, model mean validation loss 0.9387662410736084, embedding dim 32, hidden size 1, num layers 1, train loss 0.7098137140274048, validation loss 0.934041440486908\n",
      "Epoch 880, current patience 22, model mean validation loss 0.9375145435333252, embedding dim 32, hidden size 1, num layers 1, train loss 0.7189750671386719, validation loss 0.9190926551818848\n",
      "Epoch 890, current patience 21, model mean validation loss 0.9444503784179688, embedding dim 32, hidden size 1, num layers 1, train loss 0.6431159377098083, validation loss 0.968022882938385\n",
      "Epoch 900, current patience 20, model mean validation loss 0.9435296058654785, embedding dim 32, hidden size 1, num layers 1, train loss 0.6551254391670227, validation loss 0.9407014846801758\n",
      "Epoch 910, current patience 19, model mean validation loss 0.938469409942627, embedding dim 32, hidden size 1, num layers 1, train loss 0.6327105164527893, validation loss 0.901009738445282\n",
      "Epoch 920, current patience 18, model mean validation loss 0.9438899159431458, embedding dim 32, hidden size 1, num layers 1, train loss 0.5702295303344727, validation loss 0.9864534139633179\n",
      "Epoch 930, current patience 17, model mean validation loss 0.9480918049812317, embedding dim 32, hidden size 1, num layers 1, train loss 0.7825163006782532, validation loss 0.9894033074378967\n",
      "Epoch 940, current patience 16, model mean validation loss 0.9505829811096191, embedding dim 32, hidden size 1, num layers 1, train loss 0.8544038534164429, validation loss 0.9659388661384583\n",
      "Epoch 950, current patience 15, model mean validation loss 0.9545019865036011, embedding dim 32, hidden size 1, num layers 1, train loss 0.692642092704773, validation loss 0.9653937220573425\n",
      "Epoch 960, current patience 14, model mean validation loss 0.9614951610565186, embedding dim 32, hidden size 1, num layers 1, train loss 0.6041148900985718, validation loss 0.975037693977356\n",
      "Epoch 970, current patience 13, model mean validation loss 0.9594675898551941, embedding dim 32, hidden size 1, num layers 1, train loss 0.6304836273193359, validation loss 0.9518027901649475\n",
      "Epoch 980, current patience 12, model mean validation loss 0.9617794752120972, embedding dim 32, hidden size 1, num layers 1, train loss 0.6729559898376465, validation loss 0.9591963887214661\n",
      "Epoch 990, current patience 11, model mean validation loss 0.9707457423210144, embedding dim 32, hidden size 1, num layers 1, train loss 0.7033495306968689, validation loss 0.9727399349212646\n",
      "Epoch 1000, current patience 10, model mean validation loss 0.9609605073928833, embedding dim 32, hidden size 1, num layers 1, train loss 0.6437615156173706, validation loss 0.9081717133522034\n",
      "Epoch 1010, current patience 9, model mean validation loss 0.9596283435821533, embedding dim 32, hidden size 1, num layers 1, train loss 0.7174350619316101, validation loss 0.9787458777427673\n",
      "Epoch 1020, current patience 8, model mean validation loss 0.9601468443870544, embedding dim 32, hidden size 1, num layers 1, train loss 0.6292579174041748, validation loss 0.9700861573219299\n",
      "Epoch 1030, current patience 7, model mean validation loss 0.9584134221076965, embedding dim 32, hidden size 1, num layers 1, train loss 0.6208662390708923, validation loss 0.9515267610549927\n",
      "Epoch 1040, current patience 6, model mean validation loss 0.9531358480453491, embedding dim 32, hidden size 1, num layers 1, train loss 0.6960053443908691, validation loss 0.9328168034553528\n",
      "Epoch 1050, current patience 5, model mean validation loss 0.9569205045700073, embedding dim 32, hidden size 1, num layers 1, train loss 0.49734383821487427, validation loss 0.9820804595947266\n",
      "Epoch 1060, current patience 4, model mean validation loss 0.9585816860198975, embedding dim 32, hidden size 1, num layers 1, train loss 0.6908831000328064, validation loss 0.9724857807159424\n",
      "Epoch 1070, current patience 3, model mean validation loss 0.9625669717788696, embedding dim 32, hidden size 1, num layers 1, train loss 0.48747891187667847, validation loss 1.0046223402023315\n",
      "Epoch 1080, current patience 2, model mean validation loss 0.9727965593338013, embedding dim 32, hidden size 1, num layers 1, train loss 0.6429734826087952, validation loss 0.9900078177452087\n",
      "Epoch 1090, current patience 1, model mean validation loss 0.9730614423751831, embedding dim 32, hidden size 1, num layers 1, train loss 0.664375901222229, validation loss 0.9808655977249146\n",
      "Epoch 0, current patience 30, model mean validation loss 1.10223388671875, embedding dim 32, hidden size 2, num layers 1, train loss 1.123679280281067, validation loss 1.10223388671875\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0991740226745605, embedding dim 32, hidden size 2, num layers 1, train loss 1.093217372894287, validation loss 1.0961140394210815\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0975245237350464, embedding dim 32, hidden size 2, num layers 1, train loss 1.0886762142181396, validation loss 1.094225287437439\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0975759029388428, embedding dim 32, hidden size 2, num layers 1, train loss 1.0920238494873047, validation loss 1.097730278968811\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0966780185699463, embedding dim 32, hidden size 2, num layers 1, train loss 1.1016452312469482, validation loss 1.093086838722229\n",
      "Epoch 50, current patience 30, model mean validation loss 1.096293330192566, embedding dim 32, hidden size 2, num layers 1, train loss 1.0930471420288086, validation loss 1.094369649887085\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0957818031311035, embedding dim 32, hidden size 2, num layers 1, train loss 1.0766229629516602, validation loss 1.09271240234375\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0949658155441284, embedding dim 32, hidden size 2, num layers 1, train loss 1.100667953491211, validation loss 1.0892542600631714\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0939093828201294, embedding dim 32, hidden size 2, num layers 1, train loss 1.089379072189331, validation loss 1.0937823057174683\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0936352014541626, embedding dim 32, hidden size 2, num layers 1, train loss 1.0893155336380005, validation loss 1.0939204692840576\n",
      "Epoch 100, current patience 30, model mean validation loss 1.09256112575531, embedding dim 32, hidden size 2, num layers 1, train loss 1.0898396968841553, validation loss 1.0856326818466187\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0911332368850708, embedding dim 32, hidden size 2, num layers 1, train loss 1.1043668985366821, validation loss 1.086307168006897\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0903767347335815, embedding dim 32, hidden size 2, num layers 1, train loss 1.0846290588378906, validation loss 1.0870349407196045\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0901308059692383, embedding dim 32, hidden size 2, num layers 1, train loss 1.081797480583191, validation loss 1.0924017429351807\n",
      "Epoch 140, current patience 30, model mean validation loss 1.088658094406128, embedding dim 32, hidden size 2, num layers 1, train loss 1.0813359022140503, validation loss 1.0809308290481567\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0874563455581665, embedding dim 32, hidden size 2, num layers 1, train loss 1.1082853078842163, validation loss 1.0796407461166382\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0856997966766357, embedding dim 32, hidden size 2, num layers 1, train loss 1.0546488761901855, validation loss 1.0797302722930908\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0844719409942627, embedding dim 32, hidden size 2, num layers 1, train loss 1.0721490383148193, validation loss 1.0840973854064941\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0821524858474731, embedding dim 32, hidden size 2, num layers 1, train loss 1.0332539081573486, validation loss 1.0670764446258545\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0796937942504883, embedding dim 32, hidden size 2, num layers 1, train loss 1.0674411058425903, validation loss 1.0666377544403076\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0760570764541626, embedding dim 32, hidden size 2, num layers 1, train loss 0.9215739369392395, validation loss 1.057941198348999\n",
      "Epoch 210, current patience 30, model mean validation loss 1.069754719734192, embedding dim 32, hidden size 2, num layers 1, train loss 1.0374857187271118, validation loss 1.0419833660125732\n",
      "Epoch 220, current patience 30, model mean validation loss 1.06390380859375, embedding dim 32, hidden size 2, num layers 1, train loss 1.0072870254516602, validation loss 1.0341236591339111\n",
      "Epoch 230, current patience 30, model mean validation loss 1.060860276222229, embedding dim 32, hidden size 2, num layers 1, train loss 1.061842441558838, validation loss 1.0552922487258911\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0566941499710083, embedding dim 32, hidden size 2, num layers 1, train loss 0.9992568492889404, validation loss 1.0464012622833252\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0514549016952515, embedding dim 32, hidden size 2, num layers 1, train loss 1.0857374668121338, validation loss 1.0421829223632812\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0482572317123413, embedding dim 32, hidden size 2, num layers 1, train loss 0.9111087322235107, validation loss 1.0414950847625732\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0427868366241455, embedding dim 32, hidden size 2, num layers 1, train loss 1.0187747478485107, validation loss 1.0228748321533203\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0357528924942017, embedding dim 32, hidden size 2, num layers 1, train loss 0.8717809915542603, validation loss 1.0016698837280273\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0296671390533447, embedding dim 32, hidden size 2, num layers 1, train loss 0.8951292037963867, validation loss 0.9932981133460999\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0226253271102905, embedding dim 32, hidden size 2, num layers 1, train loss 0.8872670531272888, validation loss 0.9777887463569641\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0130829811096191, embedding dim 32, hidden size 2, num layers 1, train loss 0.9171591997146606, validation loss 0.9789533615112305\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0022143125534058, embedding dim 32, hidden size 2, num layers 1, train loss 0.8640506267547607, validation loss 0.9594519138336182\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9905919432640076, embedding dim 32, hidden size 2, num layers 1, train loss 0.9473214149475098, validation loss 0.9492033123970032\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9797710180282593, embedding dim 32, hidden size 2, num layers 1, train loss 0.9428607225418091, validation loss 0.9549282789230347\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9710637927055359, embedding dim 32, hidden size 2, num layers 1, train loss 1.0009880065917969, validation loss 0.9532171487808228\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9657974243164062, embedding dim 32, hidden size 2, num layers 1, train loss 0.8044770956039429, validation loss 0.9595386385917664\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9603028297424316, embedding dim 32, hidden size 2, num layers 1, train loss 0.8764845132827759, validation loss 0.9493411779403687\n",
      "Epoch 380, current patience 30, model mean validation loss 0.953222393989563, embedding dim 32, hidden size 2, num layers 1, train loss 0.7819280028343201, validation loss 0.9211455583572388\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9455962181091309, embedding dim 32, hidden size 2, num layers 1, train loss 0.8336718082427979, validation loss 0.9179431796073914\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9411464333534241, embedding dim 32, hidden size 2, num layers 1, train loss 0.6335583329200745, validation loss 0.9238540530204773\n",
      "Epoch 410, current patience 30, model mean validation loss 0.9364602565765381, embedding dim 32, hidden size 2, num layers 1, train loss 0.9295430183410645, validation loss 0.9117141962051392\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9298077821731567, embedding dim 32, hidden size 2, num layers 1, train loss 0.6447047591209412, validation loss 0.9017086029052734\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9253675937652588, embedding dim 32, hidden size 2, num layers 1, train loss 0.665282666683197, validation loss 0.9176955223083496\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9190786480903625, embedding dim 32, hidden size 2, num layers 1, train loss 0.8181852102279663, validation loss 0.9092267155647278\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9126107692718506, embedding dim 32, hidden size 2, num layers 1, train loss 0.8353115320205688, validation loss 0.8975979685783386\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9092963337898254, embedding dim 32, hidden size 2, num layers 1, train loss 0.5963668823242188, validation loss 0.894630491733551\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9054593443870544, embedding dim 32, hidden size 2, num layers 1, train loss 0.5549374222755432, validation loss 0.8872472047805786\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9047387838363647, embedding dim 32, hidden size 2, num layers 1, train loss 0.745947539806366, validation loss 0.9180896878242493\n",
      "Epoch 490, current patience 30, model mean validation loss 0.907626748085022, embedding dim 32, hidden size 2, num layers 1, train loss 0.9376335740089417, validation loss 0.9348180294036865\n",
      "Epoch 500, current patience 29, model mean validation loss 0.9125854969024658, embedding dim 32, hidden size 2, num layers 1, train loss 0.7090911269187927, validation loss 0.9413783550262451\n",
      "Epoch 510, current patience 28, model mean validation loss 0.9097833037376404, embedding dim 32, hidden size 2, num layers 1, train loss 0.6483524441719055, validation loss 0.8952784538269043\n",
      "Epoch 520, current patience 27, model mean validation loss 0.9125180244445801, embedding dim 32, hidden size 2, num layers 1, train loss 0.7712318897247314, validation loss 0.9311037659645081\n",
      "Epoch 530, current patience 26, model mean validation loss 0.9136371612548828, embedding dim 32, hidden size 2, num layers 1, train loss 0.6455881595611572, validation loss 0.9065512418746948\n",
      "Epoch 540, current patience 25, model mean validation loss 0.9185531139373779, embedding dim 32, hidden size 2, num layers 1, train loss 0.6171642541885376, validation loss 0.9339585304260254\n",
      "Epoch 550, current patience 24, model mean validation loss 0.9214686751365662, embedding dim 32, hidden size 2, num layers 1, train loss 0.5589396953582764, validation loss 0.9105712175369263\n",
      "Epoch 560, current patience 23, model mean validation loss 0.9220024347305298, embedding dim 32, hidden size 2, num layers 1, train loss 0.6046590805053711, validation loss 0.9223595857620239\n",
      "Epoch 570, current patience 22, model mean validation loss 0.9175394773483276, embedding dim 32, hidden size 2, num layers 1, train loss 0.7811499834060669, validation loss 0.8991144895553589\n",
      "Epoch 580, current patience 21, model mean validation loss 0.9101002812385559, embedding dim 32, hidden size 2, num layers 1, train loss 0.6739451289176941, validation loss 0.8818644285202026\n",
      "Epoch 590, current patience 20, model mean validation loss 0.9125173091888428, embedding dim 32, hidden size 2, num layers 1, train loss 0.470784068107605, validation loss 0.9146149754524231\n",
      "Epoch 600, current patience 19, model mean validation loss 0.9106745719909668, embedding dim 32, hidden size 2, num layers 1, train loss 0.6777997016906738, validation loss 0.9163622260093689\n",
      "Epoch 610, current patience 18, model mean validation loss 0.9093471765518188, embedding dim 32, hidden size 2, num layers 1, train loss 0.7306545972824097, validation loss 0.8959317207336426\n",
      "Epoch 620, current patience 17, model mean validation loss 0.9051691293716431, embedding dim 32, hidden size 2, num layers 1, train loss 0.5333114862442017, validation loss 0.9005342721939087\n",
      "Epoch 630, current patience 16, model mean validation loss 0.903011679649353, embedding dim 32, hidden size 2, num layers 1, train loss 0.6327601671218872, validation loss 0.893311619758606\n",
      "Epoch 640, current patience 30, model mean validation loss 0.8996391892433167, embedding dim 32, hidden size 2, num layers 1, train loss 0.676601767539978, validation loss 0.8953795433044434\n",
      "Epoch 650, current patience 30, model mean validation loss 0.9043715000152588, embedding dim 32, hidden size 2, num layers 1, train loss 0.7001175880432129, validation loss 0.9369729161262512\n",
      "Epoch 660, current patience 29, model mean validation loss 0.9086803793907166, embedding dim 32, hidden size 2, num layers 1, train loss 0.7170279622077942, validation loss 0.9163360595703125\n",
      "Epoch 670, current patience 28, model mean validation loss 0.9142711162567139, embedding dim 32, hidden size 2, num layers 1, train loss 0.5247572660446167, validation loss 0.9593403339385986\n",
      "Epoch 680, current patience 27, model mean validation loss 0.9175349473953247, embedding dim 32, hidden size 2, num layers 1, train loss 0.6919921040534973, validation loss 0.9424732327461243\n",
      "Epoch 690, current patience 26, model mean validation loss 0.92689049243927, embedding dim 32, hidden size 2, num layers 1, train loss 0.5323783159255981, validation loss 0.9707763195037842\n",
      "Epoch 700, current patience 25, model mean validation loss 0.9327825307846069, embedding dim 32, hidden size 2, num layers 1, train loss 0.6694712042808533, validation loss 0.9476706981658936\n",
      "Epoch 710, current patience 24, model mean validation loss 0.9400851726531982, embedding dim 32, hidden size 2, num layers 1, train loss 0.5506778955459595, validation loss 0.9517322182655334\n",
      "Epoch 720, current patience 23, model mean validation loss 0.9502849578857422, embedding dim 32, hidden size 2, num layers 1, train loss 0.5454097390174866, validation loss 0.9769783020019531\n",
      "Epoch 730, current patience 22, model mean validation loss 0.952890932559967, embedding dim 32, hidden size 2, num layers 1, train loss 0.533292293548584, validation loss 0.95782071352005\n",
      "Epoch 740, current patience 21, model mean validation loss 0.9528344869613647, embedding dim 32, hidden size 2, num layers 1, train loss 0.5307108163833618, validation loss 0.9158840179443359\n",
      "Epoch 750, current patience 20, model mean validation loss 0.9560061693191528, embedding dim 32, hidden size 2, num layers 1, train loss 0.5202269554138184, validation loss 0.9847142696380615\n",
      "Epoch 760, current patience 19, model mean validation loss 0.9536197185516357, embedding dim 32, hidden size 2, num layers 1, train loss 0.579204797744751, validation loss 0.9233811497688293\n",
      "Epoch 770, current patience 18, model mean validation loss 0.9485912322998047, embedding dim 32, hidden size 2, num layers 1, train loss 0.44254839420318604, validation loss 0.9305487871170044\n",
      "Epoch 780, current patience 17, model mean validation loss 0.9477628469467163, embedding dim 32, hidden size 2, num layers 1, train loss 0.6673508882522583, validation loss 0.9410433173179626\n",
      "Epoch 790, current patience 16, model mean validation loss 0.9494694471359253, embedding dim 32, hidden size 2, num layers 1, train loss 0.609448254108429, validation loss 0.9653847217559814\n",
      "Epoch 800, current patience 15, model mean validation loss 0.9458299279212952, embedding dim 32, hidden size 2, num layers 1, train loss 0.6968055963516235, validation loss 0.9478623867034912\n",
      "Epoch 810, current patience 14, model mean validation loss 0.9456372261047363, embedding dim 32, hidden size 2, num layers 1, train loss 0.5802913904190063, validation loss 0.9562792181968689\n",
      "Epoch 820, current patience 13, model mean validation loss 0.9492271542549133, embedding dim 32, hidden size 2, num layers 1, train loss 0.4962335228919983, validation loss 0.9446033835411072\n",
      "Epoch 830, current patience 12, model mean validation loss 0.9456796646118164, embedding dim 32, hidden size 2, num layers 1, train loss 0.4457475244998932, validation loss 0.9563343524932861\n",
      "Epoch 840, current patience 11, model mean validation loss 0.9480719566345215, embedding dim 32, hidden size 2, num layers 1, train loss 0.4886828660964966, validation loss 0.9425197243690491\n",
      "Epoch 850, current patience 10, model mean validation loss 0.95423823595047, embedding dim 32, hidden size 2, num layers 1, train loss 0.7957714796066284, validation loss 0.9798784255981445\n",
      "Epoch 860, current patience 9, model mean validation loss 0.9587481021881104, embedding dim 32, hidden size 2, num layers 1, train loss 0.7794679403305054, validation loss 0.9771227836608887\n",
      "Epoch 870, current patience 8, model mean validation loss 0.953108549118042, embedding dim 32, hidden size 2, num layers 1, train loss 0.5051668882369995, validation loss 0.9202678203582764\n",
      "Epoch 880, current patience 7, model mean validation loss 0.9559069871902466, embedding dim 32, hidden size 2, num layers 1, train loss 0.5568056702613831, validation loss 0.970250129699707\n",
      "Epoch 890, current patience 6, model mean validation loss 0.9575031399726868, embedding dim 32, hidden size 2, num layers 1, train loss 0.7016677856445312, validation loss 0.9690483808517456\n",
      "Epoch 900, current patience 5, model mean validation loss 0.9639209508895874, embedding dim 32, hidden size 2, num layers 1, train loss 0.5027268528938293, validation loss 0.9959460496902466\n",
      "Epoch 910, current patience 4, model mean validation loss 0.9624080657958984, embedding dim 32, hidden size 2, num layers 1, train loss 0.520687460899353, validation loss 0.9442310333251953\n",
      "Epoch 920, current patience 3, model mean validation loss 0.9642811417579651, embedding dim 32, hidden size 2, num layers 1, train loss 0.4918958246707916, validation loss 0.9575047492980957\n",
      "Epoch 930, current patience 2, model mean validation loss 0.9607333540916443, embedding dim 32, hidden size 2, num layers 1, train loss 0.3992249369621277, validation loss 0.9514958262443542\n",
      "Epoch 940, current patience 1, model mean validation loss 0.9604637622833252, embedding dim 32, hidden size 2, num layers 1, train loss 0.660088062286377, validation loss 0.9749660491943359\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1427555084228516, embedding dim 32, hidden size 4, num layers 1, train loss 1.1613308191299438, validation loss 1.1427555084228516\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1268441677093506, embedding dim 32, hidden size 4, num layers 1, train loss 1.1128270626068115, validation loss 1.1109329462051392\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1165255308151245, embedding dim 32, hidden size 4, num layers 1, train loss 1.09562087059021, validation loss 1.0958882570266724\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1100744009017944, embedding dim 32, hidden size 4, num layers 1, train loss 1.085631251335144, validation loss 1.0907211303710938\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1065722703933716, embedding dim 32, hidden size 4, num layers 1, train loss 1.0964374542236328, validation loss 1.0925636291503906\n",
      "Epoch 50, current patience 30, model mean validation loss 1.104020357131958, embedding dim 32, hidden size 4, num layers 1, train loss 1.1023308038711548, validation loss 1.0912606716156006\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1013184785842896, embedding dim 32, hidden size 4, num layers 1, train loss 1.086228370666504, validation loss 1.0851072072982788\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0985193252563477, embedding dim 32, hidden size 4, num layers 1, train loss 1.0423328876495361, validation loss 1.078925371170044\n",
      "Epoch 80, current patience 30, model mean validation loss 1.088073968887329, embedding dim 32, hidden size 4, num layers 1, train loss 1.0876494646072388, validation loss 1.0591926574707031\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0802679061889648, embedding dim 32, hidden size 4, num layers 1, train loss 1.106719732284546, validation loss 1.0484834909439087\n",
      "Epoch 100, current patience 30, model mean validation loss 1.070473313331604, embedding dim 32, hidden size 4, num layers 1, train loss 1.0631303787231445, validation loss 1.0175323486328125\n",
      "Epoch 110, current patience 30, model mean validation loss 1.059098482131958, embedding dim 32, hidden size 4, num layers 1, train loss 1.0048259496688843, validation loss 0.9997223615646362\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0469491481781006, embedding dim 32, hidden size 4, num layers 1, train loss 0.8991518020629883, validation loss 0.9953689575195312\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0333783626556396, embedding dim 32, hidden size 4, num layers 1, train loss 1.0080184936523438, validation loss 0.9826946258544922\n",
      "Epoch 140, current patience 30, model mean validation loss 1.019634485244751, embedding dim 32, hidden size 4, num layers 1, train loss 0.8551567792892456, validation loss 0.9751566648483276\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0062800645828247, embedding dim 32, hidden size 4, num layers 1, train loss 0.9817969799041748, validation loss 0.9720891714096069\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9916102886199951, embedding dim 32, hidden size 4, num layers 1, train loss 0.9004303216934204, validation loss 0.941834568977356\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9749884605407715, embedding dim 32, hidden size 4, num layers 1, train loss 0.9580705165863037, validation loss 0.9155089259147644\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9628065824508667, embedding dim 32, hidden size 4, num layers 1, train loss 0.9710632562637329, validation loss 0.9200776815414429\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9506649971008301, embedding dim 32, hidden size 4, num layers 1, train loss 0.7922655344009399, validation loss 0.902589738368988\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9374099969863892, embedding dim 32, hidden size 4, num layers 1, train loss 0.7751283049583435, validation loss 0.8893289566040039\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9297537803649902, embedding dim 32, hidden size 4, num layers 1, train loss 0.9284096956253052, validation loss 0.9214450120925903\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9193477034568787, embedding dim 32, hidden size 4, num layers 1, train loss 0.8562469482421875, validation loss 0.8919078707695007\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9122177362442017, embedding dim 32, hidden size 4, num layers 1, train loss 0.7285364866256714, validation loss 0.9150494337081909\n",
      "Epoch 240, current patience 30, model mean validation loss 0.901114284992218, embedding dim 32, hidden size 4, num layers 1, train loss 0.7418683767318726, validation loss 0.8530069589614868\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9006303548812866, embedding dim 32, hidden size 4, num layers 1, train loss 0.6929134130477905, validation loss 0.9116370677947998\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8962192535400391, embedding dim 32, hidden size 4, num layers 1, train loss 0.7670016288757324, validation loss 0.8847885131835938\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8975698351860046, embedding dim 32, hidden size 4, num layers 1, train loss 0.9081828594207764, validation loss 0.913394570350647\n",
      "Epoch 280, current patience 29, model mean validation loss 0.8937663435935974, embedding dim 32, hidden size 4, num layers 1, train loss 0.728929877281189, validation loss 0.8589012622833252\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8853577971458435, embedding dim 32, hidden size 4, num layers 1, train loss 0.6082403659820557, validation loss 0.8541767597198486\n",
      "Epoch 300, current patience 30, model mean validation loss 0.881744384765625, embedding dim 32, hidden size 4, num layers 1, train loss 0.8092421293258667, validation loss 0.8630002737045288\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8765128254890442, embedding dim 32, hidden size 4, num layers 1, train loss 0.8165349364280701, validation loss 0.8731970191001892\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8767102360725403, embedding dim 32, hidden size 4, num layers 1, train loss 0.7203637361526489, validation loss 0.8545863032341003\n",
      "Epoch 330, current patience 29, model mean validation loss 0.8719783425331116, embedding dim 32, hidden size 4, num layers 1, train loss 0.5932273268699646, validation loss 0.8737820386886597\n",
      "Epoch 340, current patience 30, model mean validation loss 0.867428183555603, embedding dim 32, hidden size 4, num layers 1, train loss 0.7380330562591553, validation loss 0.8483870625495911\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8586860299110413, embedding dim 32, hidden size 4, num layers 1, train loss 0.7193662524223328, validation loss 0.8434573411941528\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8599462509155273, embedding dim 32, hidden size 4, num layers 1, train loss 0.6689019799232483, validation loss 0.8689831495285034\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8592510223388672, embedding dim 32, hidden size 4, num layers 1, train loss 0.71863853931427, validation loss 0.848614513874054\n",
      "Epoch 380, current patience 28, model mean validation loss 0.8568354845046997, embedding dim 32, hidden size 4, num layers 1, train loss 0.6254574060440063, validation loss 0.8436764478683472\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8554867506027222, embedding dim 32, hidden size 4, num layers 1, train loss 0.7246043086051941, validation loss 0.8624069094657898\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8572414517402649, embedding dim 32, hidden size 4, num layers 1, train loss 0.8119964003562927, validation loss 0.868624210357666\n",
      "Epoch 410, current patience 29, model mean validation loss 0.861064076423645, embedding dim 32, hidden size 4, num layers 1, train loss 1.0760656595230103, validation loss 0.9043630957603455\n",
      "Epoch 420, current patience 28, model mean validation loss 0.8648030757904053, embedding dim 32, hidden size 4, num layers 1, train loss 0.8397729396820068, validation loss 0.8782985806465149\n",
      "Epoch 430, current patience 27, model mean validation loss 0.8647207021713257, embedding dim 32, hidden size 4, num layers 1, train loss 0.6709833741188049, validation loss 0.8427991271018982\n",
      "Epoch 440, current patience 26, model mean validation loss 0.8612918853759766, embedding dim 32, hidden size 4, num layers 1, train loss 0.5031602382659912, validation loss 0.8415520191192627\n",
      "Epoch 450, current patience 25, model mean validation loss 0.8635923862457275, embedding dim 32, hidden size 4, num layers 1, train loss 0.46849462389945984, validation loss 0.8670179843902588\n",
      "Epoch 460, current patience 24, model mean validation loss 0.8660719990730286, embedding dim 32, hidden size 4, num layers 1, train loss 0.6017534732818604, validation loss 0.8635135889053345\n",
      "Epoch 470, current patience 23, model mean validation loss 0.8693233728408813, embedding dim 32, hidden size 4, num layers 1, train loss 0.6761716604232788, validation loss 0.8884183168411255\n",
      "Epoch 480, current patience 22, model mean validation loss 0.8717168569564819, embedding dim 32, hidden size 4, num layers 1, train loss 0.4765245020389557, validation loss 0.8877720832824707\n",
      "Epoch 490, current patience 21, model mean validation loss 0.8620319366455078, embedding dim 32, hidden size 4, num layers 1, train loss 0.5476000905036926, validation loss 0.8268841505050659\n",
      "Epoch 500, current patience 20, model mean validation loss 0.8665204048156738, embedding dim 32, hidden size 4, num layers 1, train loss 0.5512584447860718, validation loss 0.91420578956604\n",
      "Epoch 510, current patience 19, model mean validation loss 0.8751170039176941, embedding dim 32, hidden size 4, num layers 1, train loss 0.5797027945518494, validation loss 0.911571741104126\n",
      "Epoch 520, current patience 18, model mean validation loss 0.8849745392799377, embedding dim 32, hidden size 4, num layers 1, train loss 0.49227777123451233, validation loss 0.9204126596450806\n",
      "Epoch 530, current patience 17, model mean validation loss 0.8919309973716736, embedding dim 32, hidden size 4, num layers 1, train loss 0.4026050567626953, validation loss 0.9226695895195007\n",
      "Epoch 540, current patience 16, model mean validation loss 0.8970233201980591, embedding dim 32, hidden size 4, num layers 1, train loss 0.5166844725608826, validation loss 0.9042524099349976\n",
      "Epoch 550, current patience 15, model mean validation loss 0.897005558013916, embedding dim 32, hidden size 4, num layers 1, train loss 0.6899151802062988, validation loss 0.8882765769958496\n",
      "Epoch 560, current patience 14, model mean validation loss 0.8957239389419556, embedding dim 32, hidden size 4, num layers 1, train loss 0.3991742730140686, validation loss 0.8775193095207214\n",
      "Epoch 570, current patience 13, model mean validation loss 0.908377468585968, embedding dim 32, hidden size 4, num layers 1, train loss 0.45739978551864624, validation loss 0.9281113147735596\n",
      "Epoch 580, current patience 12, model mean validation loss 0.9077292084693909, embedding dim 32, hidden size 4, num layers 1, train loss 0.5010348558425903, validation loss 0.9090201258659363\n",
      "Epoch 590, current patience 11, model mean validation loss 0.9104284048080444, embedding dim 32, hidden size 4, num layers 1, train loss 0.5867083072662354, validation loss 0.9331647753715515\n",
      "Epoch 600, current patience 10, model mean validation loss 0.9086596369743347, embedding dim 32, hidden size 4, num layers 1, train loss 0.4347909986972809, validation loss 0.9062632918357849\n",
      "Epoch 610, current patience 9, model mean validation loss 0.9092429280281067, embedding dim 32, hidden size 4, num layers 1, train loss 0.4551432132720947, validation loss 0.9273354411125183\n",
      "Epoch 620, current patience 8, model mean validation loss 0.9158798456192017, embedding dim 32, hidden size 4, num layers 1, train loss 0.6027178764343262, validation loss 0.9573479890823364\n",
      "Epoch 630, current patience 7, model mean validation loss 0.9173747301101685, embedding dim 32, hidden size 4, num layers 1, train loss 0.661065399646759, validation loss 0.9002362489700317\n",
      "Epoch 640, current patience 6, model mean validation loss 0.9221168756484985, embedding dim 32, hidden size 4, num layers 1, train loss 0.5338385701179504, validation loss 0.9154559373855591\n",
      "Epoch 650, current patience 5, model mean validation loss 0.9262229800224304, embedding dim 32, hidden size 4, num layers 1, train loss 0.5402641296386719, validation loss 0.9609600901603699\n",
      "Epoch 660, current patience 4, model mean validation loss 0.9291406869888306, embedding dim 32, hidden size 4, num layers 1, train loss 0.5798161625862122, validation loss 0.9323618412017822\n",
      "Epoch 670, current patience 3, model mean validation loss 0.9290937781333923, embedding dim 32, hidden size 4, num layers 1, train loss 0.4587141275405884, validation loss 0.9327893257141113\n",
      "Epoch 680, current patience 2, model mean validation loss 0.9325777292251587, embedding dim 32, hidden size 4, num layers 1, train loss 0.589665412902832, validation loss 0.9341347217559814\n",
      "Epoch 690, current patience 1, model mean validation loss 0.932867169380188, embedding dim 32, hidden size 4, num layers 1, train loss 0.4683385491371155, validation loss 0.9296513199806213\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1239001750946045, embedding dim 32, hidden size 8, num layers 1, train loss 1.1046931743621826, validation loss 1.1239001750946045\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1103923320770264, embedding dim 32, hidden size 8, num layers 1, train loss 1.0981438159942627, validation loss 1.0968846082687378\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1061900854110718, embedding dim 32, hidden size 8, num layers 1, train loss 1.09084153175354, validation loss 1.097785472869873\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1031341552734375, embedding dim 32, hidden size 8, num layers 1, train loss 1.0975607633590698, validation loss 1.0939666032791138\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1015442609786987, embedding dim 32, hidden size 8, num layers 1, train loss 1.097765564918518, validation loss 1.0951848030090332\n",
      "Epoch 50, current patience 30, model mean validation loss 1.099985957145691, embedding dim 32, hidden size 8, num layers 1, train loss 1.1010624170303345, validation loss 1.092193841934204\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0989032983779907, embedding dim 32, hidden size 8, num layers 1, train loss 1.0816736221313477, validation loss 1.0924079418182373\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0982292890548706, embedding dim 32, hidden size 8, num layers 1, train loss 1.0954233407974243, validation loss 1.0935115814208984\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0938382148742676, embedding dim 32, hidden size 8, num layers 1, train loss 1.0788946151733398, validation loss 1.0887707471847534\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0929163694381714, embedding dim 32, hidden size 8, num layers 1, train loss 1.0858879089355469, validation loss 1.089510440826416\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0900065898895264, embedding dim 32, hidden size 8, num layers 1, train loss 1.1104686260223389, validation loss 1.0745073556900024\n",
      "Epoch 110, current patience 30, model mean validation loss 1.087266445159912, embedding dim 32, hidden size 8, num layers 1, train loss 1.0948094129562378, validation loss 1.0720443725585938\n",
      "Epoch 120, current patience 30, model mean validation loss 1.081831455230713, embedding dim 32, hidden size 8, num layers 1, train loss 1.041871190071106, validation loss 1.0517055988311768\n",
      "Epoch 130, current patience 30, model mean validation loss 1.073876142501831, embedding dim 32, hidden size 8, num layers 1, train loss 0.9768213033676147, validation loss 1.028550624847412\n",
      "Epoch 140, current patience 30, model mean validation loss 1.06437087059021, embedding dim 32, hidden size 8, num layers 1, train loss 1.0216588973999023, validation loss 1.0163661241531372\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0488590002059937, embedding dim 32, hidden size 8, num layers 1, train loss 0.920128583908081, validation loss 0.9694168567657471\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0277777910232544, embedding dim 32, hidden size 8, num layers 1, train loss 0.9769670963287354, validation loss 0.9201210141181946\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0086755752563477, embedding dim 32, hidden size 8, num layers 1, train loss 0.8047168254852295, validation loss 0.9366923570632935\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9882619380950928, embedding dim 32, hidden size 8, num layers 1, train loss 0.6476249694824219, validation loss 0.9111989140510559\n",
      "Epoch 190, current patience 30, model mean validation loss 0.965741753578186, embedding dim 32, hidden size 8, num layers 1, train loss 1.0304040908813477, validation loss 0.8918827772140503\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9422875642776489, embedding dim 32, hidden size 8, num layers 1, train loss 0.8365291953086853, validation loss 0.8640717267990112\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9206504225730896, embedding dim 32, hidden size 8, num layers 1, train loss 0.7681937217712402, validation loss 0.8554538488388062\n",
      "Epoch 220, current patience 30, model mean validation loss 0.898346483707428, embedding dim 32, hidden size 8, num layers 1, train loss 0.811271071434021, validation loss 0.8379342555999756\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8827980756759644, embedding dim 32, hidden size 8, num layers 1, train loss 0.7347414493560791, validation loss 0.8450301885604858\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8722012042999268, embedding dim 32, hidden size 8, num layers 1, train loss 0.7090263366699219, validation loss 0.8353453874588013\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8555130958557129, embedding dim 32, hidden size 8, num layers 1, train loss 0.7688289880752563, validation loss 0.8031878471374512\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8477451801300049, embedding dim 32, hidden size 8, num layers 1, train loss 0.8167455792427063, validation loss 0.8490553498268127\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8406071662902832, embedding dim 32, hidden size 8, num layers 1, train loss 0.7345538139343262, validation loss 0.8347783088684082\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8315475583076477, embedding dim 32, hidden size 8, num layers 1, train loss 0.8015106320381165, validation loss 0.791595458984375\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8246752619743347, embedding dim 32, hidden size 8, num layers 1, train loss 0.6860846281051636, validation loss 0.8004756569862366\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8229898810386658, embedding dim 32, hidden size 8, num layers 1, train loss 0.5318489074707031, validation loss 0.8244509696960449\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8181090354919434, embedding dim 32, hidden size 8, num layers 1, train loss 0.6959208250045776, validation loss 0.8059832453727722\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8144465088844299, embedding dim 32, hidden size 8, num layers 1, train loss 0.9411745071411133, validation loss 0.8060451149940491\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8170710802078247, embedding dim 32, hidden size 8, num layers 1, train loss 0.5806461572647095, validation loss 0.8241846561431885\n",
      "Epoch 340, current patience 29, model mean validation loss 0.8158044815063477, embedding dim 32, hidden size 8, num layers 1, train loss 0.8433349132537842, validation loss 0.8389225602149963\n",
      "Epoch 350, current patience 28, model mean validation loss 0.8216739892959595, embedding dim 32, hidden size 8, num layers 1, train loss 0.7716102600097656, validation loss 0.8817338943481445\n",
      "Epoch 360, current patience 27, model mean validation loss 0.8312926292419434, embedding dim 32, hidden size 8, num layers 1, train loss 0.5394517183303833, validation loss 0.8685449361801147\n",
      "Epoch 370, current patience 26, model mean validation loss 0.8339770436286926, embedding dim 32, hidden size 8, num layers 1, train loss 0.45994240045547485, validation loss 0.821951150894165\n",
      "Epoch 380, current patience 25, model mean validation loss 0.8365744352340698, embedding dim 32, hidden size 8, num layers 1, train loss 0.6230841875076294, validation loss 0.845229983329773\n",
      "Epoch 390, current patience 24, model mean validation loss 0.8392025828361511, embedding dim 32, hidden size 8, num layers 1, train loss 0.6141057014465332, validation loss 0.8270082473754883\n",
      "Epoch 400, current patience 23, model mean validation loss 0.8453702926635742, embedding dim 32, hidden size 8, num layers 1, train loss 0.6129366159439087, validation loss 0.8553866147994995\n",
      "Epoch 410, current patience 22, model mean validation loss 0.8483771085739136, embedding dim 32, hidden size 8, num layers 1, train loss 0.5745922327041626, validation loss 0.8482394218444824\n",
      "Epoch 420, current patience 21, model mean validation loss 0.8507199287414551, embedding dim 32, hidden size 8, num layers 1, train loss 0.5516816973686218, validation loss 0.8576651811599731\n",
      "Epoch 430, current patience 20, model mean validation loss 0.8455922603607178, embedding dim 32, hidden size 8, num layers 1, train loss 0.5863521695137024, validation loss 0.8407126665115356\n",
      "Epoch 440, current patience 19, model mean validation loss 0.845974326133728, embedding dim 32, hidden size 8, num layers 1, train loss 0.7661358118057251, validation loss 0.871601402759552\n",
      "Epoch 450, current patience 18, model mean validation loss 0.8505393862724304, embedding dim 32, hidden size 8, num layers 1, train loss 0.5174252986907959, validation loss 0.8584719300270081\n",
      "Epoch 460, current patience 17, model mean validation loss 0.8496195077896118, embedding dim 32, hidden size 8, num layers 1, train loss 0.5130680203437805, validation loss 0.837870180606842\n",
      "Epoch 470, current patience 16, model mean validation loss 0.8526016473770142, embedding dim 32, hidden size 8, num layers 1, train loss 0.6965926885604858, validation loss 0.8508655428886414\n",
      "Epoch 480, current patience 15, model mean validation loss 0.8497914671897888, embedding dim 32, hidden size 8, num layers 1, train loss 0.4315720796585083, validation loss 0.8329054117202759\n",
      "Epoch 490, current patience 14, model mean validation loss 0.8459597826004028, embedding dim 32, hidden size 8, num layers 1, train loss 0.45693379640579224, validation loss 0.817585825920105\n",
      "Epoch 500, current patience 13, model mean validation loss 0.8483928442001343, embedding dim 32, hidden size 8, num layers 1, train loss 0.7949365377426147, validation loss 0.8771300911903381\n",
      "Epoch 510, current patience 12, model mean validation loss 0.843142032623291, embedding dim 32, hidden size 8, num layers 1, train loss 0.4133175015449524, validation loss 0.7987060546875\n",
      "Epoch 520, current patience 11, model mean validation loss 0.8424396514892578, embedding dim 32, hidden size 8, num layers 1, train loss 0.5818126797676086, validation loss 0.8659826517105103\n",
      "Epoch 530, current patience 10, model mean validation loss 0.8388043642044067, embedding dim 32, hidden size 8, num layers 1, train loss 0.5399543046951294, validation loss 0.8293884992599487\n",
      "Epoch 540, current patience 9, model mean validation loss 0.8518224358558655, embedding dim 32, hidden size 8, num layers 1, train loss 0.39240193367004395, validation loss 0.9420156478881836\n",
      "Epoch 550, current patience 8, model mean validation loss 0.8587827682495117, embedding dim 32, hidden size 8, num layers 1, train loss 0.3648216128349304, validation loss 0.9065477252006531\n",
      "Epoch 560, current patience 7, model mean validation loss 0.867951512336731, embedding dim 32, hidden size 8, num layers 1, train loss 0.2847481071949005, validation loss 0.9062556028366089\n",
      "Epoch 570, current patience 6, model mean validation loss 0.883378267288208, embedding dim 32, hidden size 8, num layers 1, train loss 0.41677290201187134, validation loss 0.94100022315979\n",
      "Epoch 580, current patience 5, model mean validation loss 0.8839619159698486, embedding dim 32, hidden size 8, num layers 1, train loss 0.5339126586914062, validation loss 0.881798505783081\n",
      "Epoch 590, current patience 4, model mean validation loss 0.89654141664505, embedding dim 32, hidden size 8, num layers 1, train loss 0.40001288056373596, validation loss 0.8993428349494934\n",
      "Epoch 600, current patience 3, model mean validation loss 0.9042860269546509, embedding dim 32, hidden size 8, num layers 1, train loss 0.4187231659889221, validation loss 0.9279390573501587\n",
      "Epoch 610, current patience 2, model mean validation loss 0.9128224849700928, embedding dim 32, hidden size 8, num layers 1, train loss 0.28768402338027954, validation loss 0.8976801037788391\n",
      "Epoch 620, current patience 1, model mean validation loss 0.9090660810470581, embedding dim 32, hidden size 8, num layers 1, train loss 0.2766173183917999, validation loss 0.9119646549224854\n",
      "Epoch 0, current patience 30, model mean validation loss 1.098398208618164, embedding dim 32, hidden size 16, num layers 1, train loss 1.0768896341323853, validation loss 1.098398208618164\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0965230464935303, embedding dim 32, hidden size 16, num layers 1, train loss 1.096632719039917, validation loss 1.094647765159607\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0959428548812866, embedding dim 32, hidden size 16, num layers 1, train loss 1.0960588455200195, validation loss 1.0947823524475098\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0959744453430176, embedding dim 32, hidden size 16, num layers 1, train loss 1.0991203784942627, validation loss 1.0960694551467896\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0948742628097534, embedding dim 32, hidden size 16, num layers 1, train loss 1.1192002296447754, validation loss 1.0904737710952759\n",
      "Epoch 50, current patience 30, model mean validation loss 1.094622015953064, embedding dim 32, hidden size 16, num layers 1, train loss 1.0731230974197388, validation loss 1.0933605432510376\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0926191806793213, embedding dim 32, hidden size 16, num layers 1, train loss 1.0684939622879028, validation loss 1.0806021690368652\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0890812873840332, embedding dim 32, hidden size 16, num layers 1, train loss 0.9845811128616333, validation loss 1.064315915107727\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0823522806167603, embedding dim 32, hidden size 16, num layers 1, train loss 1.0104129314422607, validation loss 1.0445663928985596\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0714733600616455, embedding dim 32, hidden size 16, num layers 1, train loss 0.9234691858291626, validation loss 1.0076169967651367\n",
      "Epoch 100, current patience 30, model mean validation loss 1.055409550666809, embedding dim 32, hidden size 16, num layers 1, train loss 1.0254617929458618, validation loss 0.9662716388702393\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0393178462982178, embedding dim 32, hidden size 16, num layers 1, train loss 0.9356452822685242, validation loss 0.967336118221283\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0187586545944214, embedding dim 32, hidden size 16, num layers 1, train loss 0.9049365520477295, validation loss 0.9259999394416809\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9975481033325195, embedding dim 32, hidden size 16, num layers 1, train loss 1.0377544164657593, validation loss 0.9236757755279541\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9769418835639954, embedding dim 32, hidden size 16, num layers 1, train loss 0.8795080184936523, validation loss 0.915752649307251\n",
      "Epoch 150, current patience 30, model mean validation loss 0.955747663974762, embedding dim 32, hidden size 16, num layers 1, train loss 0.7976240515708923, validation loss 0.8947621583938599\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9331086874008179, embedding dim 32, hidden size 16, num layers 1, train loss 0.728121280670166, validation loss 0.8634545803070068\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9124491214752197, embedding dim 32, hidden size 16, num layers 1, train loss 1.0719279050827026, validation loss 0.8423402309417725\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8991526961326599, embedding dim 32, hidden size 16, num layers 1, train loss 0.8113691806793213, validation loss 0.859900176525116\n",
      "Epoch 190, current patience 30, model mean validation loss 0.880622148513794, embedding dim 32, hidden size 16, num layers 1, train loss 0.7338305711746216, validation loss 0.8190913796424866\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8654251098632812, embedding dim 32, hidden size 16, num layers 1, train loss 0.8919909000396729, validation loss 0.8044233322143555\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8542224168777466, embedding dim 32, hidden size 16, num layers 1, train loss 0.9249399304389954, validation loss 0.8340544104576111\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8432385921478271, embedding dim 32, hidden size 16, num layers 1, train loss 0.6339247822761536, validation loss 0.8278821706771851\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8352210521697998, embedding dim 32, hidden size 16, num layers 1, train loss 0.8113241195678711, validation loss 0.8306219577789307\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8275800347328186, embedding dim 32, hidden size 16, num layers 1, train loss 0.8647916913032532, validation loss 0.8023266792297363\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8270519971847534, embedding dim 32, hidden size 16, num layers 1, train loss 0.7756471633911133, validation loss 0.8381160497665405\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8266270160675049, embedding dim 32, hidden size 16, num layers 1, train loss 0.7780911326408386, validation loss 0.8565003871917725\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8311303853988647, embedding dim 32, hidden size 16, num layers 1, train loss 0.9970395565032959, validation loss 0.8551180362701416\n",
      "Epoch 280, current patience 29, model mean validation loss 0.8345602750778198, embedding dim 32, hidden size 16, num layers 1, train loss 0.7432264685630798, validation loss 0.831862211227417\n",
      "Epoch 290, current patience 28, model mean validation loss 0.8293827176094055, embedding dim 32, hidden size 16, num layers 1, train loss 0.6214340329170227, validation loss 0.7926342487335205\n",
      "Epoch 300, current patience 27, model mean validation loss 0.8236448764801025, embedding dim 32, hidden size 16, num layers 1, train loss 0.5065221786499023, validation loss 0.7819790244102478\n",
      "Epoch 310, current patience 30, model mean validation loss 0.821488082408905, embedding dim 32, hidden size 16, num layers 1, train loss 0.995834231376648, validation loss 0.8133679628372192\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8181999921798706, embedding dim 32, hidden size 16, num layers 1, train loss 0.5000506639480591, validation loss 0.7760214805603027\n",
      "Epoch 330, current patience 30, model mean validation loss 0.8116198182106018, embedding dim 32, hidden size 16, num layers 1, train loss 0.5901049971580505, validation loss 0.7854750156402588\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8065284490585327, embedding dim 32, hidden size 16, num layers 1, train loss 0.5885026454925537, validation loss 0.8157696723937988\n",
      "Epoch 350, current patience 30, model mean validation loss 0.7971458435058594, embedding dim 32, hidden size 16, num layers 1, train loss 0.7119966149330139, validation loss 0.780056893825531\n",
      "Epoch 360, current patience 30, model mean validation loss 0.7910170555114746, embedding dim 32, hidden size 16, num layers 1, train loss 0.7308386564254761, validation loss 0.7828323841094971\n",
      "Epoch 370, current patience 30, model mean validation loss 0.7985191345214844, embedding dim 32, hidden size 16, num layers 1, train loss 0.500698447227478, validation loss 0.8526501655578613\n",
      "Epoch 380, current patience 29, model mean validation loss 0.7969537973403931, embedding dim 32, hidden size 16, num layers 1, train loss 0.7258958220481873, validation loss 0.7694571614265442\n",
      "Epoch 390, current patience 28, model mean validation loss 0.7955100536346436, embedding dim 32, hidden size 16, num layers 1, train loss 0.6834816932678223, validation loss 0.8018178939819336\n",
      "Epoch 400, current patience 27, model mean validation loss 0.7993872761726379, embedding dim 32, hidden size 16, num layers 1, train loss 0.5167753100395203, validation loss 0.8070389628410339\n",
      "Epoch 410, current patience 26, model mean validation loss 0.7995139360427856, embedding dim 32, hidden size 16, num layers 1, train loss 0.8781953454017639, validation loss 0.7864879369735718\n",
      "Epoch 420, current patience 25, model mean validation loss 0.8056536316871643, embedding dim 32, hidden size 16, num layers 1, train loss 0.46702665090560913, validation loss 0.864887535572052\n",
      "Epoch 430, current patience 24, model mean validation loss 0.8101955652236938, embedding dim 32, hidden size 16, num layers 1, train loss 0.5114115476608276, validation loss 0.8163921236991882\n",
      "Epoch 440, current patience 23, model mean validation loss 0.8176720142364502, embedding dim 32, hidden size 16, num layers 1, train loss 0.48657795786857605, validation loss 0.8426439762115479\n",
      "Epoch 450, current patience 22, model mean validation loss 0.8109081387519836, embedding dim 32, hidden size 16, num layers 1, train loss 0.7322705984115601, validation loss 0.7985391616821289\n",
      "Epoch 460, current patience 21, model mean validation loss 0.8219738602638245, embedding dim 32, hidden size 16, num layers 1, train loss 0.6807865500450134, validation loss 0.8579831719398499\n",
      "Epoch 470, current patience 20, model mean validation loss 0.823939859867096, embedding dim 32, hidden size 16, num layers 1, train loss 0.36398881673812866, validation loss 0.8175457715988159\n",
      "Epoch 480, current patience 19, model mean validation loss 0.8247863054275513, embedding dim 32, hidden size 16, num layers 1, train loss 0.45493191480636597, validation loss 0.8138110041618347\n",
      "Epoch 490, current patience 18, model mean validation loss 0.8262354135513306, embedding dim 32, hidden size 16, num layers 1, train loss 0.46972978115081787, validation loss 0.7980801463127136\n",
      "Epoch 500, current patience 17, model mean validation loss 0.8232381939888, embedding dim 32, hidden size 16, num layers 1, train loss 0.45441627502441406, validation loss 0.8409099578857422\n",
      "Epoch 510, current patience 16, model mean validation loss 0.8294024467468262, embedding dim 32, hidden size 16, num layers 1, train loss 0.4248664379119873, validation loss 0.8657068014144897\n",
      "Epoch 520, current patience 15, model mean validation loss 0.825039267539978, embedding dim 32, hidden size 16, num layers 1, train loss 0.6327537298202515, validation loss 0.8077380657196045\n",
      "Epoch 530, current patience 14, model mean validation loss 0.8347020149230957, embedding dim 32, hidden size 16, num layers 1, train loss 0.4914051294326782, validation loss 0.8758412599563599\n",
      "Epoch 540, current patience 13, model mean validation loss 0.8328995108604431, embedding dim 32, hidden size 16, num layers 1, train loss 0.6105575561523438, validation loss 0.8435629606246948\n",
      "Epoch 550, current patience 12, model mean validation loss 0.8352898359298706, embedding dim 32, hidden size 16, num layers 1, train loss 0.44647160172462463, validation loss 0.8366684913635254\n",
      "Epoch 560, current patience 11, model mean validation loss 0.8473398685455322, embedding dim 32, hidden size 16, num layers 1, train loss 0.48143988847732544, validation loss 0.910211443901062\n",
      "Epoch 570, current patience 10, model mean validation loss 0.8516506552696228, embedding dim 32, hidden size 16, num layers 1, train loss 0.3787340521812439, validation loss 0.8325662016868591\n",
      "Epoch 580, current patience 9, model mean validation loss 0.8581128120422363, embedding dim 32, hidden size 16, num layers 1, train loss 0.3761674761772156, validation loss 0.8926070928573608\n",
      "Epoch 590, current patience 8, model mean validation loss 0.8561772108078003, embedding dim 32, hidden size 16, num layers 1, train loss 0.4600982666015625, validation loss 0.8502223491668701\n",
      "Epoch 600, current patience 7, model mean validation loss 0.867731511592865, embedding dim 32, hidden size 16, num layers 1, train loss 0.32543861865997314, validation loss 0.900172233581543\n",
      "Epoch 610, current patience 6, model mean validation loss 0.8725713491439819, embedding dim 32, hidden size 16, num layers 1, train loss 0.40355241298675537, validation loss 0.914560079574585\n",
      "Epoch 620, current patience 5, model mean validation loss 0.8797367811203003, embedding dim 32, hidden size 16, num layers 1, train loss 0.4241945445537567, validation loss 0.9008859395980835\n",
      "Epoch 630, current patience 4, model mean validation loss 0.8940213322639465, embedding dim 32, hidden size 16, num layers 1, train loss 0.5242645740509033, validation loss 0.9509457349777222\n",
      "Epoch 640, current patience 3, model mean validation loss 0.8903000950813293, embedding dim 32, hidden size 16, num layers 1, train loss 0.2547265291213989, validation loss 0.8804413080215454\n",
      "Epoch 650, current patience 2, model mean validation loss 0.9072130918502808, embedding dim 32, hidden size 16, num layers 1, train loss 0.277037650346756, validation loss 0.9678701162338257\n",
      "Epoch 660, current patience 1, model mean validation loss 0.9180254936218262, embedding dim 32, hidden size 16, num layers 1, train loss 0.7112308144569397, validation loss 0.9791057705879211\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1091771125793457, embedding dim 32, hidden size 32, num layers 1, train loss 1.0881963968276978, validation loss 1.1091771125793457\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1016017198562622, embedding dim 32, hidden size 32, num layers 1, train loss 1.090327262878418, validation loss 1.0940263271331787\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0972590446472168, embedding dim 32, hidden size 32, num layers 1, train loss 1.0910677909851074, validation loss 1.088573694229126\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0958666801452637, embedding dim 32, hidden size 32, num layers 1, train loss 1.0793120861053467, validation loss 1.0916897058486938\n",
      "Epoch 40, current patience 30, model mean validation loss 1.094214677810669, embedding dim 32, hidden size 32, num layers 1, train loss 1.0900871753692627, validation loss 1.0876071453094482\n",
      "Epoch 50, current patience 30, model mean validation loss 1.091523289680481, embedding dim 32, hidden size 32, num layers 1, train loss 1.0194342136383057, validation loss 1.0780655145645142\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0843465328216553, embedding dim 32, hidden size 32, num layers 1, train loss 1.0178444385528564, validation loss 1.0412863492965698\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0764904022216797, embedding dim 32, hidden size 32, num layers 1, train loss 0.9498418569564819, validation loss 1.0214974880218506\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0653150081634521, embedding dim 32, hidden size 32, num layers 1, train loss 1.0310100317001343, validation loss 1.0197733640670776\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0494658946990967, embedding dim 32, hidden size 32, num layers 1, train loss 0.9479230642318726, validation loss 0.9672341346740723\n",
      "Epoch 100, current patience 30, model mean validation loss 1.033293604850769, embedding dim 32, hidden size 32, num layers 1, train loss 0.9702576398849487, validation loss 0.9591951370239258\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0142101049423218, embedding dim 32, hidden size 32, num layers 1, train loss 0.9226540327072144, validation loss 0.9390217065811157\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9987269639968872, embedding dim 32, hidden size 32, num layers 1, train loss 0.845749020576477, validation loss 0.963741660118103\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9775089025497437, embedding dim 32, hidden size 32, num layers 1, train loss 0.8097805976867676, validation loss 0.9083207845687866\n",
      "Epoch 140, current patience 30, model mean validation loss 0.96022629737854, embedding dim 32, hidden size 32, num layers 1, train loss 0.8783373832702637, validation loss 0.9030262231826782\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9438024759292603, embedding dim 32, hidden size 32, num layers 1, train loss 0.9168506860733032, validation loss 0.8901073336601257\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9303001761436462, embedding dim 32, hidden size 32, num layers 1, train loss 0.808253288269043, validation loss 0.9117547273635864\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9192556142807007, embedding dim 32, hidden size 32, num layers 1, train loss 0.727123498916626, validation loss 0.8788775205612183\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9191970825195312, embedding dim 32, hidden size 32, num layers 1, train loss 0.7133926153182983, validation loss 0.9587265253067017\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9108462929725647, embedding dim 32, hidden size 32, num layers 1, train loss 0.7305253148078918, validation loss 0.8722155690193176\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9019511342048645, embedding dim 32, hidden size 32, num layers 1, train loss 0.6669413447380066, validation loss 0.8925804495811462\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8940389156341553, embedding dim 32, hidden size 32, num layers 1, train loss 0.8911462426185608, validation loss 0.8450233936309814\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8865890502929688, embedding dim 32, hidden size 32, num layers 1, train loss 0.8170636296272278, validation loss 0.8434271812438965\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8753493428230286, embedding dim 32, hidden size 32, num layers 1, train loss 0.8364588022232056, validation loss 0.800189733505249\n",
      "Epoch 240, current patience 30, model mean validation loss 0.862964391708374, embedding dim 32, hidden size 32, num layers 1, train loss 0.7093591690063477, validation loss 0.8126748204231262\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8495299220085144, embedding dim 32, hidden size 32, num layers 1, train loss 0.6765822172164917, validation loss 0.7714017629623413\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8312645554542542, embedding dim 32, hidden size 32, num layers 1, train loss 0.8554652333259583, validation loss 0.8126034736633301\n",
      "Epoch 270, current patience 30, model mean validation loss 0.818368673324585, embedding dim 32, hidden size 32, num layers 1, train loss 0.8841834664344788, validation loss 0.7690483331680298\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8047534227371216, embedding dim 32, hidden size 32, num layers 1, train loss 0.6265295147895813, validation loss 0.783658504486084\n",
      "Epoch 290, current patience 30, model mean validation loss 0.7961087226867676, embedding dim 32, hidden size 32, num layers 1, train loss 0.593536913394928, validation loss 0.775865912437439\n",
      "Epoch 300, current patience 30, model mean validation loss 0.7912726402282715, embedding dim 32, hidden size 32, num layers 1, train loss 0.6137063503265381, validation loss 0.8047385215759277\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7864019274711609, embedding dim 32, hidden size 32, num layers 1, train loss 0.6794944405555725, validation loss 0.761224091053009\n",
      "Epoch 320, current patience 30, model mean validation loss 0.7793221473693848, embedding dim 32, hidden size 32, num layers 1, train loss 0.7659491300582886, validation loss 0.7560365796089172\n",
      "Epoch 330, current patience 30, model mean validation loss 0.7828363180160522, embedding dim 32, hidden size 32, num layers 1, train loss 0.5242220163345337, validation loss 0.7995153665542603\n",
      "Epoch 340, current patience 29, model mean validation loss 0.782469630241394, embedding dim 32, hidden size 32, num layers 1, train loss 0.8092281222343445, validation loss 0.8096701502799988\n",
      "Epoch 350, current patience 28, model mean validation loss 0.7855958938598633, embedding dim 32, hidden size 32, num layers 1, train loss 0.6103205680847168, validation loss 0.794058084487915\n",
      "Epoch 360, current patience 27, model mean validation loss 0.7872253060340881, embedding dim 32, hidden size 32, num layers 1, train loss 0.5541363954544067, validation loss 0.7966934442520142\n",
      "Epoch 370, current patience 26, model mean validation loss 0.7864224910736084, embedding dim 32, hidden size 32, num layers 1, train loss 0.5287514925003052, validation loss 0.7694441080093384\n",
      "Epoch 380, current patience 25, model mean validation loss 0.7765024900436401, embedding dim 32, hidden size 32, num layers 1, train loss 0.6117978096008301, validation loss 0.7253782749176025\n",
      "Epoch 390, current patience 30, model mean validation loss 0.7788202166557312, embedding dim 32, hidden size 32, num layers 1, train loss 0.66534423828125, validation loss 0.7797653675079346\n",
      "Epoch 400, current patience 29, model mean validation loss 0.7858293056488037, embedding dim 32, hidden size 32, num layers 1, train loss 0.4623115062713623, validation loss 0.812109112739563\n",
      "Epoch 410, current patience 28, model mean validation loss 0.7868611812591553, embedding dim 32, hidden size 32, num layers 1, train loss 0.5663806200027466, validation loss 0.8077710270881653\n",
      "Epoch 420, current patience 27, model mean validation loss 0.7774035930633545, embedding dim 32, hidden size 32, num layers 1, train loss 0.742153525352478, validation loss 0.7340097427368164\n",
      "Epoch 430, current patience 26, model mean validation loss 0.7772793769836426, embedding dim 32, hidden size 32, num layers 1, train loss 0.6596865653991699, validation loss 0.7930637001991272\n",
      "Epoch 440, current patience 25, model mean validation loss 0.7762191295623779, embedding dim 32, hidden size 32, num layers 1, train loss 0.6129469871520996, validation loss 0.7882115840911865\n",
      "Epoch 450, current patience 30, model mean validation loss 0.7747848033905029, embedding dim 32, hidden size 32, num layers 1, train loss 0.3972254991531372, validation loss 0.757969856262207\n",
      "Epoch 460, current patience 30, model mean validation loss 0.7825831174850464, embedding dim 32, hidden size 32, num layers 1, train loss 0.5354058742523193, validation loss 0.7877643704414368\n",
      "Epoch 470, current patience 29, model mean validation loss 0.7846339344978333, embedding dim 32, hidden size 32, num layers 1, train loss 0.5607571601867676, validation loss 0.796172022819519\n",
      "Epoch 480, current patience 28, model mean validation loss 0.7835098505020142, embedding dim 32, hidden size 32, num layers 1, train loss 0.32537949085235596, validation loss 0.8031164407730103\n",
      "Epoch 490, current patience 27, model mean validation loss 0.7858076095581055, embedding dim 32, hidden size 32, num layers 1, train loss 0.6823142766952515, validation loss 0.8261533975601196\n",
      "Epoch 500, current patience 26, model mean validation loss 0.792925238609314, embedding dim 32, hidden size 32, num layers 1, train loss 0.5570389628410339, validation loss 0.7909505367279053\n",
      "Epoch 510, current patience 25, model mean validation loss 0.7949262857437134, embedding dim 32, hidden size 32, num layers 1, train loss 0.4708636999130249, validation loss 0.8090721368789673\n",
      "Epoch 520, current patience 24, model mean validation loss 0.7990428805351257, embedding dim 32, hidden size 32, num layers 1, train loss 0.6172125339508057, validation loss 0.8211445212364197\n",
      "Epoch 530, current patience 23, model mean validation loss 0.7934201955795288, embedding dim 32, hidden size 32, num layers 1, train loss 0.7194802761077881, validation loss 0.7129881978034973\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.7129881978034973_32_32_1_530.pt\n",
      "Epoch 540, current patience 22, model mean validation loss 0.7932021617889404, embedding dim 32, hidden size 32, num layers 1, train loss 0.4824253022670746, validation loss 0.7860202789306641\n",
      "Epoch 550, current patience 21, model mean validation loss 0.7937625646591187, embedding dim 32, hidden size 32, num layers 1, train loss 0.4995596408843994, validation loss 0.800654947757721\n",
      "Epoch 560, current patience 20, model mean validation loss 0.7925125360488892, embedding dim 32, hidden size 32, num layers 1, train loss 0.44128355383872986, validation loss 0.7931159734725952\n",
      "Epoch 570, current patience 19, model mean validation loss 0.7930135726928711, embedding dim 32, hidden size 32, num layers 1, train loss 0.467704176902771, validation loss 0.8301618099212646\n",
      "Epoch 580, current patience 18, model mean validation loss 0.8038415908813477, embedding dim 32, hidden size 32, num layers 1, train loss 0.2992974519729614, validation loss 0.8775748014450073\n",
      "Epoch 590, current patience 17, model mean validation loss 0.8092756867408752, embedding dim 32, hidden size 32, num layers 1, train loss 0.5048038959503174, validation loss 0.8525452613830566\n",
      "Epoch 600, current patience 16, model mean validation loss 0.8083466291427612, embedding dim 32, hidden size 32, num layers 1, train loss 0.4387807548046112, validation loss 0.8137116432189941\n",
      "Epoch 610, current patience 15, model mean validation loss 0.8244025707244873, embedding dim 32, hidden size 32, num layers 1, train loss 0.42042702436447144, validation loss 0.8414357900619507\n",
      "Epoch 620, current patience 14, model mean validation loss 0.8306052684783936, embedding dim 32, hidden size 32, num layers 1, train loss 0.5527375936508179, validation loss 0.8356421589851379\n",
      "Epoch 630, current patience 13, model mean validation loss 0.8290078043937683, embedding dim 32, hidden size 32, num layers 1, train loss 0.39258331060409546, validation loss 0.7878751158714294\n",
      "Epoch 640, current patience 12, model mean validation loss 0.8456927537918091, embedding dim 32, hidden size 32, num layers 1, train loss 0.41442835330963135, validation loss 0.9265950918197632\n",
      "Epoch 650, current patience 11, model mean validation loss 0.8566475510597229, embedding dim 32, hidden size 32, num layers 1, train loss 0.3413010537624359, validation loss 0.9178004264831543\n",
      "Epoch 660, current patience 10, model mean validation loss 0.8534845113754272, embedding dim 32, hidden size 32, num layers 1, train loss 0.4716215133666992, validation loss 0.8522703647613525\n",
      "Epoch 670, current patience 9, model mean validation loss 0.8568336963653564, embedding dim 32, hidden size 32, num layers 1, train loss 0.5032196044921875, validation loss 0.8793392181396484\n",
      "Epoch 680, current patience 8, model mean validation loss 0.8687821626663208, embedding dim 32, hidden size 32, num layers 1, train loss 0.24021023511886597, validation loss 0.9092991352081299\n",
      "Epoch 690, current patience 7, model mean validation loss 0.8799702525138855, embedding dim 32, hidden size 32, num layers 1, train loss 0.23978780210018158, validation loss 0.930940568447113\n",
      "Epoch 700, current patience 6, model mean validation loss 0.8789583444595337, embedding dim 32, hidden size 32, num layers 1, train loss 0.25557249784469604, validation loss 0.8275469541549683\n",
      "Epoch 710, current patience 5, model mean validation loss 0.8902592658996582, embedding dim 32, hidden size 32, num layers 1, train loss 0.48501431941986084, validation loss 0.8782828450202942\n",
      "Epoch 720, current patience 4, model mean validation loss 0.8793933391571045, embedding dim 32, hidden size 32, num layers 1, train loss 0.3469330072402954, validation loss 0.8396668434143066\n",
      "Epoch 730, current patience 3, model mean validation loss 0.8768670558929443, embedding dim 32, hidden size 32, num layers 1, train loss 0.2861288785934448, validation loss 0.8975908756256104\n",
      "Epoch 740, current patience 2, model mean validation loss 0.8828285336494446, embedding dim 32, hidden size 32, num layers 1, train loss 0.5716544389724731, validation loss 0.8999620676040649\n",
      "Epoch 750, current patience 1, model mean validation loss 0.8847103118896484, embedding dim 32, hidden size 32, num layers 1, train loss 0.3361356854438782, validation loss 0.8943934440612793\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0981335639953613, embedding dim 32, hidden size 64, num layers 1, train loss 1.103621482849121, validation loss 1.0981335639953613\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0984113216400146, embedding dim 32, hidden size 64, num layers 1, train loss 1.0981725454330444, validation loss 1.0986891984939575\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0969339609146118, embedding dim 32, hidden size 64, num layers 1, train loss 1.084655523300171, validation loss 1.0939793586730957\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0916088819503784, embedding dim 32, hidden size 64, num layers 1, train loss 1.0937716960906982, validation loss 1.0756334066390991\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0842714309692383, embedding dim 32, hidden size 64, num layers 1, train loss 1.0709329843521118, validation loss 1.0549216270446777\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0773289203643799, embedding dim 32, hidden size 64, num layers 1, train loss 0.9941688776016235, validation loss 1.0426162481307983\n",
      "Epoch 60, current patience 30, model mean validation loss 1.066677212715149, embedding dim 32, hidden size 64, num layers 1, train loss 0.9644184112548828, validation loss 1.002766728401184\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0565308332443237, embedding dim 32, hidden size 64, num layers 1, train loss 0.9413517713546753, validation loss 0.9855069518089294\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0370539426803589, embedding dim 32, hidden size 64, num layers 1, train loss 0.9925057888031006, validation loss 0.9423184394836426\n",
      "Epoch 90, current patience 30, model mean validation loss 1.017561674118042, embedding dim 32, hidden size 64, num layers 1, train loss 1.0966706275939941, validation loss 0.9427506923675537\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0040253400802612, embedding dim 32, hidden size 64, num layers 1, train loss 0.8443958759307861, validation loss 0.9856891632080078\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9866596460342407, embedding dim 32, hidden size 64, num layers 1, train loss 1.0607361793518066, validation loss 0.9367072582244873\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9666239619255066, embedding dim 32, hidden size 64, num layers 1, train loss 0.8178806304931641, validation loss 0.8946360945701599\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9453974962234497, embedding dim 32, hidden size 64, num layers 1, train loss 0.7423619627952576, validation loss 0.8728046417236328\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9277772307395935, embedding dim 32, hidden size 64, num layers 1, train loss 0.9049973487854004, validation loss 0.8618045449256897\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9105051755905151, embedding dim 32, hidden size 64, num layers 1, train loss 0.6623255610466003, validation loss 0.8473305106163025\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8974562883377075, embedding dim 32, hidden size 64, num layers 1, train loss 0.7156493663787842, validation loss 0.8379271030426025\n",
      "Epoch 170, current patience 30, model mean validation loss 0.882811427116394, embedding dim 32, hidden size 64, num layers 1, train loss 0.9206528663635254, validation loss 0.8255918025970459\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8650027513504028, embedding dim 32, hidden size 64, num layers 1, train loss 0.6324439644813538, validation loss 0.8432204723358154\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8535223007202148, embedding dim 32, hidden size 64, num layers 1, train loss 0.8742799758911133, validation loss 0.8448635339736938\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8442767858505249, embedding dim 32, hidden size 64, num layers 1, train loss 0.7716315388679504, validation loss 0.820671558380127\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8372935056686401, embedding dim 32, hidden size 64, num layers 1, train loss 0.6919175386428833, validation loss 0.8169388771057129\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8290289640426636, embedding dim 32, hidden size 64, num layers 1, train loss 0.7516946792602539, validation loss 0.7956881523132324\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8228611350059509, embedding dim 32, hidden size 64, num layers 1, train loss 0.5959093570709229, validation loss 0.7979878187179565\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8156840801239014, embedding dim 32, hidden size 64, num layers 1, train loss 0.660231351852417, validation loss 0.7805105447769165\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8083410263061523, embedding dim 32, hidden size 64, num layers 1, train loss 0.700869083404541, validation loss 0.7668470144271851\n",
      "Epoch 260, current patience 30, model mean validation loss 0.7983497381210327, embedding dim 32, hidden size 64, num layers 1, train loss 0.5054490566253662, validation loss 0.7632907032966614\n",
      "Epoch 270, current patience 30, model mean validation loss 0.7926357388496399, embedding dim 32, hidden size 64, num layers 1, train loss 0.7206366658210754, validation loss 0.7991509437561035\n",
      "Epoch 280, current patience 30, model mean validation loss 0.7856537103652954, embedding dim 32, hidden size 64, num layers 1, train loss 0.8763271570205688, validation loss 0.7648155093193054\n",
      "Epoch 290, current patience 30, model mean validation loss 0.7820789813995361, embedding dim 32, hidden size 64, num layers 1, train loss 0.7891262769699097, validation loss 0.7883414030075073\n",
      "Epoch 300, current patience 30, model mean validation loss 0.7806404232978821, embedding dim 32, hidden size 64, num layers 1, train loss 0.7593487501144409, validation loss 0.7841797471046448\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7790222764015198, embedding dim 32, hidden size 64, num layers 1, train loss 0.6679863929748535, validation loss 0.785042405128479\n",
      "Epoch 320, current patience 30, model mean validation loss 0.7742336988449097, embedding dim 32, hidden size 64, num layers 1, train loss 0.3955264091491699, validation loss 0.7422020435333252\n",
      "Epoch 330, current patience 30, model mean validation loss 0.7735687494277954, embedding dim 32, hidden size 64, num layers 1, train loss 0.5864977836608887, validation loss 0.7615274786949158\n",
      "Epoch 340, current patience 30, model mean validation loss 0.774699866771698, embedding dim 32, hidden size 64, num layers 1, train loss 0.719752311706543, validation loss 0.7723392248153687\n",
      "Epoch 350, current patience 29, model mean validation loss 0.7725951671600342, embedding dim 32, hidden size 64, num layers 1, train loss 0.42138347029685974, validation loss 0.7823140025138855\n",
      "Epoch 360, current patience 30, model mean validation loss 0.7818829417228699, embedding dim 32, hidden size 64, num layers 1, train loss 0.4079205095767975, validation loss 0.8391174077987671\n",
      "Epoch 370, current patience 29, model mean validation loss 0.7797933220863342, embedding dim 32, hidden size 64, num layers 1, train loss 0.4701783359050751, validation loss 0.7716242074966431\n",
      "Epoch 380, current patience 28, model mean validation loss 0.776131272315979, embedding dim 32, hidden size 64, num layers 1, train loss 0.7099233865737915, validation loss 0.7548837065696716\n",
      "Epoch 390, current patience 27, model mean validation loss 0.7746349573135376, embedding dim 32, hidden size 64, num layers 1, train loss 0.6404668092727661, validation loss 0.7730715870857239\n",
      "Epoch 400, current patience 26, model mean validation loss 0.7839055061340332, embedding dim 32, hidden size 64, num layers 1, train loss 0.3811691999435425, validation loss 0.8163666725158691\n",
      "Epoch 410, current patience 25, model mean validation loss 0.7915109395980835, embedding dim 32, hidden size 64, num layers 1, train loss 0.4302080571651459, validation loss 0.8223710656166077\n",
      "Epoch 420, current patience 24, model mean validation loss 0.7929195165634155, embedding dim 32, hidden size 64, num layers 1, train loss 0.6259812116622925, validation loss 0.7836077213287354\n",
      "Epoch 430, current patience 23, model mean validation loss 0.7896164059638977, embedding dim 32, hidden size 64, num layers 1, train loss 0.5437156558036804, validation loss 0.7558891177177429\n",
      "Epoch 440, current patience 22, model mean validation loss 0.7929447889328003, embedding dim 32, hidden size 64, num layers 1, train loss 0.37933075428009033, validation loss 0.86574387550354\n",
      "Epoch 450, current patience 21, model mean validation loss 0.7956439256668091, embedding dim 32, hidden size 64, num layers 1, train loss 0.5496646165847778, validation loss 0.7932173013687134\n",
      "Epoch 460, current patience 20, model mean validation loss 0.8095187544822693, embedding dim 32, hidden size 64, num layers 1, train loss 0.45380324125289917, validation loss 0.8658825159072876\n",
      "Epoch 470, current patience 19, model mean validation loss 0.8133038282394409, embedding dim 32, hidden size 64, num layers 1, train loss 0.5826606154441833, validation loss 0.8033521175384521\n",
      "Epoch 480, current patience 18, model mean validation loss 0.8133707046508789, embedding dim 32, hidden size 64, num layers 1, train loss 0.2794650197029114, validation loss 0.816901683807373\n",
      "Epoch 490, current patience 17, model mean validation loss 0.8212143182754517, embedding dim 32, hidden size 64, num layers 1, train loss 0.1486043781042099, validation loss 0.8851197361946106\n",
      "Epoch 500, current patience 16, model mean validation loss 0.825471818447113, embedding dim 32, hidden size 64, num layers 1, train loss 0.4193122386932373, validation loss 0.8176679611206055\n",
      "Epoch 510, current patience 15, model mean validation loss 0.8300433158874512, embedding dim 32, hidden size 64, num layers 1, train loss 0.43886762857437134, validation loss 0.7924611568450928\n",
      "Epoch 520, current patience 14, model mean validation loss 0.8356818556785583, embedding dim 32, hidden size 64, num layers 1, train loss 0.6857397556304932, validation loss 0.910852313041687\n",
      "Epoch 530, current patience 13, model mean validation loss 0.8424241542816162, embedding dim 32, hidden size 64, num layers 1, train loss 0.5208702683448792, validation loss 0.8471556305885315\n",
      "Epoch 540, current patience 12, model mean validation loss 0.8347452878952026, embedding dim 32, hidden size 64, num layers 1, train loss 0.3844676613807678, validation loss 0.8044512271881104\n",
      "Epoch 550, current patience 11, model mean validation loss 0.8387935161590576, embedding dim 32, hidden size 64, num layers 1, train loss 0.35173383355140686, validation loss 0.8357387185096741\n",
      "Epoch 560, current patience 10, model mean validation loss 0.8375952243804932, embedding dim 32, hidden size 64, num layers 1, train loss 0.5020798444747925, validation loss 0.8073147535324097\n",
      "Epoch 570, current patience 9, model mean validation loss 0.8220912218093872, embedding dim 32, hidden size 64, num layers 1, train loss 0.3107805550098419, validation loss 0.7610880136489868\n",
      "Epoch 580, current patience 8, model mean validation loss 0.8268190622329712, embedding dim 32, hidden size 64, num layers 1, train loss 0.376728892326355, validation loss 0.8554905652999878\n",
      "Epoch 590, current patience 7, model mean validation loss 0.8368355631828308, embedding dim 32, hidden size 64, num layers 1, train loss 0.31507056951522827, validation loss 0.8725934028625488\n",
      "Epoch 600, current patience 6, model mean validation loss 0.8319126963615417, embedding dim 32, hidden size 64, num layers 1, train loss 0.2728390097618103, validation loss 0.8714691400527954\n",
      "Epoch 610, current patience 5, model mean validation loss 0.8369575142860413, embedding dim 32, hidden size 64, num layers 1, train loss 0.18523432314395905, validation loss 0.8875144720077515\n",
      "Epoch 620, current patience 4, model mean validation loss 0.8666207790374756, embedding dim 32, hidden size 64, num layers 1, train loss 0.28267329931259155, validation loss 1.0417571067810059\n",
      "Epoch 630, current patience 3, model mean validation loss 0.871176540851593, embedding dim 32, hidden size 64, num layers 1, train loss 0.47691693902015686, validation loss 0.8721847534179688\n",
      "Epoch 640, current patience 2, model mean validation loss 0.8765395879745483, embedding dim 32, hidden size 64, num layers 1, train loss 0.2638421654701233, validation loss 0.8502190113067627\n",
      "Epoch 650, current patience 1, model mean validation loss 0.9012535810470581, embedding dim 32, hidden size 64, num layers 1, train loss 0.36292898654937744, validation loss 0.9587999582290649\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1051170825958252, embedding dim 32, hidden size 128, num layers 1, train loss 1.106624960899353, validation loss 1.1051170825958252\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0978889465332031, embedding dim 32, hidden size 128, num layers 1, train loss 1.105478048324585, validation loss 1.090660810470581\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0941613912582397, embedding dim 32, hidden size 128, num layers 1, train loss 1.0940215587615967, validation loss 1.0867061614990234\n",
      "Epoch 30, current patience 30, model mean validation loss 1.095169186592102, embedding dim 32, hidden size 128, num layers 1, train loss 1.240752100944519, validation loss 1.0981926918029785\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0914456844329834, embedding dim 32, hidden size 128, num layers 1, train loss 1.0852705240249634, validation loss 1.0765511989593506\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0869704484939575, embedding dim 32, hidden size 128, num layers 1, train loss 0.9967262744903564, validation loss 1.0645947456359863\n",
      "Epoch 60, current patience 30, model mean validation loss 1.08385169506073, embedding dim 32, hidden size 128, num layers 1, train loss 0.9172326922416687, validation loss 1.0651390552520752\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0727730989456177, embedding dim 32, hidden size 128, num layers 1, train loss 1.0349069833755493, validation loss 0.9952234029769897\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0598307847976685, embedding dim 32, hidden size 128, num layers 1, train loss 0.9288185238838196, validation loss 1.0015783309936523\n",
      "Epoch 90, current patience 30, model mean validation loss 1.040212869644165, embedding dim 32, hidden size 128, num layers 1, train loss 0.87763512134552, validation loss 0.9337171316146851\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0250800848007202, embedding dim 32, hidden size 128, num layers 1, train loss 0.874656617641449, validation loss 0.9656438827514648\n",
      "Epoch 110, current patience 30, model mean validation loss 1.001561164855957, embedding dim 32, hidden size 128, num layers 1, train loss 0.8093447089195251, validation loss 0.910041332244873\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9768671989440918, embedding dim 32, hidden size 128, num layers 1, train loss 1.049381971359253, validation loss 0.8789995908737183\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9534124135971069, embedding dim 32, hidden size 128, num layers 1, train loss 0.9227858781814575, validation loss 0.8769568204879761\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9280760288238525, embedding dim 32, hidden size 128, num layers 1, train loss 0.8310939073562622, validation loss 0.86244797706604\n",
      "Epoch 150, current patience 30, model mean validation loss 0.907865047454834, embedding dim 32, hidden size 128, num layers 1, train loss 0.8437366485595703, validation loss 0.8335358500480652\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8863551616668701, embedding dim 32, hidden size 128, num layers 1, train loss 0.8524473905563354, validation loss 0.8294981718063354\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8734419345855713, embedding dim 32, hidden size 128, num layers 1, train loss 0.6239351034164429, validation loss 0.8304118514060974\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8750277757644653, embedding dim 32, hidden size 128, num layers 1, train loss 0.8083727359771729, validation loss 0.9783302545547485\n",
      "Epoch 190, current patience 29, model mean validation loss 0.8692419528961182, embedding dim 32, hidden size 128, num layers 1, train loss 0.7283847332000732, validation loss 0.8637551665306091\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8620828986167908, embedding dim 32, hidden size 128, num layers 1, train loss 0.9336937665939331, validation loss 0.8217273354530334\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8583122491836548, embedding dim 32, hidden size 128, num layers 1, train loss 0.7525928616523743, validation loss 0.8467916250228882\n",
      "Epoch 220, current patience 30, model mean validation loss 0.847986102104187, embedding dim 32, hidden size 128, num layers 1, train loss 0.7678488492965698, validation loss 0.7798389196395874\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8431139588356018, embedding dim 32, hidden size 128, num layers 1, train loss 0.593369722366333, validation loss 0.7945581674575806\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8370842337608337, embedding dim 32, hidden size 128, num layers 1, train loss 0.7633362412452698, validation loss 0.7812603712081909\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8324456214904785, embedding dim 32, hidden size 128, num layers 1, train loss 0.7811603546142578, validation loss 0.7933032512664795\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8081511855125427, embedding dim 32, hidden size 128, num layers 1, train loss 0.6867871284484863, validation loss 0.7839747667312622\n",
      "Epoch 270, current patience 30, model mean validation loss 0.7995373606681824, embedding dim 32, hidden size 128, num layers 1, train loss 0.5157792568206787, validation loss 0.794844388961792\n",
      "Epoch 280, current patience 30, model mean validation loss 0.7946086525917053, embedding dim 32, hidden size 128, num layers 1, train loss 0.48887550830841064, validation loss 0.7822977304458618\n",
      "Epoch 290, current patience 30, model mean validation loss 0.7866814136505127, embedding dim 32, hidden size 128, num layers 1, train loss 0.7561160326004028, validation loss 0.7833735942840576\n",
      "Epoch 300, current patience 30, model mean validation loss 0.7842011451721191, embedding dim 32, hidden size 128, num layers 1, train loss 0.7388399839401245, validation loss 0.7599967122077942\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7773267030715942, embedding dim 32, hidden size 128, num layers 1, train loss 0.6161863207817078, validation loss 0.7395627498626709\n",
      "Epoch 320, current patience 30, model mean validation loss 0.7775338888168335, embedding dim 32, hidden size 128, num layers 1, train loss 0.46336400508880615, validation loss 0.7829177379608154\n",
      "Epoch 330, current patience 29, model mean validation loss 0.7744554281234741, embedding dim 32, hidden size 128, num layers 1, train loss 0.5363274216651917, validation loss 0.7686757445335388\n",
      "Epoch 340, current patience 30, model mean validation loss 0.7798278331756592, embedding dim 32, hidden size 128, num layers 1, train loss 0.5815489292144775, validation loss 0.8269532918930054\n",
      "Epoch 350, current patience 29, model mean validation loss 0.77562415599823, embedding dim 32, hidden size 128, num layers 1, train loss 0.5444725751876831, validation loss 0.7612155675888062\n",
      "Epoch 360, current patience 28, model mean validation loss 0.7712048888206482, embedding dim 32, hidden size 128, num layers 1, train loss 0.4625033736228943, validation loss 0.7469437122344971\n",
      "Epoch 370, current patience 30, model mean validation loss 0.7723298668861389, embedding dim 32, hidden size 128, num layers 1, train loss 0.5632325410842896, validation loss 0.7923733592033386\n",
      "Epoch 380, current patience 29, model mean validation loss 0.7746361494064331, embedding dim 32, hidden size 128, num layers 1, train loss 0.6711385846138, validation loss 0.7784470915794373\n",
      "Epoch 390, current patience 28, model mean validation loss 0.7756009697914124, embedding dim 32, hidden size 128, num layers 1, train loss 0.564279317855835, validation loss 0.7472810745239258\n",
      "Epoch 400, current patience 27, model mean validation loss 0.7783445119857788, embedding dim 32, hidden size 128, num layers 1, train loss 0.7024902105331421, validation loss 0.8048660755157471\n",
      "Epoch 410, current patience 26, model mean validation loss 0.7790646553039551, embedding dim 32, hidden size 128, num layers 1, train loss 0.5830255746841431, validation loss 0.774437427520752\n",
      "Epoch 420, current patience 25, model mean validation loss 0.7739138007164001, embedding dim 32, hidden size 128, num layers 1, train loss 0.5611007213592529, validation loss 0.7857462167739868\n",
      "Epoch 430, current patience 24, model mean validation loss 0.7771788239479065, embedding dim 32, hidden size 128, num layers 1, train loss 0.3828497529029846, validation loss 0.7873357534408569\n",
      "Epoch 440, current patience 23, model mean validation loss 0.7799911499023438, embedding dim 32, hidden size 128, num layers 1, train loss 0.4757451117038727, validation loss 0.7694423794746399\n",
      "Epoch 450, current patience 22, model mean validation loss 0.7865840792655945, embedding dim 32, hidden size 128, num layers 1, train loss 0.48398298025131226, validation loss 0.8451164960861206\n",
      "Epoch 460, current patience 21, model mean validation loss 0.7859468460083008, embedding dim 32, hidden size 128, num layers 1, train loss 0.44394755363464355, validation loss 0.7733492851257324\n",
      "Epoch 470, current patience 20, model mean validation loss 0.7928858399391174, embedding dim 32, hidden size 128, num layers 1, train loss 0.4645939767360687, validation loss 0.8027932643890381\n",
      "Epoch 480, current patience 19, model mean validation loss 0.8001941442489624, embedding dim 32, hidden size 128, num layers 1, train loss 0.4058232307434082, validation loss 0.8633321523666382\n",
      "Epoch 490, current patience 18, model mean validation loss 0.8030948638916016, embedding dim 32, hidden size 128, num layers 1, train loss 0.35113605856895447, validation loss 0.7976431250572205\n",
      "Epoch 500, current patience 17, model mean validation loss 0.8062968254089355, embedding dim 32, hidden size 128, num layers 1, train loss 0.6977000832557678, validation loss 0.8113616704940796\n",
      "Epoch 510, current patience 16, model mean validation loss 0.8054481744766235, embedding dim 32, hidden size 128, num layers 1, train loss 0.40930044651031494, validation loss 0.7805472016334534\n",
      "Epoch 520, current patience 15, model mean validation loss 0.818670928478241, embedding dim 32, hidden size 128, num layers 1, train loss 0.383587121963501, validation loss 0.875224232673645\n",
      "Epoch 530, current patience 14, model mean validation loss 0.8150284290313721, embedding dim 32, hidden size 128, num layers 1, train loss 0.5624003410339355, validation loss 0.8159769177436829\n",
      "Epoch 540, current patience 13, model mean validation loss 0.8243436813354492, embedding dim 32, hidden size 128, num layers 1, train loss 0.6339653134346008, validation loss 0.8478707075119019\n",
      "Epoch 550, current patience 12, model mean validation loss 0.8276830911636353, embedding dim 32, hidden size 128, num layers 1, train loss 0.2321128100156784, validation loss 0.8295087814331055\n",
      "Epoch 560, current patience 11, model mean validation loss 0.829812228679657, embedding dim 32, hidden size 128, num layers 1, train loss 0.44666147232055664, validation loss 0.8803651332855225\n",
      "Epoch 570, current patience 10, model mean validation loss 0.8353197574615479, embedding dim 32, hidden size 128, num layers 1, train loss 0.3044702410697937, validation loss 0.8417036533355713\n",
      "Epoch 580, current patience 9, model mean validation loss 0.8446820378303528, embedding dim 32, hidden size 128, num layers 1, train loss 0.34935232996940613, validation loss 0.8862596154212952\n",
      "Epoch 590, current patience 8, model mean validation loss 0.8586859703063965, embedding dim 32, hidden size 128, num layers 1, train loss 0.3910800516605377, validation loss 0.8925783634185791\n",
      "Epoch 600, current patience 7, model mean validation loss 0.8514081835746765, embedding dim 32, hidden size 128, num layers 1, train loss 0.3055216073989868, validation loss 0.81700199842453\n",
      "Epoch 610, current patience 6, model mean validation loss 0.8587091565132141, embedding dim 32, hidden size 128, num layers 1, train loss 0.30338340997695923, validation loss 0.8743851780891418\n",
      "Epoch 620, current patience 5, model mean validation loss 0.872524619102478, embedding dim 32, hidden size 128, num layers 1, train loss 0.6455036401748657, validation loss 0.9583947062492371\n",
      "Epoch 630, current patience 4, model mean validation loss 0.8701726198196411, embedding dim 32, hidden size 128, num layers 1, train loss 0.41341471672058105, validation loss 0.810692548751831\n",
      "Epoch 640, current patience 3, model mean validation loss 0.8715925812721252, embedding dim 32, hidden size 128, num layers 1, train loss 0.5650204420089722, validation loss 0.8917242884635925\n",
      "Epoch 650, current patience 2, model mean validation loss 0.8743271231651306, embedding dim 32, hidden size 128, num layers 1, train loss 0.5768121480941772, validation loss 0.8635804653167725\n",
      "Epoch 660, current patience 1, model mean validation loss 0.8747652769088745, embedding dim 32, hidden size 128, num layers 1, train loss 0.25411102175712585, validation loss 0.8897648453712463\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1273088455200195, embedding dim 32, hidden size 256, num layers 1, train loss 1.098657250404358, validation loss 1.1273088455200195\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1051589250564575, embedding dim 32, hidden size 256, num layers 1, train loss 1.0581060647964478, validation loss 1.0830090045928955\n",
      "Epoch 20, current patience 30, model mean validation loss 1.101860523223877, embedding dim 32, hidden size 256, num layers 1, train loss 1.0883337259292603, validation loss 1.0952636003494263\n",
      "Epoch 30, current patience 30, model mean validation loss 1.09758460521698, embedding dim 32, hidden size 256, num layers 1, train loss 1.0798978805541992, validation loss 1.084756851196289\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0963993072509766, embedding dim 32, hidden size 256, num layers 1, train loss 1.0803816318511963, validation loss 1.091658115386963\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0885576009750366, embedding dim 32, hidden size 256, num layers 1, train loss 1.0067377090454102, validation loss 1.0493489503860474\n",
      "Epoch 60, current patience 30, model mean validation loss 1.086178183555603, embedding dim 32, hidden size 256, num layers 1, train loss 1.081446647644043, validation loss 1.071902871131897\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0811887979507446, embedding dim 32, hidden size 256, num layers 1, train loss 1.0967679023742676, validation loss 1.0462617874145508\n",
      "Epoch 80, current patience 30, model mean validation loss 1.064936876296997, embedding dim 32, hidden size 256, num layers 1, train loss 0.9784532785415649, validation loss 0.9972943663597107\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0522336959838867, embedding dim 32, hidden size 256, num layers 1, train loss 0.8710203766822815, validation loss 0.9813829064369202\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0378389358520508, embedding dim 32, hidden size 256, num layers 1, train loss 0.8546402454376221, validation loss 0.9801055788993835\n",
      "Epoch 110, current patience 30, model mean validation loss 1.020633339881897, embedding dim 32, hidden size 256, num layers 1, train loss 0.9609803557395935, validation loss 0.9471122622489929\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9964737892150879, embedding dim 32, hidden size 256, num layers 1, train loss 0.9476699233055115, validation loss 0.8983810544013977\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9794833660125732, embedding dim 32, hidden size 256, num layers 1, train loss 0.9771302938461304, validation loss 0.913425862789154\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9571735858917236, embedding dim 32, hidden size 256, num layers 1, train loss 0.7097238302230835, validation loss 0.8934245109558105\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9329839944839478, embedding dim 32, hidden size 256, num layers 1, train loss 0.906265139579773, validation loss 0.8527452945709229\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9135115742683411, embedding dim 32, hidden size 256, num layers 1, train loss 0.8432484269142151, validation loss 0.8415151238441467\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8986132144927979, embedding dim 32, hidden size 256, num layers 1, train loss 0.7917004823684692, validation loss 0.8621958494186401\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8804129362106323, embedding dim 32, hidden size 256, num layers 1, train loss 0.7844210267066956, validation loss 0.8345037698745728\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8681825399398804, embedding dim 32, hidden size 256, num layers 1, train loss 0.873356819152832, validation loss 0.8492688536643982\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8623735308647156, embedding dim 32, hidden size 256, num layers 1, train loss 0.8372316360473633, validation loss 0.8519086837768555\n",
      "Epoch 210, current patience 30, model mean validation loss 0.851688027381897, embedding dim 32, hidden size 256, num layers 1, train loss 0.737866222858429, validation loss 0.8279417157173157\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8428702354431152, embedding dim 32, hidden size 256, num layers 1, train loss 0.9246371984481812, validation loss 0.8228825330734253\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8360113501548767, embedding dim 32, hidden size 256, num layers 1, train loss 0.8301913142204285, validation loss 0.7978739738464355\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8284067511558533, embedding dim 32, hidden size 256, num layers 1, train loss 0.7167109847068787, validation loss 0.7806782126426697\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8265024423599243, embedding dim 32, hidden size 256, num layers 1, train loss 0.4642559587955475, validation loss 0.8469619750976562\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8200055360794067, embedding dim 32, hidden size 256, num layers 1, train loss 0.7433840036392212, validation loss 0.7825281620025635\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8123533725738525, embedding dim 32, hidden size 256, num layers 1, train loss 0.6123883724212646, validation loss 0.7880513668060303\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8150992393493652, embedding dim 32, hidden size 256, num layers 1, train loss 0.406707227230072, validation loss 0.87387615442276\n",
      "Epoch 290, current patience 29, model mean validation loss 0.8108677864074707, embedding dim 32, hidden size 256, num layers 1, train loss 0.5028406381607056, validation loss 0.7940895557403564\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8045807480812073, embedding dim 32, hidden size 256, num layers 1, train loss 0.835359513759613, validation loss 0.7725867033004761\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8075957298278809, embedding dim 32, hidden size 256, num layers 1, train loss 0.5533411502838135, validation loss 0.8219935894012451\n",
      "Epoch 320, current patience 29, model mean validation loss 0.8084728717803955, embedding dim 32, hidden size 256, num layers 1, train loss 0.6505435705184937, validation loss 0.787695586681366\n",
      "Epoch 330, current patience 28, model mean validation loss 0.8007679581642151, embedding dim 32, hidden size 256, num layers 1, train loss 0.6207480430603027, validation loss 0.7853223085403442\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8044599294662476, embedding dim 32, hidden size 256, num layers 1, train loss 0.7093019485473633, validation loss 0.8120641708374023\n",
      "Epoch 350, current patience 29, model mean validation loss 0.8106056451797485, embedding dim 32, hidden size 256, num layers 1, train loss 0.5555911064147949, validation loss 0.8372172117233276\n",
      "Epoch 360, current patience 28, model mean validation loss 0.8075246810913086, embedding dim 32, hidden size 256, num layers 1, train loss 0.7637659907341003, validation loss 0.8492279052734375\n",
      "Epoch 370, current patience 27, model mean validation loss 0.8108728528022766, embedding dim 32, hidden size 256, num layers 1, train loss 0.7640966176986694, validation loss 0.8208754062652588\n",
      "Epoch 380, current patience 26, model mean validation loss 0.8191072344779968, embedding dim 32, hidden size 256, num layers 1, train loss 0.6598818302154541, validation loss 0.8384613990783691\n",
      "Epoch 390, current patience 25, model mean validation loss 0.8238402009010315, embedding dim 32, hidden size 256, num layers 1, train loss 0.4345981478691101, validation loss 0.8598577380180359\n",
      "Epoch 400, current patience 24, model mean validation loss 0.8255583643913269, embedding dim 32, hidden size 256, num layers 1, train loss 0.5544342994689941, validation loss 0.8014407753944397\n",
      "Epoch 410, current patience 23, model mean validation loss 0.8331679701805115, embedding dim 32, hidden size 256, num layers 1, train loss 0.37997832894325256, validation loss 0.8461991548538208\n",
      "Epoch 420, current patience 22, model mean validation loss 0.8453963398933411, embedding dim 32, hidden size 256, num layers 1, train loss 0.5787512063980103, validation loss 0.9098911881446838\n",
      "Epoch 430, current patience 21, model mean validation loss 0.8464404344558716, embedding dim 32, hidden size 256, num layers 1, train loss 0.4010826349258423, validation loss 0.8455700874328613\n",
      "Epoch 440, current patience 20, model mean validation loss 0.8488783240318298, embedding dim 32, hidden size 256, num layers 1, train loss 0.34301072359085083, validation loss 0.8687304258346558\n",
      "Epoch 450, current patience 19, model mean validation loss 0.8539661169052124, embedding dim 32, hidden size 256, num layers 1, train loss 0.5148196220397949, validation loss 0.861578106880188\n",
      "Epoch 460, current patience 18, model mean validation loss 0.8557471632957458, embedding dim 32, hidden size 256, num layers 1, train loss 0.12240530550479889, validation loss 0.8527097702026367\n",
      "Epoch 470, current patience 17, model mean validation loss 0.852213978767395, embedding dim 32, hidden size 256, num layers 1, train loss 0.5299354791641235, validation loss 0.831591784954071\n",
      "Epoch 480, current patience 16, model mean validation loss 0.8582117557525635, embedding dim 32, hidden size 256, num layers 1, train loss 0.4920480251312256, validation loss 0.8494237065315247\n",
      "Epoch 490, current patience 15, model mean validation loss 0.8644767999649048, embedding dim 32, hidden size 256, num layers 1, train loss 0.48586174845695496, validation loss 0.8963191509246826\n",
      "Epoch 500, current patience 14, model mean validation loss 0.8594080209732056, embedding dim 32, hidden size 256, num layers 1, train loss 0.4611506164073944, validation loss 0.8693406581878662\n",
      "Epoch 510, current patience 13, model mean validation loss 0.8635756969451904, embedding dim 32, hidden size 256, num layers 1, train loss 0.23187071084976196, validation loss 0.8789117336273193\n",
      "Epoch 520, current patience 12, model mean validation loss 0.8653994798660278, embedding dim 32, hidden size 256, num layers 1, train loss 0.4422811269760132, validation loss 0.8833209872245789\n",
      "Epoch 530, current patience 11, model mean validation loss 0.8720190525054932, embedding dim 32, hidden size 256, num layers 1, train loss 0.19604098796844482, validation loss 0.9145346283912659\n",
      "Epoch 540, current patience 10, model mean validation loss 0.8940074443817139, embedding dim 32, hidden size 256, num layers 1, train loss 0.24565866589546204, validation loss 1.028617262840271\n",
      "Epoch 550, current patience 9, model mean validation loss 0.9163193106651306, embedding dim 32, hidden size 256, num layers 1, train loss 0.5165876150131226, validation loss 1.0100864171981812\n",
      "Epoch 560, current patience 8, model mean validation loss 0.9376104474067688, embedding dim 32, hidden size 256, num layers 1, train loss 0.13198742270469666, validation loss 1.0197527408599854\n",
      "Epoch 570, current patience 7, model mean validation loss 0.9587496519088745, embedding dim 32, hidden size 256, num layers 1, train loss 0.23962989449501038, validation loss 1.0654323101043701\n",
      "Epoch 580, current patience 6, model mean validation loss 0.9651280045509338, embedding dim 32, hidden size 256, num layers 1, train loss 0.23748928308486938, validation loss 0.9203684329986572\n",
      "Epoch 590, current patience 5, model mean validation loss 0.9813627004623413, embedding dim 32, hidden size 256, num layers 1, train loss 0.42840901017189026, validation loss 1.0087885856628418\n",
      "Epoch 600, current patience 4, model mean validation loss 1.0016690492630005, embedding dim 32, hidden size 256, num layers 1, train loss 0.13080903887748718, validation loss 1.0457720756530762\n",
      "Epoch 610, current patience 3, model mean validation loss 1.0160154104232788, embedding dim 32, hidden size 256, num layers 1, train loss 0.3935188055038452, validation loss 1.0293055772781372\n",
      "Epoch 620, current patience 2, model mean validation loss 1.01286780834198, embedding dim 32, hidden size 256, num layers 1, train loss 0.16081179678440094, validation loss 1.003435730934143\n",
      "Epoch 630, current patience 1, model mean validation loss 1.0124789476394653, embedding dim 32, hidden size 256, num layers 1, train loss 0.3298450708389282, validation loss 1.0069756507873535\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1699384450912476, embedding dim 32, hidden size 512, num layers 1, train loss 1.0977305173873901, validation loss 1.1699384450912476\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1310791969299316, embedding dim 32, hidden size 512, num layers 1, train loss 1.1002750396728516, validation loss 1.0922198295593262\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1196650266647339, embedding dim 32, hidden size 512, num layers 1, train loss 1.0940042734146118, validation loss 1.0968364477157593\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1130714416503906, embedding dim 32, hidden size 512, num layers 1, train loss 1.1028110980987549, validation loss 1.0932905673980713\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1105226278305054, embedding dim 32, hidden size 512, num layers 1, train loss 1.0543166399002075, validation loss 1.1003282070159912\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1080876588821411, embedding dim 32, hidden size 512, num layers 1, train loss 1.1002304553985596, validation loss 1.0959129333496094\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1069847345352173, embedding dim 32, hidden size 512, num layers 1, train loss 1.10081148147583, validation loss 1.1003659963607788\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1047756671905518, embedding dim 32, hidden size 512, num layers 1, train loss 1.0788766145706177, validation loss 1.0893127918243408\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0946699380874634, embedding dim 32, hidden size 512, num layers 1, train loss 1.0882116556167603, validation loss 1.0890932083129883\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0946776866912842, embedding dim 32, hidden size 512, num layers 1, train loss 1.0441559553146362, validation loss 1.0922813415527344\n",
      "Epoch 100, current patience 29, model mean validation loss 1.0925524234771729, embedding dim 32, hidden size 512, num layers 1, train loss 1.094710350036621, validation loss 1.079835057258606\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0866694450378418, embedding dim 32, hidden size 512, num layers 1, train loss 0.9994699358940125, validation loss 1.0462257862091064\n",
      "Epoch 120, current patience 30, model mean validation loss 1.073103904724121, embedding dim 32, hidden size 512, num layers 1, train loss 1.1322171688079834, validation loss 0.9918039441108704\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0597331523895264, embedding dim 32, hidden size 512, num layers 1, train loss 1.0467207431793213, validation loss 0.9889469146728516\n",
      "Epoch 140, current patience 30, model mean validation loss 1.043566346168518, embedding dim 32, hidden size 512, num layers 1, train loss 0.9123668074607849, validation loss 0.9710320234298706\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0225183963775635, embedding dim 32, hidden size 512, num layers 1, train loss 0.9048589468002319, validation loss 0.9209288954734802\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9988039135932922, embedding dim 32, hidden size 512, num layers 1, train loss 0.8741753101348877, validation loss 0.8993775844573975\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9719537496566772, embedding dim 32, hidden size 512, num layers 1, train loss 0.8656982183456421, validation loss 0.8774800300598145\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9554916024208069, embedding dim 32, hidden size 512, num layers 1, train loss 0.8450276851654053, validation loss 0.9481379985809326\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9310793876647949, embedding dim 32, hidden size 512, num layers 1, train loss 0.8645769357681274, validation loss 0.8509281277656555\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9168719053268433, embedding dim 32, hidden size 512, num layers 1, train loss 0.650519073009491, validation loss 0.8781436681747437\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8998992443084717, embedding dim 32, hidden size 512, num layers 1, train loss 0.646141529083252, validation loss 0.853165864944458\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8829880952835083, embedding dim 32, hidden size 512, num layers 1, train loss 0.8263107538223267, validation loss 0.835742175579071\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8734737634658813, embedding dim 32, hidden size 512, num layers 1, train loss 0.792999804019928, validation loss 0.844814658164978\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8701483011245728, embedding dim 32, hidden size 512, num layers 1, train loss 0.7100486755371094, validation loss 0.8727740049362183\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8632931709289551, embedding dim 32, hidden size 512, num layers 1, train loss 0.6699733734130859, validation loss 0.822638988494873\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8479121923446655, embedding dim 32, hidden size 512, num layers 1, train loss 0.6357654333114624, validation loss 0.8250904679298401\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8434128165245056, embedding dim 32, hidden size 512, num layers 1, train loss 0.9512933492660522, validation loss 0.8149328827857971\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8328630328178406, embedding dim 32, hidden size 512, num layers 1, train loss 0.7906005382537842, validation loss 0.7937451601028442\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8265729546546936, embedding dim 32, hidden size 512, num layers 1, train loss 0.9130251407623291, validation loss 0.8028451204299927\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8261705636978149, embedding dim 32, hidden size 512, num layers 1, train loss 0.4701085090637207, validation loss 0.8325235247612\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8246784210205078, embedding dim 32, hidden size 512, num layers 1, train loss 0.7776868939399719, validation loss 0.8328770399093628\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8170011639595032, embedding dim 32, hidden size 512, num layers 1, train loss 0.477492094039917, validation loss 0.8113559484481812\n",
      "Epoch 330, current patience 30, model mean validation loss 0.814250648021698, embedding dim 32, hidden size 512, num layers 1, train loss 0.8036097288131714, validation loss 0.8006347417831421\n",
      "Epoch 340, current patience 30, model mean validation loss 0.8077654838562012, embedding dim 32, hidden size 512, num layers 1, train loss 0.4823061525821686, validation loss 0.7732095718383789\n",
      "Epoch 350, current patience 30, model mean validation loss 0.8109893798828125, embedding dim 32, hidden size 512, num layers 1, train loss 0.7016026973724365, validation loss 0.8407239317893982\n",
      "Epoch 360, current patience 29, model mean validation loss 0.8171132206916809, embedding dim 32, hidden size 512, num layers 1, train loss 0.3295421004295349, validation loss 0.842735767364502\n",
      "Epoch 370, current patience 28, model mean validation loss 0.822787880897522, embedding dim 32, hidden size 512, num layers 1, train loss 0.4738181233406067, validation loss 0.8482425212860107\n",
      "Epoch 380, current patience 27, model mean validation loss 0.8205439448356628, embedding dim 32, hidden size 512, num layers 1, train loss 0.7455952763557434, validation loss 0.8145724534988403\n",
      "Epoch 390, current patience 26, model mean validation loss 0.8221795558929443, embedding dim 32, hidden size 512, num layers 1, train loss 0.4816196858882904, validation loss 0.8459617495536804\n",
      "Epoch 400, current patience 25, model mean validation loss 0.8361348509788513, embedding dim 32, hidden size 512, num layers 1, train loss 0.3410216271877289, validation loss 0.9229980707168579\n",
      "Epoch 410, current patience 24, model mean validation loss 0.8467413187026978, embedding dim 32, hidden size 512, num layers 1, train loss 0.6956499814987183, validation loss 0.8854862451553345\n",
      "Epoch 420, current patience 23, model mean validation loss 0.8574103116989136, embedding dim 32, hidden size 512, num layers 1, train loss 0.3095451593399048, validation loss 0.8585621118545532\n",
      "Epoch 430, current patience 22, model mean validation loss 0.8647032976150513, embedding dim 32, hidden size 512, num layers 1, train loss 0.377704381942749, validation loss 0.8990676403045654\n",
      "Epoch 440, current patience 21, model mean validation loss 0.8718725442886353, embedding dim 32, hidden size 512, num layers 1, train loss 0.6925674676895142, validation loss 0.9000893831253052\n",
      "Epoch 450, current patience 20, model mean validation loss 0.8714427351951599, embedding dim 32, hidden size 512, num layers 1, train loss 0.3342132866382599, validation loss 0.8448041081428528\n",
      "Epoch 460, current patience 19, model mean validation loss 0.8763290643692017, embedding dim 32, hidden size 512, num layers 1, train loss 0.28463172912597656, validation loss 0.8536626696586609\n",
      "Epoch 470, current patience 18, model mean validation loss 0.8857280015945435, embedding dim 32, hidden size 512, num layers 1, train loss 0.4118041396141052, validation loss 0.9211535453796387\n",
      "Epoch 480, current patience 17, model mean validation loss 0.8825006484985352, embedding dim 32, hidden size 512, num layers 1, train loss 0.3279169499874115, validation loss 0.8971792459487915\n",
      "Epoch 490, current patience 16, model mean validation loss 0.8827722072601318, embedding dim 32, hidden size 512, num layers 1, train loss 0.21166455745697021, validation loss 0.8876587748527527\n",
      "Epoch 500, current patience 15, model mean validation loss 0.8891868591308594, embedding dim 32, hidden size 512, num layers 1, train loss 0.1671256422996521, validation loss 0.9098795652389526\n",
      "Epoch 510, current patience 14, model mean validation loss 0.9006936550140381, embedding dim 32, hidden size 512, num layers 1, train loss 0.35620051622390747, validation loss 0.9911215305328369\n",
      "Epoch 520, current patience 13, model mean validation loss 0.9177500605583191, embedding dim 32, hidden size 512, num layers 1, train loss 0.28271567821502686, validation loss 1.0365407466888428\n",
      "Epoch 530, current patience 12, model mean validation loss 0.962766706943512, embedding dim 32, hidden size 512, num layers 1, train loss 0.2023739218711853, validation loss 1.2049378156661987\n",
      "Epoch 540, current patience 11, model mean validation loss 0.9733317494392395, embedding dim 32, hidden size 512, num layers 1, train loss 0.5956586599349976, validation loss 0.9381829500198364\n",
      "Epoch 550, current patience 10, model mean validation loss 0.9728584885597229, embedding dim 32, hidden size 512, num layers 1, train loss 0.712424635887146, validation loss 0.9173672199249268\n",
      "Epoch 560, current patience 9, model mean validation loss 0.9800496101379395, embedding dim 32, hidden size 512, num layers 1, train loss 0.17713937163352966, validation loss 0.9547085165977478\n",
      "Epoch 570, current patience 8, model mean validation loss 0.9910362958908081, embedding dim 32, hidden size 512, num layers 1, train loss 0.5263772010803223, validation loss 0.9755514860153198\n",
      "Epoch 580, current patience 7, model mean validation loss 1.0030754804611206, embedding dim 32, hidden size 512, num layers 1, train loss 0.4189120829105377, validation loss 1.0061935186386108\n",
      "Epoch 590, current patience 6, model mean validation loss 1.0003522634506226, embedding dim 32, hidden size 512, num layers 1, train loss 0.23878608644008636, validation loss 0.9693360328674316\n",
      "Epoch 600, current patience 5, model mean validation loss 0.9979480504989624, embedding dim 32, hidden size 512, num layers 1, train loss 0.1843516230583191, validation loss 1.017307162284851\n",
      "Epoch 610, current patience 4, model mean validation loss 0.9712643027305603, embedding dim 32, hidden size 512, num layers 1, train loss 0.28429800271987915, validation loss 0.9914677143096924\n",
      "Epoch 620, current patience 3, model mean validation loss 0.9756462574005127, embedding dim 32, hidden size 512, num layers 1, train loss 0.3939020335674286, validation loss 0.9732383489608765\n",
      "Epoch 630, current patience 2, model mean validation loss 1.0023763179779053, embedding dim 32, hidden size 512, num layers 1, train loss 0.24878594279289246, validation loss 1.131207823753357\n",
      "Epoch 640, current patience 1, model mean validation loss 1.0157053470611572, embedding dim 32, hidden size 512, num layers 1, train loss 0.3155055642127991, validation loss 1.061340093612671\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2126513719558716, embedding dim 32, hidden size 1024, num layers 1, train loss 1.096861720085144, validation loss 1.2126513719558716\n",
      "Epoch 10, current patience 30, model mean validation loss 1.154449701309204, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0887205600738525, validation loss 1.0962481498718262\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1382039785385132, embedding dim 32, hidden size 1024, num layers 1, train loss 1.1147675514221191, validation loss 1.105712652206421\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1275569200515747, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0954395532608032, validation loss 1.0956155061721802\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1205847263336182, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0899262428283691, validation loss 1.0926954746246338\n",
      "Epoch 50, current patience 30, model mean validation loss 1.117517113685608, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0786958932876587, validation loss 1.1021798849105835\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1168590784072876, embedding dim 32, hidden size 1024, num layers 1, train loss 1.100411057472229, validation loss 1.1129100322723389\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1133232116699219, embedding dim 32, hidden size 1024, num layers 1, train loss 1.098260760307312, validation loss 1.0885728597640991\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0977368354797363, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0741209983825684, validation loss 1.0879602432250977\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0941786766052246, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0730115175247192, validation loss 1.0677831172943115\n",
      "Epoch 100, current patience 30, model mean validation loss 1.086183786392212, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0885039567947388, validation loss 1.0417531728744507\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0763696432113647, embedding dim 32, hidden size 1024, num layers 1, train loss 0.9412175416946411, validation loss 1.017102837562561\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0637750625610352, embedding dim 32, hidden size 1024, num layers 1, train loss 0.9758840799331665, validation loss 0.9919388294219971\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0503779649734497, embedding dim 32, hidden size 1024, num layers 1, train loss 1.000572681427002, validation loss 0.9950032830238342\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0320076942443848, embedding dim 32, hidden size 1024, num layers 1, train loss 1.0158629417419434, validation loss 0.9659473896026611\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0160129070281982, embedding dim 32, hidden size 1024, num layers 1, train loss 0.9421006441116333, validation loss 0.9606150388717651\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0001153945922852, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8510699272155762, validation loss 0.9607788920402527\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9807822704315186, embedding dim 32, hidden size 1024, num layers 1, train loss 0.7561856508255005, validation loss 0.9131190776824951\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9642452597618103, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8217978477478027, validation loss 0.9094566106796265\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9486901760101318, embedding dim 32, hidden size 1024, num layers 1, train loss 0.908554196357727, validation loss 0.8926621675491333\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9358744621276855, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8314621448516846, validation loss 0.8894129991531372\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9174721240997314, embedding dim 32, hidden size 1024, num layers 1, train loss 0.813900351524353, validation loss 0.847785234451294\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9043182134628296, embedding dim 32, hidden size 1024, num layers 1, train loss 0.9134808778762817, validation loss 0.860715389251709\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8978675603866577, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8401145935058594, validation loss 0.9090103507041931\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8854250907897949, embedding dim 32, hidden size 1024, num layers 1, train loss 0.5502721071243286, validation loss 0.8612388372421265\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8805327415466309, embedding dim 32, hidden size 1024, num layers 1, train loss 0.6589885950088501, validation loss 0.8739804625511169\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8748034238815308, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4529629647731781, validation loss 0.86362224817276\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8667726516723633, embedding dim 32, hidden size 1024, num layers 1, train loss 0.65629643201828, validation loss 0.8284155130386353\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8614602088928223, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8540942668914795, validation loss 0.8469138145446777\n",
      "Epoch 290, current patience 30, model mean validation loss 0.858098566532135, embedding dim 32, hidden size 1024, num layers 1, train loss 0.6010072231292725, validation loss 0.820891797542572\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8548902273178101, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3885633945465088, validation loss 0.8350486159324646\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8545441627502441, embedding dim 32, hidden size 1024, num layers 1, train loss 0.7812700867652893, validation loss 0.9062420725822449\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8559995293617249, embedding dim 32, hidden size 1024, num layers 1, train loss 0.7146775126457214, validation loss 0.8728817701339722\n",
      "Epoch 330, current patience 29, model mean validation loss 0.8551878929138184, embedding dim 32, hidden size 1024, num layers 1, train loss 0.37903374433517456, validation loss 0.8674876689910889\n",
      "Epoch 340, current patience 28, model mean validation loss 0.8567104339599609, embedding dim 32, hidden size 1024, num layers 1, train loss 0.5845174789428711, validation loss 0.8758022785186768\n",
      "Epoch 350, current patience 27, model mean validation loss 0.8603354692459106, embedding dim 32, hidden size 1024, num layers 1, train loss 0.8360553979873657, validation loss 0.8574151992797852\n",
      "Epoch 360, current patience 26, model mean validation loss 0.8605248928070068, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4198687672615051, validation loss 0.8484300971031189\n",
      "Epoch 370, current patience 25, model mean validation loss 0.8728679418563843, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4436565041542053, validation loss 0.9196359515190125\n",
      "Epoch 380, current patience 24, model mean validation loss 0.8827282190322876, embedding dim 32, hidden size 1024, num layers 1, train loss 0.6073029041290283, validation loss 0.9139308929443359\n",
      "Epoch 390, current patience 23, model mean validation loss 0.8847990036010742, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4609564244747162, validation loss 0.9228082895278931\n",
      "Epoch 400, current patience 22, model mean validation loss 0.8912129998207092, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4295209050178528, validation loss 0.9241935014724731\n",
      "Epoch 410, current patience 21, model mean validation loss 0.8958626985549927, embedding dim 32, hidden size 1024, num layers 1, train loss 0.5566999912261963, validation loss 0.9046854972839355\n",
      "Epoch 420, current patience 20, model mean validation loss 0.9021024703979492, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4915475845336914, validation loss 0.9257203340530396\n",
      "Epoch 430, current patience 19, model mean validation loss 0.9080279469490051, embedding dim 32, hidden size 1024, num layers 1, train loss 0.46241289377212524, validation loss 0.9048190116882324\n",
      "Epoch 440, current patience 18, model mean validation loss 0.9159534573554993, embedding dim 32, hidden size 1024, num layers 1, train loss 0.5948783159255981, validation loss 0.9118340015411377\n",
      "Epoch 450, current patience 17, model mean validation loss 0.9218561053276062, embedding dim 32, hidden size 1024, num layers 1, train loss 0.17501047253608704, validation loss 0.9668575525283813\n",
      "Epoch 460, current patience 16, model mean validation loss 0.924938976764679, embedding dim 32, hidden size 1024, num layers 1, train loss 0.15582986176013947, validation loss 0.9385936260223389\n",
      "Epoch 470, current patience 15, model mean validation loss 0.9291505813598633, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3650414049625397, validation loss 0.9565010070800781\n",
      "Epoch 480, current patience 14, model mean validation loss 0.9331903457641602, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3559378385543823, validation loss 0.9565114974975586\n",
      "Epoch 490, current patience 13, model mean validation loss 0.9370640516281128, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3344799280166626, validation loss 0.9356749653816223\n",
      "Epoch 500, current patience 12, model mean validation loss 0.9496310353279114, embedding dim 32, hidden size 1024, num layers 1, train loss 0.5255470275878906, validation loss 1.0262563228607178\n",
      "Epoch 510, current patience 11, model mean validation loss 0.9622233510017395, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3871007263660431, validation loss 1.0055575370788574\n",
      "Epoch 520, current patience 10, model mean validation loss 0.9625208377838135, embedding dim 32, hidden size 1024, num layers 1, train loss 0.2095942199230194, validation loss 0.9142143726348877\n",
      "Epoch 530, current patience 9, model mean validation loss 0.9761443138122559, embedding dim 32, hidden size 1024, num layers 1, train loss 0.44101259112358093, validation loss 1.075845718383789\n",
      "Epoch 540, current patience 8, model mean validation loss 0.9900356531143188, embedding dim 32, hidden size 1024, num layers 1, train loss 0.25649625062942505, validation loss 1.0497239828109741\n",
      "Epoch 550, current patience 7, model mean validation loss 0.9969916343688965, embedding dim 32, hidden size 1024, num layers 1, train loss 0.24392321705818176, validation loss 1.0121488571166992\n",
      "Epoch 560, current patience 6, model mean validation loss 1.000115156173706, embedding dim 32, hidden size 1024, num layers 1, train loss 0.3390503227710724, validation loss 0.9814997911453247\n",
      "Epoch 570, current patience 5, model mean validation loss 1.008107304573059, embedding dim 32, hidden size 1024, num layers 1, train loss 0.380389928817749, validation loss 0.9996119737625122\n",
      "Epoch 580, current patience 4, model mean validation loss 1.0008423328399658, embedding dim 32, hidden size 1024, num layers 1, train loss 0.7289148569107056, validation loss 0.9681362509727478\n",
      "Epoch 590, current patience 3, model mean validation loss 0.9957656264305115, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4696362614631653, validation loss 0.9649443030357361\n",
      "Epoch 600, current patience 2, model mean validation loss 1.0088205337524414, embedding dim 32, hidden size 1024, num layers 1, train loss 0.4152429401874542, validation loss 1.0186530351638794\n",
      "Epoch 610, current patience 1, model mean validation loss 0.999803900718689, embedding dim 32, hidden size 1024, num layers 1, train loss 0.42126017808914185, validation loss 1.0037128925323486\n",
      "Epoch 0, current patience 30, model mean validation loss 1.512219786643982, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0982177257537842, validation loss 1.512219786643982\n",
      "Epoch 10, current patience 30, model mean validation loss 1.4645981788635254, embedding dim 32, hidden size 2048, num layers 1, train loss 1.7530673742294312, validation loss 1.4169766902923584\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3814562559127808, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1794811487197876, validation loss 1.2151721715927124\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3346279859542847, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1376876831054688, validation loss 1.194143295288086\n",
      "Epoch 40, current patience 30, model mean validation loss 1.2955868244171143, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1017141342163086, validation loss 1.1394225358963013\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2648828029632568, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0960490703582764, validation loss 1.1113618612289429\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2524234056472778, embedding dim 32, hidden size 2048, num layers 1, train loss 1.108999252319336, validation loss 1.1776665449142456\n",
      "Epoch 70, current patience 30, model mean validation loss 1.24716055393219, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1429686546325684, validation loss 1.2103216648101807\n",
      "Epoch 80, current patience 30, model mean validation loss 1.210603952407837, embedding dim 32, hidden size 2048, num layers 1, train loss 1.10868239402771, validation loss 1.2197678089141846\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1783883571624756, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1151119470596313, validation loss 1.1592512130737305\n",
      "Epoch 100, current patience 30, model mean validation loss 1.172635555267334, embedding dim 32, hidden size 2048, num layers 1, train loss 1.553551197052002, validation loss 1.1691490411758423\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1794309616088867, embedding dim 32, hidden size 2048, num layers 1, train loss 1.4600673913955688, validation loss 1.2485064268112183\n",
      "Epoch 120, current patience 29, model mean validation loss 1.2075468301773071, embedding dim 32, hidden size 2048, num layers 1, train loss 1.5462021827697754, validation loss 1.3643498420715332\n",
      "Epoch 130, current patience 28, model mean validation loss 1.255798578262329, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1459314823150635, validation loss 1.4973764419555664\n",
      "Epoch 140, current patience 27, model mean validation loss 1.2563209533691406, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1168506145477295, validation loss 1.1818456649780273\n",
      "Epoch 150, current patience 26, model mean validation loss 1.2420978546142578, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0895626544952393, validation loss 1.0965368747711182\n",
      "Epoch 160, current patience 25, model mean validation loss 1.235026478767395, embedding dim 32, hidden size 2048, num layers 1, train loss 1.2337393760681152, validation loss 1.163196325302124\n",
      "Epoch 170, current patience 24, model mean validation loss 1.2344419956207275, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1054391860961914, validation loss 1.1545755863189697\n",
      "Epoch 180, current patience 23, model mean validation loss 1.2252252101898193, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0062562227249146, validation loss 1.0954147577285767\n",
      "Epoch 190, current patience 22, model mean validation loss 1.2172319889068604, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1799793243408203, validation loss 1.1845601797103882\n",
      "Epoch 200, current patience 21, model mean validation loss 1.1835789680480957, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1811347007751465, validation loss 1.0951261520385742\n",
      "Epoch 210, current patience 20, model mean validation loss 1.138059139251709, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1429462432861328, validation loss 1.133217453956604\n",
      "Epoch 220, current patience 30, model mean validation loss 1.1288602352142334, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1103800535202026, validation loss 1.1082549095153809\n",
      "Epoch 230, current patience 30, model mean validation loss 1.1336143016815186, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0275253057479858, validation loss 1.1345690488815308\n",
      "Epoch 240, current patience 29, model mean validation loss 1.1312916278839111, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0800520181655884, validation loss 1.1446154117584229\n",
      "Epoch 250, current patience 28, model mean validation loss 1.1227765083312988, embedding dim 32, hidden size 2048, num layers 1, train loss 1.2355480194091797, validation loss 1.0864548683166504\n",
      "Epoch 260, current patience 30, model mean validation loss 1.120514988899231, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0951272249221802, validation loss 1.0773217678070068\n",
      "Epoch 270, current patience 30, model mean validation loss 1.1098005771636963, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1891180276870728, validation loss 1.0988457202911377\n",
      "Epoch 280, current patience 30, model mean validation loss 1.124129056930542, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0836296081542969, validation loss 1.209753394126892\n",
      "Epoch 290, current patience 29, model mean validation loss 1.1532237529754639, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1053884029388428, validation loss 1.3659758567810059\n",
      "Epoch 300, current patience 28, model mean validation loss 1.1623058319091797, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0387035608291626, validation loss 1.1809108257293701\n",
      "Epoch 310, current patience 27, model mean validation loss 1.160081386566162, embedding dim 32, hidden size 2048, num layers 1, train loss 1.3608064651489258, validation loss 1.116773009300232\n",
      "Epoch 320, current patience 26, model mean validation loss 1.1588460206985474, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1185038089752197, validation loss 1.134732723236084\n",
      "Epoch 330, current patience 25, model mean validation loss 1.1833035945892334, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1933727264404297, validation loss 1.2821154594421387\n",
      "Epoch 340, current patience 24, model mean validation loss 1.19427490234375, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1058859825134277, validation loss 1.1650917530059814\n",
      "Epoch 350, current patience 23, model mean validation loss 1.201775312423706, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0795607566833496, validation loss 1.1588490009307861\n",
      "Epoch 360, current patience 22, model mean validation loss 1.1882712841033936, embedding dim 32, hidden size 2048, num layers 1, train loss 1.151942253112793, validation loss 1.1017218828201294\n",
      "Epoch 370, current patience 21, model mean validation loss 1.1649346351623535, embedding dim 32, hidden size 2048, num layers 1, train loss 0.9700822830200195, validation loss 1.1792824268341064\n",
      "Epoch 380, current patience 20, model mean validation loss 1.1557023525238037, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0284947156906128, validation loss 1.107051968574524\n",
      "Epoch 390, current patience 19, model mean validation loss 1.1525397300720215, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0467219352722168, validation loss 1.0914734601974487\n",
      "Epoch 400, current patience 18, model mean validation loss 1.1514583826065063, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0922338962554932, validation loss 1.1260813474655151\n",
      "Epoch 410, current patience 17, model mean validation loss 1.1343872547149658, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0810147523880005, validation loss 1.1455457210540771\n",
      "Epoch 420, current patience 16, model mean validation loss 1.1432719230651855, embedding dim 32, hidden size 2048, num layers 1, train loss 1.071015477180481, validation loss 1.2361701726913452\n",
      "Epoch 430, current patience 15, model mean validation loss 1.1391708850860596, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0098170042037964, validation loss 1.126039981842041\n",
      "Epoch 440, current patience 14, model mean validation loss 1.147137999534607, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1145635843276978, validation loss 1.1654589176177979\n",
      "Epoch 450, current patience 13, model mean validation loss 1.138922929763794, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0927385091781616, validation loss 1.1135615110397339\n",
      "Epoch 460, current patience 12, model mean validation loss 1.1428167819976807, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0487167835235596, validation loss 1.1382031440734863\n",
      "Epoch 470, current patience 11, model mean validation loss 1.1486892700195312, embedding dim 32, hidden size 2048, num layers 1, train loss 1.122344970703125, validation loss 1.1384539604187012\n",
      "Epoch 480, current patience 10, model mean validation loss 1.1508395671844482, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1384670734405518, validation loss 1.1432836055755615\n",
      "Epoch 490, current patience 9, model mean validation loss 1.1502768993377686, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0640990734100342, validation loss 1.14104425907135\n",
      "Epoch 500, current patience 8, model mean validation loss 1.1703264713287354, embedding dim 32, hidden size 2048, num layers 1, train loss 1.2252339124679565, validation loss 1.3965668678283691\n",
      "Epoch 510, current patience 7, model mean validation loss 1.1744508743286133, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1900187730789185, validation loss 1.1590347290039062\n",
      "Epoch 520, current patience 6, model mean validation loss 1.1838847398757935, embedding dim 32, hidden size 2048, num layers 1, train loss 1.16377592086792, validation loss 1.2409296035766602\n",
      "Epoch 530, current patience 5, model mean validation loss 1.1905395984649658, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0976271629333496, validation loss 1.16680109500885\n",
      "Epoch 540, current patience 4, model mean validation loss 1.1872138977050781, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0166590213775635, validation loss 1.1115975379943848\n",
      "Epoch 550, current patience 3, model mean validation loss 1.18191397190094, embedding dim 32, hidden size 2048, num layers 1, train loss 1.131563425064087, validation loss 1.096053957939148\n",
      "Epoch 560, current patience 2, model mean validation loss 1.175088882446289, embedding dim 32, hidden size 2048, num layers 1, train loss 1.0856199264526367, validation loss 1.0886831283569336\n",
      "Epoch 570, current patience 1, model mean validation loss 1.1730875968933105, embedding dim 32, hidden size 2048, num layers 1, train loss 1.1000416278839111, validation loss 1.1250340938568115\n",
      "Epoch 0, current patience 30, model mean validation loss 1.150588035583496, embedding dim 64, hidden size 1, num layers 1, train loss 1.1252630949020386, validation loss 1.150588035583496\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1385071277618408, embedding dim 64, hidden size 1, num layers 1, train loss 1.134685754776001, validation loss 1.126426339149475\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1292303800582886, embedding dim 64, hidden size 1, num layers 1, train loss 1.1012216806411743, validation loss 1.110676646232605\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1239246129989624, embedding dim 64, hidden size 1, num layers 1, train loss 1.0749077796936035, validation loss 1.108007550239563\n",
      "Epoch 40, current patience 30, model mean validation loss 1.118257761001587, embedding dim 64, hidden size 1, num layers 1, train loss 1.1098434925079346, validation loss 1.0955898761749268\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1142933368682861, embedding dim 64, hidden size 1, num layers 1, train loss 1.1226305961608887, validation loss 1.0944716930389404\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1109756231307983, embedding dim 64, hidden size 1, num layers 1, train loss 1.093616008758545, validation loss 1.0910691022872925\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1093257665634155, embedding dim 64, hidden size 1, num layers 1, train loss 1.0991978645324707, validation loss 1.097776174545288\n",
      "Epoch 80, current patience 30, model mean validation loss 1.101658821105957, embedding dim 64, hidden size 1, num layers 1, train loss 1.0612295866012573, validation loss 1.0892536640167236\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0972583293914795, embedding dim 64, hidden size 1, num layers 1, train loss 1.0696496963500977, validation loss 1.0912210941314697\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0940457582473755, embedding dim 64, hidden size 1, num layers 1, train loss 1.081688642501831, validation loss 1.0849766731262207\n",
      "Epoch 110, current patience 30, model mean validation loss 1.091229796409607, embedding dim 64, hidden size 1, num layers 1, train loss 1.0804648399353027, validation loss 1.085479974746704\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0898281335830688, embedding dim 64, hidden size 1, num layers 1, train loss 1.0688164234161377, validation loss 1.084376335144043\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0887072086334229, embedding dim 64, hidden size 1, num layers 1, train loss 1.0607234239578247, validation loss 1.0855048894882202\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0872888565063477, embedding dim 64, hidden size 1, num layers 1, train loss 1.056633710861206, validation loss 1.079722285270691\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0844368934631348, embedding dim 64, hidden size 1, num layers 1, train loss 1.0187548398971558, validation loss 1.074960470199585\n",
      "Epoch 160, current patience 30, model mean validation loss 1.082465410232544, embedding dim 64, hidden size 1, num layers 1, train loss 0.9998909831047058, validation loss 1.0734813213348389\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0795353651046753, embedding dim 64, hidden size 1, num layers 1, train loss 1.0890297889709473, validation loss 1.0677810907363892\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0776188373565674, embedding dim 64, hidden size 1, num layers 1, train loss 1.0512243509292603, validation loss 1.0696439743041992\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0755401849746704, embedding dim 64, hidden size 1, num layers 1, train loss 1.0134899616241455, validation loss 1.0688507556915283\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0719364881515503, embedding dim 64, hidden size 1, num layers 1, train loss 1.0630837678909302, validation loss 1.0555472373962402\n",
      "Epoch 210, current patience 30, model mean validation loss 1.068528652191162, embedding dim 64, hidden size 1, num layers 1, train loss 0.9959015846252441, validation loss 1.0582422018051147\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0657916069030762, embedding dim 64, hidden size 1, num layers 1, train loss 1.0062865018844604, validation loss 1.0578259229660034\n",
      "Epoch 230, current patience 30, model mean validation loss 1.062727928161621, embedding dim 64, hidden size 1, num layers 1, train loss 0.9966588616371155, validation loss 1.0504508018493652\n",
      "Epoch 240, current patience 30, model mean validation loss 1.06050705909729, embedding dim 64, hidden size 1, num layers 1, train loss 0.9933325052261353, validation loss 1.055714726448059\n",
      "Epoch 250, current patience 30, model mean validation loss 1.058732509613037, embedding dim 64, hidden size 1, num layers 1, train loss 1.0383045673370361, validation loss 1.053584337234497\n",
      "Epoch 260, current patience 30, model mean validation loss 1.057417392730713, embedding dim 64, hidden size 1, num layers 1, train loss 1.039193868637085, validation loss 1.0591237545013428\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0565564632415771, embedding dim 64, hidden size 1, num layers 1, train loss 1.032926321029663, validation loss 1.0619628429412842\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0559523105621338, embedding dim 64, hidden size 1, num layers 1, train loss 1.028314232826233, validation loss 1.050714135169983\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0566926002502441, embedding dim 64, hidden size 1, num layers 1, train loss 0.9265713691711426, validation loss 1.064163327217102\n",
      "Epoch 300, current patience 29, model mean validation loss 1.055213212966919, embedding dim 64, hidden size 1, num layers 1, train loss 1.0900225639343262, validation loss 1.0459911823272705\n",
      "Epoch 310, current patience 30, model mean validation loss 1.054079532623291, embedding dim 64, hidden size 1, num layers 1, train loss 1.0717897415161133, validation loss 1.0413823127746582\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0529875755310059, embedding dim 64, hidden size 1, num layers 1, train loss 1.008345127105713, validation loss 1.0469778776168823\n",
      "Epoch 330, current patience 30, model mean validation loss 1.049889087677002, embedding dim 64, hidden size 1, num layers 1, train loss 1.011056661605835, validation loss 1.0287972688674927\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0461262464523315, embedding dim 64, hidden size 1, num layers 1, train loss 0.9080094695091248, validation loss 1.0290207862854004\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0423691272735596, embedding dim 64, hidden size 1, num layers 1, train loss 0.8924323916435242, validation loss 1.0319056510925293\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0385890007019043, embedding dim 64, hidden size 1, num layers 1, train loss 0.8771757483482361, validation loss 1.0204732418060303\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0319864749908447, embedding dim 64, hidden size 1, num layers 1, train loss 0.9282670617103577, validation loss 1.0113428831100464\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0279244184494019, embedding dim 64, hidden size 1, num layers 1, train loss 0.933260440826416, validation loss 1.0134952068328857\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0227736234664917, embedding dim 64, hidden size 1, num layers 1, train loss 0.8828651905059814, validation loss 1.0001758337020874\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0170272588729858, embedding dim 64, hidden size 1, num layers 1, train loss 0.8519730567932129, validation loss 1.001007080078125\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0146064758300781, embedding dim 64, hidden size 1, num layers 1, train loss 1.0031017065048218, validation loss 1.0094311237335205\n",
      "Epoch 420, current patience 30, model mean validation loss 1.014686942100525, embedding dim 64, hidden size 1, num layers 1, train loss 0.9174596071243286, validation loss 1.029664397239685\n",
      "Epoch 430, current patience 29, model mean validation loss 1.0112149715423584, embedding dim 64, hidden size 1, num layers 1, train loss 0.8929406404495239, validation loss 1.0041296482086182\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0117478370666504, embedding dim 64, hidden size 1, num layers 1, train loss 0.9499496221542358, validation loss 1.0247362852096558\n",
      "Epoch 450, current patience 29, model mean validation loss 1.011081337928772, embedding dim 64, hidden size 1, num layers 1, train loss 0.9385600090026855, validation loss 1.0060113668441772\n",
      "Epoch 460, current patience 30, model mean validation loss 1.0078213214874268, embedding dim 64, hidden size 1, num layers 1, train loss 0.9054540395736694, validation loss 0.9874155521392822\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0087320804595947, embedding dim 64, hidden size 1, num layers 1, train loss 0.8543811440467834, validation loss 1.0074607133865356\n",
      "Epoch 480, current patience 29, model mean validation loss 1.0099962949752808, embedding dim 64, hidden size 1, num layers 1, train loss 0.9061334133148193, validation loss 1.011121153831482\n",
      "Epoch 490, current patience 28, model mean validation loss 1.0072542428970337, embedding dim 64, hidden size 1, num layers 1, train loss 0.9368183612823486, validation loss 0.987494707107544\n",
      "Epoch 500, current patience 30, model mean validation loss 1.004286527633667, embedding dim 64, hidden size 1, num layers 1, train loss 0.9263967275619507, validation loss 1.0059221982955933\n",
      "Epoch 510, current patience 30, model mean validation loss 1.0030386447906494, embedding dim 64, hidden size 1, num layers 1, train loss 0.8761735558509827, validation loss 0.9941475987434387\n",
      "Epoch 520, current patience 30, model mean validation loss 1.001468300819397, embedding dim 64, hidden size 1, num layers 1, train loss 0.9685877561569214, validation loss 1.0121734142303467\n",
      "Epoch 530, current patience 30, model mean validation loss 1.002967119216919, embedding dim 64, hidden size 1, num layers 1, train loss 0.8541778326034546, validation loss 1.0180023908615112\n",
      "Epoch 540, current patience 29, model mean validation loss 1.0053333044052124, embedding dim 64, hidden size 1, num layers 1, train loss 0.8414057493209839, validation loss 1.0063443183898926\n",
      "Epoch 550, current patience 28, model mean validation loss 1.0021641254425049, embedding dim 64, hidden size 1, num layers 1, train loss 0.8902000188827515, validation loss 0.9821078777313232\n",
      "Epoch 560, current patience 27, model mean validation loss 1.0005168914794922, embedding dim 64, hidden size 1, num layers 1, train loss 0.8040258884429932, validation loss 0.9979428648948669\n",
      "Epoch 570, current patience 30, model mean validation loss 1.0022571086883545, embedding dim 64, hidden size 1, num layers 1, train loss 0.8072829842567444, validation loss 1.0014166831970215\n",
      "Epoch 580, current patience 29, model mean validation loss 0.9999452233314514, embedding dim 64, hidden size 1, num layers 1, train loss 0.8273434042930603, validation loss 0.9874266982078552\n",
      "Epoch 590, current patience 30, model mean validation loss 1.0036044120788574, embedding dim 64, hidden size 1, num layers 1, train loss 0.8637415766716003, validation loss 1.023421049118042\n",
      "Epoch 600, current patience 29, model mean validation loss 1.0005803108215332, embedding dim 64, hidden size 1, num layers 1, train loss 0.8172338604927063, validation loss 0.9879807233810425\n",
      "Epoch 610, current patience 28, model mean validation loss 0.9976416826248169, embedding dim 64, hidden size 1, num layers 1, train loss 0.8621317744255066, validation loss 0.9944930076599121\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9973145723342896, embedding dim 64, hidden size 1, num layers 1, train loss 0.8256644010543823, validation loss 1.0037280321121216\n",
      "Epoch 630, current patience 30, model mean validation loss 0.9972273707389832, embedding dim 64, hidden size 1, num layers 1, train loss 0.7770258188247681, validation loss 0.9814098477363586\n",
      "Epoch 640, current patience 30, model mean validation loss 0.9980610609054565, embedding dim 64, hidden size 1, num layers 1, train loss 0.8181432485580444, validation loss 1.0046128034591675\n",
      "Epoch 650, current patience 29, model mean validation loss 0.9968302249908447, embedding dim 64, hidden size 1, num layers 1, train loss 0.7723601460456848, validation loss 0.9915698170661926\n",
      "Epoch 660, current patience 30, model mean validation loss 0.9983618855476379, embedding dim 64, hidden size 1, num layers 1, train loss 0.7614926099777222, validation loss 0.9996798634529114\n",
      "Epoch 670, current patience 29, model mean validation loss 0.9966228008270264, embedding dim 64, hidden size 1, num layers 1, train loss 0.8502237796783447, validation loss 1.0095081329345703\n",
      "Epoch 680, current patience 30, model mean validation loss 0.9901862144470215, embedding dim 64, hidden size 1, num layers 1, train loss 0.8989830613136292, validation loss 0.9364880919456482\n",
      "Epoch 690, current patience 30, model mean validation loss 0.9941010475158691, embedding dim 64, hidden size 1, num layers 1, train loss 0.8335047960281372, validation loss 1.0258121490478516\n",
      "Epoch 700, current patience 29, model mean validation loss 0.9911274313926697, embedding dim 64, hidden size 1, num layers 1, train loss 0.8415026664733887, validation loss 0.9799386858940125\n",
      "Epoch 710, current patience 28, model mean validation loss 0.9943063259124756, embedding dim 64, hidden size 1, num layers 1, train loss 0.7229877710342407, validation loss 1.0068414211273193\n",
      "Epoch 720, current patience 27, model mean validation loss 0.989035964012146, embedding dim 64, hidden size 1, num layers 1, train loss 0.7386224865913391, validation loss 0.962449312210083\n",
      "Epoch 730, current patience 30, model mean validation loss 0.9901332855224609, embedding dim 64, hidden size 1, num layers 1, train loss 0.736457347869873, validation loss 1.000348448753357\n",
      "Epoch 740, current patience 29, model mean validation loss 0.9934676885604858, embedding dim 64, hidden size 1, num layers 1, train loss 0.7988279461860657, validation loss 1.0263553857803345\n",
      "Epoch 750, current patience 28, model mean validation loss 0.9924131631851196, embedding dim 64, hidden size 1, num layers 1, train loss 0.768471896648407, validation loss 1.0010716915130615\n",
      "Epoch 760, current patience 27, model mean validation loss 0.9995658993721008, embedding dim 64, hidden size 1, num layers 1, train loss 0.8077561855316162, validation loss 0.9937102794647217\n",
      "Epoch 770, current patience 26, model mean validation loss 0.9976648092269897, embedding dim 64, hidden size 1, num layers 1, train loss 0.9865580797195435, validation loss 1.010603427886963\n",
      "Epoch 780, current patience 25, model mean validation loss 1.0018119812011719, embedding dim 64, hidden size 1, num layers 1, train loss 0.9687304496765137, validation loss 1.013115406036377\n",
      "Epoch 790, current patience 24, model mean validation loss 1.0021809339523315, embedding dim 64, hidden size 1, num layers 1, train loss 0.7349744439125061, validation loss 1.0097932815551758\n",
      "Epoch 800, current patience 23, model mean validation loss 1.004339337348938, embedding dim 64, hidden size 1, num layers 1, train loss 0.693352222442627, validation loss 0.9797161817550659\n",
      "Epoch 810, current patience 22, model mean validation loss 1.0051484107971191, embedding dim 64, hidden size 1, num layers 1, train loss 0.691106915473938, validation loss 1.006821870803833\n",
      "Epoch 820, current patience 21, model mean validation loss 0.9977177381515503, embedding dim 64, hidden size 1, num layers 1, train loss 0.6769933700561523, validation loss 0.966909646987915\n",
      "Epoch 830, current patience 20, model mean validation loss 0.9971678256988525, embedding dim 64, hidden size 1, num layers 1, train loss 0.7649129033088684, validation loss 0.9966726899147034\n",
      "Epoch 840, current patience 19, model mean validation loss 1.00196373462677, embedding dim 64, hidden size 1, num layers 1, train loss 0.6696896553039551, validation loss 1.0320773124694824\n",
      "Epoch 850, current patience 18, model mean validation loss 0.9963048696517944, embedding dim 64, hidden size 1, num layers 1, train loss 0.7434853315353394, validation loss 0.9653324484825134\n",
      "Epoch 860, current patience 17, model mean validation loss 0.9932727217674255, embedding dim 64, hidden size 1, num layers 1, train loss 0.7838985919952393, validation loss 0.9888584613800049\n",
      "Epoch 870, current patience 16, model mean validation loss 0.9921988248825073, embedding dim 64, hidden size 1, num layers 1, train loss 0.7033754587173462, validation loss 1.0012013912200928\n",
      "Epoch 880, current patience 15, model mean validation loss 0.986892819404602, embedding dim 64, hidden size 1, num layers 1, train loss 0.8437314033508301, validation loss 0.9372687339782715\n",
      "Epoch 890, current patience 30, model mean validation loss 0.9858241081237793, embedding dim 64, hidden size 1, num layers 1, train loss 0.6676483154296875, validation loss 0.998272180557251\n",
      "Epoch 900, current patience 30, model mean validation loss 0.9892418384552002, embedding dim 64, hidden size 1, num layers 1, train loss 0.7520684599876404, validation loss 0.9942514300346375\n",
      "Epoch 910, current patience 29, model mean validation loss 0.9871776103973389, embedding dim 64, hidden size 1, num layers 1, train loss 0.7270684242248535, validation loss 0.9801589250564575\n",
      "Epoch 920, current patience 28, model mean validation loss 0.9801076650619507, embedding dim 64, hidden size 1, num layers 1, train loss 0.6522851586341858, validation loss 0.975517749786377\n",
      "Epoch 930, current patience 30, model mean validation loss 0.9816807508468628, embedding dim 64, hidden size 1, num layers 1, train loss 0.8935264348983765, validation loss 0.9779170155525208\n",
      "Epoch 940, current patience 29, model mean validation loss 0.9835386276245117, embedding dim 64, hidden size 1, num layers 1, train loss 0.6856508255004883, validation loss 1.0037215948104858\n",
      "Epoch 950, current patience 28, model mean validation loss 0.9859396815299988, embedding dim 64, hidden size 1, num layers 1, train loss 0.7378117442131042, validation loss 1.0204100608825684\n",
      "Epoch 960, current patience 27, model mean validation loss 0.9962928295135498, embedding dim 64, hidden size 1, num layers 1, train loss 0.7187134623527527, validation loss 1.0200937986373901\n",
      "Epoch 970, current patience 26, model mean validation loss 0.9946280717849731, embedding dim 64, hidden size 1, num layers 1, train loss 0.7056779265403748, validation loss 0.9849541783332825\n",
      "Epoch 980, current patience 25, model mean validation loss 0.9981574416160583, embedding dim 64, hidden size 1, num layers 1, train loss 0.7796356678009033, validation loss 1.0224863290786743\n",
      "Epoch 990, current patience 24, model mean validation loss 1.0008857250213623, embedding dim 64, hidden size 1, num layers 1, train loss 0.8448536396026611, validation loss 1.0019844770431519\n",
      "Epoch 1000, current patience 23, model mean validation loss 1.0052471160888672, embedding dim 64, hidden size 1, num layers 1, train loss 0.8228007555007935, validation loss 1.0104100704193115\n",
      "Epoch 1010, current patience 22, model mean validation loss 1.00766122341156, embedding dim 64, hidden size 1, num layers 1, train loss 0.6995347738265991, validation loss 0.9972289800643921\n",
      "Epoch 1020, current patience 21, model mean validation loss 1.0089759826660156, embedding dim 64, hidden size 1, num layers 1, train loss 0.7993506193161011, validation loss 1.01423978805542\n",
      "Epoch 1030, current patience 20, model mean validation loss 1.0067601203918457, embedding dim 64, hidden size 1, num layers 1, train loss 0.6724560260772705, validation loss 1.0026839971542358\n",
      "Epoch 1040, current patience 19, model mean validation loss 1.0018213987350464, embedding dim 64, hidden size 1, num layers 1, train loss 0.731395959854126, validation loss 0.980583667755127\n",
      "Epoch 1050, current patience 18, model mean validation loss 1.0040814876556396, embedding dim 64, hidden size 1, num layers 1, train loss 0.8211020231246948, validation loss 1.0030348300933838\n",
      "Epoch 1060, current patience 17, model mean validation loss 1.006191611289978, embedding dim 64, hidden size 1, num layers 1, train loss 0.7365624904632568, validation loss 1.039367437362671\n",
      "Epoch 1070, current patience 16, model mean validation loss 1.0026556253433228, embedding dim 64, hidden size 1, num layers 1, train loss 0.7706514000892639, validation loss 0.9736961722373962\n",
      "Epoch 1080, current patience 15, model mean validation loss 1.00269615650177, embedding dim 64, hidden size 1, num layers 1, train loss 0.6366119384765625, validation loss 1.0107344388961792\n",
      "Epoch 1090, current patience 14, model mean validation loss 1.0054335594177246, embedding dim 64, hidden size 1, num layers 1, train loss 0.7800356149673462, validation loss 1.0191280841827393\n",
      "Epoch 1100, current patience 13, model mean validation loss 1.0049980878829956, embedding dim 64, hidden size 1, num layers 1, train loss 0.6897832155227661, validation loss 1.010756254196167\n",
      "Epoch 1110, current patience 12, model mean validation loss 1.0000160932540894, embedding dim 64, hidden size 1, num layers 1, train loss 0.8128238320350647, validation loss 0.9628279209136963\n",
      "Epoch 1120, current patience 11, model mean validation loss 1.004507303237915, embedding dim 64, hidden size 1, num layers 1, train loss 0.6413751244544983, validation loss 1.0165125131607056\n",
      "Epoch 1130, current patience 10, model mean validation loss 1.0005087852478027, embedding dim 64, hidden size 1, num layers 1, train loss 0.9014163017272949, validation loss 0.9710472226142883\n",
      "Epoch 1140, current patience 9, model mean validation loss 0.9960927367210388, embedding dim 64, hidden size 1, num layers 1, train loss 0.7864027619361877, validation loss 1.0040394067764282\n",
      "Epoch 1150, current patience 8, model mean validation loss 1.0027912855148315, embedding dim 64, hidden size 1, num layers 1, train loss 0.7078676223754883, validation loss 1.0272847414016724\n",
      "Epoch 1160, current patience 7, model mean validation loss 1.005505919456482, embedding dim 64, hidden size 1, num layers 1, train loss 0.7439168095588684, validation loss 1.0324511528015137\n",
      "Epoch 1170, current patience 6, model mean validation loss 1.005211591720581, embedding dim 64, hidden size 1, num layers 1, train loss 0.746529221534729, validation loss 1.0167739391326904\n",
      "Epoch 1180, current patience 5, model mean validation loss 1.0043070316314697, embedding dim 64, hidden size 1, num layers 1, train loss 0.6443644762039185, validation loss 1.0035194158554077\n",
      "Epoch 1190, current patience 4, model mean validation loss 1.0128164291381836, embedding dim 64, hidden size 1, num layers 1, train loss 0.7095928192138672, validation loss 1.0309032201766968\n",
      "Epoch 1200, current patience 3, model mean validation loss 1.0149229764938354, embedding dim 64, hidden size 1, num layers 1, train loss 0.8161879777908325, validation loss 1.0333645343780518\n",
      "Epoch 1210, current patience 2, model mean validation loss 1.0160679817199707, embedding dim 64, hidden size 1, num layers 1, train loss 0.6392077207565308, validation loss 0.9802071452140808\n",
      "Epoch 1220, current patience 1, model mean validation loss 1.0135431289672852, embedding dim 64, hidden size 1, num layers 1, train loss 0.6083858013153076, validation loss 0.9838414788246155\n",
      "Epoch 0, current patience 30, model mean validation loss 1.09583580493927, embedding dim 64, hidden size 2, num layers 1, train loss 1.09647536277771, validation loss 1.09583580493927\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0943207740783691, embedding dim 64, hidden size 2, num layers 1, train loss 1.0952078104019165, validation loss 1.0928058624267578\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0927211046218872, embedding dim 64, hidden size 2, num layers 1, train loss 1.1146438121795654, validation loss 1.0895220041275024\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0932265520095825, embedding dim 64, hidden size 2, num layers 1, train loss 1.0999318361282349, validation loss 1.094742774963379\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0924956798553467, embedding dim 64, hidden size 2, num layers 1, train loss 1.0914849042892456, validation loss 1.0895717144012451\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0932635068893433, embedding dim 64, hidden size 2, num layers 1, train loss 1.0943434238433838, validation loss 1.0971026420593262\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0932085514068604, embedding dim 64, hidden size 2, num layers 1, train loss 1.1066186428070068, validation loss 1.092879056930542\n",
      "Epoch 70, current patience 28, model mean validation loss 1.0923385620117188, embedding dim 64, hidden size 2, num layers 1, train loss 1.0963475704193115, validation loss 1.0862479209899902\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0908631086349487, embedding dim 64, hidden size 2, num layers 1, train loss 1.073995590209961, validation loss 1.0840325355529785\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0881683826446533, embedding dim 64, hidden size 2, num layers 1, train loss 1.0454175472259521, validation loss 1.0712485313415527\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0845507383346558, embedding dim 64, hidden size 2, num layers 1, train loss 0.9834638833999634, validation loss 1.0605804920196533\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0797362327575684, embedding dim 64, hidden size 2, num layers 1, train loss 1.009674310684204, validation loss 1.0562273263931274\n",
      "Epoch 120, current patience 30, model mean validation loss 1.075876235961914, embedding dim 64, hidden size 2, num layers 1, train loss 1.0723615884780884, validation loss 1.0586910247802734\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0699419975280762, embedding dim 64, hidden size 2, num layers 1, train loss 1.0527422428131104, validation loss 1.04962956905365\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0633009672164917, embedding dim 64, hidden size 2, num layers 1, train loss 0.9352529644966125, validation loss 1.039750576019287\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0582964420318604, embedding dim 64, hidden size 2, num layers 1, train loss 1.0302554368972778, validation loss 1.0462119579315186\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0504778623580933, embedding dim 64, hidden size 2, num layers 1, train loss 0.9911254644393921, validation loss 1.0214831829071045\n",
      "Epoch 170, current patience 30, model mean validation loss 1.042312502861023, embedding dim 64, hidden size 2, num layers 1, train loss 0.8993114233016968, validation loss 1.0059256553649902\n",
      "Epoch 180, current patience 30, model mean validation loss 1.036743402481079, embedding dim 64, hidden size 2, num layers 1, train loss 1.0757439136505127, validation loss 1.0160273313522339\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0305674076080322, embedding dim 64, hidden size 2, num layers 1, train loss 0.8895351886749268, validation loss 1.006819248199463\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0233008861541748, embedding dim 64, hidden size 2, num layers 1, train loss 0.8823062777519226, validation loss 1.000559687614441\n",
      "Epoch 210, current patience 30, model mean validation loss 1.017261028289795, embedding dim 64, hidden size 2, num layers 1, train loss 0.8546916246414185, validation loss 1.001309871673584\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0101261138916016, embedding dim 64, hidden size 2, num layers 1, train loss 0.8603936433792114, validation loss 0.9826714396476746\n",
      "Epoch 230, current patience 30, model mean validation loss 1.003840684890747, embedding dim 64, hidden size 2, num layers 1, train loss 0.9032633900642395, validation loss 0.9959291219711304\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9957034587860107, embedding dim 64, hidden size 2, num layers 1, train loss 0.9311335682868958, validation loss 0.9563851356506348\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9934108257293701, embedding dim 64, hidden size 2, num layers 1, train loss 0.8102191090583801, validation loss 0.9875842928886414\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9848363399505615, embedding dim 64, hidden size 2, num layers 1, train loss 0.8446555137634277, validation loss 0.947431743144989\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9804431200027466, embedding dim 64, hidden size 2, num layers 1, train loss 0.7797669172286987, validation loss 0.9716735482215881\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9737563729286194, embedding dim 64, hidden size 2, num layers 1, train loss 1.0368322134017944, validation loss 0.9470658898353577\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9667423367500305, embedding dim 64, hidden size 2, num layers 1, train loss 0.8123065829277039, validation loss 0.9451974034309387\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9626942873001099, embedding dim 64, hidden size 2, num layers 1, train loss 0.8560049533843994, validation loss 0.9502873420715332\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9561284780502319, embedding dim 64, hidden size 2, num layers 1, train loss 0.7216929793357849, validation loss 0.9434025883674622\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9553933143615723, embedding dim 64, hidden size 2, num layers 1, train loss 0.9567681550979614, validation loss 0.9505034685134888\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9504279494285583, embedding dim 64, hidden size 2, num layers 1, train loss 0.7595471143722534, validation loss 0.9478617906570435\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9522185325622559, embedding dim 64, hidden size 2, num layers 1, train loss 0.8466227650642395, validation loss 0.9617559909820557\n",
      "Epoch 350, current patience 29, model mean validation loss 0.9487380981445312, embedding dim 64, hidden size 2, num layers 1, train loss 0.7945880889892578, validation loss 0.9438300132751465\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9482866525650024, embedding dim 64, hidden size 2, num layers 1, train loss 0.7375658750534058, validation loss 0.9434546232223511\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9459608793258667, embedding dim 64, hidden size 2, num layers 1, train loss 0.655262291431427, validation loss 0.9265915155410767\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9440215826034546, embedding dim 64, hidden size 2, num layers 1, train loss 0.8408902287483215, validation loss 0.9347729086875916\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9437358379364014, embedding dim 64, hidden size 2, num layers 1, train loss 0.7029093503952026, validation loss 0.9411160349845886\n",
      "Epoch 400, current patience 30, model mean validation loss 0.9441620111465454, embedding dim 64, hidden size 2, num layers 1, train loss 0.7326269149780273, validation loss 0.9539129137992859\n",
      "Epoch 410, current patience 29, model mean validation loss 0.9445140361785889, embedding dim 64, hidden size 2, num layers 1, train loss 0.8458408117294312, validation loss 0.9506779909133911\n",
      "Epoch 420, current patience 28, model mean validation loss 0.9384750127792358, embedding dim 64, hidden size 2, num layers 1, train loss 0.9070825576782227, validation loss 0.9134442806243896\n",
      "Epoch 430, current patience 30, model mean validation loss 0.9380893707275391, embedding dim 64, hidden size 2, num layers 1, train loss 0.6154810190200806, validation loss 0.9407446384429932\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9408131241798401, embedding dim 64, hidden size 2, num layers 1, train loss 0.6437470316886902, validation loss 0.9652446508407593\n",
      "Epoch 450, current patience 29, model mean validation loss 0.9400967955589294, embedding dim 64, hidden size 2, num layers 1, train loss 0.9437757730484009, validation loss 0.9208607077598572\n",
      "Epoch 460, current patience 28, model mean validation loss 0.9408321380615234, embedding dim 64, hidden size 2, num layers 1, train loss 0.6811347603797913, validation loss 0.9406561851501465\n",
      "Epoch 470, current patience 27, model mean validation loss 0.9370015263557434, embedding dim 64, hidden size 2, num layers 1, train loss 0.8329228162765503, validation loss 0.9104712605476379\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9374233484268188, embedding dim 64, hidden size 2, num layers 1, train loss 0.6030175685882568, validation loss 0.9572872519493103\n",
      "Epoch 490, current patience 29, model mean validation loss 0.9430158138275146, embedding dim 64, hidden size 2, num layers 1, train loss 0.6889885663986206, validation loss 0.9954173564910889\n",
      "Epoch 500, current patience 28, model mean validation loss 0.9509714841842651, embedding dim 64, hidden size 2, num layers 1, train loss 0.64622563123703, validation loss 0.9770901203155518\n",
      "Epoch 510, current patience 27, model mean validation loss 0.9471071362495422, embedding dim 64, hidden size 2, num layers 1, train loss 0.80226731300354, validation loss 0.9098293781280518\n",
      "Epoch 520, current patience 26, model mean validation loss 0.944728434085846, embedding dim 64, hidden size 2, num layers 1, train loss 1.0097737312316895, validation loss 0.9462150931358337\n",
      "Epoch 530, current patience 25, model mean validation loss 0.9471937417984009, embedding dim 64, hidden size 2, num layers 1, train loss 0.7175588607788086, validation loss 0.9405832290649414\n",
      "Epoch 540, current patience 24, model mean validation loss 0.9534580707550049, embedding dim 64, hidden size 2, num layers 1, train loss 0.7855950593948364, validation loss 0.9907708168029785\n",
      "Epoch 550, current patience 23, model mean validation loss 0.9597793221473694, embedding dim 64, hidden size 2, num layers 1, train loss 0.6506656408309937, validation loss 0.9610415697097778\n",
      "Epoch 560, current patience 22, model mean validation loss 0.954850435256958, embedding dim 64, hidden size 2, num layers 1, train loss 0.6185941696166992, validation loss 0.917855978012085\n",
      "Epoch 570, current patience 21, model mean validation loss 0.951285719871521, embedding dim 64, hidden size 2, num layers 1, train loss 0.7450714111328125, validation loss 0.9668996334075928\n",
      "Epoch 580, current patience 20, model mean validation loss 0.9476338028907776, embedding dim 64, hidden size 2, num layers 1, train loss 0.5660710334777832, validation loss 0.9478749632835388\n",
      "Epoch 590, current patience 19, model mean validation loss 0.9523590207099915, embedding dim 64, hidden size 2, num layers 1, train loss 0.5727138519287109, validation loss 0.9476306438446045\n",
      "Epoch 600, current patience 18, model mean validation loss 0.9535398483276367, embedding dim 64, hidden size 2, num layers 1, train loss 0.5305787324905396, validation loss 0.955662190914154\n",
      "Epoch 610, current patience 17, model mean validation loss 0.9549989104270935, embedding dim 64, hidden size 2, num layers 1, train loss 0.6974079608917236, validation loss 0.9522548913955688\n",
      "Epoch 620, current patience 16, model mean validation loss 0.9461174607276917, embedding dim 64, hidden size 2, num layers 1, train loss 0.7854851484298706, validation loss 0.9197196364402771\n",
      "Epoch 630, current patience 15, model mean validation loss 0.9437559843063354, embedding dim 64, hidden size 2, num layers 1, train loss 0.6411229968070984, validation loss 0.9421499967575073\n",
      "Epoch 640, current patience 14, model mean validation loss 0.9563302993774414, embedding dim 64, hidden size 2, num layers 1, train loss 0.7352491021156311, validation loss 1.0184500217437744\n",
      "Epoch 650, current patience 13, model mean validation loss 0.9582188725471497, embedding dim 64, hidden size 2, num layers 1, train loss 0.5949104428291321, validation loss 0.9820088148117065\n",
      "Epoch 660, current patience 12, model mean validation loss 0.967063307762146, embedding dim 64, hidden size 2, num layers 1, train loss 0.6235713362693787, validation loss 1.018630027770996\n",
      "Epoch 670, current patience 11, model mean validation loss 0.9710709452629089, embedding dim 64, hidden size 2, num layers 1, train loss 0.6267814636230469, validation loss 0.9796921014785767\n",
      "Epoch 680, current patience 10, model mean validation loss 0.974190354347229, embedding dim 64, hidden size 2, num layers 1, train loss 0.7082520723342896, validation loss 0.980617105960846\n",
      "Epoch 690, current patience 9, model mean validation loss 0.9774353504180908, embedding dim 64, hidden size 2, num layers 1, train loss 0.6267704963684082, validation loss 0.978215217590332\n",
      "Epoch 700, current patience 8, model mean validation loss 0.9843630790710449, embedding dim 64, hidden size 2, num layers 1, train loss 0.6530473232269287, validation loss 0.9751412272453308\n",
      "Epoch 710, current patience 7, model mean validation loss 0.9879661202430725, embedding dim 64, hidden size 2, num layers 1, train loss 0.4865891933441162, validation loss 0.970974862575531\n",
      "Epoch 720, current patience 6, model mean validation loss 0.9849189519882202, embedding dim 64, hidden size 2, num layers 1, train loss 0.4209129810333252, validation loss 0.9940725564956665\n",
      "Epoch 730, current patience 5, model mean validation loss 0.9856072664260864, embedding dim 64, hidden size 2, num layers 1, train loss 0.5561051368713379, validation loss 0.9875149726867676\n",
      "Epoch 740, current patience 4, model mean validation loss 0.9779207706451416, embedding dim 64, hidden size 2, num layers 1, train loss 0.5860919952392578, validation loss 0.957138180732727\n",
      "Epoch 750, current patience 3, model mean validation loss 0.979731559753418, embedding dim 64, hidden size 2, num layers 1, train loss 0.5059943795204163, validation loss 0.9941784739494324\n",
      "Epoch 760, current patience 2, model mean validation loss 0.9770765900611877, embedding dim 64, hidden size 2, num layers 1, train loss 0.5918273329734802, validation loss 0.9593772292137146\n",
      "Epoch 770, current patience 1, model mean validation loss 0.978585958480835, embedding dim 64, hidden size 2, num layers 1, train loss 0.5275039672851562, validation loss 0.9902904033660889\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1293740272521973, embedding dim 64, hidden size 4, num layers 1, train loss 1.1114311218261719, validation loss 1.1293740272521973\n",
      "Epoch 10, current patience 30, model mean validation loss 1.121095061302185, embedding dim 64, hidden size 4, num layers 1, train loss 1.0755313634872437, validation loss 1.1128160953521729\n",
      "Epoch 20, current patience 30, model mean validation loss 1.115209698677063, embedding dim 64, hidden size 4, num layers 1, train loss 1.111362338066101, validation loss 1.1034390926361084\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1091820001602173, embedding dim 64, hidden size 4, num layers 1, train loss 1.0813292264938354, validation loss 1.0910987854003906\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1066200733184814, embedding dim 64, hidden size 4, num layers 1, train loss 1.0893242359161377, validation loss 1.0963718891143799\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1049195528030396, embedding dim 64, hidden size 4, num layers 1, train loss 1.0831962823867798, validation loss 1.0964173078536987\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1025974750518799, embedding dim 64, hidden size 4, num layers 1, train loss 1.0419504642486572, validation loss 1.0886653661727905\n",
      "Epoch 70, current patience 30, model mean validation loss 1.100077509880066, embedding dim 64, hidden size 4, num layers 1, train loss 1.0851945877075195, validation loss 1.08243727684021\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0918402671813965, embedding dim 64, hidden size 4, num layers 1, train loss 1.0378937721252441, validation loss 1.0634760856628418\n",
      "Epoch 90, current patience 30, model mean validation loss 1.085222601890564, embedding dim 64, hidden size 4, num layers 1, train loss 0.9793144464492798, validation loss 1.0598747730255127\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0788109302520752, embedding dim 64, hidden size 4, num layers 1, train loss 1.0687001943588257, validation loss 1.0521466732025146\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0715210437774658, embedding dim 64, hidden size 4, num layers 1, train loss 1.1143790483474731, validation loss 1.0327789783477783\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0634344816207886, embedding dim 64, hidden size 4, num layers 1, train loss 0.9882586598396301, validation loss 1.0316798686981201\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0556676387786865, embedding dim 64, hidden size 4, num layers 1, train loss 0.9039657711982727, validation loss 1.0342823266983032\n",
      "Epoch 140, current patience 30, model mean validation loss 1.045989751815796, embedding dim 64, hidden size 4, num layers 1, train loss 0.9374895691871643, validation loss 1.0112427473068237\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0368704795837402, embedding dim 64, hidden size 4, num layers 1, train loss 0.9519572257995605, validation loss 1.0094821453094482\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0284373760223389, embedding dim 64, hidden size 4, num layers 1, train loss 0.9900614023208618, validation loss 0.9960108995437622\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0196044445037842, embedding dim 64, hidden size 4, num layers 1, train loss 1.0990501642227173, validation loss 0.9892115592956543\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0080175399780273, embedding dim 64, hidden size 4, num layers 1, train loss 0.9172592759132385, validation loss 0.9594513177871704\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0017468929290771, embedding dim 64, hidden size 4, num layers 1, train loss 0.7889482975006104, validation loss 0.9826148152351379\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9944521188735962, embedding dim 64, hidden size 4, num layers 1, train loss 1.0763347148895264, validation loss 0.9733213186264038\n",
      "Epoch 210, current patience 30, model mean validation loss 0.983704686164856, embedding dim 64, hidden size 4, num layers 1, train loss 1.055269718170166, validation loss 0.9483025074005127\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9770378470420837, embedding dim 64, hidden size 4, num layers 1, train loss 0.7896426916122437, validation loss 0.9579084515571594\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9703302979469299, embedding dim 64, hidden size 4, num layers 1, train loss 0.8422130346298218, validation loss 0.9558212757110596\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9627779126167297, embedding dim 64, hidden size 4, num layers 1, train loss 1.0569298267364502, validation loss 0.9355918765068054\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9540872573852539, embedding dim 64, hidden size 4, num layers 1, train loss 1.1469272375106812, validation loss 0.9196866750717163\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9484236240386963, embedding dim 64, hidden size 4, num layers 1, train loss 0.7243295907974243, validation loss 0.9141426086425781\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9424409866333008, embedding dim 64, hidden size 4, num layers 1, train loss 0.6877989768981934, validation loss 0.9347532391548157\n",
      "Epoch 280, current patience 30, model mean validation loss 0.934515118598938, embedding dim 64, hidden size 4, num layers 1, train loss 0.8739415407180786, validation loss 0.9099144339561462\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9292894005775452, embedding dim 64, hidden size 4, num layers 1, train loss 0.6602525115013123, validation loss 0.9064965844154358\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9210542440414429, embedding dim 64, hidden size 4, num layers 1, train loss 0.6694477796554565, validation loss 0.8920272588729858\n",
      "Epoch 310, current patience 30, model mean validation loss 0.9154642820358276, embedding dim 64, hidden size 4, num layers 1, train loss 0.6472494006156921, validation loss 0.9111015796661377\n",
      "Epoch 320, current patience 30, model mean validation loss 0.9110391139984131, embedding dim 64, hidden size 4, num layers 1, train loss 0.889386773109436, validation loss 0.9001903533935547\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9099833965301514, embedding dim 64, hidden size 4, num layers 1, train loss 0.6401837468147278, validation loss 0.9112407565116882\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9036844968795776, embedding dim 64, hidden size 4, num layers 1, train loss 0.7932461500167847, validation loss 0.8637518286705017\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9005022048950195, embedding dim 64, hidden size 4, num layers 1, train loss 0.7374316453933716, validation loss 0.9092950224876404\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8972642421722412, embedding dim 64, hidden size 4, num layers 1, train loss 0.9721518158912659, validation loss 0.8840101361274719\n",
      "Epoch 370, current patience 30, model mean validation loss 0.8967510461807251, embedding dim 64, hidden size 4, num layers 1, train loss 0.7090686559677124, validation loss 0.9023910760879517\n",
      "Epoch 380, current patience 30, model mean validation loss 0.8974384069442749, embedding dim 64, hidden size 4, num layers 1, train loss 0.5502570867538452, validation loss 0.8975262641906738\n",
      "Epoch 390, current patience 29, model mean validation loss 0.8970768451690674, embedding dim 64, hidden size 4, num layers 1, train loss 0.6289278268814087, validation loss 0.9082093238830566\n",
      "Epoch 400, current patience 28, model mean validation loss 0.8989819288253784, embedding dim 64, hidden size 4, num layers 1, train loss 0.6535196304321289, validation loss 0.9154314398765564\n",
      "Epoch 410, current patience 27, model mean validation loss 0.8937981128692627, embedding dim 64, hidden size 4, num layers 1, train loss 0.6640167832374573, validation loss 0.8697695732116699\n",
      "Epoch 420, current patience 30, model mean validation loss 0.9013094902038574, embedding dim 64, hidden size 4, num layers 1, train loss 0.5394078493118286, validation loss 0.9238430261611938\n",
      "Epoch 430, current patience 29, model mean validation loss 0.9029220938682556, embedding dim 64, hidden size 4, num layers 1, train loss 0.5987021923065186, validation loss 0.9221959710121155\n",
      "Epoch 440, current patience 28, model mean validation loss 0.9070405960083008, embedding dim 64, hidden size 4, num layers 1, train loss 0.6299406886100769, validation loss 0.9169583320617676\n",
      "Epoch 450, current patience 27, model mean validation loss 0.9097632169723511, embedding dim 64, hidden size 4, num layers 1, train loss 0.7469242215156555, validation loss 0.9241719245910645\n",
      "Epoch 460, current patience 26, model mean validation loss 0.9048006534576416, embedding dim 64, hidden size 4, num layers 1, train loss 0.6829882264137268, validation loss 0.857825517654419\n",
      "Epoch 470, current patience 25, model mean validation loss 0.8996515274047852, embedding dim 64, hidden size 4, num layers 1, train loss 0.5908815264701843, validation loss 0.8670164346694946\n",
      "Epoch 480, current patience 24, model mean validation loss 0.8964884281158447, embedding dim 64, hidden size 4, num layers 1, train loss 0.5955991744995117, validation loss 0.8901269435882568\n",
      "Epoch 490, current patience 23, model mean validation loss 0.8909939527511597, embedding dim 64, hidden size 4, num layers 1, train loss 0.5375077724456787, validation loss 0.8258137702941895\n",
      "Epoch 500, current patience 30, model mean validation loss 0.8872957825660706, embedding dim 64, hidden size 4, num layers 1, train loss 0.5123938918113708, validation loss 0.8942573070526123\n",
      "Epoch 510, current patience 30, model mean validation loss 0.8836725354194641, embedding dim 64, hidden size 4, num layers 1, train loss 0.5494134426116943, validation loss 0.8932104110717773\n",
      "Epoch 520, current patience 30, model mean validation loss 0.8818861246109009, embedding dim 64, hidden size 4, num layers 1, train loss 0.6551897525787354, validation loss 0.9026671051979065\n",
      "Epoch 530, current patience 30, model mean validation loss 0.8875988721847534, embedding dim 64, hidden size 4, num layers 1, train loss 0.6762087345123291, validation loss 0.9698739051818848\n",
      "Epoch 540, current patience 29, model mean validation loss 0.8959701657295227, embedding dim 64, hidden size 4, num layers 1, train loss 0.5633397102355957, validation loss 0.9247954487800598\n",
      "Epoch 550, current patience 28, model mean validation loss 0.9023069739341736, embedding dim 64, hidden size 4, num layers 1, train loss 0.5418674945831299, validation loss 0.9177107214927673\n",
      "Epoch 560, current patience 27, model mean validation loss 0.9133985042572021, embedding dim 64, hidden size 4, num layers 1, train loss 0.547347903251648, validation loss 0.9788593053817749\n",
      "Epoch 570, current patience 26, model mean validation loss 0.9359366297721863, embedding dim 64, hidden size 4, num layers 1, train loss 0.4577433168888092, validation loss 1.006118893623352\n",
      "Epoch 580, current patience 25, model mean validation loss 0.946351945400238, embedding dim 64, hidden size 4, num layers 1, train loss 0.5915132761001587, validation loss 0.9775798320770264\n",
      "Epoch 590, current patience 24, model mean validation loss 0.9503889083862305, embedding dim 64, hidden size 4, num layers 1, train loss 0.5359599590301514, validation loss 0.9255062937736511\n",
      "Epoch 600, current patience 23, model mean validation loss 0.9565984010696411, embedding dim 64, hidden size 4, num layers 1, train loss 0.7192366123199463, validation loss 0.9523431658744812\n",
      "Epoch 610, current patience 22, model mean validation loss 0.9706778526306152, embedding dim 64, hidden size 4, num layers 1, train loss 0.5112754106521606, validation loss 1.0825092792510986\n",
      "Epoch 620, current patience 21, model mean validation loss 0.9719538688659668, embedding dim 64, hidden size 4, num layers 1, train loss 0.828587532043457, validation loss 0.9350036978721619\n",
      "Epoch 630, current patience 20, model mean validation loss 0.9791262149810791, embedding dim 64, hidden size 4, num layers 1, train loss 0.5287997722625732, validation loss 0.9750895500183105\n",
      "Epoch 640, current patience 19, model mean validation loss 0.978737473487854, embedding dim 64, hidden size 4, num layers 1, train loss 0.549202561378479, validation loss 0.9757487177848816\n",
      "Epoch 650, current patience 18, model mean validation loss 0.9703761339187622, embedding dim 64, hidden size 4, num layers 1, train loss 0.5568652153015137, validation loss 0.9392280578613281\n",
      "Epoch 660, current patience 17, model mean validation loss 0.9645999670028687, embedding dim 64, hidden size 4, num layers 1, train loss 0.5992440581321716, validation loss 0.9313710927963257\n",
      "Epoch 670, current patience 16, model mean validation loss 0.9757115840911865, embedding dim 64, hidden size 4, num layers 1, train loss 0.6111456751823425, validation loss 1.0143988132476807\n",
      "Epoch 680, current patience 15, model mean validation loss 0.9781539440155029, embedding dim 64, hidden size 4, num layers 1, train loss 0.4372897148132324, validation loss 0.9718823432922363\n",
      "Epoch 690, current patience 14, model mean validation loss 0.9617319107055664, embedding dim 64, hidden size 4, num layers 1, train loss 0.9877941608428955, validation loss 0.9511327147483826\n",
      "Epoch 700, current patience 13, model mean validation loss 0.9666163325309753, embedding dim 64, hidden size 4, num layers 1, train loss 0.3607679307460785, validation loss 0.9740791320800781\n",
      "Epoch 710, current patience 12, model mean validation loss 0.962485134601593, embedding dim 64, hidden size 4, num layers 1, train loss 0.3698888421058655, validation loss 0.9420402646064758\n",
      "Epoch 720, current patience 11, model mean validation loss 0.9600217938423157, embedding dim 64, hidden size 4, num layers 1, train loss 0.43721941113471985, validation loss 0.9560419321060181\n",
      "Epoch 730, current patience 10, model mean validation loss 0.9603546857833862, embedding dim 64, hidden size 4, num layers 1, train loss 0.7188388109207153, validation loss 0.9418914318084717\n",
      "Epoch 740, current patience 9, model mean validation loss 0.9676077365875244, embedding dim 64, hidden size 4, num layers 1, train loss 0.6750333905220032, validation loss 0.9893949031829834\n",
      "Epoch 750, current patience 8, model mean validation loss 0.9588122963905334, embedding dim 64, hidden size 4, num layers 1, train loss 1.0302588939666748, validation loss 0.9440351128578186\n",
      "Epoch 760, current patience 7, model mean validation loss 0.9639071226119995, embedding dim 64, hidden size 4, num layers 1, train loss 0.3513225317001343, validation loss 1.0126415491104126\n",
      "Epoch 770, current patience 6, model mean validation loss 0.9721028804779053, embedding dim 64, hidden size 4, num layers 1, train loss 0.6579676866531372, validation loss 1.0166990756988525\n",
      "Epoch 780, current patience 5, model mean validation loss 0.9637837409973145, embedding dim 64, hidden size 4, num layers 1, train loss 0.4729427099227905, validation loss 0.9075260758399963\n",
      "Epoch 790, current patience 4, model mean validation loss 0.9716620445251465, embedding dim 64, hidden size 4, num layers 1, train loss 0.648566484451294, validation loss 1.0050660371780396\n",
      "Epoch 800, current patience 3, model mean validation loss 0.9712767601013184, embedding dim 64, hidden size 4, num layers 1, train loss 0.5414074659347534, validation loss 0.9529598951339722\n",
      "Epoch 810, current patience 2, model mean validation loss 0.9807562828063965, embedding dim 64, hidden size 4, num layers 1, train loss 0.6064494252204895, validation loss 1.0177278518676758\n",
      "Epoch 820, current patience 1, model mean validation loss 0.9808053970336914, embedding dim 64, hidden size 4, num layers 1, train loss 0.45626920461654663, validation loss 0.989787220954895\n",
      "Epoch 0, current patience 30, model mean validation loss 1.180613398551941, embedding dim 64, hidden size 8, num layers 1, train loss 1.2201223373413086, validation loss 1.180613398551941\n",
      "Epoch 10, current patience 30, model mean validation loss 1.144718050956726, embedding dim 64, hidden size 8, num layers 1, train loss 1.1671326160430908, validation loss 1.1088227033615112\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1283165216445923, embedding dim 64, hidden size 8, num layers 1, train loss 1.1088900566101074, validation loss 1.0955133438110352\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1202223300933838, embedding dim 64, hidden size 8, num layers 1, train loss 1.1169836521148682, validation loss 1.0959396362304688\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1146037578582764, embedding dim 64, hidden size 8, num layers 1, train loss 1.0750865936279297, validation loss 1.0921297073364258\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1105231046676636, embedding dim 64, hidden size 8, num layers 1, train loss 1.1050083637237549, validation loss 1.0901198387145996\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1081068515777588, embedding dim 64, hidden size 8, num layers 1, train loss 1.1029374599456787, validation loss 1.0936095714569092\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1060103178024292, embedding dim 64, hidden size 8, num layers 1, train loss 1.066818356513977, validation loss 1.091334342956543\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0951159000396729, embedding dim 64, hidden size 8, num layers 1, train loss 1.0757315158843994, validation loss 1.0934576988220215\n",
      "Epoch 90, current patience 30, model mean validation loss 1.091871976852417, embedding dim 64, hidden size 8, num layers 1, train loss 1.0917919874191284, validation loss 1.082871437072754\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0895763635635376, embedding dim 64, hidden size 8, num layers 1, train loss 1.0232892036437988, validation loss 1.0771489143371582\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0868576765060425, embedding dim 64, hidden size 8, num layers 1, train loss 1.0841835737228394, validation loss 1.0741899013519287\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0833766460418701, embedding dim 64, hidden size 8, num layers 1, train loss 1.0449717044830322, validation loss 1.0642814636230469\n",
      "Epoch 130, current patience 30, model mean validation loss 1.079088568687439, embedding dim 64, hidden size 8, num layers 1, train loss 1.0206270217895508, validation loss 1.0558149814605713\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0734093189239502, embedding dim 64, hidden size 8, num layers 1, train loss 1.0175278186798096, validation loss 1.0481759309768677\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0638046264648438, embedding dim 64, hidden size 8, num layers 1, train loss 1.015692949295044, validation loss 1.0144962072372437\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0544239282608032, embedding dim 64, hidden size 8, num layers 1, train loss 0.8638326525688171, validation loss 1.0184128284454346\n",
      "Epoch 170, current patience 30, model mean validation loss 1.042472004890442, embedding dim 64, hidden size 8, num layers 1, train loss 0.9752451181411743, validation loss 0.9872558116912842\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0331085920333862, embedding dim 64, hidden size 8, num layers 1, train loss 0.9976367354393005, validation loss 1.0022417306900024\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0222796201705933, embedding dim 64, hidden size 8, num layers 1, train loss 0.8422284722328186, validation loss 0.9875577092170715\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0095667839050293, embedding dim 64, hidden size 8, num layers 1, train loss 0.8694747686386108, validation loss 0.9625782370567322\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9972573518753052, embedding dim 64, hidden size 8, num layers 1, train loss 0.8712561130523682, validation loss 0.9573403596878052\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9854028224945068, embedding dim 64, hidden size 8, num layers 1, train loss 0.8850060105323792, validation loss 0.953339695930481\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9741314649581909, embedding dim 64, hidden size 8, num layers 1, train loss 0.9569443464279175, validation loss 0.9243255853652954\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9585566520690918, embedding dim 64, hidden size 8, num layers 1, train loss 0.7860895991325378, validation loss 0.893813967704773\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9491644501686096, embedding dim 64, hidden size 8, num layers 1, train loss 0.9326163530349731, validation loss 0.9121181964874268\n",
      "Epoch 260, current patience 30, model mean validation loss 0.9378008842468262, embedding dim 64, hidden size 8, num layers 1, train loss 0.6800582408905029, validation loss 0.9113335609436035\n",
      "Epoch 270, current patience 30, model mean validation loss 0.931171715259552, embedding dim 64, hidden size 8, num layers 1, train loss 0.7748228311538696, validation loss 0.934524416923523\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9187445044517517, embedding dim 64, hidden size 8, num layers 1, train loss 0.62761390209198, validation loss 0.8631603121757507\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9116771817207336, embedding dim 64, hidden size 8, num layers 1, train loss 0.5579016804695129, validation loss 0.9008018374443054\n",
      "Epoch 300, current patience 30, model mean validation loss 0.904887318611145, embedding dim 64, hidden size 8, num layers 1, train loss 0.5936422348022461, validation loss 0.8990209102630615\n",
      "Epoch 310, current patience 30, model mean validation loss 0.8982778787612915, embedding dim 64, hidden size 8, num layers 1, train loss 0.6750509738922119, validation loss 0.8714498281478882\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8984324932098389, embedding dim 64, hidden size 8, num layers 1, train loss 0.5742415189743042, validation loss 0.8950508236885071\n",
      "Epoch 330, current patience 29, model mean validation loss 0.9010270833969116, embedding dim 64, hidden size 8, num layers 1, train loss 0.9408460855484009, validation loss 0.9328749179840088\n",
      "Epoch 340, current patience 28, model mean validation loss 0.9019612073898315, embedding dim 64, hidden size 8, num layers 1, train loss 0.5898456573486328, validation loss 0.9188065528869629\n",
      "Epoch 350, current patience 27, model mean validation loss 0.8894855976104736, embedding dim 64, hidden size 8, num layers 1, train loss 0.9237565994262695, validation loss 0.8347195386886597\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8947353363037109, embedding dim 64, hidden size 8, num layers 1, train loss 0.6874498128890991, validation loss 0.9051584601402283\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8931850790977478, embedding dim 64, hidden size 8, num layers 1, train loss 0.52936190366745, validation loss 0.8883994817733765\n",
      "Epoch 380, current patience 28, model mean validation loss 0.8892555832862854, embedding dim 64, hidden size 8, num layers 1, train loss 0.8745077252388, validation loss 0.8675851821899414\n",
      "Epoch 390, current patience 30, model mean validation loss 0.8865794539451599, embedding dim 64, hidden size 8, num layers 1, train loss 0.8155390620231628, validation loss 0.8500404357910156\n",
      "Epoch 400, current patience 30, model mean validation loss 0.8856148719787598, embedding dim 64, hidden size 8, num layers 1, train loss 0.4855533838272095, validation loss 0.8873345851898193\n",
      "Epoch 410, current patience 30, model mean validation loss 0.8810030221939087, embedding dim 64, hidden size 8, num layers 1, train loss 0.3700318932533264, validation loss 0.8959795236587524\n",
      "Epoch 420, current patience 30, model mean validation loss 0.8737931251525879, embedding dim 64, hidden size 8, num layers 1, train loss 0.5817025899887085, validation loss 0.8611277341842651\n",
      "Epoch 430, current patience 30, model mean validation loss 0.8750866651535034, embedding dim 64, hidden size 8, num layers 1, train loss 0.8906052112579346, validation loss 0.845068097114563\n",
      "Epoch 440, current patience 29, model mean validation loss 0.8683120012283325, embedding dim 64, hidden size 8, num layers 1, train loss 0.5953723192214966, validation loss 0.8509610891342163\n",
      "Epoch 450, current patience 30, model mean validation loss 0.8693115711212158, embedding dim 64, hidden size 8, num layers 1, train loss 0.623113751411438, validation loss 0.8963960409164429\n",
      "Epoch 460, current patience 29, model mean validation loss 0.8736015558242798, embedding dim 64, hidden size 8, num layers 1, train loss 0.6332428455352783, validation loss 0.9019054174423218\n",
      "Epoch 470, current patience 28, model mean validation loss 0.8810069561004639, embedding dim 64, hidden size 8, num layers 1, train loss 0.8200079798698425, validation loss 0.9092833995819092\n",
      "Epoch 480, current patience 27, model mean validation loss 0.8749048113822937, embedding dim 64, hidden size 8, num layers 1, train loss 0.6723270416259766, validation loss 0.8385171890258789\n",
      "Epoch 490, current patience 26, model mean validation loss 0.8741573095321655, embedding dim 64, hidden size 8, num layers 1, train loss 0.49814122915267944, validation loss 0.8899997472763062\n",
      "Epoch 500, current patience 25, model mean validation loss 0.8824118375778198, embedding dim 64, hidden size 8, num layers 1, train loss 0.46389907598495483, validation loss 0.9271634817123413\n",
      "Epoch 510, current patience 24, model mean validation loss 0.8905156850814819, embedding dim 64, hidden size 8, num layers 1, train loss 0.6025620698928833, validation loss 0.9098992347717285\n",
      "Epoch 520, current patience 23, model mean validation loss 0.8963438868522644, embedding dim 64, hidden size 8, num layers 1, train loss 0.5066787004470825, validation loss 0.8975862264633179\n",
      "Epoch 530, current patience 22, model mean validation loss 0.9010432958602905, embedding dim 64, hidden size 8, num layers 1, train loss 0.7563133835792542, validation loss 0.9339916706085205\n",
      "Epoch 540, current patience 21, model mean validation loss 0.8937616348266602, embedding dim 64, hidden size 8, num layers 1, train loss 0.9231060147285461, validation loss 0.8436526656150818\n",
      "Epoch 550, current patience 20, model mean validation loss 0.8910729885101318, embedding dim 64, hidden size 8, num layers 1, train loss 0.5152316093444824, validation loss 0.887773871421814\n",
      "Epoch 560, current patience 19, model mean validation loss 0.899440586566925, embedding dim 64, hidden size 8, num layers 1, train loss 0.5966699123382568, validation loss 0.9054577350616455\n",
      "Epoch 570, current patience 18, model mean validation loss 0.8979632258415222, embedding dim 64, hidden size 8, num layers 1, train loss 0.5107689499855042, validation loss 0.8781812191009521\n",
      "Epoch 580, current patience 17, model mean validation loss 0.8935852646827698, embedding dim 64, hidden size 8, num layers 1, train loss 0.550871729850769, validation loss 0.8921393752098083\n",
      "Epoch 590, current patience 16, model mean validation loss 0.8887401819229126, embedding dim 64, hidden size 8, num layers 1, train loss 0.6850061416625977, validation loss 0.8711383938789368\n",
      "Epoch 600, current patience 15, model mean validation loss 0.887590765953064, embedding dim 64, hidden size 8, num layers 1, train loss 0.7726027965545654, validation loss 0.8883909583091736\n",
      "Epoch 610, current patience 14, model mean validation loss 0.8824321627616882, embedding dim 64, hidden size 8, num layers 1, train loss 0.45177561044692993, validation loss 0.8927227854728699\n",
      "Epoch 620, current patience 13, model mean validation loss 0.8903334736824036, embedding dim 64, hidden size 8, num layers 1, train loss 0.41623228788375854, validation loss 0.9068632125854492\n",
      "Epoch 630, current patience 12, model mean validation loss 0.8957825899124146, embedding dim 64, hidden size 8, num layers 1, train loss 0.6866084933280945, validation loss 0.9313668012619019\n",
      "Epoch 640, current patience 11, model mean validation loss 0.8987388610839844, embedding dim 64, hidden size 8, num layers 1, train loss 0.7950776815414429, validation loss 0.9291080236434937\n",
      "Epoch 650, current patience 10, model mean validation loss 0.9008909463882446, embedding dim 64, hidden size 8, num layers 1, train loss 0.4105975925922394, validation loss 0.8953982591629028\n",
      "Epoch 660, current patience 9, model mean validation loss 0.9089600443840027, embedding dim 64, hidden size 8, num layers 1, train loss 0.41865506768226624, validation loss 0.956692099571228\n",
      "Epoch 670, current patience 8, model mean validation loss 0.9119254350662231, embedding dim 64, hidden size 8, num layers 1, train loss 0.33763548731803894, validation loss 0.89486163854599\n",
      "Epoch 680, current patience 7, model mean validation loss 0.9188001751899719, embedding dim 64, hidden size 8, num layers 1, train loss 0.4022919535636902, validation loss 0.9433891773223877\n",
      "Epoch 690, current patience 6, model mean validation loss 0.9215479493141174, embedding dim 64, hidden size 8, num layers 1, train loss 0.4870343804359436, validation loss 0.9147046804428101\n",
      "Epoch 700, current patience 5, model mean validation loss 0.9247973561286926, embedding dim 64, hidden size 8, num layers 1, train loss 0.38959801197052, validation loss 0.9328581690788269\n",
      "Epoch 710, current patience 4, model mean validation loss 0.9321199655532837, embedding dim 64, hidden size 8, num layers 1, train loss 0.8164578676223755, validation loss 0.989948034286499\n",
      "Epoch 720, current patience 3, model mean validation loss 0.9314082264900208, embedding dim 64, hidden size 8, num layers 1, train loss 0.5355151891708374, validation loss 0.9234134554862976\n",
      "Epoch 730, current patience 2, model mean validation loss 0.9355185627937317, embedding dim 64, hidden size 8, num layers 1, train loss 0.5679997205734253, validation loss 0.9282808303833008\n",
      "Epoch 740, current patience 1, model mean validation loss 0.9361864328384399, embedding dim 64, hidden size 8, num layers 1, train loss 0.5226647257804871, validation loss 0.9620357751846313\n",
      "Epoch 0, current patience 30, model mean validation loss 1.103027582168579, embedding dim 64, hidden size 16, num layers 1, train loss 1.0997226238250732, validation loss 1.103027582168579\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0989234447479248, embedding dim 64, hidden size 16, num layers 1, train loss 1.0966999530792236, validation loss 1.094819188117981\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0973581075668335, embedding dim 64, hidden size 16, num layers 1, train loss 1.1025075912475586, validation loss 1.0942271947860718\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0970782041549683, embedding dim 64, hidden size 16, num layers 1, train loss 1.0789114236831665, validation loss 1.0962387323379517\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0957716703414917, embedding dim 64, hidden size 16, num layers 1, train loss 1.092024326324463, validation loss 1.090545654296875\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0942059755325317, embedding dim 64, hidden size 16, num layers 1, train loss 1.0988171100616455, validation loss 1.0863776206970215\n",
      "Epoch 60, current patience 30, model mean validation loss 1.091948390007019, embedding dim 64, hidden size 16, num layers 1, train loss 1.0239386558532715, validation loss 1.0784027576446533\n",
      "Epoch 70, current patience 30, model mean validation loss 1.085463285446167, embedding dim 64, hidden size 16, num layers 1, train loss 0.9767393469810486, validation loss 1.0400679111480713\n",
      "Epoch 80, current patience 30, model mean validation loss 1.075413703918457, embedding dim 64, hidden size 16, num layers 1, train loss 1.0173044204711914, validation loss 1.022631287574768\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0629252195358276, embedding dim 64, hidden size 16, num layers 1, train loss 1.0163367986679077, validation loss 0.994910478591919\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0453166961669922, embedding dim 64, hidden size 16, num layers 1, train loss 1.0297006368637085, validation loss 0.9533596038818359\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0198708772659302, embedding dim 64, hidden size 16, num layers 1, train loss 1.1828678846359253, validation loss 0.8926721811294556\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9996262788772583, embedding dim 64, hidden size 16, num layers 1, train loss 0.7837592363357544, validation loss 0.9285882711410522\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9729127883911133, embedding dim 64, hidden size 16, num layers 1, train loss 0.7364568114280701, validation loss 0.8726696372032166\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9479938745498657, embedding dim 64, hidden size 16, num layers 1, train loss 0.6876016855239868, validation loss 0.8790512681007385\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9282075762748718, embedding dim 64, hidden size 16, num layers 1, train loss 0.749861478805542, validation loss 0.8817776441574097\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9080955982208252, embedding dim 64, hidden size 16, num layers 1, train loss 0.6735571622848511, validation loss 0.8617357015609741\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8938741683959961, embedding dim 64, hidden size 16, num layers 1, train loss 0.755876898765564, validation loss 0.8811392188072205\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8798716068267822, embedding dim 64, hidden size 16, num layers 1, train loss 1.0078487396240234, validation loss 0.8413387537002563\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8679898381233215, embedding dim 64, hidden size 16, num layers 1, train loss 0.8654817342758179, validation loss 0.7976185083389282\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8504500389099121, embedding dim 64, hidden size 16, num layers 1, train loss 0.6774678826332092, validation loss 0.7882696986198425\n",
      "Epoch 210, current patience 30, model mean validation loss 0.841310977935791, embedding dim 64, hidden size 16, num layers 1, train loss 0.9839417934417725, validation loss 0.7995575666427612\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8332101702690125, embedding dim 64, hidden size 16, num layers 1, train loss 0.6310401558876038, validation loss 0.8142442107200623\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8265236616134644, embedding dim 64, hidden size 16, num layers 1, train loss 0.9030282497406006, validation loss 0.8282853960990906\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8202724456787109, embedding dim 64, hidden size 16, num layers 1, train loss 0.5581376552581787, validation loss 0.811726450920105\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8116610050201416, embedding dim 64, hidden size 16, num layers 1, train loss 0.5270237922668457, validation loss 0.812247633934021\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8058346509933472, embedding dim 64, hidden size 16, num layers 1, train loss 0.6530921459197998, validation loss 0.7947279810905457\n",
      "Epoch 270, current patience 30, model mean validation loss 0.810971736907959, embedding dim 64, hidden size 16, num layers 1, train loss 0.777429461479187, validation loss 0.8387149572372437\n",
      "Epoch 280, current patience 29, model mean validation loss 0.8113248348236084, embedding dim 64, hidden size 16, num layers 1, train loss 0.6186894178390503, validation loss 0.7910947203636169\n",
      "Epoch 290, current patience 28, model mean validation loss 0.8122921586036682, embedding dim 64, hidden size 16, num layers 1, train loss 0.49069032073020935, validation loss 0.8072957992553711\n",
      "Epoch 300, current patience 27, model mean validation loss 0.8120124340057373, embedding dim 64, hidden size 16, num layers 1, train loss 0.6863714456558228, validation loss 0.8120067119598389\n",
      "Epoch 310, current patience 26, model mean validation loss 0.8095934987068176, embedding dim 64, hidden size 16, num layers 1, train loss 0.5404174327850342, validation loss 0.8089339733123779\n",
      "Epoch 320, current patience 25, model mean validation loss 0.8077589273452759, embedding dim 64, hidden size 16, num layers 1, train loss 0.6390858888626099, validation loss 0.797049880027771\n",
      "Epoch 330, current patience 24, model mean validation loss 0.8101361989974976, embedding dim 64, hidden size 16, num layers 1, train loss 0.5270723104476929, validation loss 0.8312653303146362\n",
      "Epoch 340, current patience 23, model mean validation loss 0.8080303072929382, embedding dim 64, hidden size 16, num layers 1, train loss 0.538634181022644, validation loss 0.7778810262680054\n",
      "Epoch 350, current patience 22, model mean validation loss 0.8056096434593201, embedding dim 64, hidden size 16, num layers 1, train loss 0.6557037830352783, validation loss 0.8193501234054565\n",
      "Epoch 360, current patience 30, model mean validation loss 0.8114056587219238, embedding dim 64, hidden size 16, num layers 1, train loss 0.6072349548339844, validation loss 0.8374627232551575\n",
      "Epoch 370, current patience 29, model mean validation loss 0.8133623600006104, embedding dim 64, hidden size 16, num layers 1, train loss 0.40359658002853394, validation loss 0.8229491710662842\n",
      "Epoch 380, current patience 28, model mean validation loss 0.8175241351127625, embedding dim 64, hidden size 16, num layers 1, train loss 0.4583684802055359, validation loss 0.8453008532524109\n",
      "Epoch 390, current patience 27, model mean validation loss 0.8211125731468201, embedding dim 64, hidden size 16, num layers 1, train loss 0.3787332773208618, validation loss 0.8376412391662598\n",
      "Epoch 400, current patience 26, model mean validation loss 0.8266831040382385, embedding dim 64, hidden size 16, num layers 1, train loss 0.4531330466270447, validation loss 0.8416143655776978\n",
      "Epoch 410, current patience 25, model mean validation loss 0.8379414081573486, embedding dim 64, hidden size 16, num layers 1, train loss 0.4034128785133362, validation loss 0.9213315844535828\n",
      "Epoch 420, current patience 24, model mean validation loss 0.8425992727279663, embedding dim 64, hidden size 16, num layers 1, train loss 0.8419788479804993, validation loss 0.8151441812515259\n",
      "Epoch 430, current patience 23, model mean validation loss 0.8506572246551514, embedding dim 64, hidden size 16, num layers 1, train loss 0.7190499305725098, validation loss 0.8838131427764893\n",
      "Epoch 440, current patience 22, model mean validation loss 0.8611826300621033, embedding dim 64, hidden size 16, num layers 1, train loss 0.4737662076950073, validation loss 0.9216663837432861\n",
      "Epoch 450, current patience 21, model mean validation loss 0.8679883480072021, embedding dim 64, hidden size 16, num layers 1, train loss 0.4863397479057312, validation loss 0.8773946762084961\n",
      "Epoch 460, current patience 20, model mean validation loss 0.8788709044456482, embedding dim 64, hidden size 16, num layers 1, train loss 0.6597567796707153, validation loss 0.9323616027832031\n",
      "Epoch 470, current patience 19, model mean validation loss 0.8853460550308228, embedding dim 64, hidden size 16, num layers 1, train loss 0.25530314445495605, validation loss 0.8894423842430115\n",
      "Epoch 480, current patience 18, model mean validation loss 0.8901121616363525, embedding dim 64, hidden size 16, num layers 1, train loss 0.7542834281921387, validation loss 0.8797435164451599\n",
      "Epoch 490, current patience 17, model mean validation loss 0.880874514579773, embedding dim 64, hidden size 16, num layers 1, train loss 0.40862181782722473, validation loss 0.8474300503730774\n",
      "Epoch 500, current patience 16, model mean validation loss 0.8829083442687988, embedding dim 64, hidden size 16, num layers 1, train loss 0.2411746084690094, validation loss 0.8314154148101807\n",
      "Epoch 510, current patience 15, model mean validation loss 0.8902055025100708, embedding dim 64, hidden size 16, num layers 1, train loss 0.3576192855834961, validation loss 0.942190408706665\n",
      "Epoch 520, current patience 14, model mean validation loss 0.8900511860847473, embedding dim 64, hidden size 16, num layers 1, train loss 0.45771270990371704, validation loss 0.9204316139221191\n",
      "Epoch 530, current patience 13, model mean validation loss 0.8953886032104492, embedding dim 64, hidden size 16, num layers 1, train loss 0.20077484846115112, validation loss 0.9200938940048218\n",
      "Epoch 540, current patience 12, model mean validation loss 0.892874538898468, embedding dim 64, hidden size 16, num layers 1, train loss 0.6762991547584534, validation loss 0.9122487902641296\n",
      "Epoch 550, current patience 11, model mean validation loss 0.8875517249107361, embedding dim 64, hidden size 16, num layers 1, train loss 0.3559094965457916, validation loss 0.8468600511550903\n",
      "Epoch 560, current patience 10, model mean validation loss 0.8965510129928589, embedding dim 64, hidden size 16, num layers 1, train loss 0.45312172174453735, validation loss 0.9517379999160767\n",
      "Epoch 570, current patience 9, model mean validation loss 0.9019859433174133, embedding dim 64, hidden size 16, num layers 1, train loss 0.1831740289926529, validation loss 0.8909091949462891\n",
      "Epoch 580, current patience 8, model mean validation loss 0.9096680879592896, embedding dim 64, hidden size 16, num layers 1, train loss 0.20753145217895508, validation loss 0.8928728699684143\n",
      "Epoch 590, current patience 7, model mean validation loss 0.9128075838088989, embedding dim 64, hidden size 16, num layers 1, train loss 0.4106747508049011, validation loss 0.9673057794570923\n",
      "Epoch 600, current patience 6, model mean validation loss 0.9164202213287354, embedding dim 64, hidden size 16, num layers 1, train loss 0.5167240500450134, validation loss 0.9493336081504822\n",
      "Epoch 610, current patience 5, model mean validation loss 0.9141301512718201, embedding dim 64, hidden size 16, num layers 1, train loss 0.45046567916870117, validation loss 0.9017729759216309\n",
      "Epoch 620, current patience 4, model mean validation loss 0.9180675745010376, embedding dim 64, hidden size 16, num layers 1, train loss 0.35285693407058716, validation loss 0.9437484741210938\n",
      "Epoch 630, current patience 3, model mean validation loss 0.9386510848999023, embedding dim 64, hidden size 16, num layers 1, train loss 0.4080303907394409, validation loss 1.0115278959274292\n",
      "Epoch 640, current patience 2, model mean validation loss 0.9436159729957581, embedding dim 64, hidden size 16, num layers 1, train loss 0.30628055334091187, validation loss 0.9914571046829224\n",
      "Epoch 650, current patience 1, model mean validation loss 0.948623776435852, embedding dim 64, hidden size 16, num layers 1, train loss 0.32994717359542847, validation loss 0.9309718608856201\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1033332347869873, embedding dim 64, hidden size 32, num layers 1, train loss 1.1017212867736816, validation loss 1.1033332347869873\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0975046157836914, embedding dim 64, hidden size 32, num layers 1, train loss 1.0574077367782593, validation loss 1.0916759967803955\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0963499546051025, embedding dim 64, hidden size 32, num layers 1, train loss 1.076993703842163, validation loss 1.0940406322479248\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0927821397781372, embedding dim 64, hidden size 32, num layers 1, train loss 1.0824174880981445, validation loss 1.0820785760879517\n",
      "Epoch 40, current patience 30, model mean validation loss 1.081324815750122, embedding dim 64, hidden size 32, num layers 1, train loss 0.8835301399230957, validation loss 1.0354961156845093\n",
      "Epoch 50, current patience 30, model mean validation loss 1.072611927986145, embedding dim 64, hidden size 32, num layers 1, train loss 0.9469725489616394, validation loss 1.0290471315383911\n",
      "Epoch 60, current patience 30, model mean validation loss 1.059465765953064, embedding dim 64, hidden size 32, num layers 1, train loss 0.7894673943519592, validation loss 0.9805885553359985\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0448148250579834, embedding dim 64, hidden size 32, num layers 1, train loss 0.9068727493286133, validation loss 0.9422581195831299\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0184532403945923, embedding dim 64, hidden size 32, num layers 1, train loss 0.8557060956954956, validation loss 0.892440676689148\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9914137721061707, embedding dim 64, hidden size 32, num layers 1, train loss 0.824545681476593, validation loss 0.8753599524497986\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9684937000274658, embedding dim 64, hidden size 32, num layers 1, train loss 0.7146387100219727, validation loss 0.9106798768043518\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9392712116241455, embedding dim 64, hidden size 32, num layers 1, train loss 0.7684661149978638, validation loss 0.8482993245124817\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9265397787094116, embedding dim 64, hidden size 32, num layers 1, train loss 0.788867712020874, validation loss 0.9336446523666382\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9028456211090088, embedding dim 64, hidden size 32, num layers 1, train loss 0.8060952425003052, validation loss 0.8394936323165894\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8808488845825195, embedding dim 64, hidden size 32, num layers 1, train loss 0.8007410764694214, validation loss 0.8046150207519531\n",
      "Epoch 150, current patience 30, model mean validation loss 0.86597740650177, embedding dim 64, hidden size 32, num layers 1, train loss 0.59019535779953, validation loss 0.8232859373092651\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8625484704971313, embedding dim 64, hidden size 32, num layers 1, train loss 0.5557678937911987, validation loss 0.8650091886520386\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8575927019119263, embedding dim 64, hidden size 32, num layers 1, train loss 0.7760927677154541, validation loss 0.8357137441635132\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8446782827377319, embedding dim 64, hidden size 32, num layers 1, train loss 0.49215275049209595, validation loss 0.8073643445968628\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8392683863639832, embedding dim 64, hidden size 32, num layers 1, train loss 0.5822641253471375, validation loss 0.8050204515457153\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8238518834114075, embedding dim 64, hidden size 32, num layers 1, train loss 0.4903530478477478, validation loss 0.8103128671646118\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8180513381958008, embedding dim 64, hidden size 32, num layers 1, train loss 0.6489214897155762, validation loss 0.7930890321731567\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8308118581771851, embedding dim 64, hidden size 32, num layers 1, train loss 0.726935625076294, validation loss 0.9066992402076721\n",
      "Epoch 230, current patience 29, model mean validation loss 0.8311479091644287, embedding dim 64, hidden size 32, num layers 1, train loss 0.6624702215194702, validation loss 0.8259745836257935\n",
      "Epoch 240, current patience 28, model mean validation loss 0.8198744058609009, embedding dim 64, hidden size 32, num layers 1, train loss 0.5642025470733643, validation loss 0.7748209238052368\n",
      "Epoch 250, current patience 27, model mean validation loss 0.8112744092941284, embedding dim 64, hidden size 32, num layers 1, train loss 0.7162731885910034, validation loss 0.766913652420044\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8083779811859131, embedding dim 64, hidden size 32, num layers 1, train loss 0.5262377262115479, validation loss 0.784192681312561\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8079169988632202, embedding dim 64, hidden size 32, num layers 1, train loss 0.7505783438682556, validation loss 0.8013332486152649\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8011430501937866, embedding dim 64, hidden size 32, num layers 1, train loss 0.6295151710510254, validation loss 0.7561209201812744\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8025684356689453, embedding dim 64, hidden size 32, num layers 1, train loss 0.5799475312232971, validation loss 0.8044921159744263\n",
      "Epoch 300, current patience 29, model mean validation loss 0.7897062301635742, embedding dim 64, hidden size 32, num layers 1, train loss 0.4382278323173523, validation loss 0.803801417350769\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7876620292663574, embedding dim 64, hidden size 32, num layers 1, train loss 0.45368531346321106, validation loss 0.8096208572387695\n",
      "Epoch 320, current patience 30, model mean validation loss 0.7856201529502869, embedding dim 64, hidden size 32, num layers 1, train loss 0.5710049867630005, validation loss 0.7584860324859619\n",
      "Epoch 330, current patience 30, model mean validation loss 0.7889567613601685, embedding dim 64, hidden size 32, num layers 1, train loss 0.614338219165802, validation loss 0.7936064004898071\n",
      "Epoch 340, current patience 29, model mean validation loss 0.7961990237236023, embedding dim 64, hidden size 32, num layers 1, train loss 0.440572053194046, validation loss 0.8421312570571899\n",
      "Epoch 350, current patience 28, model mean validation loss 0.7945035099983215, embedding dim 64, hidden size 32, num layers 1, train loss 0.6264046430587769, validation loss 0.7877687215805054\n",
      "Epoch 360, current patience 27, model mean validation loss 0.8041336536407471, embedding dim 64, hidden size 32, num layers 1, train loss 0.5221899747848511, validation loss 0.8331623673439026\n",
      "Epoch 370, current patience 26, model mean validation loss 0.8068991899490356, embedding dim 64, hidden size 32, num layers 1, train loss 0.4828014075756073, validation loss 0.8266168236732483\n",
      "Epoch 380, current patience 25, model mean validation loss 0.8099139928817749, embedding dim 64, hidden size 32, num layers 1, train loss 0.43537819385528564, validation loss 0.8279193639755249\n",
      "Epoch 390, current patience 24, model mean validation loss 0.8102149367332458, embedding dim 64, hidden size 32, num layers 1, train loss 0.3303726315498352, validation loss 0.8120285272598267\n",
      "Epoch 400, current patience 23, model mean validation loss 0.8156694173812866, embedding dim 64, hidden size 32, num layers 1, train loss 0.36750900745391846, validation loss 0.8021219968795776\n",
      "Epoch 410, current patience 22, model mean validation loss 0.8180514574050903, embedding dim 64, hidden size 32, num layers 1, train loss 0.3494516909122467, validation loss 0.8126625418663025\n",
      "Epoch 420, current patience 21, model mean validation loss 0.8163555860519409, embedding dim 64, hidden size 32, num layers 1, train loss 0.5762173533439636, validation loss 0.8285645842552185\n",
      "Epoch 430, current patience 20, model mean validation loss 0.8195233345031738, embedding dim 64, hidden size 32, num layers 1, train loss 0.4101729393005371, validation loss 0.8131110072135925\n",
      "Epoch 440, current patience 19, model mean validation loss 0.8210179805755615, embedding dim 64, hidden size 32, num layers 1, train loss 0.38454365730285645, validation loss 0.8451191186904907\n",
      "Epoch 450, current patience 18, model mean validation loss 0.8135280013084412, embedding dim 64, hidden size 32, num layers 1, train loss 0.6440820693969727, validation loss 0.7666970491409302\n",
      "Epoch 460, current patience 17, model mean validation loss 0.8141223788261414, embedding dim 64, hidden size 32, num layers 1, train loss 0.3468116521835327, validation loss 0.8326746225357056\n",
      "Epoch 470, current patience 16, model mean validation loss 0.8280573487281799, embedding dim 64, hidden size 32, num layers 1, train loss 0.5434281826019287, validation loss 0.9235081076622009\n",
      "Epoch 480, current patience 15, model mean validation loss 0.8409900069236755, embedding dim 64, hidden size 32, num layers 1, train loss 0.670619010925293, validation loss 0.9055832028388977\n",
      "Epoch 490, current patience 14, model mean validation loss 0.8443335294723511, embedding dim 64, hidden size 32, num layers 1, train loss 0.3421143889427185, validation loss 0.8394107818603516\n",
      "Epoch 500, current patience 13, model mean validation loss 0.844398558139801, embedding dim 64, hidden size 32, num layers 1, train loss 0.276197612285614, validation loss 0.8290846347808838\n",
      "Epoch 510, current patience 12, model mean validation loss 0.8509883880615234, embedding dim 64, hidden size 32, num layers 1, train loss 0.32676273584365845, validation loss 0.8658294081687927\n",
      "Epoch 520, current patience 11, model mean validation loss 0.8571690917015076, embedding dim 64, hidden size 32, num layers 1, train loss 0.40439724922180176, validation loss 0.8945649266242981\n",
      "Epoch 530, current patience 10, model mean validation loss 0.8692492246627808, embedding dim 64, hidden size 32, num layers 1, train loss 0.2765781879425049, validation loss 0.86333829164505\n",
      "Epoch 540, current patience 9, model mean validation loss 0.873107373714447, embedding dim 64, hidden size 32, num layers 1, train loss 0.2426133155822754, validation loss 0.8635399341583252\n",
      "Epoch 550, current patience 8, model mean validation loss 0.8802288770675659, embedding dim 64, hidden size 32, num layers 1, train loss 0.24630922079086304, validation loss 0.9804795980453491\n",
      "Epoch 560, current patience 7, model mean validation loss 0.8820164203643799, embedding dim 64, hidden size 32, num layers 1, train loss 0.589131772518158, validation loss 0.9198836088180542\n",
      "Epoch 570, current patience 6, model mean validation loss 0.8843100070953369, embedding dim 64, hidden size 32, num layers 1, train loss 0.5271162986755371, validation loss 0.8577597141265869\n",
      "Epoch 580, current patience 5, model mean validation loss 0.8863057494163513, embedding dim 64, hidden size 32, num layers 1, train loss 0.3861944079399109, validation loss 0.8450504541397095\n",
      "Epoch 590, current patience 4, model mean validation loss 0.884872317314148, embedding dim 64, hidden size 32, num layers 1, train loss 0.15841373801231384, validation loss 0.8543623089790344\n",
      "Epoch 600, current patience 3, model mean validation loss 0.8893060684204102, embedding dim 64, hidden size 32, num layers 1, train loss 0.37157613039016724, validation loss 0.9300347566604614\n",
      "Epoch 610, current patience 2, model mean validation loss 0.8912442922592163, embedding dim 64, hidden size 32, num layers 1, train loss 0.3437795042991638, validation loss 0.8788440227508545\n",
      "Epoch 620, current patience 1, model mean validation loss 0.8946022391319275, embedding dim 64, hidden size 32, num layers 1, train loss 0.2750850319862366, validation loss 0.8904035687446594\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1002944707870483, embedding dim 64, hidden size 64, num layers 1, train loss 1.1050493717193604, validation loss 1.1002944707870483\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0977537631988525, embedding dim 64, hidden size 64, num layers 1, train loss 1.0918116569519043, validation loss 1.0952129364013672\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0961304903030396, embedding dim 64, hidden size 64, num layers 1, train loss 1.0691277980804443, validation loss 1.0928839445114136\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0933738946914673, embedding dim 64, hidden size 64, num layers 1, train loss 1.1202411651611328, validation loss 1.085103988647461\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0895501375198364, embedding dim 64, hidden size 64, num layers 1, train loss 1.0223795175552368, validation loss 1.0742552280426025\n",
      "Epoch 50, current patience 30, model mean validation loss 1.085034728050232, embedding dim 64, hidden size 64, num layers 1, train loss 1.0678045749664307, validation loss 1.0624574422836304\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0718377828598022, embedding dim 64, hidden size 64, num layers 1, train loss 1.0351507663726807, validation loss 0.9926570057868958\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0603663921356201, embedding dim 64, hidden size 64, num layers 1, train loss 0.9183675646781921, validation loss 0.9800662994384766\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0468238592147827, embedding dim 64, hidden size 64, num layers 1, train loss 0.9189044833183289, validation loss 0.9919535517692566\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0278023481369019, embedding dim 64, hidden size 64, num layers 1, train loss 0.9435677528381348, validation loss 0.9430412650108337\n",
      "Epoch 100, current patience 30, model mean validation loss 1.003310203552246, embedding dim 64, hidden size 64, num layers 1, train loss 0.8373620510101318, validation loss 0.8969465494155884\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9774165153503418, embedding dim 64, hidden size 64, num layers 1, train loss 0.8881131410598755, validation loss 0.8779547214508057\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9506020545959473, embedding dim 64, hidden size 64, num layers 1, train loss 0.6680561304092407, validation loss 0.8597397804260254\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9274762868881226, embedding dim 64, hidden size 64, num layers 1, train loss 0.8364217877388, validation loss 0.8774511218070984\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9074624180793762, embedding dim 64, hidden size 64, num layers 1, train loss 0.7374610900878906, validation loss 0.8325459957122803\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8871055841445923, embedding dim 64, hidden size 64, num layers 1, train loss 0.8985192775726318, validation loss 0.8172114491462708\n",
      "Epoch 160, current patience 30, model mean validation loss 0.86354660987854, embedding dim 64, hidden size 64, num layers 1, train loss 0.7049954533576965, validation loss 0.803482174873352\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8493499159812927, embedding dim 64, hidden size 64, num layers 1, train loss 0.5108988285064697, validation loss 0.8294677138328552\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8390783071517944, embedding dim 64, hidden size 64, num layers 1, train loss 0.7213863730430603, validation loss 0.814773678779602\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8284345865249634, embedding dim 64, hidden size 64, num layers 1, train loss 0.6357407569885254, validation loss 0.792805016040802\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8222463726997375, embedding dim 64, hidden size 64, num layers 1, train loss 0.5917830467224121, validation loss 0.8102338910102844\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8146872520446777, embedding dim 64, hidden size 64, num layers 1, train loss 0.9417015314102173, validation loss 0.8169782161712646\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8095749616622925, embedding dim 64, hidden size 64, num layers 1, train loss 0.9303433299064636, validation loss 0.7916480898857117\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8051069974899292, embedding dim 64, hidden size 64, num layers 1, train loss 0.5513249635696411, validation loss 0.7814673781394958\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8079627752304077, embedding dim 64, hidden size 64, num layers 1, train loss 0.5693416595458984, validation loss 0.8263287544250488\n",
      "Epoch 250, current patience 29, model mean validation loss 0.8053674101829529, embedding dim 64, hidden size 64, num layers 1, train loss 0.7036731243133545, validation loss 0.8087040185928345\n",
      "Epoch 260, current patience 28, model mean validation loss 0.80193030834198, embedding dim 64, hidden size 64, num layers 1, train loss 0.48887065052986145, validation loss 0.7872772216796875\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8022704124450684, embedding dim 64, hidden size 64, num layers 1, train loss 0.4926323890686035, validation loss 0.795525312423706\n",
      "Epoch 280, current patience 29, model mean validation loss 0.8075149059295654, embedding dim 64, hidden size 64, num layers 1, train loss 0.417376309633255, validation loss 0.8521904945373535\n",
      "Epoch 290, current patience 28, model mean validation loss 0.8079860210418701, embedding dim 64, hidden size 64, num layers 1, train loss 0.5229547023773193, validation loss 0.820746660232544\n",
      "Epoch 300, current patience 27, model mean validation loss 0.8093295097351074, embedding dim 64, hidden size 64, num layers 1, train loss 0.5483947992324829, validation loss 0.8023961782455444\n",
      "Epoch 310, current patience 26, model mean validation loss 0.8106082677841187, embedding dim 64, hidden size 64, num layers 1, train loss 0.5939828157424927, validation loss 0.7916975021362305\n",
      "Epoch 320, current patience 25, model mean validation loss 0.8089911341667175, embedding dim 64, hidden size 64, num layers 1, train loss 0.6827290058135986, validation loss 0.8133915662765503\n",
      "Epoch 330, current patience 24, model mean validation loss 0.8139930963516235, embedding dim 64, hidden size 64, num layers 1, train loss 0.4207620620727539, validation loss 0.848719596862793\n",
      "Epoch 340, current patience 23, model mean validation loss 0.8205073475837708, embedding dim 64, hidden size 64, num layers 1, train loss 0.5720114707946777, validation loss 0.839391827583313\n",
      "Epoch 350, current patience 22, model mean validation loss 0.8243911266326904, embedding dim 64, hidden size 64, num layers 1, train loss 0.6837737560272217, validation loss 0.8265950083732605\n",
      "Epoch 360, current patience 21, model mean validation loss 0.8161773681640625, embedding dim 64, hidden size 64, num layers 1, train loss 0.5469239950180054, validation loss 0.786480724811554\n",
      "Epoch 370, current patience 20, model mean validation loss 0.8174020648002625, embedding dim 64, hidden size 64, num layers 1, train loss 0.44817596673965454, validation loss 0.830544114112854\n",
      "Epoch 380, current patience 19, model mean validation loss 0.8237106800079346, embedding dim 64, hidden size 64, num layers 1, train loss 0.5797467231750488, validation loss 0.8528648018836975\n",
      "Epoch 390, current patience 18, model mean validation loss 0.834428071975708, embedding dim 64, hidden size 64, num layers 1, train loss 0.6455670595169067, validation loss 0.8774368762969971\n",
      "Epoch 400, current patience 17, model mean validation loss 0.8331828117370605, embedding dim 64, hidden size 64, num layers 1, train loss 0.3971441984176636, validation loss 0.8034294247627258\n",
      "Epoch 410, current patience 16, model mean validation loss 0.8310824632644653, embedding dim 64, hidden size 64, num layers 1, train loss 0.559566855430603, validation loss 0.8319164514541626\n",
      "Epoch 420, current patience 15, model mean validation loss 0.8322668075561523, embedding dim 64, hidden size 64, num layers 1, train loss 0.7728920578956604, validation loss 0.8488668203353882\n",
      "Epoch 430, current patience 14, model mean validation loss 0.8340965509414673, embedding dim 64, hidden size 64, num layers 1, train loss 0.23115672171115875, validation loss 0.8412333130836487\n",
      "Epoch 440, current patience 13, model mean validation loss 0.8472794890403748, embedding dim 64, hidden size 64, num layers 1, train loss 0.2593637704849243, validation loss 0.8919440507888794\n",
      "Epoch 450, current patience 12, model mean validation loss 0.8568572998046875, embedding dim 64, hidden size 64, num layers 1, train loss 0.3227199912071228, validation loss 0.9071670770645142\n",
      "Epoch 460, current patience 11, model mean validation loss 0.8504461646080017, embedding dim 64, hidden size 64, num layers 1, train loss 0.6540812253952026, validation loss 0.801575243473053\n",
      "Epoch 470, current patience 10, model mean validation loss 0.8574616312980652, embedding dim 64, hidden size 64, num layers 1, train loss 0.8254919052124023, validation loss 0.933560848236084\n",
      "Epoch 480, current patience 9, model mean validation loss 0.8616048693656921, embedding dim 64, hidden size 64, num layers 1, train loss 0.6393640041351318, validation loss 0.8365747928619385\n",
      "Epoch 490, current patience 8, model mean validation loss 0.8643554449081421, embedding dim 64, hidden size 64, num layers 1, train loss 0.3549160957336426, validation loss 0.8539214730262756\n",
      "Epoch 500, current patience 7, model mean validation loss 0.8729779720306396, embedding dim 64, hidden size 64, num layers 1, train loss 0.33826249837875366, validation loss 0.9178473353385925\n",
      "Epoch 510, current patience 6, model mean validation loss 0.896092414855957, embedding dim 64, hidden size 64, num layers 1, train loss 0.30912673473358154, validation loss 1.0261483192443848\n",
      "Epoch 520, current patience 5, model mean validation loss 0.8934064507484436, embedding dim 64, hidden size 64, num layers 1, train loss 0.23551715910434723, validation loss 0.8704565763473511\n",
      "Epoch 530, current patience 4, model mean validation loss 0.8990038633346558, embedding dim 64, hidden size 64, num layers 1, train loss 0.2055821716785431, validation loss 0.9519462585449219\n",
      "Epoch 540, current patience 3, model mean validation loss 0.9183762073516846, embedding dim 64, hidden size 64, num layers 1, train loss 0.4305110573768616, validation loss 0.9565541744232178\n",
      "Epoch 550, current patience 2, model mean validation loss 0.9300196170806885, embedding dim 64, hidden size 64, num layers 1, train loss 0.20037584006786346, validation loss 1.0267081260681152\n",
      "Epoch 560, current patience 1, model mean validation loss 0.9343535900115967, embedding dim 64, hidden size 64, num layers 1, train loss 0.38698720932006836, validation loss 0.871246337890625\n",
      "Epoch 0, current patience 30, model mean validation loss 1.09743332862854, embedding dim 64, hidden size 128, num layers 1, train loss 1.096134901046753, validation loss 1.09743332862854\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0946125984191895, embedding dim 64, hidden size 128, num layers 1, train loss 1.1027687788009644, validation loss 1.0917918682098389\n",
      "Epoch 20, current patience 30, model mean validation loss 1.093989372253418, embedding dim 64, hidden size 128, num layers 1, train loss 1.1078169345855713, validation loss 1.0927430391311646\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0895634889602661, embedding dim 64, hidden size 128, num layers 1, train loss 1.0872966051101685, validation loss 1.0762858390808105\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0807448625564575, embedding dim 64, hidden size 128, num layers 1, train loss 1.0467188358306885, validation loss 1.045469880104065\n",
      "Epoch 50, current patience 30, model mean validation loss 1.076047420501709, embedding dim 64, hidden size 128, num layers 1, train loss 1.0657403469085693, validation loss 1.052560806274414\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0660529136657715, embedding dim 64, hidden size 128, num layers 1, train loss 0.9537234902381897, validation loss 1.0060858726501465\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0509650707244873, embedding dim 64, hidden size 128, num layers 1, train loss 0.9448950290679932, validation loss 0.9453494548797607\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0327306985855103, embedding dim 64, hidden size 128, num layers 1, train loss 0.886393666267395, validation loss 0.9515593647956848\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0148377418518066, embedding dim 64, hidden size 128, num layers 1, train loss 0.9098696708679199, validation loss 0.9486475586891174\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9922041893005371, embedding dim 64, hidden size 128, num layers 1, train loss 0.9601740837097168, validation loss 0.9116750955581665\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9636654853820801, embedding dim 64, hidden size 128, num layers 1, train loss 0.7821906805038452, validation loss 0.8479758501052856\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9350603818893433, embedding dim 64, hidden size 128, num layers 1, train loss 0.8117458820343018, validation loss 0.8166290521621704\n",
      "Epoch 130, current patience 30, model mean validation loss 0.910426139831543, embedding dim 64, hidden size 128, num layers 1, train loss 0.8350108861923218, validation loss 0.8554871082305908\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8842537999153137, embedding dim 64, hidden size 128, num layers 1, train loss 0.6801056265830994, validation loss 0.7967069149017334\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8663651943206787, embedding dim 64, hidden size 128, num layers 1, train loss 0.5831260681152344, validation loss 0.8022410273551941\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8525403738021851, embedding dim 64, hidden size 128, num layers 1, train loss 0.6961572170257568, validation loss 0.8409611582756042\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8358253240585327, embedding dim 64, hidden size 128, num layers 1, train loss 0.7992830872535706, validation loss 0.8149267435073853\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8206163644790649, embedding dim 64, hidden size 128, num layers 1, train loss 0.7411412000656128, validation loss 0.7900030612945557\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8133125305175781, embedding dim 64, hidden size 128, num layers 1, train loss 0.5636053681373596, validation loss 0.7895452976226807\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8089657425880432, embedding dim 64, hidden size 128, num layers 1, train loss 0.8172139525413513, validation loss 0.7818543910980225\n",
      "Epoch 210, current patience 30, model mean validation loss 0.7995027899742126, embedding dim 64, hidden size 128, num layers 1, train loss 0.6260459423065186, validation loss 0.7797837257385254\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8000029921531677, embedding dim 64, hidden size 128, num layers 1, train loss 0.5015672445297241, validation loss 0.800708532333374\n",
      "Epoch 230, current patience 29, model mean validation loss 0.7951796054840088, embedding dim 64, hidden size 128, num layers 1, train loss 0.8279351592063904, validation loss 0.7636539936065674\n",
      "Epoch 240, current patience 30, model mean validation loss 0.7858198881149292, embedding dim 64, hidden size 128, num layers 1, train loss 0.5958602428436279, validation loss 0.7660835981369019\n",
      "Epoch 250, current patience 30, model mean validation loss 0.7772876024246216, embedding dim 64, hidden size 128, num layers 1, train loss 0.6554673910140991, validation loss 0.7466683387756348\n",
      "Epoch 260, current patience 30, model mean validation loss 0.7754274606704712, embedding dim 64, hidden size 128, num layers 1, train loss 0.4482858180999756, validation loss 0.7751220464706421\n",
      "Epoch 270, current patience 30, model mean validation loss 0.7731677293777466, embedding dim 64, hidden size 128, num layers 1, train loss 0.5265577435493469, validation loss 0.7714671492576599\n",
      "Epoch 280, current patience 30, model mean validation loss 0.7753491997718811, embedding dim 64, hidden size 128, num layers 1, train loss 0.4924617409706116, validation loss 0.7993065118789673\n",
      "Epoch 290, current patience 29, model mean validation loss 0.7722772359848022, embedding dim 64, hidden size 128, num layers 1, train loss 0.38301944732666016, validation loss 0.7552075386047363\n",
      "Epoch 300, current patience 30, model mean validation loss 0.76438307762146, embedding dim 64, hidden size 128, num layers 1, train loss 0.25355592370033264, validation loss 0.7375554442405701\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7700101733207703, embedding dim 64, hidden size 128, num layers 1, train loss 0.41558051109313965, validation loss 0.8086704611778259\n",
      "Epoch 320, current patience 29, model mean validation loss 0.7697408199310303, embedding dim 64, hidden size 128, num layers 1, train loss 0.5439900159835815, validation loss 0.7639294862747192\n",
      "Epoch 330, current patience 28, model mean validation loss 0.7714266777038574, embedding dim 64, hidden size 128, num layers 1, train loss 0.4971710443496704, validation loss 0.7601554989814758\n",
      "Epoch 340, current patience 27, model mean validation loss 0.7747371196746826, embedding dim 64, hidden size 128, num layers 1, train loss 0.556881308555603, validation loss 0.8016055822372437\n",
      "Epoch 350, current patience 26, model mean validation loss 0.7786597013473511, embedding dim 64, hidden size 128, num layers 1, train loss 0.3502079248428345, validation loss 0.8028475642204285\n",
      "Epoch 360, current patience 25, model mean validation loss 0.7842094898223877, embedding dim 64, hidden size 128, num layers 1, train loss 0.5906556844711304, validation loss 0.8437047004699707\n",
      "Epoch 370, current patience 24, model mean validation loss 0.785982608795166, embedding dim 64, hidden size 128, num layers 1, train loss 0.7327412366867065, validation loss 0.7693921327590942\n",
      "Epoch 380, current patience 23, model mean validation loss 0.7914210557937622, embedding dim 64, hidden size 128, num layers 1, train loss 0.4026046395301819, validation loss 0.7810624837875366\n",
      "Epoch 390, current patience 22, model mean validation loss 0.8008443117141724, embedding dim 64, hidden size 128, num layers 1, train loss 0.30396318435668945, validation loss 0.8840576410293579\n",
      "Epoch 400, current patience 21, model mean validation loss 0.8044204115867615, embedding dim 64, hidden size 128, num layers 1, train loss 0.48625344038009644, validation loss 0.7925375699996948\n",
      "Epoch 410, current patience 20, model mean validation loss 0.8169870972633362, embedding dim 64, hidden size 128, num layers 1, train loss 0.25532811880111694, validation loss 0.8606891632080078\n",
      "Epoch 420, current patience 19, model mean validation loss 0.8277851939201355, embedding dim 64, hidden size 128, num layers 1, train loss 0.19379779696464539, validation loss 0.8879907131195068\n",
      "Epoch 430, current patience 18, model mean validation loss 0.8324226140975952, embedding dim 64, hidden size 128, num layers 1, train loss 0.42247164249420166, validation loss 0.8399463891983032\n",
      "Epoch 440, current patience 17, model mean validation loss 0.82867830991745, embedding dim 64, hidden size 128, num layers 1, train loss 0.3317759931087494, validation loss 0.8137502670288086\n",
      "Epoch 450, current patience 16, model mean validation loss 0.8445711135864258, embedding dim 64, hidden size 128, num layers 1, train loss 0.2929583191871643, validation loss 0.8965342044830322\n",
      "Epoch 460, current patience 15, model mean validation loss 0.8598493337631226, embedding dim 64, hidden size 128, num layers 1, train loss 0.36242228746414185, validation loss 0.9032890796661377\n",
      "Epoch 470, current patience 14, model mean validation loss 0.8486536741256714, embedding dim 64, hidden size 128, num layers 1, train loss 0.30415189266204834, validation loss 0.7944919466972351\n",
      "Epoch 480, current patience 13, model mean validation loss 0.8561018705368042, embedding dim 64, hidden size 128, num layers 1, train loss 0.7810928821563721, validation loss 0.8521233201026917\n",
      "Epoch 490, current patience 12, model mean validation loss 0.8646587133407593, embedding dim 64, hidden size 128, num layers 1, train loss 0.6257905960083008, validation loss 0.9291437864303589\n",
      "Epoch 500, current patience 11, model mean validation loss 0.869862973690033, embedding dim 64, hidden size 128, num layers 1, train loss 0.20070457458496094, validation loss 0.9296247363090515\n",
      "Epoch 510, current patience 10, model mean validation loss 0.8839901685714722, embedding dim 64, hidden size 128, num layers 1, train loss 0.264659583568573, validation loss 0.9529643654823303\n",
      "Epoch 520, current patience 9, model mean validation loss 0.890898585319519, embedding dim 64, hidden size 128, num layers 1, train loss 0.13477370142936707, validation loss 0.869017481803894\n",
      "Epoch 530, current patience 8, model mean validation loss 0.9027022123336792, embedding dim 64, hidden size 128, num layers 1, train loss 0.10383512079715729, validation loss 0.9909629225730896\n",
      "Epoch 540, current patience 7, model mean validation loss 0.9293689131736755, embedding dim 64, hidden size 128, num layers 1, train loss 0.322684645652771, validation loss 1.116622805595398\n",
      "Epoch 550, current patience 6, model mean validation loss 0.9475278854370117, embedding dim 64, hidden size 128, num layers 1, train loss 0.41201964020729065, validation loss 0.9397632479667664\n",
      "Epoch 560, current patience 5, model mean validation loss 0.9426020383834839, embedding dim 64, hidden size 128, num layers 1, train loss 0.4722255766391754, validation loss 0.8127172589302063\n",
      "Epoch 570, current patience 4, model mean validation loss 0.9365757703781128, embedding dim 64, hidden size 128, num layers 1, train loss 0.29816585779190063, validation loss 0.8809335231781006\n",
      "Epoch 580, current patience 3, model mean validation loss 0.9449905753135681, embedding dim 64, hidden size 128, num layers 1, train loss 0.3676595389842987, validation loss 0.9969431161880493\n",
      "Epoch 590, current patience 2, model mean validation loss 0.9372663497924805, embedding dim 64, hidden size 128, num layers 1, train loss 0.4266495704650879, validation loss 0.891170084476471\n",
      "Epoch 600, current patience 1, model mean validation loss 0.9438281059265137, embedding dim 64, hidden size 128, num layers 1, train loss 0.27075421810150146, validation loss 0.9215121269226074\n",
      "Epoch 0, current patience 30, model mean validation loss 1.104034185409546, embedding dim 64, hidden size 256, num layers 1, train loss 1.1010254621505737, validation loss 1.104034185409546\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1015005111694336, embedding dim 64, hidden size 256, num layers 1, train loss 1.0993030071258545, validation loss 1.0989667177200317\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0907293558120728, embedding dim 64, hidden size 256, num layers 1, train loss 1.0568897724151611, validation loss 1.0691869258880615\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0877573490142822, embedding dim 64, hidden size 256, num layers 1, train loss 1.1026849746704102, validation loss 1.0788416862487793\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0833640098571777, embedding dim 64, hidden size 256, num layers 1, train loss 1.084964394569397, validation loss 1.0657904148101807\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0734542608261108, embedding dim 64, hidden size 256, num layers 1, train loss 0.9423205256462097, validation loss 1.0239059925079346\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0637896060943604, embedding dim 64, hidden size 256, num layers 1, train loss 1.0050957202911377, validation loss 1.0058010816574097\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0726597309112549, embedding dim 64, hidden size 256, num layers 1, train loss 0.7682061195373535, validation loss 1.1347509622573853\n",
      "Epoch 80, current patience 29, model mean validation loss 1.0540800094604492, embedding dim 64, hidden size 256, num layers 1, train loss 1.010389804840088, validation loss 0.9553970098495483\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0332411527633667, embedding dim 64, hidden size 256, num layers 1, train loss 0.8973757028579712, validation loss 0.932255744934082\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0163137912750244, embedding dim 64, hidden size 256, num layers 1, train loss 0.8390512466430664, validation loss 0.933767557144165\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9901116490364075, embedding dim 64, hidden size 256, num layers 1, train loss 0.9045427441596985, validation loss 0.8692243099212646\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9608789086341858, embedding dim 64, hidden size 256, num layers 1, train loss 0.7387109994888306, validation loss 0.8319284319877625\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9473875761032104, embedding dim 64, hidden size 256, num layers 1, train loss 0.7966312170028687, validation loss 0.9159755110740662\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9327564239501953, embedding dim 64, hidden size 256, num layers 1, train loss 0.9303776621818542, validation loss 0.8887520432472229\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8928914666175842, embedding dim 64, hidden size 256, num layers 1, train loss 0.9240313768386841, validation loss 0.8158308267593384\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8760718107223511, embedding dim 64, hidden size 256, num layers 1, train loss 0.8298299312591553, validation loss 0.8208401203155518\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8622159361839294, embedding dim 64, hidden size 256, num layers 1, train loss 0.8413492441177368, validation loss 0.8214088678359985\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8498486876487732, embedding dim 64, hidden size 256, num layers 1, train loss 0.7773681879043579, validation loss 0.8348293304443359\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8394210338592529, embedding dim 64, hidden size 256, num layers 1, train loss 0.5911753177642822, validation loss 0.785803496837616\n",
      "Epoch 200, current patience 30, model mean validation loss 0.835075318813324, embedding dim 64, hidden size 256, num layers 1, train loss 0.768028974533081, validation loss 0.7971621751785278\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8235582709312439, embedding dim 64, hidden size 256, num layers 1, train loss 0.45162367820739746, validation loss 0.8238396048545837\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8146052956581116, embedding dim 64, hidden size 256, num layers 1, train loss 0.7006480097770691, validation loss 0.8171281814575195\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8207405209541321, embedding dim 64, hidden size 256, num layers 1, train loss 0.6763107776641846, validation loss 0.8649122714996338\n",
      "Epoch 240, current patience 29, model mean validation loss 0.8166077136993408, embedding dim 64, hidden size 256, num layers 1, train loss 0.7907167673110962, validation loss 0.7877779603004456\n",
      "Epoch 250, current patience 28, model mean validation loss 0.810857355594635, embedding dim 64, hidden size 256, num layers 1, train loss 0.7705446481704712, validation loss 0.775406002998352\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8137373328208923, embedding dim 64, hidden size 256, num layers 1, train loss 0.519792914390564, validation loss 0.8578686714172363\n",
      "Epoch 270, current patience 29, model mean validation loss 0.814171552658081, embedding dim 64, hidden size 256, num layers 1, train loss 0.5313291549682617, validation loss 0.7892776727676392\n",
      "Epoch 280, current patience 28, model mean validation loss 0.812576174736023, embedding dim 64, hidden size 256, num layers 1, train loss 0.578231930732727, validation loss 0.784399151802063\n",
      "Epoch 290, current patience 27, model mean validation loss 0.8087243437767029, embedding dim 64, hidden size 256, num layers 1, train loss 0.4998195469379425, validation loss 0.7930245399475098\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8082008361816406, embedding dim 64, hidden size 256, num layers 1, train loss 0.624962568283081, validation loss 0.8129408359527588\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7995108366012573, embedding dim 64, hidden size 256, num layers 1, train loss 0.611004114151001, validation loss 0.7953914999961853\n",
      "Epoch 320, current patience 30, model mean validation loss 0.8028607368469238, embedding dim 64, hidden size 256, num layers 1, train loss 0.45677584409713745, validation loss 0.8145774602890015\n",
      "Epoch 330, current patience 29, model mean validation loss 0.8143680691719055, embedding dim 64, hidden size 256, num layers 1, train loss 0.3771708607673645, validation loss 0.8674649000167847\n",
      "Epoch 340, current patience 28, model mean validation loss 0.8127801418304443, embedding dim 64, hidden size 256, num layers 1, train loss 0.8524949550628662, validation loss 0.8451647162437439\n",
      "Epoch 350, current patience 27, model mean validation loss 0.8152981400489807, embedding dim 64, hidden size 256, num layers 1, train loss 0.3902565836906433, validation loss 0.8094214797019958\n",
      "Epoch 360, current patience 26, model mean validation loss 0.8259702324867249, embedding dim 64, hidden size 256, num layers 1, train loss 0.17095962166786194, validation loss 0.8697764873504639\n",
      "Epoch 370, current patience 25, model mean validation loss 0.8257892727851868, embedding dim 64, hidden size 256, num layers 1, train loss 0.5007443428039551, validation loss 0.7915768623352051\n",
      "Epoch 380, current patience 24, model mean validation loss 0.8291991949081421, embedding dim 64, hidden size 256, num layers 1, train loss 0.2532413601875305, validation loss 0.8402199745178223\n",
      "Epoch 390, current patience 23, model mean validation loss 0.8419731855392456, embedding dim 64, hidden size 256, num layers 1, train loss 0.665988028049469, validation loss 0.8975837230682373\n",
      "Epoch 400, current patience 22, model mean validation loss 0.8509708642959595, embedding dim 64, hidden size 256, num layers 1, train loss 0.24163168668746948, validation loss 0.886559009552002\n",
      "Epoch 410, current patience 21, model mean validation loss 0.8477050065994263, embedding dim 64, hidden size 256, num layers 1, train loss 0.743604838848114, validation loss 0.8413378596305847\n",
      "Epoch 420, current patience 20, model mean validation loss 0.8431318402290344, embedding dim 64, hidden size 256, num layers 1, train loss 0.24126258492469788, validation loss 0.8085795044898987\n",
      "Epoch 430, current patience 19, model mean validation loss 0.8510262370109558, embedding dim 64, hidden size 256, num layers 1, train loss 0.3048480749130249, validation loss 0.8725764751434326\n",
      "Epoch 440, current patience 18, model mean validation loss 0.8442285060882568, embedding dim 64, hidden size 256, num layers 1, train loss 0.3919714093208313, validation loss 0.8153948187828064\n",
      "Epoch 450, current patience 17, model mean validation loss 0.855230450630188, embedding dim 64, hidden size 256, num layers 1, train loss 0.23450443148612976, validation loss 0.8795920610427856\n",
      "Epoch 460, current patience 16, model mean validation loss 0.8564736247062683, embedding dim 64, hidden size 256, num layers 1, train loss 0.4432194232940674, validation loss 0.8501657247543335\n",
      "Epoch 470, current patience 15, model mean validation loss 0.8633944988250732, embedding dim 64, hidden size 256, num layers 1, train loss 0.32670217752456665, validation loss 0.9529505968093872\n",
      "Epoch 480, current patience 14, model mean validation loss 0.8672600984573364, embedding dim 64, hidden size 256, num layers 1, train loss 0.13589122891426086, validation loss 0.9174836874008179\n",
      "Epoch 490, current patience 13, model mean validation loss 0.8716636300086975, embedding dim 64, hidden size 256, num layers 1, train loss 0.8220184445381165, validation loss 0.8765663504600525\n",
      "Epoch 500, current patience 12, model mean validation loss 0.8819355964660645, embedding dim 64, hidden size 256, num layers 1, train loss 0.51933753490448, validation loss 0.8907551169395447\n",
      "Epoch 510, current patience 11, model mean validation loss 0.8851727247238159, embedding dim 64, hidden size 256, num layers 1, train loss 0.24175027012825012, validation loss 0.898473858833313\n",
      "Epoch 520, current patience 10, model mean validation loss 0.9005856513977051, embedding dim 64, hidden size 256, num layers 1, train loss 0.17570306360721588, validation loss 0.9386981725692749\n",
      "Epoch 530, current patience 9, model mean validation loss 0.903928279876709, embedding dim 64, hidden size 256, num layers 1, train loss 0.6123290061950684, validation loss 0.9063325524330139\n",
      "Epoch 540, current patience 8, model mean validation loss 0.9013026356697083, embedding dim 64, hidden size 256, num layers 1, train loss 0.28893736004829407, validation loss 0.829160749912262\n",
      "Epoch 550, current patience 7, model mean validation loss 0.892821729183197, embedding dim 64, hidden size 256, num layers 1, train loss 0.5611412525177002, validation loss 0.885103702545166\n",
      "Epoch 560, current patience 6, model mean validation loss 0.9071527719497681, embedding dim 64, hidden size 256, num layers 1, train loss 0.27626004815101624, validation loss 1.0321319103240967\n",
      "Epoch 570, current patience 5, model mean validation loss 0.9042285680770874, embedding dim 64, hidden size 256, num layers 1, train loss 0.7549166679382324, validation loss 0.8531724810600281\n",
      "Epoch 580, current patience 4, model mean validation loss 0.9066042900085449, embedding dim 64, hidden size 256, num layers 1, train loss 0.11592398583889008, validation loss 0.9097609519958496\n",
      "Epoch 590, current patience 3, model mean validation loss 0.9118341207504272, embedding dim 64, hidden size 256, num layers 1, train loss 0.16537758708000183, validation loss 0.9403125047683716\n",
      "Epoch 600, current patience 2, model mean validation loss 0.9219989776611328, embedding dim 64, hidden size 256, num layers 1, train loss 0.07855390012264252, validation loss 1.0200169086456299\n",
      "Epoch 610, current patience 1, model mean validation loss 0.9352943897247314, embedding dim 64, hidden size 256, num layers 1, train loss 0.5559026002883911, validation loss 1.0126957893371582\n",
      "Epoch 0, current patience 30, model mean validation loss 1.112259030342102, embedding dim 64, hidden size 512, num layers 1, train loss 1.0996778011322021, validation loss 1.112259030342102\n",
      "Epoch 10, current patience 30, model mean validation loss 1.104305386543274, embedding dim 64, hidden size 512, num layers 1, train loss 1.101071834564209, validation loss 1.0963517427444458\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1079158782958984, embedding dim 64, hidden size 512, num layers 1, train loss 1.0986180305480957, validation loss 1.1151368618011475\n",
      "Epoch 30, current patience 29, model mean validation loss 1.1166040897369385, embedding dim 64, hidden size 512, num layers 1, train loss 1.1374588012695312, validation loss 1.1426688432693481\n",
      "Epoch 40, current patience 28, model mean validation loss 1.14031982421875, embedding dim 64, hidden size 512, num layers 1, train loss 1.2726976871490479, validation loss 1.235182523727417\n",
      "Epoch 50, current patience 27, model mean validation loss 1.1397708654403687, embedding dim 64, hidden size 512, num layers 1, train loss 1.143459439277649, validation loss 1.137026071548462\n",
      "Epoch 60, current patience 26, model mean validation loss 1.1401824951171875, embedding dim 64, hidden size 512, num layers 1, train loss 1.2074445486068726, validation loss 1.1426526308059692\n",
      "Epoch 70, current patience 25, model mean validation loss 1.1417078971862793, embedding dim 64, hidden size 512, num layers 1, train loss 1.1477329730987549, validation loss 1.1523847579956055\n",
      "Epoch 80, current patience 24, model mean validation loss 1.1453502178192139, embedding dim 64, hidden size 512, num layers 1, train loss 1.1178288459777832, validation loss 1.141398549079895\n",
      "Epoch 90, current patience 23, model mean validation loss 1.1459230184555054, embedding dim 64, hidden size 512, num layers 1, train loss 1.1248993873596191, validation loss 1.1009340286254883\n",
      "Epoch 100, current patience 22, model mean validation loss 1.1450861692428589, embedding dim 64, hidden size 512, num layers 1, train loss 1.0914350748062134, validation loss 1.1084423065185547\n",
      "Epoch 110, current patience 21, model mean validation loss 1.139365553855896, embedding dim 64, hidden size 512, num layers 1, train loss 1.137054204940796, validation loss 1.0969035625457764\n",
      "Epoch 120, current patience 20, model mean validation loss 1.1219508647918701, embedding dim 64, hidden size 512, num layers 1, train loss 1.1049976348876953, validation loss 1.0958657264709473\n",
      "Epoch 130, current patience 19, model mean validation loss 1.1163183450698853, embedding dim 64, hidden size 512, num layers 1, train loss 1.0919263362884521, validation loss 1.0919654369354248\n",
      "Epoch 140, current patience 18, model mean validation loss 1.1102992296218872, embedding dim 64, hidden size 512, num layers 1, train loss 1.091402530670166, validation loss 1.0944994688034058\n",
      "Epoch 150, current patience 17, model mean validation loss 1.1019725799560547, embedding dim 64, hidden size 512, num layers 1, train loss 1.1146748065948486, validation loss 1.0857720375061035\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0968608856201172, embedding dim 64, hidden size 512, num layers 1, train loss 1.1163735389709473, validation loss 1.1005046367645264\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0961763858795166, embedding dim 64, hidden size 512, num layers 1, train loss 1.0858969688415527, validation loss 1.095457673072815\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0954394340515137, embedding dim 64, hidden size 512, num layers 1, train loss 1.1140375137329102, validation loss 1.1025463342666626\n",
      "Epoch 190, current patience 30, model mean validation loss 1.096570611000061, embedding dim 64, hidden size 512, num layers 1, train loss 1.120274543762207, validation loss 1.1059534549713135\n",
      "Epoch 200, current patience 29, model mean validation loss 1.0977332592010498, embedding dim 64, hidden size 512, num layers 1, train loss 1.1122453212738037, validation loss 1.1051665544509888\n",
      "Epoch 210, current patience 28, model mean validation loss 1.0987045764923096, embedding dim 64, hidden size 512, num layers 1, train loss 1.097316026687622, validation loss 1.0997363328933716\n",
      "Epoch 220, current patience 27, model mean validation loss 1.1001554727554321, embedding dim 64, hidden size 512, num layers 1, train loss 1.168858528137207, validation loss 1.1061060428619385\n",
      "Epoch 230, current patience 26, model mean validation loss 1.1102654933929443, embedding dim 64, hidden size 512, num layers 1, train loss 1.1099927425384521, validation loss 1.1666522026062012\n",
      "Epoch 240, current patience 25, model mean validation loss 1.1090712547302246, embedding dim 64, hidden size 512, num layers 1, train loss 1.103914737701416, validation loss 1.0909504890441895\n",
      "Epoch 250, current patience 24, model mean validation loss 1.110251784324646, embedding dim 64, hidden size 512, num layers 1, train loss 1.1329026222229004, validation loss 1.104902744293213\n",
      "Epoch 260, current patience 23, model mean validation loss 1.1098179817199707, embedding dim 64, hidden size 512, num layers 1, train loss 1.0447728633880615, validation loss 1.0990759134292603\n",
      "Epoch 270, current patience 22, model mean validation loss 1.108989953994751, embedding dim 64, hidden size 512, num layers 1, train loss 1.1219747066497803, validation loss 1.099329948425293\n",
      "Epoch 280, current patience 21, model mean validation loss 1.11019766330719, embedding dim 64, hidden size 512, num layers 1, train loss 1.0769298076629639, validation loss 1.1148278713226318\n",
      "Epoch 290, current patience 20, model mean validation loss 1.1132105588912964, embedding dim 64, hidden size 512, num layers 1, train loss 1.097944974899292, validation loss 1.1238387823104858\n",
      "Epoch 300, current patience 19, model mean validation loss 1.1146514415740967, embedding dim 64, hidden size 512, num layers 1, train loss 1.0578155517578125, validation loss 1.1176338195800781\n",
      "Epoch 310, current patience 18, model mean validation loss 1.1069549322128296, embedding dim 64, hidden size 512, num layers 1, train loss 1.0913143157958984, validation loss 1.1050801277160645\n",
      "Epoch 320, current patience 17, model mean validation loss 1.1181070804595947, embedding dim 64, hidden size 512, num layers 1, train loss 1.175000786781311, validation loss 1.1801677942276\n",
      "Epoch 330, current patience 16, model mean validation loss 1.1187365055084229, embedding dim 64, hidden size 512, num layers 1, train loss 1.1241780519485474, validation loss 1.109937310218811\n",
      "Epoch 340, current patience 15, model mean validation loss 1.1179958581924438, embedding dim 64, hidden size 512, num layers 1, train loss 1.09159517288208, validation loss 1.0931510925292969\n",
      "Epoch 350, current patience 14, model mean validation loss 1.1161969900131226, embedding dim 64, hidden size 512, num layers 1, train loss 1.1549181938171387, validation loss 1.0849390029907227\n",
      "Epoch 360, current patience 13, model mean validation loss 1.116267442703247, embedding dim 64, hidden size 512, num layers 1, train loss 1.1330682039260864, validation loss 1.1153910160064697\n",
      "Epoch 370, current patience 12, model mean validation loss 1.1154406070709229, embedding dim 64, hidden size 512, num layers 1, train loss 1.135080337524414, validation loss 1.117224931716919\n",
      "Epoch 380, current patience 11, model mean validation loss 1.1126461029052734, embedding dim 64, hidden size 512, num layers 1, train loss 1.1212760210037231, validation loss 1.0952773094177246\n",
      "Epoch 390, current patience 10, model mean validation loss 1.1142184734344482, embedding dim 64, hidden size 512, num layers 1, train loss 1.08578622341156, validation loss 1.117659091949463\n",
      "Epoch 400, current patience 9, model mean validation loss 1.1084566116333008, embedding dim 64, hidden size 512, num layers 1, train loss 0.9894270300865173, validation loss 1.13407301902771\n",
      "Epoch 410, current patience 8, model mean validation loss 1.1053848266601562, embedding dim 64, hidden size 512, num layers 1, train loss 1.1143462657928467, validation loss 1.0853626728057861\n",
      "Epoch 420, current patience 7, model mean validation loss 1.108724594116211, embedding dim 64, hidden size 512, num layers 1, train loss 1.019862413406372, validation loss 1.1198703050613403\n",
      "Epoch 430, current patience 6, model mean validation loss 1.108069658279419, embedding dim 64, hidden size 512, num layers 1, train loss 1.1118006706237793, validation loss 1.0796985626220703\n",
      "Epoch 440, current patience 5, model mean validation loss 1.105940580368042, embedding dim 64, hidden size 512, num layers 1, train loss 1.063838243484497, validation loss 1.0983591079711914\n",
      "Epoch 450, current patience 4, model mean validation loss 1.1089982986450195, embedding dim 64, hidden size 512, num layers 1, train loss 1.1490345001220703, validation loss 1.141686201095581\n",
      "Epoch 460, current patience 3, model mean validation loss 1.1080715656280518, embedding dim 64, hidden size 512, num layers 1, train loss 1.1418145895004272, validation loss 1.0878634452819824\n",
      "Epoch 470, current patience 2, model mean validation loss 1.1053361892700195, embedding dim 64, hidden size 512, num layers 1, train loss 1.0997745990753174, validation loss 1.0957759618759155\n",
      "Epoch 480, current patience 1, model mean validation loss 1.1070191860198975, embedding dim 64, hidden size 512, num layers 1, train loss 1.1038966178894043, validation loss 1.147537350654602\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1646368503570557, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0947043895721436, validation loss 1.1646368503570557\n",
      "Epoch 10, current patience 30, model mean validation loss 1.145082950592041, embedding dim 64, hidden size 1024, num layers 1, train loss 1.084033727645874, validation loss 1.1255290508270264\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1400455236434937, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0473639965057373, validation loss 1.1299707889556885\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1300323009490967, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0859102010726929, validation loss 1.0999926328659058\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1234686374664307, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0977661609649658, validation loss 1.0972139835357666\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1248430013656616, embedding dim 64, hidden size 1024, num layers 1, train loss 1.067348599433899, validation loss 1.1317148208618164\n",
      "Epoch 60, current patience 29, model mean validation loss 1.1276785135269165, embedding dim 64, hidden size 1024, num layers 1, train loss 1.1108064651489258, validation loss 1.1446906328201294\n",
      "Epoch 70, current patience 28, model mean validation loss 1.12610924243927, embedding dim 64, hidden size 1024, num layers 1, train loss 1.1037168502807617, validation loss 1.1151251792907715\n",
      "Epoch 80, current patience 27, model mean validation loss 1.134143352508545, embedding dim 64, hidden size 1024, num layers 1, train loss 1.1525663137435913, validation loss 1.2289094924926758\n",
      "Epoch 90, current patience 26, model mean validation loss 1.1301020383834839, embedding dim 64, hidden size 1024, num layers 1, train loss 1.1182594299316406, validation loss 1.0931988954544067\n",
      "Epoch 100, current patience 25, model mean validation loss 1.1275885105133057, embedding dim 64, hidden size 1024, num layers 1, train loss 1.1004022359848022, validation loss 1.1098625659942627\n",
      "Epoch 110, current patience 24, model mean validation loss 1.126131534576416, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0903236865997314, validation loss 1.0883373022079468\n",
      "Epoch 120, current patience 23, model mean validation loss 1.1230223178863525, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0677030086517334, validation loss 1.0723400115966797\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1165530681610107, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0269403457641602, validation loss 1.0799602270126343\n",
      "Epoch 140, current patience 30, model mean validation loss 1.1059095859527588, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9838977456092834, validation loss 1.0595433712005615\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0979344844818115, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0902271270751953, validation loss 1.0513237714767456\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0769788026809692, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0717947483062744, validation loss 1.0612640380859375\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0781376361846924, embedding dim 64, hidden size 1024, num layers 1, train loss 1.092927098274231, validation loss 1.1024699211120605\n",
      "Epoch 180, current patience 29, model mean validation loss 1.075303316116333, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0831823348999023, validation loss 1.0871880054473877\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0723676681518555, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0462043285369873, validation loss 1.0648517608642578\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0702365636825562, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9942750930786133, validation loss 1.055290937423706\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0667542219161987, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0916355848312378, validation loss 1.0521018505096436\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0645726919174194, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9682738780975342, validation loss 1.0420913696289062\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0640169382095337, embedding dim 64, hidden size 1024, num layers 1, train loss 1.059691071510315, validation loss 1.0468776226043701\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0746657848358154, embedding dim 64, hidden size 1024, num layers 1, train loss 1.057935118675232, validation loss 1.1464544534683228\n",
      "Epoch 250, current patience 29, model mean validation loss 1.0890491008758545, embedding dim 64, hidden size 1024, num layers 1, train loss 1.4313015937805176, validation loss 1.217536211013794\n",
      "Epoch 260, current patience 28, model mean validation loss 1.088991403579712, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0467853546142578, validation loss 1.0867270231246948\n",
      "Epoch 270, current patience 27, model mean validation loss 1.0888817310333252, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0650290250778198, validation loss 1.0639746189117432\n",
      "Epoch 280, current patience 26, model mean validation loss 1.0884485244750977, embedding dim 64, hidden size 1024, num layers 1, train loss 1.023135781288147, validation loss 1.0518245697021484\n",
      "Epoch 290, current patience 25, model mean validation loss 1.0861108303070068, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9818341732025146, validation loss 1.033400535583496\n",
      "Epoch 300, current patience 24, model mean validation loss 1.0814862251281738, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9689008593559265, validation loss 1.0050950050354004\n",
      "Epoch 310, current patience 23, model mean validation loss 1.0757840871810913, embedding dim 64, hidden size 1024, num layers 1, train loss 1.074684977531433, validation loss 1.0012601613998413\n",
      "Epoch 320, current patience 22, model mean validation loss 1.060067892074585, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0448273420333862, validation loss 1.0207242965698242\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0398170948028564, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0245990753173828, validation loss 1.0555310249328613\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0338990688323975, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8056658506393433, validation loss 1.039383053779602\n",
      "Epoch 350, current patience 30, model mean validation loss 1.023867130279541, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7411481738090515, validation loss 0.9837190508842468\n",
      "Epoch 360, current patience 30, model mean validation loss 1.017108678817749, embedding dim 64, hidden size 1024, num layers 1, train loss 0.961108922958374, validation loss 0.9977567791938782\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0184736251831055, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8048617839813232, validation loss 1.0443192720413208\n",
      "Epoch 380, current patience 29, model mean validation loss 1.021593689918518, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7693506479263306, validation loss 1.0300565958023071\n",
      "Epoch 390, current patience 28, model mean validation loss 1.0274661779403687, embedding dim 64, hidden size 1024, num layers 1, train loss 0.9035413265228271, validation loss 1.0482397079467773\n",
      "Epoch 400, current patience 27, model mean validation loss 1.0266704559326172, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7791801691055298, validation loss 1.0143581628799438\n",
      "Epoch 410, current patience 26, model mean validation loss 1.0175306797027588, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8634049892425537, validation loss 0.9824122190475464\n",
      "Epoch 420, current patience 25, model mean validation loss 1.014018177986145, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5767712593078613, validation loss 1.0112831592559814\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0204734802246094, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8018818497657776, validation loss 1.0353621244430542\n",
      "Epoch 440, current patience 29, model mean validation loss 1.0160421133041382, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7105844020843506, validation loss 0.9623053669929504\n",
      "Epoch 450, current patience 28, model mean validation loss 1.0124608278274536, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6423145532608032, validation loss 1.0156688690185547\n",
      "Epoch 460, current patience 30, model mean validation loss 1.0070114135742188, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7393206357955933, validation loss 0.9864616394042969\n",
      "Epoch 470, current patience 30, model mean validation loss 0.9948847889900208, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7355939745903015, validation loss 0.9512269496917725\n",
      "Epoch 480, current patience 30, model mean validation loss 0.984243631362915, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7220441699028015, validation loss 0.9292292594909668\n",
      "Epoch 490, current patience 30, model mean validation loss 0.9844588041305542, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7605346441268921, validation loss 0.9841326475143433\n",
      "Epoch 500, current patience 29, model mean validation loss 0.9810563325881958, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5079988241195679, validation loss 0.9840638637542725\n",
      "Epoch 510, current patience 30, model mean validation loss 0.9713829159736633, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6312094926834106, validation loss 0.9579752087593079\n",
      "Epoch 520, current patience 30, model mean validation loss 0.9737541079521179, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7666469812393188, validation loss 0.9812746644020081\n",
      "Epoch 530, current patience 29, model mean validation loss 0.968818187713623, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7010571956634521, validation loss 0.9761810302734375\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9636568427085876, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6728768348693848, validation loss 0.9451711177825928\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9724729657173157, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5656371116638184, validation loss 1.0217558145523071\n",
      "Epoch 560, current patience 29, model mean validation loss 0.9786947965621948, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7669297456741333, validation loss 0.9790036678314209\n",
      "Epoch 570, current patience 28, model mean validation loss 0.9764301776885986, embedding dim 64, hidden size 1024, num layers 1, train loss 0.427338570356369, validation loss 0.9660155773162842\n",
      "Epoch 580, current patience 27, model mean validation loss 0.9733047485351562, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5512986779212952, validation loss 0.9590612053871155\n",
      "Epoch 590, current patience 26, model mean validation loss 0.9749061465263367, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0446697473526, validation loss 0.9707858562469482\n",
      "Epoch 600, current patience 25, model mean validation loss 0.987751841545105, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5614373683929443, validation loss 1.0840401649475098\n",
      "Epoch 610, current patience 24, model mean validation loss 1.0292909145355225, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7092443108558655, validation loss 1.3084933757781982\n",
      "Epoch 620, current patience 23, model mean validation loss 1.0409650802612305, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5322492718696594, validation loss 1.0385655164718628\n",
      "Epoch 630, current patience 22, model mean validation loss 1.050485372543335, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7934650778770447, validation loss 1.097916841506958\n",
      "Epoch 640, current patience 21, model mean validation loss 1.0532152652740479, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6723612546920776, validation loss 1.0008437633514404\n",
      "Epoch 650, current patience 20, model mean validation loss 1.0592920780181885, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6179765462875366, validation loss 1.0146291255950928\n",
      "Epoch 660, current patience 19, model mean validation loss 1.0602165460586548, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6985437273979187, validation loss 0.9664577841758728\n",
      "Epoch 670, current patience 18, model mean validation loss 1.0575592517852783, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8094310760498047, validation loss 0.9495279788970947\n",
      "Epoch 680, current patience 17, model mean validation loss 1.046331524848938, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8034384250640869, validation loss 0.9942175149917603\n",
      "Epoch 690, current patience 16, model mean validation loss 1.010116696357727, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7375627756118774, validation loss 1.0187745094299316\n",
      "Epoch 700, current patience 15, model mean validation loss 1.005910038948059, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5944417119026184, validation loss 1.004913091659546\n",
      "Epoch 710, current patience 14, model mean validation loss 0.9918357729911804, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7794639468193054, validation loss 0.9853223562240601\n",
      "Epoch 720, current patience 13, model mean validation loss 0.9843917489051819, embedding dim 64, hidden size 1024, num layers 1, train loss 1.0143091678619385, validation loss 0.9412916898727417\n",
      "Epoch 730, current patience 12, model mean validation loss 0.9821345806121826, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6287782788276672, validation loss 0.9965717196464539\n",
      "Epoch 740, current patience 11, model mean validation loss 0.98681640625, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5031311511993408, validation loss 1.0039122104644775\n",
      "Epoch 750, current patience 10, model mean validation loss 0.9978451132774353, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7025719285011292, validation loss 1.0377579927444458\n",
      "Epoch 760, current patience 9, model mean validation loss 0.9910374879837036, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7560434937477112, validation loss 0.9397560358047485\n",
      "Epoch 770, current patience 8, model mean validation loss 0.981708288192749, embedding dim 64, hidden size 1024, num layers 1, train loss 0.8041523098945618, validation loss 0.9441412687301636\n",
      "Epoch 780, current patience 7, model mean validation loss 0.9727155566215515, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5935657024383545, validation loss 0.9329711198806763\n",
      "Epoch 790, current patience 6, model mean validation loss 0.9631128311157227, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7934437990188599, validation loss 0.9085004329681396\n",
      "Epoch 800, current patience 30, model mean validation loss 0.968423068523407, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5071623921394348, validation loss 0.9837735891342163\n",
      "Epoch 810, current patience 29, model mean validation loss 0.9638359546661377, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6486968398094177, validation loss 0.9598753452301025\n",
      "Epoch 820, current patience 28, model mean validation loss 0.9520021677017212, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4968143105506897, validation loss 0.9092413187026978\n",
      "Epoch 830, current patience 30, model mean validation loss 0.9368103742599487, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7855414152145386, validation loss 0.9162236452102661\n",
      "Epoch 840, current patience 30, model mean validation loss 0.9439146518707275, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6559609174728394, validation loss 0.9965903759002686\n",
      "Epoch 850, current patience 29, model mean validation loss 0.946881890296936, embedding dim 64, hidden size 1024, num layers 1, train loss 0.563493013381958, validation loss 0.967879593372345\n",
      "Epoch 860, current patience 28, model mean validation loss 0.9449688196182251, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4116976261138916, validation loss 0.9176664352416992\n",
      "Epoch 870, current patience 27, model mean validation loss 0.9489574432373047, embedding dim 64, hidden size 1024, num layers 1, train loss 0.7513196468353271, validation loss 0.9404097199440002\n",
      "Epoch 880, current patience 26, model mean validation loss 0.9414483308792114, embedding dim 64, hidden size 1024, num layers 1, train loss 0.417500376701355, validation loss 0.9237003326416016\n",
      "Epoch 890, current patience 25, model mean validation loss 0.9407493472099304, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6768075227737427, validation loss 0.9542829990386963\n",
      "Epoch 900, current patience 24, model mean validation loss 0.9518143534660339, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4986494481563568, validation loss 0.9977617263793945\n",
      "Epoch 910, current patience 23, model mean validation loss 0.9677330255508423, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4078168570995331, validation loss 1.0435731410980225\n",
      "Epoch 920, current patience 22, model mean validation loss 0.9747742414474487, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4418344497680664, validation loss 1.0529202222824097\n",
      "Epoch 930, current patience 21, model mean validation loss 0.9763157963752747, embedding dim 64, hidden size 1024, num layers 1, train loss 0.663318395614624, validation loss 0.9802120923995972\n",
      "Epoch 940, current patience 20, model mean validation loss 0.9853402376174927, embedding dim 64, hidden size 1024, num layers 1, train loss 0.44278353452682495, validation loss 0.9898619651794434\n",
      "Epoch 950, current patience 19, model mean validation loss 0.9908431172370911, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5586607456207275, validation loss 0.984432578086853\n",
      "Epoch 960, current patience 18, model mean validation loss 0.9987257719039917, embedding dim 64, hidden size 1024, num layers 1, train loss 0.39705371856689453, validation loss 0.9867615699768066\n",
      "Epoch 970, current patience 17, model mean validation loss 1.0032917261123657, embedding dim 64, hidden size 1024, num layers 1, train loss 0.3477334976196289, validation loss 0.9908101558685303\n",
      "Epoch 980, current patience 16, model mean validation loss 1.002733826637268, embedding dim 64, hidden size 1024, num layers 1, train loss 0.6918882131576538, validation loss 0.9932987093925476\n",
      "Epoch 990, current patience 15, model mean validation loss 1.0033040046691895, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5733320116996765, validation loss 1.0481348037719727\n",
      "Epoch 1000, current patience 14, model mean validation loss 0.9977059364318848, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5019446611404419, validation loss 1.0081350803375244\n",
      "Epoch 1010, current patience 13, model mean validation loss 1.0009117126464844, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5239008665084839, validation loss 1.0058581829071045\n",
      "Epoch 1020, current patience 12, model mean validation loss 1.0031707286834717, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4420379102230072, validation loss 1.0079350471496582\n",
      "Epoch 1030, current patience 11, model mean validation loss 1.0063858032226562, embedding dim 64, hidden size 1024, num layers 1, train loss 0.35553988814353943, validation loss 1.0101524591445923\n",
      "Epoch 1040, current patience 10, model mean validation loss 1.0088739395141602, embedding dim 64, hidden size 1024, num layers 1, train loss 0.3566166162490845, validation loss 1.0066665410995483\n",
      "Epoch 1050, current patience 9, model mean validation loss 1.0084067583084106, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4344675540924072, validation loss 0.9870736598968506\n",
      "Epoch 1060, current patience 8, model mean validation loss 1.0137261152267456, embedding dim 64, hidden size 1024, num layers 1, train loss 0.48182380199432373, validation loss 1.035853385925293\n",
      "Epoch 1070, current patience 7, model mean validation loss 1.0106780529022217, embedding dim 64, hidden size 1024, num layers 1, train loss 0.3888324499130249, validation loss 1.0237500667572021\n",
      "Epoch 1080, current patience 6, model mean validation loss 1.013299822807312, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5341545939445496, validation loss 1.029109001159668\n",
      "Epoch 1090, current patience 5, model mean validation loss 1.011318564414978, embedding dim 64, hidden size 1024, num layers 1, train loss 0.5808281898498535, validation loss 0.9900082349777222\n",
      "Epoch 1100, current patience 4, model mean validation loss 1.008373737335205, embedding dim 64, hidden size 1024, num layers 1, train loss 0.49539077281951904, validation loss 0.984376072883606\n",
      "Epoch 1110, current patience 3, model mean validation loss 1.0079197883605957, embedding dim 64, hidden size 1024, num layers 1, train loss 0.35559505224227905, validation loss 1.006521463394165\n",
      "Epoch 1120, current patience 2, model mean validation loss 1.0100651979446411, embedding dim 64, hidden size 1024, num layers 1, train loss 0.4898776710033417, validation loss 1.0238299369812012\n",
      "Epoch 1130, current patience 1, model mean validation loss 1.022397756576538, embedding dim 64, hidden size 1024, num layers 1, train loss 0.28017503023147583, validation loss 1.0857338905334473\n",
      "Epoch 0, current patience 30, model mean validation loss 1.5300744771957397, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0996811389923096, validation loss 1.5300744771957397\n",
      "Epoch 10, current patience 30, model mean validation loss 1.4974497556686401, embedding dim 64, hidden size 2048, num layers 1, train loss 1.36825430393219, validation loss 1.4648250341415405\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3892393112182617, embedding dim 64, hidden size 2048, num layers 1, train loss 1.1907408237457275, validation loss 1.172818660736084\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3303933143615723, embedding dim 64, hidden size 2048, num layers 1, train loss 1.2184817790985107, validation loss 1.153855323791504\n",
      "Epoch 40, current patience 30, model mean validation loss 1.2872499227523804, embedding dim 64, hidden size 2048, num layers 1, train loss 1.1824262142181396, validation loss 1.1146762371063232\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2625374794006348, embedding dim 64, hidden size 2048, num layers 1, train loss 1.3074735403060913, validation loss 1.1389747858047485\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2402406930923462, embedding dim 64, hidden size 2048, num layers 1, train loss 1.074733018875122, validation loss 1.1064599752426147\n",
      "Epoch 70, current patience 30, model mean validation loss 1.224396824836731, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0136325359344482, validation loss 1.1134898662567139\n",
      "Epoch 80, current patience 30, model mean validation loss 1.167734146118164, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0907318592071533, validation loss 1.0767734050750732\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1225757598876953, embedding dim 64, hidden size 2048, num layers 1, train loss 1.029712438583374, validation loss 1.1035571098327637\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1100467443466187, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0557941198349, validation loss 1.072587490081787\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1193948984146118, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0762701034545898, validation loss 1.2286405563354492\n",
      "Epoch 120, current patience 29, model mean validation loss 1.1334580183029175, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0658661127090454, validation loss 1.2271809577941895\n",
      "Epoch 130, current patience 28, model mean validation loss 1.1235613822937012, embedding dim 64, hidden size 2048, num layers 1, train loss 1.110531210899353, validation loss 1.0598015785217285\n",
      "Epoch 140, current patience 27, model mean validation loss 1.1232707500457764, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0648839473724365, validation loss 1.1041345596313477\n",
      "Epoch 150, current patience 26, model mean validation loss 1.1253528594970703, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0743943452835083, validation loss 1.1301472187042236\n",
      "Epoch 160, current patience 25, model mean validation loss 1.1225703954696655, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0432121753692627, validation loss 1.0545135736465454\n",
      "Epoch 170, current patience 24, model mean validation loss 1.1162104606628418, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9905763864517212, validation loss 1.0526776313781738\n",
      "Epoch 180, current patience 23, model mean validation loss 1.1194769144058228, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0512248277664185, validation loss 1.098719835281372\n",
      "Epoch 190, current patience 22, model mean validation loss 1.1074916124343872, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0580122470855713, validation loss 1.1327577829360962\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0918066501617432, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9185113906860352, validation loss 1.1017005443572998\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0863327980041504, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9948810338973999, validation loss 1.0160115957260132\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0794309377670288, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9726925492286682, validation loss 1.0489189624786377\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0787632465362549, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9534859657287598, validation loss 1.1248059272766113\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0778088569641113, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9459847211837769, validation loss 1.0468782186508179\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0745052099227905, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9100950360298157, validation loss 1.0262491703033447\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0713214874267578, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0208317041397095, validation loss 1.0732498168945312\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0592864751815796, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9824886918067932, validation loss 1.03647780418396\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0490343570709229, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8437857031822205, validation loss 1.019683599472046\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0499480962753296, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9684333801269531, validation loss 1.023321270942688\n",
      "Epoch 300, current patience 29, model mean validation loss 1.0489827394485474, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8254518508911133, validation loss 1.041196346282959\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0364867448806763, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8905042409896851, validation loss 1.0248377323150635\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0343983173370361, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8899401426315308, validation loss 1.030170202255249\n",
      "Epoch 330, current patience 30, model mean validation loss 1.03307044506073, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8477472066879272, validation loss 1.0156266689300537\n",
      "Epoch 340, current patience 30, model mean validation loss 1.022788643836975, embedding dim 64, hidden size 2048, num layers 1, train loss 1.0206842422485352, validation loss 0.9909956455230713\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0249251127243042, embedding dim 64, hidden size 2048, num layers 1, train loss 0.955071210861206, validation loss 1.0535696744918823\n",
      "Epoch 360, current patience 29, model mean validation loss 1.0201159715652466, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8513562679290771, validation loss 0.9812098741531372\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0193850994110107, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7868418097496033, validation loss 1.0174747705459595\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0173745155334473, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9816169142723083, validation loss 1.0251109600067139\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0121159553527832, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8014359474182129, validation loss 0.9827690124511719\n",
      "Epoch 400, current patience 30, model mean validation loss 1.015950322151184, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7992084622383118, validation loss 1.0608457326889038\n",
      "Epoch 410, current patience 29, model mean validation loss 1.018000602722168, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8933941721916199, validation loss 1.0320295095443726\n",
      "Epoch 420, current patience 28, model mean validation loss 1.014897108078003, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9015716314315796, validation loss 0.9661672115325928\n",
      "Epoch 430, current patience 27, model mean validation loss 1.009264588356018, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8590370416641235, validation loss 1.0085093975067139\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0103338956832886, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8908422589302063, validation loss 0.989764928817749\n",
      "Epoch 450, current patience 29, model mean validation loss 1.0044891834259033, embedding dim 64, hidden size 2048, num layers 1, train loss 0.815849781036377, validation loss 0.9707175493240356\n",
      "Epoch 460, current patience 30, model mean validation loss 1.003961205482483, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8043928146362305, validation loss 1.0208864212036133\n",
      "Epoch 470, current patience 30, model mean validation loss 1.011181116104126, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7705506682395935, validation loss 1.040528655052185\n",
      "Epoch 480, current patience 29, model mean validation loss 1.003696322441101, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7295854091644287, validation loss 1.000967264175415\n",
      "Epoch 490, current patience 30, model mean validation loss 1.0002834796905518, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8658534288406372, validation loss 1.0047259330749512\n",
      "Epoch 500, current patience 30, model mean validation loss 1.0096484422683716, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9070519208908081, validation loss 1.0410875082015991\n",
      "Epoch 510, current patience 29, model mean validation loss 1.006732702255249, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8287389278411865, validation loss 0.9851829409599304\n",
      "Epoch 520, current patience 28, model mean validation loss 1.006799578666687, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7588764429092407, validation loss 0.9903003573417664\n",
      "Epoch 530, current patience 27, model mean validation loss 1.0080949068069458, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7751637697219849, validation loss 0.9810797572135925\n",
      "Epoch 540, current patience 26, model mean validation loss 1.002751350402832, embedding dim 64, hidden size 2048, num layers 1, train loss 0.9216702580451965, validation loss 0.9781385660171509\n",
      "Epoch 550, current patience 25, model mean validation loss 0.9989136457443237, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6966297626495361, validation loss 1.009826421737671\n",
      "Epoch 560, current patience 30, model mean validation loss 1.0011117458343506, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6695529222488403, validation loss 1.0185527801513672\n",
      "Epoch 570, current patience 29, model mean validation loss 0.9954451322555542, embedding dim 64, hidden size 2048, num layers 1, train loss 0.600596010684967, validation loss 0.9593926668167114\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9850127696990967, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5833150148391724, validation loss 0.9576283097267151\n",
      "Epoch 590, current patience 30, model mean validation loss 0.986015796661377, embedding dim 64, hidden size 2048, num layers 1, train loss 0.737609326839447, validation loss 0.9932074546813965\n",
      "Epoch 600, current patience 29, model mean validation loss 0.9963298439979553, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5034717321395874, validation loss 1.0728126764297485\n",
      "Epoch 610, current patience 28, model mean validation loss 1.0018455982208252, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8877016305923462, validation loss 1.0252063274383545\n",
      "Epoch 620, current patience 27, model mean validation loss 0.9992291927337646, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5168784856796265, validation loss 0.9572063684463501\n",
      "Epoch 630, current patience 26, model mean validation loss 0.998910129070282, embedding dim 64, hidden size 2048, num layers 1, train loss 0.26255902647972107, validation loss 1.0072746276855469\n",
      "Epoch 640, current patience 25, model mean validation loss 1.0039570331573486, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6169091463088989, validation loss 1.0589282512664795\n",
      "Epoch 650, current patience 24, model mean validation loss 1.0098581314086914, embedding dim 64, hidden size 2048, num layers 1, train loss 0.4525321125984192, validation loss 1.0066001415252686\n",
      "Epoch 660, current patience 23, model mean validation loss 1.0304749011993408, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7132613062858582, validation loss 1.122563123703003\n",
      "Epoch 670, current patience 22, model mean validation loss 1.0444509983062744, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5980125665664673, validation loss 1.1050167083740234\n",
      "Epoch 680, current patience 21, model mean validation loss 1.0457143783569336, embedding dim 64, hidden size 2048, num layers 1, train loss 0.8527834415435791, validation loss 1.0829188823699951\n",
      "Epoch 690, current patience 20, model mean validation loss 1.0536226034164429, embedding dim 64, hidden size 2048, num layers 1, train loss 0.32416319847106934, validation loss 1.088472843170166\n",
      "Epoch 700, current patience 19, model mean validation loss 1.0615601539611816, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5838974118232727, validation loss 1.020706295967102\n",
      "Epoch 710, current patience 18, model mean validation loss 1.064562201499939, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6064532995223999, validation loss 1.031291127204895\n",
      "Epoch 720, current patience 17, model mean validation loss 1.0644111633300781, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7970378398895264, validation loss 1.0577210187911987\n",
      "Epoch 730, current patience 16, model mean validation loss 1.0721646547317505, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6722204685211182, validation loss 1.068627119064331\n",
      "Epoch 740, current patience 15, model mean validation loss 1.0547397136688232, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5541867613792419, validation loss 0.9831634163856506\n",
      "Epoch 750, current patience 14, model mean validation loss 1.0427324771881104, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5431197285652161, validation loss 1.0089586973190308\n",
      "Epoch 760, current patience 13, model mean validation loss 1.0379084348678589, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5820904970169067, validation loss 1.0443267822265625\n",
      "Epoch 770, current patience 12, model mean validation loss 1.0312578678131104, embedding dim 64, hidden size 2048, num layers 1, train loss 0.798272430896759, validation loss 1.03526771068573\n",
      "Epoch 780, current patience 11, model mean validation loss 1.0385065078735352, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5283423662185669, validation loss 1.0786964893341064\n",
      "Epoch 790, current patience 10, model mean validation loss 1.0527446269989014, embedding dim 64, hidden size 2048, num layers 1, train loss 0.5836422443389893, validation loss 1.1451958417892456\n",
      "Epoch 800, current patience 9, model mean validation loss 1.0433954000473022, embedding dim 64, hidden size 2048, num layers 1, train loss 0.3664417266845703, validation loss 0.9829272627830505\n",
      "Epoch 810, current patience 8, model mean validation loss 1.0380902290344238, embedding dim 64, hidden size 2048, num layers 1, train loss 0.40008264780044556, validation loss 1.0261859893798828\n",
      "Epoch 820, current patience 7, model mean validation loss 1.0412592887878418, embedding dim 64, hidden size 2048, num layers 1, train loss 0.35986799001693726, validation loss 1.008515477180481\n",
      "Epoch 830, current patience 6, model mean validation loss 1.0410927534103394, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6105566620826721, validation loss 1.0076264142990112\n",
      "Epoch 840, current patience 5, model mean validation loss 1.0367059707641602, embedding dim 64, hidden size 2048, num layers 1, train loss 0.6064153909683228, validation loss 1.0092322826385498\n",
      "Epoch 850, current patience 4, model mean validation loss 1.0429706573486328, embedding dim 64, hidden size 2048, num layers 1, train loss 0.7229276299476624, validation loss 1.0853850841522217\n",
      "Epoch 860, current patience 3, model mean validation loss 1.048255443572998, embedding dim 64, hidden size 2048, num layers 1, train loss 0.4478176534175873, validation loss 1.1209752559661865\n",
      "Epoch 870, current patience 2, model mean validation loss 1.0381417274475098, embedding dim 64, hidden size 2048, num layers 1, train loss 0.3398723006248474, validation loss 1.0642852783203125\n",
      "Epoch 880, current patience 1, model mean validation loss 1.052076816558838, embedding dim 64, hidden size 2048, num layers 1, train loss 0.24756759405136108, validation loss 1.0944077968597412\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2936818599700928, embedding dim 128, hidden size 1, num layers 1, train loss 1.3259344100952148, validation loss 1.2936818599700928\n",
      "Epoch 10, current patience 30, model mean validation loss 1.2616260051727295, embedding dim 128, hidden size 1, num layers 1, train loss 1.2544325590133667, validation loss 1.2295700311660767\n",
      "Epoch 20, current patience 30, model mean validation loss 1.241409420967102, embedding dim 128, hidden size 1, num layers 1, train loss 1.1353657245635986, validation loss 1.2009762525558472\n",
      "Epoch 30, current patience 30, model mean validation loss 1.2229703664779663, embedding dim 128, hidden size 1, num layers 1, train loss 1.1489453315734863, validation loss 1.16765296459198\n",
      "Epoch 40, current patience 30, model mean validation loss 1.2098548412322998, embedding dim 128, hidden size 1, num layers 1, train loss 1.1712232828140259, validation loss 1.1573925018310547\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1987425088882446, embedding dim 128, hidden size 1, num layers 1, train loss 1.1165316104888916, validation loss 1.1431810855865479\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1882609128952026, embedding dim 128, hidden size 1, num layers 1, train loss 1.1081383228302002, validation loss 1.125372052192688\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1793034076690674, embedding dim 128, hidden size 1, num layers 1, train loss 1.0800291299819946, validation loss 1.116600513458252\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1576752662658691, embedding dim 128, hidden size 1, num layers 1, train loss 1.0914438962936401, validation loss 1.1206570863723755\n",
      "Epoch 90, current patience 30, model mean validation loss 1.141851544380188, embedding dim 128, hidden size 1, num layers 1, train loss 1.09770929813385, validation loss 1.1029800176620483\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1287801265716553, embedding dim 128, hidden size 1, num layers 1, train loss 1.0733137130737305, validation loss 1.0964051485061646\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1197776794433594, embedding dim 128, hidden size 1, num layers 1, train loss 1.0849496126174927, validation loss 1.095632553100586\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1120867729187012, embedding dim 128, hidden size 1, num layers 1, train loss 1.0885934829711914, validation loss 1.0958659648895264\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1061482429504395, embedding dim 128, hidden size 1, num layers 1, train loss 1.1026757955551147, validation loss 1.0956716537475586\n",
      "Epoch 140, current patience 30, model mean validation loss 1.101806640625, embedding dim 128, hidden size 1, num layers 1, train loss 1.092404842376709, validation loss 1.0906397104263306\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0993012189865112, embedding dim 128, hidden size 1, num layers 1, train loss 1.1076536178588867, validation loss 1.096557378768921\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0963904857635498, embedding dim 128, hidden size 1, num layers 1, train loss 1.0851936340332031, validation loss 1.0973708629608154\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0953658819198608, embedding dim 128, hidden size 1, num layers 1, train loss 1.0990031957626343, validation loss 1.0947836637496948\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0948703289031982, embedding dim 128, hidden size 1, num layers 1, train loss 1.0977429151535034, validation loss 1.0924403667449951\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0941834449768066, embedding dim 128, hidden size 1, num layers 1, train loss 1.0829582214355469, validation loss 1.0901374816894531\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0938806533813477, embedding dim 128, hidden size 1, num layers 1, train loss 1.0852534770965576, validation loss 1.0934444665908813\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0937488079071045, embedding dim 128, hidden size 1, num layers 1, train loss 1.0837430953979492, validation loss 1.094616413116455\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0941646099090576, embedding dim 128, hidden size 1, num layers 1, train loss 1.0996184349060059, validation loss 1.0939667224884033\n",
      "Epoch 230, current patience 29, model mean validation loss 1.0942937135696411, embedding dim 128, hidden size 1, num layers 1, train loss 1.0945252180099487, validation loss 1.0975897312164307\n",
      "Epoch 240, current patience 28, model mean validation loss 1.093809723854065, embedding dim 128, hidden size 1, num layers 1, train loss 1.0783531665802002, validation loss 1.0934985876083374\n",
      "Epoch 250, current patience 27, model mean validation loss 1.093721866607666, embedding dim 128, hidden size 1, num layers 1, train loss 1.1068699359893799, validation loss 1.094081163406372\n",
      "Epoch 260, current patience 30, model mean validation loss 1.0933120250701904, embedding dim 128, hidden size 1, num layers 1, train loss 1.081046462059021, validation loss 1.0891610383987427\n",
      "Epoch 270, current patience 30, model mean validation loss 1.093641757965088, embedding dim 128, hidden size 1, num layers 1, train loss 1.093306303024292, validation loss 1.0927760601043701\n",
      "Epoch 280, current patience 29, model mean validation loss 1.0935616493225098, embedding dim 128, hidden size 1, num layers 1, train loss 1.0717976093292236, validation loss 1.0928038358688354\n",
      "Epoch 290, current patience 28, model mean validation loss 1.0931634902954102, embedding dim 128, hidden size 1, num layers 1, train loss 1.0706815719604492, validation loss 1.0914306640625\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0932981967926025, embedding dim 128, hidden size 1, num layers 1, train loss 1.1177587509155273, validation loss 1.095044732093811\n",
      "Epoch 310, current patience 29, model mean validation loss 1.0925755500793457, embedding dim 128, hidden size 1, num layers 1, train loss 1.1069302558898926, validation loss 1.091808557510376\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0918227434158325, embedding dim 128, hidden size 1, num layers 1, train loss 1.1077508926391602, validation loss 1.0874760150909424\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0911414623260498, embedding dim 128, hidden size 1, num layers 1, train loss 1.1089626550674438, validation loss 1.0886300802230835\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0911189317703247, embedding dim 128, hidden size 1, num layers 1, train loss 1.1137514114379883, validation loss 1.0889815092086792\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0911080837249756, embedding dim 128, hidden size 1, num layers 1, train loss 1.0108580589294434, validation loss 1.0926891565322876\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0912503004074097, embedding dim 128, hidden size 1, num layers 1, train loss 1.055625557899475, validation loss 1.0939414501190186\n",
      "Epoch 370, current patience 29, model mean validation loss 1.0918182134628296, embedding dim 128, hidden size 1, num layers 1, train loss 1.0901119709014893, validation loss 1.0959738492965698\n",
      "Epoch 380, current patience 28, model mean validation loss 1.0919663906097412, embedding dim 128, hidden size 1, num layers 1, train loss 1.0392025709152222, validation loss 1.0962305068969727\n",
      "Epoch 390, current patience 27, model mean validation loss 1.0924097299575806, embedding dim 128, hidden size 1, num layers 1, train loss 1.007080316543579, validation loss 1.0953551530838013\n",
      "Epoch 400, current patience 26, model mean validation loss 1.0926928520202637, embedding dim 128, hidden size 1, num layers 1, train loss 1.0684993267059326, validation loss 1.0897409915924072\n",
      "Epoch 410, current patience 25, model mean validation loss 1.0932443141937256, embedding dim 128, hidden size 1, num layers 1, train loss 1.0727804899215698, validation loss 1.0930413007736206\n",
      "Epoch 420, current patience 24, model mean validation loss 1.094158411026001, embedding dim 128, hidden size 1, num layers 1, train loss 1.0123780965805054, validation loss 1.0962938070297241\n",
      "Epoch 430, current patience 23, model mean validation loss 1.0938704013824463, embedding dim 128, hidden size 1, num layers 1, train loss 1.0799357891082764, validation loss 1.0903863906860352\n",
      "Epoch 440, current patience 22, model mean validation loss 1.093638300895691, embedding dim 128, hidden size 1, num layers 1, train loss 1.0224906206130981, validation loss 1.0920846462249756\n",
      "Epoch 450, current patience 21, model mean validation loss 1.0939675569534302, embedding dim 128, hidden size 1, num layers 1, train loss 1.0768342018127441, validation loss 1.0986076593399048\n",
      "Epoch 460, current patience 20, model mean validation loss 1.0943878889083862, embedding dim 128, hidden size 1, num layers 1, train loss 1.021492600440979, validation loss 1.0995930433273315\n",
      "Epoch 470, current patience 19, model mean validation loss 1.093891978263855, embedding dim 128, hidden size 1, num layers 1, train loss 1.041935682296753, validation loss 1.0913878679275513\n",
      "Epoch 480, current patience 18, model mean validation loss 1.0944321155548096, embedding dim 128, hidden size 1, num layers 1, train loss 1.0313005447387695, validation loss 1.0940618515014648\n",
      "Epoch 490, current patience 17, model mean validation loss 1.0940043926239014, embedding dim 128, hidden size 1, num layers 1, train loss 1.082726001739502, validation loss 1.0896193981170654\n",
      "Epoch 500, current patience 16, model mean validation loss 1.0931730270385742, embedding dim 128, hidden size 1, num layers 1, train loss 1.1214590072631836, validation loss 1.0896432399749756\n",
      "Epoch 510, current patience 15, model mean validation loss 1.0941535234451294, embedding dim 128, hidden size 1, num layers 1, train loss 1.088587760925293, validation loss 1.0982307195663452\n",
      "Epoch 520, current patience 14, model mean validation loss 1.0939255952835083, embedding dim 128, hidden size 1, num layers 1, train loss 1.06103515625, validation loss 1.0902609825134277\n",
      "Epoch 530, current patience 13, model mean validation loss 1.0943143367767334, embedding dim 128, hidden size 1, num layers 1, train loss 1.0514872074127197, validation loss 1.101717233657837\n",
      "Epoch 540, current patience 12, model mean validation loss 1.092930793762207, embedding dim 128, hidden size 1, num layers 1, train loss 1.072914958000183, validation loss 1.0885255336761475\n",
      "Epoch 550, current patience 11, model mean validation loss 1.0932953357696533, embedding dim 128, hidden size 1, num layers 1, train loss 1.008498191833496, validation loss 1.0943031311035156\n",
      "Epoch 560, current patience 10, model mean validation loss 1.0954861640930176, embedding dim 128, hidden size 1, num layers 1, train loss 1.0960158109664917, validation loss 1.111588478088379\n",
      "Epoch 570, current patience 9, model mean validation loss 1.0966076850891113, embedding dim 128, hidden size 1, num layers 1, train loss 1.069948434829712, validation loss 1.0985914468765259\n",
      "Epoch 580, current patience 8, model mean validation loss 1.0979114770889282, embedding dim 128, hidden size 1, num layers 1, train loss 1.0206689834594727, validation loss 1.1000738143920898\n",
      "Epoch 590, current patience 7, model mean validation loss 1.097725510597229, embedding dim 128, hidden size 1, num layers 1, train loss 1.000805377960205, validation loss 1.0967433452606201\n",
      "Epoch 600, current patience 6, model mean validation loss 1.0981252193450928, embedding dim 128, hidden size 1, num layers 1, train loss 0.9972767233848572, validation loss 1.0934585332870483\n",
      "Epoch 610, current patience 5, model mean validation loss 1.0975010395050049, embedding dim 128, hidden size 1, num layers 1, train loss 1.011173963546753, validation loss 1.0967237949371338\n",
      "Epoch 620, current patience 4, model mean validation loss 1.101166009902954, embedding dim 128, hidden size 1, num layers 1, train loss 0.9361525177955627, validation loss 1.1178454160690308\n",
      "Epoch 630, current patience 3, model mean validation loss 1.102313756942749, embedding dim 128, hidden size 1, num layers 1, train loss 1.0923725366592407, validation loss 1.103485345840454\n",
      "Epoch 640, current patience 2, model mean validation loss 1.1004877090454102, embedding dim 128, hidden size 1, num layers 1, train loss 0.9964269399642944, validation loss 1.0969798564910889\n",
      "Epoch 650, current patience 1, model mean validation loss 1.1017640829086304, embedding dim 128, hidden size 1, num layers 1, train loss 1.01639723777771, validation loss 1.1088025569915771\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1069004535675049, embedding dim 128, hidden size 2, num layers 1, train loss 1.0573687553405762, validation loss 1.1069004535675049\n",
      "Epoch 10, current patience 30, model mean validation loss 1.104132890701294, embedding dim 128, hidden size 2, num layers 1, train loss 1.096431016921997, validation loss 1.1013652086257935\n",
      "Epoch 20, current patience 30, model mean validation loss 1.102481484413147, embedding dim 128, hidden size 2, num layers 1, train loss 1.0710514783859253, validation loss 1.0991785526275635\n",
      "Epoch 30, current patience 30, model mean validation loss 1.100833773612976, embedding dim 128, hidden size 2, num layers 1, train loss 1.0961878299713135, validation loss 1.095890760421753\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0992505550384521, embedding dim 128, hidden size 2, num layers 1, train loss 1.0977214574813843, validation loss 1.0929179191589355\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0985345840454102, embedding dim 128, hidden size 2, num layers 1, train loss 1.0832632780075073, validation loss 1.094954490661621\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0976401567459106, embedding dim 128, hidden size 2, num layers 1, train loss 1.0938276052474976, validation loss 1.0922739505767822\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0970327854156494, embedding dim 128, hidden size 2, num layers 1, train loss 1.1071949005126953, validation loss 1.0927807092666626\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0956358909606934, embedding dim 128, hidden size 2, num layers 1, train loss 1.0980610847473145, validation loss 1.0957257747650146\n",
      "Epoch 90, current patience 30, model mean validation loss 1.095383644104004, embedding dim 128, hidden size 2, num layers 1, train loss 1.0843226909637451, validation loss 1.0993473529815674\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0949242115020752, embedding dim 128, hidden size 2, num layers 1, train loss 1.0909737348556519, validation loss 1.0955026149749756\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0950371026992798, embedding dim 128, hidden size 2, num layers 1, train loss 1.088221788406372, validation loss 1.0967941284179688\n",
      "Epoch 120, current patience 29, model mean validation loss 1.0952112674713135, embedding dim 128, hidden size 2, num layers 1, train loss 1.086578369140625, validation loss 1.0943114757537842\n",
      "Epoch 130, current patience 28, model mean validation loss 1.0953129529953003, embedding dim 128, hidden size 2, num layers 1, train loss 1.093095064163208, validation loss 1.095767617225647\n",
      "Epoch 140, current patience 27, model mean validation loss 1.0956206321716309, embedding dim 128, hidden size 2, num layers 1, train loss 1.109696865081787, validation loss 1.0947352647781372\n",
      "Epoch 150, current patience 26, model mean validation loss 1.0958318710327148, embedding dim 128, hidden size 2, num layers 1, train loss 1.0967422723770142, validation loss 1.0944700241088867\n",
      "Epoch 160, current patience 25, model mean validation loss 1.0956387519836426, embedding dim 128, hidden size 2, num layers 1, train loss 1.0874395370483398, validation loss 1.0941816568374634\n",
      "Epoch 170, current patience 24, model mean validation loss 1.0951523780822754, embedding dim 128, hidden size 2, num layers 1, train loss 1.084744930267334, validation loss 1.095455527305603\n",
      "Epoch 180, current patience 23, model mean validation loss 1.09568190574646, embedding dim 128, hidden size 2, num layers 1, train loss 1.0998549461364746, validation loss 1.0997389554977417\n",
      "Epoch 190, current patience 22, model mean validation loss 1.0959992408752441, embedding dim 128, hidden size 2, num layers 1, train loss 1.087654709815979, validation loss 1.0993326902389526\n",
      "Epoch 200, current patience 21, model mean validation loss 1.096621036529541, embedding dim 128, hidden size 2, num layers 1, train loss 1.0816236734390259, validation loss 1.0992863178253174\n",
      "Epoch 210, current patience 20, model mean validation loss 1.0963432788848877, embedding dim 128, hidden size 2, num layers 1, train loss 1.0883448123931885, validation loss 1.09354567527771\n",
      "Epoch 220, current patience 19, model mean validation loss 1.0961096286773682, embedding dim 128, hidden size 2, num layers 1, train loss 1.0879411697387695, validation loss 1.0928664207458496\n",
      "Epoch 230, current patience 18, model mean validation loss 1.0961217880249023, embedding dim 128, hidden size 2, num layers 1, train loss 1.0830961465835571, validation loss 1.0945663452148438\n",
      "Epoch 240, current patience 17, model mean validation loss 1.0961891412734985, embedding dim 128, hidden size 2, num layers 1, train loss 1.0965808629989624, validation loss 1.0947213172912598\n",
      "Epoch 250, current patience 16, model mean validation loss 1.096146583557129, embedding dim 128, hidden size 2, num layers 1, train loss 1.0912704467773438, validation loss 1.095115065574646\n",
      "Epoch 260, current patience 15, model mean validation loss 1.0952764749526978, embedding dim 128, hidden size 2, num layers 1, train loss 1.0795021057128906, validation loss 1.0927778482437134\n",
      "Epoch 270, current patience 14, model mean validation loss 1.0942401885986328, embedding dim 128, hidden size 2, num layers 1, train loss 1.069937825202942, validation loss 1.0910426378250122\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0930192470550537, embedding dim 128, hidden size 2, num layers 1, train loss 1.0642831325531006, validation loss 1.0895189046859741\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0920275449752808, embedding dim 128, hidden size 2, num layers 1, train loss 1.103352427482605, validation loss 1.0856120586395264\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0908305644989014, embedding dim 128, hidden size 2, num layers 1, train loss 1.0955227613449097, validation loss 1.0832910537719727\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0898957252502441, embedding dim 128, hidden size 2, num layers 1, train loss 1.0696227550506592, validation loss 1.0870875120162964\n",
      "Epoch 320, current patience 30, model mean validation loss 1.08864164352417, embedding dim 128, hidden size 2, num layers 1, train loss 1.0528842210769653, validation loss 1.0846877098083496\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0871434211730957, embedding dim 128, hidden size 2, num layers 1, train loss 1.06882905960083, validation loss 1.083129644393921\n",
      "Epoch 340, current patience 30, model mean validation loss 1.085842251777649, embedding dim 128, hidden size 2, num layers 1, train loss 1.1194379329681396, validation loss 1.0823681354522705\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0836519002914429, embedding dim 128, hidden size 2, num layers 1, train loss 1.0958210229873657, validation loss 1.0735197067260742\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0805538892745972, embedding dim 128, hidden size 2, num layers 1, train loss 1.0319008827209473, validation loss 1.0647348165512085\n",
      "Epoch 370, current patience 30, model mean validation loss 1.078587532043457, embedding dim 128, hidden size 2, num layers 1, train loss 1.0382492542266846, validation loss 1.069881558418274\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0786484479904175, embedding dim 128, hidden size 2, num layers 1, train loss 1.041297197341919, validation loss 1.0837781429290771\n",
      "Epoch 390, current patience 29, model mean validation loss 1.07769775390625, embedding dim 128, hidden size 2, num layers 1, train loss 1.0098533630371094, validation loss 1.0794825553894043\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0745985507965088, embedding dim 128, hidden size 2, num layers 1, train loss 1.053051233291626, validation loss 1.059893250465393\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0728628635406494, embedding dim 128, hidden size 2, num layers 1, train loss 1.0505622625350952, validation loss 1.0692448616027832\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0714313983917236, embedding dim 128, hidden size 2, num layers 1, train loss 1.0332787036895752, validation loss 1.0709165334701538\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0710132122039795, embedding dim 128, hidden size 2, num layers 1, train loss 1.0107252597808838, validation loss 1.0701744556427002\n",
      "Epoch 440, current patience 30, model mean validation loss 1.071197271347046, embedding dim 128, hidden size 2, num layers 1, train loss 0.9384829998016357, validation loss 1.0662075281143188\n",
      "Epoch 450, current patience 29, model mean validation loss 1.0701202154159546, embedding dim 128, hidden size 2, num layers 1, train loss 0.9209099411964417, validation loss 1.0612643957138062\n",
      "Epoch 460, current patience 30, model mean validation loss 1.0697418451309204, embedding dim 128, hidden size 2, num layers 1, train loss 0.9320453405380249, validation loss 1.080750823020935\n",
      "Epoch 470, current patience 30, model mean validation loss 1.0675463676452637, embedding dim 128, hidden size 2, num layers 1, train loss 0.9093416929244995, validation loss 1.0619193315505981\n",
      "Epoch 480, current patience 30, model mean validation loss 1.0684317350387573, embedding dim 128, hidden size 2, num layers 1, train loss 1.0347436666488647, validation loss 1.0669753551483154\n",
      "Epoch 490, current patience 29, model mean validation loss 1.0686218738555908, embedding dim 128, hidden size 2, num layers 1, train loss 1.0127519369125366, validation loss 1.0707663297653198\n",
      "Epoch 500, current patience 28, model mean validation loss 1.06634521484375, embedding dim 128, hidden size 2, num layers 1, train loss 0.9630106687545776, validation loss 1.0527032613754272\n",
      "Epoch 510, current patience 30, model mean validation loss 1.066146969795227, embedding dim 128, hidden size 2, num layers 1, train loss 1.0801692008972168, validation loss 1.0685880184173584\n",
      "Epoch 520, current patience 30, model mean validation loss 1.0653213262557983, embedding dim 128, hidden size 2, num layers 1, train loss 1.0330703258514404, validation loss 1.059603214263916\n",
      "Epoch 530, current patience 30, model mean validation loss 1.064242959022522, embedding dim 128, hidden size 2, num layers 1, train loss 1.0207579135894775, validation loss 1.0526372194290161\n",
      "Epoch 540, current patience 30, model mean validation loss 1.063389539718628, embedding dim 128, hidden size 2, num layers 1, train loss 1.0048102140426636, validation loss 1.0739237070083618\n",
      "Epoch 550, current patience 30, model mean validation loss 1.06371009349823, embedding dim 128, hidden size 2, num layers 1, train loss 0.8710471391677856, validation loss 1.0644837617874146\n",
      "Epoch 560, current patience 29, model mean validation loss 1.06509268283844, embedding dim 128, hidden size 2, num layers 1, train loss 0.9688534736633301, validation loss 1.078035831451416\n",
      "Epoch 570, current patience 28, model mean validation loss 1.0618294477462769, embedding dim 128, hidden size 2, num layers 1, train loss 0.9706072211265564, validation loss 1.0446603298187256\n",
      "Epoch 580, current patience 30, model mean validation loss 1.0613791942596436, embedding dim 128, hidden size 2, num layers 1, train loss 0.8403089046478271, validation loss 1.0491011142730713\n",
      "Epoch 590, current patience 30, model mean validation loss 1.057591438293457, embedding dim 128, hidden size 2, num layers 1, train loss 0.9561313390731812, validation loss 1.0382866859436035\n",
      "Epoch 600, current patience 30, model mean validation loss 1.0552312135696411, embedding dim 128, hidden size 2, num layers 1, train loss 1.0394784212112427, validation loss 1.0407207012176514\n",
      "Epoch 610, current patience 30, model mean validation loss 1.0532052516937256, embedding dim 128, hidden size 2, num layers 1, train loss 1.1125550270080566, validation loss 1.0364298820495605\n",
      "Epoch 620, current patience 30, model mean validation loss 1.0509283542633057, embedding dim 128, hidden size 2, num layers 1, train loss 0.8572787046432495, validation loss 1.055708885192871\n",
      "Epoch 630, current patience 30, model mean validation loss 1.045694351196289, embedding dim 128, hidden size 2, num layers 1, train loss 0.9650387763977051, validation loss 1.0226117372512817\n",
      "Epoch 640, current patience 30, model mean validation loss 1.0445210933685303, embedding dim 128, hidden size 2, num layers 1, train loss 0.8733458518981934, validation loss 1.0686492919921875\n",
      "Epoch 650, current patience 30, model mean validation loss 1.0413999557495117, embedding dim 128, hidden size 2, num layers 1, train loss 0.8223819732666016, validation loss 1.0196915864944458\n",
      "Epoch 660, current patience 30, model mean validation loss 1.042445182800293, embedding dim 128, hidden size 2, num layers 1, train loss 0.8405295610427856, validation loss 1.05746328830719\n",
      "Epoch 670, current patience 29, model mean validation loss 1.041783094406128, embedding dim 128, hidden size 2, num layers 1, train loss 0.8238661289215088, validation loss 1.0329903364181519\n",
      "Epoch 680, current patience 28, model mean validation loss 1.041663646697998, embedding dim 128, hidden size 2, num layers 1, train loss 0.7958506345748901, validation loss 1.0397647619247437\n",
      "Epoch 690, current patience 27, model mean validation loss 1.0406094789505005, embedding dim 128, hidden size 2, num layers 1, train loss 0.8068631887435913, validation loss 1.0279961824417114\n",
      "Epoch 700, current patience 30, model mean validation loss 1.0375844240188599, embedding dim 128, hidden size 2, num layers 1, train loss 0.8015077114105225, validation loss 1.0315077304840088\n",
      "Epoch 710, current patience 30, model mean validation loss 1.0396687984466553, embedding dim 128, hidden size 2, num layers 1, train loss 0.9320240020751953, validation loss 1.0392863750457764\n",
      "Epoch 720, current patience 29, model mean validation loss 1.0338317155838013, embedding dim 128, hidden size 2, num layers 1, train loss 0.8219358921051025, validation loss 1.0219539403915405\n",
      "Epoch 730, current patience 30, model mean validation loss 1.0324923992156982, embedding dim 128, hidden size 2, num layers 1, train loss 0.8683808445930481, validation loss 1.008976697921753\n",
      "Epoch 740, current patience 30, model mean validation loss 1.02836012840271, embedding dim 128, hidden size 2, num layers 1, train loss 0.7583850622177124, validation loss 1.0244052410125732\n",
      "Epoch 750, current patience 30, model mean validation loss 1.0245659351348877, embedding dim 128, hidden size 2, num layers 1, train loss 0.7366560697555542, validation loss 1.002636194229126\n",
      "Epoch 760, current patience 30, model mean validation loss 1.0191335678100586, embedding dim 128, hidden size 2, num layers 1, train loss 0.8993086814880371, validation loss 0.9963056445121765\n",
      "Epoch 770, current patience 30, model mean validation loss 1.0164549350738525, embedding dim 128, hidden size 2, num layers 1, train loss 0.9092836380004883, validation loss 1.0065679550170898\n",
      "Epoch 780, current patience 30, model mean validation loss 1.0132722854614258, embedding dim 128, hidden size 2, num layers 1, train loss 0.7928676605224609, validation loss 1.0060466527938843\n",
      "Epoch 790, current patience 30, model mean validation loss 1.0105077028274536, embedding dim 128, hidden size 2, num layers 1, train loss 1.0435969829559326, validation loss 1.01716947555542\n",
      "Epoch 800, current patience 30, model mean validation loss 1.005599021911621, embedding dim 128, hidden size 2, num layers 1, train loss 0.6888022422790527, validation loss 0.9826844334602356\n",
      "Epoch 810, current patience 30, model mean validation loss 1.0060877799987793, embedding dim 128, hidden size 2, num layers 1, train loss 0.7752249836921692, validation loss 1.0128860473632812\n",
      "Epoch 820, current patience 29, model mean validation loss 1.0078988075256348, embedding dim 128, hidden size 2, num layers 1, train loss 0.790244460105896, validation loss 1.038893699645996\n",
      "Epoch 830, current patience 28, model mean validation loss 1.0146429538726807, embedding dim 128, hidden size 2, num layers 1, train loss 0.8515568971633911, validation loss 1.0565900802612305\n",
      "Epoch 840, current patience 27, model mean validation loss 1.0163735151290894, embedding dim 128, hidden size 2, num layers 1, train loss 0.8335886597633362, validation loss 1.0101494789123535\n",
      "Epoch 850, current patience 26, model mean validation loss 1.014725685119629, embedding dim 128, hidden size 2, num layers 1, train loss 0.7259234189987183, validation loss 0.9933854937553406\n",
      "Epoch 860, current patience 25, model mean validation loss 1.0143296718597412, embedding dim 128, hidden size 2, num layers 1, train loss 0.8788706660270691, validation loss 1.0028785467147827\n",
      "Epoch 870, current patience 24, model mean validation loss 1.012059211730957, embedding dim 128, hidden size 2, num layers 1, train loss 0.6388545036315918, validation loss 0.999005913734436\n",
      "Epoch 880, current patience 23, model mean validation loss 1.0147051811218262, embedding dim 128, hidden size 2, num layers 1, train loss 0.7134886980056763, validation loss 1.0038522481918335\n",
      "Epoch 890, current patience 22, model mean validation loss 1.0161575078964233, embedding dim 128, hidden size 2, num layers 1, train loss 0.6684246063232422, validation loss 1.0245041847229004\n",
      "Epoch 900, current patience 21, model mean validation loss 1.0134525299072266, embedding dim 128, hidden size 2, num layers 1, train loss 0.6720055937767029, validation loss 1.0172538757324219\n",
      "Epoch 910, current patience 20, model mean validation loss 1.0083425045013428, embedding dim 128, hidden size 2, num layers 1, train loss 0.7570784687995911, validation loss 1.0157103538513184\n",
      "Epoch 920, current patience 19, model mean validation loss 1.0130311250686646, embedding dim 128, hidden size 2, num layers 1, train loss 0.9485020637512207, validation loss 1.0476585626602173\n",
      "Epoch 930, current patience 18, model mean validation loss 1.0167416334152222, embedding dim 128, hidden size 2, num layers 1, train loss 0.82056725025177, validation loss 1.0230696201324463\n",
      "Epoch 940, current patience 17, model mean validation loss 1.019996166229248, embedding dim 128, hidden size 2, num layers 1, train loss 0.6146712303161621, validation loss 1.0289146900177002\n",
      "Epoch 950, current patience 16, model mean validation loss 1.0225236415863037, embedding dim 128, hidden size 2, num layers 1, train loss 0.6699177026748657, validation loss 1.0192255973815918\n",
      "Epoch 960, current patience 15, model mean validation loss 1.0272672176361084, embedding dim 128, hidden size 2, num layers 1, train loss 0.70564866065979, validation loss 1.0418012142181396\n",
      "Epoch 970, current patience 14, model mean validation loss 1.0270802974700928, embedding dim 128, hidden size 2, num layers 1, train loss 0.6401189565658569, validation loss 1.023008108139038\n",
      "Epoch 980, current patience 13, model mean validation loss 1.0262503623962402, embedding dim 128, hidden size 2, num layers 1, train loss 0.702286422252655, validation loss 1.0106152296066284\n",
      "Epoch 990, current patience 12, model mean validation loss 1.0279223918914795, embedding dim 128, hidden size 2, num layers 1, train loss 0.6782487630844116, validation loss 1.0290858745574951\n",
      "Epoch 1000, current patience 11, model mean validation loss 1.0219194889068604, embedding dim 128, hidden size 2, num layers 1, train loss 1.1005653142929077, validation loss 0.9996356964111328\n",
      "Epoch 1010, current patience 10, model mean validation loss 1.015729546546936, embedding dim 128, hidden size 2, num layers 1, train loss 0.6766956448554993, validation loss 0.9735502004623413\n",
      "Epoch 1020, current patience 9, model mean validation loss 1.0118464231491089, embedding dim 128, hidden size 2, num layers 1, train loss 0.7620840668678284, validation loss 0.9978493452072144\n",
      "Epoch 1030, current patience 8, model mean validation loss 1.009798526763916, embedding dim 128, hidden size 2, num layers 1, train loss 0.6355069875717163, validation loss 1.0028419494628906\n",
      "Epoch 1040, current patience 7, model mean validation loss 1.0095851421356201, embedding dim 128, hidden size 2, num layers 1, train loss 0.5516859889030457, validation loss 1.0400947332382202\n",
      "Epoch 1050, current patience 6, model mean validation loss 1.0082274675369263, embedding dim 128, hidden size 2, num layers 1, train loss 0.7650896310806274, validation loss 1.0121463537216187\n",
      "Epoch 1060, current patience 5, model mean validation loss 1.0060758590698242, embedding dim 128, hidden size 2, num layers 1, train loss 0.7692654132843018, validation loss 0.9934029579162598\n",
      "Epoch 1070, current patience 4, model mean validation loss 1.0102410316467285, embedding dim 128, hidden size 2, num layers 1, train loss 0.8449018597602844, validation loss 1.0624070167541504\n",
      "Epoch 1080, current patience 3, model mean validation loss 1.0159657001495361, embedding dim 128, hidden size 2, num layers 1, train loss 0.6551634073257446, validation loss 1.0454330444335938\n",
      "Epoch 1090, current patience 2, model mean validation loss 1.0211617946624756, embedding dim 128, hidden size 2, num layers 1, train loss 0.6285890340805054, validation loss 1.015118956565857\n",
      "Epoch 1100, current patience 1, model mean validation loss 1.0243967771530151, embedding dim 128, hidden size 2, num layers 1, train loss 0.7317230105400085, validation loss 1.023728609085083\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1347534656524658, embedding dim 128, hidden size 4, num layers 1, train loss 1.1465957164764404, validation loss 1.1347534656524658\n",
      "Epoch 10, current patience 30, model mean validation loss 1.121183156967163, embedding dim 128, hidden size 4, num layers 1, train loss 1.1322057247161865, validation loss 1.1076127290725708\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1142750978469849, embedding dim 128, hidden size 4, num layers 1, train loss 1.1251161098480225, validation loss 1.100459098815918\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1089842319488525, embedding dim 128, hidden size 4, num layers 1, train loss 1.0913069248199463, validation loss 1.093111276626587\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1062456369400024, embedding dim 128, hidden size 4, num layers 1, train loss 1.1073758602142334, validation loss 1.0952913761138916\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1044756174087524, embedding dim 128, hidden size 4, num layers 1, train loss 1.0751549005508423, validation loss 1.095625877380371\n",
      "Epoch 60, current patience 30, model mean validation loss 1.102585792541504, embedding dim 128, hidden size 4, num layers 1, train loss 1.0713788270950317, validation loss 1.0912467241287231\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1016193628311157, embedding dim 128, hidden size 4, num layers 1, train loss 1.0811187028884888, validation loss 1.0948545932769775\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0966989994049072, embedding dim 128, hidden size 4, num layers 1, train loss 1.0620543956756592, validation loss 1.0953900814056396\n",
      "Epoch 90, current patience 30, model mean validation loss 1.095412015914917, embedding dim 128, hidden size 4, num layers 1, train loss 1.0816888809204102, validation loss 1.0973175764083862\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0945730209350586, embedding dim 128, hidden size 4, num layers 1, train loss 1.1000341176986694, validation loss 1.0937466621398926\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0945513248443604, embedding dim 128, hidden size 4, num layers 1, train loss 1.1013305187225342, validation loss 1.0929372310638428\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0939459800720215, embedding dim 128, hidden size 4, num layers 1, train loss 1.0639315843582153, validation loss 1.0904496908187866\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0925819873809814, embedding dim 128, hidden size 4, num layers 1, train loss 1.0885121822357178, validation loss 1.0847136974334717\n",
      "Epoch 140, current patience 30, model mean validation loss 1.092343807220459, embedding dim 128, hidden size 4, num layers 1, train loss 1.042609453201294, validation loss 1.089341163635254\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0899252891540527, embedding dim 128, hidden size 4, num layers 1, train loss 1.089435338973999, validation loss 1.0755062103271484\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0866875648498535, embedding dim 128, hidden size 4, num layers 1, train loss 1.0688557624816895, validation loss 1.069488286972046\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0840225219726562, embedding dim 128, hidden size 4, num layers 1, train loss 0.9917201399803162, validation loss 1.0759975910186768\n",
      "Epoch 180, current patience 30, model mean validation loss 1.081790566444397, embedding dim 128, hidden size 4, num layers 1, train loss 1.022545337677002, validation loss 1.075890302658081\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0800549983978271, embedding dim 128, hidden size 4, num layers 1, train loss 1.0390605926513672, validation loss 1.0790534019470215\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0767784118652344, embedding dim 128, hidden size 4, num layers 1, train loss 0.9338017106056213, validation loss 1.0642359256744385\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0755829811096191, embedding dim 128, hidden size 4, num layers 1, train loss 1.0706613063812256, validation loss 1.075150966644287\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0718863010406494, embedding dim 128, hidden size 4, num layers 1, train loss 1.0565032958984375, validation loss 1.0597678422927856\n",
      "Epoch 230, current patience 30, model mean validation loss 1.071524739265442, embedding dim 128, hidden size 4, num layers 1, train loss 0.8014872074127197, validation loss 1.0726134777069092\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0664087533950806, embedding dim 128, hidden size 4, num layers 1, train loss 1.1289987564086914, validation loss 1.0285601615905762\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0597964525222778, embedding dim 128, hidden size 4, num layers 1, train loss 1.0719245672225952, validation loss 1.0230993032455444\n",
      "Epoch 260, current patience 30, model mean validation loss 1.055192470550537, embedding dim 128, hidden size 4, num layers 1, train loss 0.9538754224777222, validation loss 1.0390584468841553\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0490909814834595, embedding dim 128, hidden size 4, num layers 1, train loss 0.8335373401641846, validation loss 1.0302412509918213\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0444029569625854, embedding dim 128, hidden size 4, num layers 1, train loss 0.8981198072433472, validation loss 1.0267317295074463\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0369398593902588, embedding dim 128, hidden size 4, num layers 1, train loss 0.6781390309333801, validation loss 1.0154461860656738\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0308756828308105, embedding dim 128, hidden size 4, num layers 1, train loss 0.9736560583114624, validation loss 1.0112544298171997\n",
      "Epoch 310, current patience 30, model mean validation loss 1.021964430809021, embedding dim 128, hidden size 4, num layers 1, train loss 0.8705922961235046, validation loss 1.0013234615325928\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0197809934616089, embedding dim 128, hidden size 4, num layers 1, train loss 0.9456828832626343, validation loss 1.0110931396484375\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0199222564697266, embedding dim 128, hidden size 4, num layers 1, train loss 0.8028860092163086, validation loss 1.0242290496826172\n",
      "Epoch 340, current patience 29, model mean validation loss 1.0165451765060425, embedding dim 128, hidden size 4, num layers 1, train loss 0.9187489151954651, validation loss 1.01204252243042\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0153380632400513, embedding dim 128, hidden size 4, num layers 1, train loss 0.979435920715332, validation loss 1.0205838680267334\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0127928256988525, embedding dim 128, hidden size 4, num layers 1, train loss 0.7162569165229797, validation loss 1.0063700675964355\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0131957530975342, embedding dim 128, hidden size 4, num layers 1, train loss 1.1393210887908936, validation loss 1.0186700820922852\n",
      "Epoch 380, current patience 29, model mean validation loss 1.0111864805221558, embedding dim 128, hidden size 4, num layers 1, train loss 1.0984516143798828, validation loss 0.9951795935630798\n",
      "Epoch 390, current patience 30, model mean validation loss 1.009986400604248, embedding dim 128, hidden size 4, num layers 1, train loss 0.7573537826538086, validation loss 0.9917224049568176\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0075302124023438, embedding dim 128, hidden size 4, num layers 1, train loss 0.9681332111358643, validation loss 0.9914446473121643\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0039695501327515, embedding dim 128, hidden size 4, num layers 1, train loss 0.8911505341529846, validation loss 0.995743453502655\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0014612674713135, embedding dim 128, hidden size 4, num layers 1, train loss 0.785861611366272, validation loss 0.9919766187667847\n",
      "Epoch 430, current patience 30, model mean validation loss 0.995268702507019, embedding dim 128, hidden size 4, num layers 1, train loss 0.7334146499633789, validation loss 0.9710429906845093\n",
      "Epoch 440, current patience 30, model mean validation loss 0.9926170110702515, embedding dim 128, hidden size 4, num layers 1, train loss 0.7064119577407837, validation loss 0.9851562976837158\n",
      "Epoch 450, current patience 30, model mean validation loss 0.9921228885650635, embedding dim 128, hidden size 4, num layers 1, train loss 0.6820370554924011, validation loss 1.0147173404693604\n",
      "Epoch 460, current patience 30, model mean validation loss 0.9970138072967529, embedding dim 128, hidden size 4, num layers 1, train loss 0.6702836751937866, validation loss 1.0343067646026611\n",
      "Epoch 470, current patience 29, model mean validation loss 1.0034689903259277, embedding dim 128, hidden size 4, num layers 1, train loss 0.7095096111297607, validation loss 1.0433647632598877\n",
      "Epoch 480, current patience 28, model mean validation loss 1.000417709350586, embedding dim 128, hidden size 4, num layers 1, train loss 0.5922764539718628, validation loss 0.9670336842536926\n",
      "Epoch 490, current patience 27, model mean validation loss 0.9985040426254272, embedding dim 128, hidden size 4, num layers 1, train loss 0.8133171200752258, validation loss 0.9804341197013855\n",
      "Epoch 500, current patience 26, model mean validation loss 0.9977239966392517, embedding dim 128, hidden size 4, num layers 1, train loss 0.9196429252624512, validation loss 0.985736072063446\n",
      "Epoch 510, current patience 25, model mean validation loss 0.9945916533470154, embedding dim 128, hidden size 4, num layers 1, train loss 0.6397177577018738, validation loss 0.9459840655326843\n",
      "Epoch 520, current patience 24, model mean validation loss 0.9943861365318298, embedding dim 128, hidden size 4, num layers 1, train loss 0.5538783073425293, validation loss 0.9835120439529419\n",
      "Epoch 530, current patience 23, model mean validation loss 0.9902074337005615, embedding dim 128, hidden size 4, num layers 1, train loss 0.9926338791847229, validation loss 0.9812880754470825\n",
      "Epoch 540, current patience 30, model mean validation loss 0.9776096940040588, embedding dim 128, hidden size 4, num layers 1, train loss 0.9360811710357666, validation loss 0.9335243701934814\n",
      "Epoch 550, current patience 30, model mean validation loss 0.9650053977966309, embedding dim 128, hidden size 4, num layers 1, train loss 0.6165327429771423, validation loss 0.942530632019043\n",
      "Epoch 560, current patience 30, model mean validation loss 0.9711315631866455, embedding dim 128, hidden size 4, num layers 1, train loss 0.6289682388305664, validation loss 1.0160430669784546\n",
      "Epoch 570, current patience 29, model mean validation loss 0.9682723879814148, embedding dim 128, hidden size 4, num layers 1, train loss 0.692380428314209, validation loss 0.9575609564781189\n",
      "Epoch 580, current patience 28, model mean validation loss 0.9718091487884521, embedding dim 128, hidden size 4, num layers 1, train loss 0.5448288917541504, validation loss 1.0140302181243896\n",
      "Epoch 590, current patience 27, model mean validation loss 0.9768751859664917, embedding dim 128, hidden size 4, num layers 1, train loss 0.6514352560043335, validation loss 0.986512303352356\n",
      "Epoch 600, current patience 26, model mean validation loss 0.9743812680244446, embedding dim 128, hidden size 4, num layers 1, train loss 0.6764724254608154, validation loss 0.9635607004165649\n",
      "Epoch 610, current patience 25, model mean validation loss 0.9734356999397278, embedding dim 128, hidden size 4, num layers 1, train loss 0.5858646631240845, validation loss 0.9737235903739929\n",
      "Epoch 620, current patience 24, model mean validation loss 0.9820800423622131, embedding dim 128, hidden size 4, num layers 1, train loss 0.725603461265564, validation loss 1.0026791095733643\n",
      "Epoch 630, current patience 23, model mean validation loss 0.9886390566825867, embedding dim 128, hidden size 4, num layers 1, train loss 0.5167158842086792, validation loss 0.9950027465820312\n",
      "Epoch 640, current patience 22, model mean validation loss 0.9900165796279907, embedding dim 128, hidden size 4, num layers 1, train loss 0.9493660926818848, validation loss 1.0270631313323975\n",
      "Epoch 650, current patience 21, model mean validation loss 0.996080756187439, embedding dim 128, hidden size 4, num layers 1, train loss 0.4510176181793213, validation loss 1.0060741901397705\n",
      "Epoch 660, current patience 20, model mean validation loss 0.9915953874588013, embedding dim 128, hidden size 4, num layers 1, train loss 0.5044764876365662, validation loss 0.978147029876709\n",
      "Epoch 670, current patience 19, model mean validation loss 0.994067907333374, embedding dim 128, hidden size 4, num layers 1, train loss 0.605122447013855, validation loss 1.0062925815582275\n",
      "Epoch 680, current patience 18, model mean validation loss 1.0014686584472656, embedding dim 128, hidden size 4, num layers 1, train loss 0.6860233545303345, validation loss 1.022767186164856\n",
      "Epoch 690, current patience 17, model mean validation loss 1.008175015449524, embedding dim 128, hidden size 4, num layers 1, train loss 0.643378496170044, validation loss 1.027374029159546\n",
      "Epoch 700, current patience 16, model mean validation loss 1.0135036706924438, embedding dim 128, hidden size 4, num layers 1, train loss 0.7496150135993958, validation loss 1.0453088283538818\n",
      "Epoch 710, current patience 15, model mean validation loss 1.018169641494751, embedding dim 128, hidden size 4, num layers 1, train loss 0.5719903707504272, validation loss 1.0323306322097778\n",
      "Epoch 720, current patience 14, model mean validation loss 1.0177853107452393, embedding dim 128, hidden size 4, num layers 1, train loss 0.6760761737823486, validation loss 1.0239886045455933\n",
      "Epoch 730, current patience 13, model mean validation loss 1.0198768377304077, embedding dim 128, hidden size 4, num layers 1, train loss 0.7177258729934692, validation loss 1.0228055715560913\n",
      "Epoch 740, current patience 12, model mean validation loss 1.0225136280059814, embedding dim 128, hidden size 4, num layers 1, train loss 0.5677298307418823, validation loss 0.9992409944534302\n",
      "Epoch 750, current patience 11, model mean validation loss 1.0246410369873047, embedding dim 128, hidden size 4, num layers 1, train loss 0.5614039897918701, validation loss 1.0233128070831299\n",
      "Epoch 760, current patience 10, model mean validation loss 1.0282882452011108, embedding dim 128, hidden size 4, num layers 1, train loss 0.6464431881904602, validation loss 1.051944375038147\n",
      "Epoch 770, current patience 9, model mean validation loss 1.0276625156402588, embedding dim 128, hidden size 4, num layers 1, train loss 0.6015068292617798, validation loss 1.02236807346344\n",
      "Epoch 780, current patience 8, model mean validation loss 1.0259921550750732, embedding dim 128, hidden size 4, num layers 1, train loss 0.4311767816543579, validation loss 1.031945824623108\n",
      "Epoch 790, current patience 7, model mean validation loss 1.0261211395263672, embedding dim 128, hidden size 4, num layers 1, train loss 0.5520226955413818, validation loss 1.0333633422851562\n",
      "Epoch 800, current patience 6, model mean validation loss 1.0239284038543701, embedding dim 128, hidden size 4, num layers 1, train loss 0.5914814472198486, validation loss 1.006446123123169\n",
      "Epoch 810, current patience 5, model mean validation loss 1.02834153175354, embedding dim 128, hidden size 4, num layers 1, train loss 0.5429887175559998, validation loss 1.0581108331680298\n",
      "Epoch 820, current patience 4, model mean validation loss 1.0343295335769653, embedding dim 128, hidden size 4, num layers 1, train loss 0.5760918855667114, validation loss 1.047145128250122\n",
      "Epoch 830, current patience 3, model mean validation loss 1.0408905744552612, embedding dim 128, hidden size 4, num layers 1, train loss 0.4939034581184387, validation loss 1.0758006572723389\n",
      "Epoch 840, current patience 2, model mean validation loss 1.03951096534729, embedding dim 128, hidden size 4, num layers 1, train loss 0.5642406940460205, validation loss 1.0409071445465088\n",
      "Epoch 850, current patience 1, model mean validation loss 1.0384979248046875, embedding dim 128, hidden size 4, num layers 1, train loss 0.4179687201976776, validation loss 1.0142641067504883\n",
      "Epoch 0, current patience 30, model mean validation loss 1.138089895248413, embedding dim 128, hidden size 8, num layers 1, train loss 1.1514636278152466, validation loss 1.138089895248413\n",
      "Epoch 10, current patience 30, model mean validation loss 1.118269681930542, embedding dim 128, hidden size 8, num layers 1, train loss 1.0993735790252686, validation loss 1.0984495878219604\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1099849939346313, embedding dim 128, hidden size 8, num layers 1, train loss 1.111040472984314, validation loss 1.0934157371520996\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1057602167129517, embedding dim 128, hidden size 8, num layers 1, train loss 1.088172435760498, validation loss 1.0930856466293335\n",
      "Epoch 40, current patience 30, model mean validation loss 1.102916955947876, embedding dim 128, hidden size 8, num layers 1, train loss 1.0764167308807373, validation loss 1.091543436050415\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0997755527496338, embedding dim 128, hidden size 8, num layers 1, train loss 1.0634574890136719, validation loss 1.084068775177002\n",
      "Epoch 60, current patience 30, model mean validation loss 1.097499966621399, embedding dim 128, hidden size 8, num layers 1, train loss 1.0738719701766968, validation loss 1.0838464498519897\n",
      "Epoch 70, current patience 30, model mean validation loss 1.092271089553833, embedding dim 128, hidden size 8, num layers 1, train loss 0.9450458288192749, validation loss 1.0556684732437134\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0780385732650757, embedding dim 128, hidden size 8, num layers 1, train loss 1.046962022781372, validation loss 1.0242304801940918\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0673210620880127, embedding dim 128, hidden size 8, num layers 1, train loss 0.9339365363121033, validation loss 1.0127085447311401\n",
      "Epoch 100, current patience 30, model mean validation loss 1.055760145187378, embedding dim 128, hidden size 8, num layers 1, train loss 0.8489043116569519, validation loss 1.0009286403656006\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0429552793502808, embedding dim 128, hidden size 8, num layers 1, train loss 0.9848921298980713, validation loss 0.9906476736068726\n",
      "Epoch 120, current patience 30, model mean validation loss 1.025914192199707, embedding dim 128, hidden size 8, num layers 1, train loss 0.853498637676239, validation loss 0.9552141427993774\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0110243558883667, embedding dim 128, hidden size 8, num layers 1, train loss 0.7565709352493286, validation loss 0.964950680732727\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9905908107757568, embedding dim 128, hidden size 8, num layers 1, train loss 0.8999695777893066, validation loss 0.9203779697418213\n",
      "Epoch 150, current patience 30, model mean validation loss 0.975187361240387, embedding dim 128, hidden size 8, num layers 1, train loss 0.8329315781593323, validation loss 0.9324407577514648\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9600234031677246, embedding dim 128, hidden size 8, num layers 1, train loss 0.8402766585350037, validation loss 0.902918815612793\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9459108114242554, embedding dim 128, hidden size 8, num layers 1, train loss 0.7352820634841919, validation loss 0.8998078107833862\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9313579797744751, embedding dim 128, hidden size 8, num layers 1, train loss 0.8117895722389221, validation loss 0.8845061659812927\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9185887575149536, embedding dim 128, hidden size 8, num layers 1, train loss 0.928648054599762, validation loss 0.8884932994842529\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9109750986099243, embedding dim 128, hidden size 8, num layers 1, train loss 0.6445654034614563, validation loss 0.8943052291870117\n",
      "Epoch 210, current patience 30, model mean validation loss 0.902330756187439, embedding dim 128, hidden size 8, num layers 1, train loss 0.6541311144828796, validation loss 0.8957961797714233\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8969514966011047, embedding dim 128, hidden size 8, num layers 1, train loss 0.8289492130279541, validation loss 0.8773437142372131\n",
      "Epoch 230, current patience 30, model mean validation loss 0.889689564704895, embedding dim 128, hidden size 8, num layers 1, train loss 0.7123390436172485, validation loss 0.8743449449539185\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8872913122177124, embedding dim 128, hidden size 8, num layers 1, train loss 0.8023536205291748, validation loss 0.8837333917617798\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8797591924667358, embedding dim 128, hidden size 8, num layers 1, train loss 0.6969815492630005, validation loss 0.8395504355430603\n",
      "Epoch 260, current patience 30, model mean validation loss 0.878078818321228, embedding dim 128, hidden size 8, num layers 1, train loss 0.5992670059204102, validation loss 0.8710635900497437\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8757057785987854, embedding dim 128, hidden size 8, num layers 1, train loss 0.5357407331466675, validation loss 0.8695085048675537\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8762975931167603, embedding dim 128, hidden size 8, num layers 1, train loss 0.8259170055389404, validation loss 0.8990402221679688\n",
      "Epoch 290, current patience 29, model mean validation loss 0.875145673751831, embedding dim 128, hidden size 8, num layers 1, train loss 0.5950124859809875, validation loss 0.8865805864334106\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8735496997833252, embedding dim 128, hidden size 8, num layers 1, train loss 0.48820072412490845, validation loss 0.8645759224891663\n",
      "Epoch 310, current patience 30, model mean validation loss 0.879430890083313, embedding dim 128, hidden size 8, num layers 1, train loss 0.6038600206375122, validation loss 0.9213947057723999\n",
      "Epoch 320, current patience 29, model mean validation loss 0.8802751898765564, embedding dim 128, hidden size 8, num layers 1, train loss 0.577421247959137, validation loss 0.890487790107727\n",
      "Epoch 330, current patience 28, model mean validation loss 0.8897110223770142, embedding dim 128, hidden size 8, num layers 1, train loss 0.6109226942062378, validation loss 0.9150367379188538\n",
      "Epoch 340, current patience 27, model mean validation loss 0.8866865634918213, embedding dim 128, hidden size 8, num layers 1, train loss 0.531646192073822, validation loss 0.8468679189682007\n",
      "Epoch 350, current patience 26, model mean validation loss 0.8907103538513184, embedding dim 128, hidden size 8, num layers 1, train loss 0.9521933794021606, validation loss 0.901698648929596\n",
      "Epoch 360, current patience 25, model mean validation loss 0.8914921283721924, embedding dim 128, hidden size 8, num layers 1, train loss 0.617196798324585, validation loss 0.9052945375442505\n",
      "Epoch 370, current patience 24, model mean validation loss 0.8958150148391724, embedding dim 128, hidden size 8, num layers 1, train loss 0.38826510310173035, validation loss 0.9211639165878296\n",
      "Epoch 380, current patience 23, model mean validation loss 0.8973780870437622, embedding dim 128, hidden size 8, num layers 1, train loss 0.6141698360443115, validation loss 0.877080500125885\n",
      "Epoch 390, current patience 22, model mean validation loss 0.9022321701049805, embedding dim 128, hidden size 8, num layers 1, train loss 0.7270922660827637, validation loss 0.9602274298667908\n",
      "Epoch 400, current patience 21, model mean validation loss 0.9079087972640991, embedding dim 128, hidden size 8, num layers 1, train loss 0.43621766567230225, validation loss 0.9359003305435181\n",
      "Epoch 410, current patience 20, model mean validation loss 0.9185931086540222, embedding dim 128, hidden size 8, num layers 1, train loss 0.48386484384536743, validation loss 1.0005114078521729\n",
      "Epoch 420, current patience 19, model mean validation loss 0.9240601062774658, embedding dim 128, hidden size 8, num layers 1, train loss 0.5656747221946716, validation loss 0.8906041383743286\n",
      "Epoch 430, current patience 18, model mean validation loss 0.9275248646736145, embedding dim 128, hidden size 8, num layers 1, train loss 0.5533493757247925, validation loss 0.9294166564941406\n",
      "Epoch 440, current patience 17, model mean validation loss 0.9413594007492065, embedding dim 128, hidden size 8, num layers 1, train loss 0.41328173875808716, validation loss 1.0159708261489868\n",
      "Epoch 450, current patience 16, model mean validation loss 0.9404155015945435, embedding dim 128, hidden size 8, num layers 1, train loss 0.6438908576965332, validation loss 0.9136127233505249\n",
      "Epoch 460, current patience 15, model mean validation loss 0.9487288594245911, embedding dim 128, hidden size 8, num layers 1, train loss 0.6773189306259155, validation loss 0.943587064743042\n",
      "Epoch 470, current patience 14, model mean validation loss 0.946372389793396, embedding dim 128, hidden size 8, num layers 1, train loss 0.6056743860244751, validation loss 0.9413759112358093\n",
      "Epoch 480, current patience 13, model mean validation loss 0.939162015914917, embedding dim 128, hidden size 8, num layers 1, train loss 0.4797884225845337, validation loss 0.8782169222831726\n",
      "Epoch 490, current patience 12, model mean validation loss 0.9317874908447266, embedding dim 128, hidden size 8, num layers 1, train loss 0.5604771971702576, validation loss 0.9415156841278076\n",
      "Epoch 500, current patience 11, model mean validation loss 0.934808611869812, embedding dim 128, hidden size 8, num layers 1, train loss 0.40782076120376587, validation loss 0.9147729873657227\n",
      "Epoch 510, current patience 10, model mean validation loss 0.9380923509597778, embedding dim 128, hidden size 8, num layers 1, train loss 0.6601893901824951, validation loss 0.9556864500045776\n",
      "Epoch 520, current patience 9, model mean validation loss 0.9245772361755371, embedding dim 128, hidden size 8, num layers 1, train loss 0.4410046935081482, validation loss 0.9078497886657715\n",
      "Epoch 530, current patience 8, model mean validation loss 0.92649906873703, embedding dim 128, hidden size 8, num layers 1, train loss 0.5659366846084595, validation loss 0.9289878010749817\n",
      "Epoch 540, current patience 7, model mean validation loss 0.9182762503623962, embedding dim 128, hidden size 8, num layers 1, train loss 0.41639387607574463, validation loss 0.8778043985366821\n",
      "Epoch 550, current patience 6, model mean validation loss 0.9191651344299316, embedding dim 128, hidden size 8, num layers 1, train loss 0.35867059230804443, validation loss 0.9484868049621582\n",
      "Epoch 560, current patience 5, model mean validation loss 0.9279630184173584, embedding dim 128, hidden size 8, num layers 1, train loss 0.3427250385284424, validation loss 0.9486004710197449\n",
      "Epoch 570, current patience 4, model mean validation loss 0.9263783693313599, embedding dim 128, hidden size 8, num layers 1, train loss 0.6384366750717163, validation loss 0.9288383722305298\n",
      "Epoch 580, current patience 3, model mean validation loss 0.9301050901412964, embedding dim 128, hidden size 8, num layers 1, train loss 0.42916813492774963, validation loss 0.9445868134498596\n",
      "Epoch 590, current patience 2, model mean validation loss 0.9289546608924866, embedding dim 128, hidden size 8, num layers 1, train loss 0.4849863052368164, validation loss 0.94648277759552\n",
      "Epoch 600, current patience 1, model mean validation loss 0.9371988773345947, embedding dim 128, hidden size 8, num layers 1, train loss 0.601401686668396, validation loss 0.9738034009933472\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1073534488677979, embedding dim 128, hidden size 16, num layers 1, train loss 1.1090857982635498, validation loss 1.1073534488677979\n",
      "Epoch 10, current patience 30, model mean validation loss 1.098134994506836, embedding dim 128, hidden size 16, num layers 1, train loss 1.088435173034668, validation loss 1.0889164209365845\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0975021123886108, embedding dim 128, hidden size 16, num layers 1, train loss 1.0959722995758057, validation loss 1.0962363481521606\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0964677333831787, embedding dim 128, hidden size 16, num layers 1, train loss 1.0913586616516113, validation loss 1.093364953994751\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0956274271011353, embedding dim 128, hidden size 16, num layers 1, train loss 1.0813446044921875, validation loss 1.092266321182251\n",
      "Epoch 50, current patience 30, model mean validation loss 1.092795968055725, embedding dim 128, hidden size 16, num layers 1, train loss 1.0263584852218628, validation loss 1.0786385536193848\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0872188806533813, embedding dim 128, hidden size 16, num layers 1, train loss 1.0485608577728271, validation loss 1.0537554025650024\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0780866146087646, embedding dim 128, hidden size 16, num layers 1, train loss 1.0777313709259033, validation loss 1.0141620635986328\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0666234493255615, embedding dim 128, hidden size 16, num layers 1, train loss 0.9895986318588257, validation loss 1.015647053718567\n",
      "Epoch 90, current patience 30, model mean validation loss 1.055891513824463, embedding dim 128, hidden size 16, num layers 1, train loss 1.0014411211013794, validation loss 1.0030617713928223\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0371413230895996, embedding dim 128, hidden size 16, num layers 1, train loss 0.9049845337867737, validation loss 0.9462345838546753\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0179883241653442, embedding dim 128, hidden size 16, num layers 1, train loss 0.7907099723815918, validation loss 0.9401404857635498\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0044727325439453, embedding dim 128, hidden size 16, num layers 1, train loss 0.7892892360687256, validation loss 0.9841421842575073\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9815943241119385, embedding dim 128, hidden size 16, num layers 1, train loss 0.8887616395950317, validation loss 0.8956114649772644\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9667987823486328, embedding dim 128, hidden size 16, num layers 1, train loss 0.9813615679740906, validation loss 0.9353903532028198\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9496254920959473, embedding dim 128, hidden size 16, num layers 1, train loss 0.8980921506881714, validation loss 0.8767756819725037\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9310505986213684, embedding dim 128, hidden size 16, num layers 1, train loss 0.8969640135765076, validation loss 0.8670480251312256\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9156613349914551, embedding dim 128, hidden size 16, num layers 1, train loss 0.650722324848175, validation loss 0.8799477815628052\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9061239957809448, embedding dim 128, hidden size 16, num layers 1, train loss 0.7704632878303528, validation loss 0.8699361085891724\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8986165523529053, embedding dim 128, hidden size 16, num layers 1, train loss 0.6291108131408691, validation loss 0.8800809383392334\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8843986988067627, embedding dim 128, hidden size 16, num layers 1, train loss 0.9558029174804688, validation loss 0.8703991770744324\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8791227340698242, embedding dim 128, hidden size 16, num layers 1, train loss 0.5474026203155518, validation loss 0.8534041047096252\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8653126955032349, embedding dim 128, hidden size 16, num layers 1, train loss 0.8644124269485474, validation loss 0.8249098658561707\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8662062883377075, embedding dim 128, hidden size 16, num layers 1, train loss 0.6350398063659668, validation loss 0.8839240074157715\n",
      "Epoch 240, current patience 29, model mean validation loss 0.8658559918403625, embedding dim 128, hidden size 16, num layers 1, train loss 0.6738029718399048, validation loss 0.8642461895942688\n",
      "Epoch 250, current patience 28, model mean validation loss 0.8638148903846741, embedding dim 128, hidden size 16, num layers 1, train loss 0.6621792316436768, validation loss 0.8636187314987183\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8604022264480591, embedding dim 128, hidden size 16, num layers 1, train loss 0.8206576108932495, validation loss 0.8426343202590942\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8555695414543152, embedding dim 128, hidden size 16, num layers 1, train loss 0.5166645050048828, validation loss 0.84142005443573\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8493209481239319, embedding dim 128, hidden size 16, num layers 1, train loss 0.5813882350921631, validation loss 0.8204103708267212\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8462153077125549, embedding dim 128, hidden size 16, num layers 1, train loss 0.4823904037475586, validation loss 0.8285590410232544\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8611271381378174, embedding dim 128, hidden size 16, num layers 1, train loss 0.5049501657485962, validation loss 0.9442040324211121\n",
      "Epoch 310, current patience 29, model mean validation loss 0.8602034449577332, embedding dim 128, hidden size 16, num layers 1, train loss 0.6719392538070679, validation loss 0.8765350580215454\n",
      "Epoch 320, current patience 28, model mean validation loss 0.8627701997756958, embedding dim 128, hidden size 16, num layers 1, train loss 0.4602208733558655, validation loss 0.8847803473472595\n",
      "Epoch 330, current patience 27, model mean validation loss 0.8605477213859558, embedding dim 128, hidden size 16, num layers 1, train loss 0.5609396696090698, validation loss 0.8458387851715088\n",
      "Epoch 340, current patience 26, model mean validation loss 0.8722724914550781, embedding dim 128, hidden size 16, num layers 1, train loss 0.41678178310394287, validation loss 0.936431884765625\n",
      "Epoch 350, current patience 25, model mean validation loss 0.8774287104606628, embedding dim 128, hidden size 16, num layers 1, train loss 0.3001254200935364, validation loss 0.8826703429222107\n",
      "Epoch 360, current patience 24, model mean validation loss 0.8906275629997253, embedding dim 128, hidden size 16, num layers 1, train loss 0.3854198455810547, validation loss 0.926001250743866\n",
      "Epoch 370, current patience 23, model mean validation loss 0.8967751264572144, embedding dim 128, hidden size 16, num layers 1, train loss 0.5060590505599976, validation loss 0.877739429473877\n",
      "Epoch 380, current patience 22, model mean validation loss 0.8907344341278076, embedding dim 128, hidden size 16, num layers 1, train loss 0.3866744637489319, validation loss 0.8958787322044373\n",
      "Epoch 390, current patience 21, model mean validation loss 0.8942243456840515, embedding dim 128, hidden size 16, num layers 1, train loss 0.3670269250869751, validation loss 0.9044538736343384\n",
      "Epoch 400, current patience 20, model mean validation loss 0.8985085487365723, embedding dim 128, hidden size 16, num layers 1, train loss 0.8562917709350586, validation loss 0.9190540313720703\n",
      "Epoch 410, current patience 19, model mean validation loss 0.9025513529777527, embedding dim 128, hidden size 16, num layers 1, train loss 0.34880778193473816, validation loss 0.8781813979148865\n",
      "Epoch 420, current patience 18, model mean validation loss 0.9021511077880859, embedding dim 128, hidden size 16, num layers 1, train loss 0.3642148971557617, validation loss 0.9332292079925537\n",
      "Epoch 430, current patience 17, model mean validation loss 0.9147579669952393, embedding dim 128, hidden size 16, num layers 1, train loss 0.624980092048645, validation loss 0.983525812625885\n",
      "Epoch 440, current patience 16, model mean validation loss 0.915326714515686, embedding dim 128, hidden size 16, num layers 1, train loss 0.2776434123516083, validation loss 0.9305508732795715\n",
      "Epoch 450, current patience 15, model mean validation loss 0.9198607206344604, embedding dim 128, hidden size 16, num layers 1, train loss 0.3281612992286682, validation loss 0.9140117764472961\n",
      "Epoch 460, current patience 14, model mean validation loss 0.9311016201972961, embedding dim 128, hidden size 16, num layers 1, train loss 0.35531085729599, validation loss 0.9858063459396362\n",
      "Epoch 470, current patience 13, model mean validation loss 0.9336577653884888, embedding dim 128, hidden size 16, num layers 1, train loss 0.4783112406730652, validation loss 0.9249027967453003\n",
      "Epoch 480, current patience 12, model mean validation loss 0.9350989460945129, embedding dim 128, hidden size 16, num layers 1, train loss 0.5490277409553528, validation loss 0.9305832982063293\n",
      "Epoch 490, current patience 11, model mean validation loss 0.9319605827331543, embedding dim 128, hidden size 16, num layers 1, train loss 0.29475560784339905, validation loss 0.853074848651886\n",
      "Epoch 500, current patience 10, model mean validation loss 0.9336448311805725, embedding dim 128, hidden size 16, num layers 1, train loss 0.6024136543273926, validation loss 0.9467029571533203\n",
      "Epoch 510, current patience 9, model mean validation loss 0.9210200309753418, embedding dim 128, hidden size 16, num layers 1, train loss 0.38551217317581177, validation loss 0.8825274705886841\n",
      "Epoch 520, current patience 8, model mean validation loss 0.9194422364234924, embedding dim 128, hidden size 16, num layers 1, train loss 0.3778613805770874, validation loss 0.9179283380508423\n",
      "Epoch 530, current patience 7, model mean validation loss 0.9360485076904297, embedding dim 128, hidden size 16, num layers 1, train loss 0.3489686846733093, validation loss 1.0468616485595703\n",
      "Epoch 540, current patience 6, model mean validation loss 0.9424540996551514, embedding dim 128, hidden size 16, num layers 1, train loss 0.34211379289627075, validation loss 1.0370509624481201\n",
      "Epoch 550, current patience 5, model mean validation loss 0.960476279258728, embedding dim 128, hidden size 16, num layers 1, train loss 0.37517499923706055, validation loss 1.0690805912017822\n",
      "Epoch 560, current patience 4, model mean validation loss 0.9610735177993774, embedding dim 128, hidden size 16, num layers 1, train loss 0.4988117218017578, validation loss 0.9353615045547485\n",
      "Epoch 570, current patience 3, model mean validation loss 0.9709780216217041, embedding dim 128, hidden size 16, num layers 1, train loss 0.2320839762687683, validation loss 0.9323110580444336\n",
      "Epoch 580, current patience 2, model mean validation loss 0.97044837474823, embedding dim 128, hidden size 16, num layers 1, train loss 0.8471235632896423, validation loss 0.9424653053283691\n",
      "Epoch 590, current patience 1, model mean validation loss 0.9887900948524475, embedding dim 128, hidden size 16, num layers 1, train loss 0.43010270595550537, validation loss 1.0292614698410034\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0992610454559326, embedding dim 128, hidden size 32, num layers 1, train loss 1.0995891094207764, validation loss 1.0992610454559326\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0963904857635498, embedding dim 128, hidden size 32, num layers 1, train loss 1.1201069355010986, validation loss 1.0935198068618774\n",
      "Epoch 20, current patience 30, model mean validation loss 1.094789743423462, embedding dim 128, hidden size 32, num layers 1, train loss 1.08367919921875, validation loss 1.0915882587432861\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0844793319702148, embedding dim 128, hidden size 32, num layers 1, train loss 1.0504915714263916, validation loss 1.0535478591918945\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0733076333999634, embedding dim 128, hidden size 32, num layers 1, train loss 1.0330969095230103, validation loss 1.0286214351654053\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0609005689620972, embedding dim 128, hidden size 32, num layers 1, train loss 0.9865919351577759, validation loss 0.9988644123077393\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0461846590042114, embedding dim 128, hidden size 32, num layers 1, train loss 0.8818819522857666, validation loss 0.9578894376754761\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0421621799468994, embedding dim 128, hidden size 32, num layers 1, train loss 0.8711589574813843, validation loss 1.0140048265457153\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0300071239471436, embedding dim 128, hidden size 32, num layers 1, train loss 0.8506420254707336, validation loss 1.002021312713623\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0123323202133179, embedding dim 128, hidden size 32, num layers 1, train loss 1.0054614543914795, validation loss 0.952121376991272\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9942293167114258, embedding dim 128, hidden size 32, num layers 1, train loss 0.8881794214248657, validation loss 0.9467640519142151\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9853346347808838, embedding dim 128, hidden size 32, num layers 1, train loss 0.9894792437553406, validation loss 0.9823901653289795\n",
      "Epoch 120, current patience 30, model mean validation loss 0.97002112865448, embedding dim 128, hidden size 32, num layers 1, train loss 0.9540058970451355, validation loss 0.9061132669448853\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9558789730072021, embedding dim 128, hidden size 32, num layers 1, train loss 0.6638067960739136, validation loss 0.8857274055480957\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9470071792602539, embedding dim 128, hidden size 32, num layers 1, train loss 0.8946437835693359, validation loss 0.8869153261184692\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9285770654678345, embedding dim 128, hidden size 32, num layers 1, train loss 0.8114557266235352, validation loss 0.8665634393692017\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9129863977432251, embedding dim 128, hidden size 32, num layers 1, train loss 0.8218079805374146, validation loss 0.8772959113121033\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9011595845222473, embedding dim 128, hidden size 32, num layers 1, train loss 0.6633636951446533, validation loss 0.8575073480606079\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8860635757446289, embedding dim 128, hidden size 32, num layers 1, train loss 0.6367278099060059, validation loss 0.8259960412979126\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8676537275314331, embedding dim 128, hidden size 32, num layers 1, train loss 0.8736569285392761, validation loss 0.8351110219955444\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8599355220794678, embedding dim 128, hidden size 32, num layers 1, train loss 0.8713299036026001, validation loss 0.8443676233291626\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8482162356376648, embedding dim 128, hidden size 32, num layers 1, train loss 0.5265908241271973, validation loss 0.7919731140136719\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8384020328521729, embedding dim 128, hidden size 32, num layers 1, train loss 0.685143232345581, validation loss 0.8084019422531128\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8295051455497742, embedding dim 128, hidden size 32, num layers 1, train loss 0.7007083296775818, validation loss 0.7953884601593018\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8202121257781982, embedding dim 128, hidden size 32, num layers 1, train loss 0.43503880500793457, validation loss 0.8029517531394958\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8183490037918091, embedding dim 128, hidden size 32, num layers 1, train loss 0.52781742811203, validation loss 0.842602550983429\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8190915584564209, embedding dim 128, hidden size 32, num layers 1, train loss 0.43780070543289185, validation loss 0.8319360613822937\n",
      "Epoch 270, current patience 29, model mean validation loss 0.8204361200332642, embedding dim 128, hidden size 32, num layers 1, train loss 0.5451432466506958, validation loss 0.8458680510520935\n",
      "Epoch 280, current patience 28, model mean validation loss 0.8147909641265869, embedding dim 128, hidden size 32, num layers 1, train loss 0.8707360029220581, validation loss 0.7992057204246521\n",
      "Epoch 290, current patience 30, model mean validation loss 0.8140411972999573, embedding dim 128, hidden size 32, num layers 1, train loss 0.5577210187911987, validation loss 0.7859752178192139\n",
      "Epoch 300, current patience 30, model mean validation loss 0.8142508268356323, embedding dim 128, hidden size 32, num layers 1, train loss 0.5077292919158936, validation loss 0.8100786209106445\n",
      "Epoch 310, current patience 29, model mean validation loss 0.8218608498573303, embedding dim 128, hidden size 32, num layers 1, train loss 0.5209611654281616, validation loss 0.8562685251235962\n",
      "Epoch 320, current patience 28, model mean validation loss 0.8238321542739868, embedding dim 128, hidden size 32, num layers 1, train loss 0.578270673751831, validation loss 0.8187227249145508\n",
      "Epoch 330, current patience 27, model mean validation loss 0.8236550092697144, embedding dim 128, hidden size 32, num layers 1, train loss 0.5495988130569458, validation loss 0.8411847949028015\n",
      "Epoch 340, current patience 26, model mean validation loss 0.8265848755836487, embedding dim 128, hidden size 32, num layers 1, train loss 0.36143702268600464, validation loss 0.8553752899169922\n",
      "Epoch 350, current patience 25, model mean validation loss 0.8250276446342468, embedding dim 128, hidden size 32, num layers 1, train loss 0.3521810472011566, validation loss 0.8334102630615234\n",
      "Epoch 360, current patience 24, model mean validation loss 0.8292769193649292, embedding dim 128, hidden size 32, num layers 1, train loss 0.5553045868873596, validation loss 0.8331997394561768\n",
      "Epoch 370, current patience 23, model mean validation loss 0.8320229053497314, embedding dim 128, hidden size 32, num layers 1, train loss 0.4350281357765198, validation loss 0.8079431653022766\n",
      "Epoch 380, current patience 22, model mean validation loss 0.8270787000656128, embedding dim 128, hidden size 32, num layers 1, train loss 0.41403937339782715, validation loss 0.7705252170562744\n",
      "Epoch 390, current patience 21, model mean validation loss 0.8235892057418823, embedding dim 128, hidden size 32, num layers 1, train loss 0.42450785636901855, validation loss 0.8283525705337524\n",
      "Epoch 400, current patience 20, model mean validation loss 0.8251880407333374, embedding dim 128, hidden size 32, num layers 1, train loss 0.5643905401229858, validation loss 0.8315128684043884\n",
      "Epoch 410, current patience 19, model mean validation loss 0.8245147466659546, embedding dim 128, hidden size 32, num layers 1, train loss 0.44201093912124634, validation loss 0.8357985019683838\n",
      "Epoch 420, current patience 18, model mean validation loss 0.8296111226081848, embedding dim 128, hidden size 32, num layers 1, train loss 0.4924052953720093, validation loss 0.8961465358734131\n",
      "Epoch 430, current patience 17, model mean validation loss 0.8248313665390015, embedding dim 128, hidden size 32, num layers 1, train loss 0.5034208297729492, validation loss 0.7951722145080566\n",
      "Epoch 440, current patience 16, model mean validation loss 0.8246619701385498, embedding dim 128, hidden size 32, num layers 1, train loss 0.6240461468696594, validation loss 0.8318449258804321\n",
      "Epoch 450, current patience 15, model mean validation loss 0.8384513854980469, embedding dim 128, hidden size 32, num layers 1, train loss 0.49061810970306396, validation loss 0.9182581901550293\n",
      "Epoch 460, current patience 14, model mean validation loss 0.8537569642066956, embedding dim 128, hidden size 32, num layers 1, train loss 0.39181363582611084, validation loss 0.8929699063301086\n",
      "Epoch 470, current patience 13, model mean validation loss 0.866089940071106, embedding dim 128, hidden size 32, num layers 1, train loss 0.4110212028026581, validation loss 0.9270167946815491\n",
      "Epoch 480, current patience 12, model mean validation loss 0.8729981184005737, embedding dim 128, hidden size 32, num layers 1, train loss 0.38256603479385376, validation loss 0.8867779970169067\n",
      "Epoch 490, current patience 11, model mean validation loss 0.8857088088989258, embedding dim 128, hidden size 32, num layers 1, train loss 0.29907548427581787, validation loss 0.9374842047691345\n",
      "Epoch 500, current patience 10, model mean validation loss 0.8793182969093323, embedding dim 128, hidden size 32, num layers 1, train loss 0.33705413341522217, validation loss 0.8450218439102173\n",
      "Epoch 510, current patience 9, model mean validation loss 0.8927978277206421, embedding dim 128, hidden size 32, num layers 1, train loss 0.7223032116889954, validation loss 0.9030091762542725\n",
      "Epoch 520, current patience 8, model mean validation loss 0.9095982313156128, embedding dim 128, hidden size 32, num layers 1, train loss 0.5287502408027649, validation loss 0.9662473201751709\n",
      "Epoch 530, current patience 7, model mean validation loss 0.9063572883605957, embedding dim 128, hidden size 32, num layers 1, train loss 0.22048218548297882, validation loss 0.8923314809799194\n",
      "Epoch 540, current patience 6, model mean validation loss 0.9107905626296997, embedding dim 128, hidden size 32, num layers 1, train loss 0.30444151163101196, validation loss 0.9284356832504272\n",
      "Epoch 550, current patience 5, model mean validation loss 0.9104834794998169, embedding dim 128, hidden size 32, num layers 1, train loss 0.1495429426431656, validation loss 0.924560546875\n",
      "Epoch 560, current patience 4, model mean validation loss 0.9229335784912109, embedding dim 128, hidden size 32, num layers 1, train loss 0.36573243141174316, validation loss 0.9863786697387695\n",
      "Epoch 570, current patience 3, model mean validation loss 0.9252134561538696, embedding dim 128, hidden size 32, num layers 1, train loss 0.42161738872528076, validation loss 0.9557229280471802\n",
      "Epoch 580, current patience 2, model mean validation loss 0.9369864463806152, embedding dim 128, hidden size 32, num layers 1, train loss 0.19869714975357056, validation loss 0.9392060041427612\n",
      "Epoch 590, current patience 1, model mean validation loss 0.9420278072357178, embedding dim 128, hidden size 32, num layers 1, train loss 0.5609173774719238, validation loss 0.9433396458625793\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0957386493682861, embedding dim 128, hidden size 64, num layers 1, train loss 1.0992696285247803, validation loss 1.0957386493682861\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0947011709213257, embedding dim 128, hidden size 64, num layers 1, train loss 1.1071431636810303, validation loss 1.0936636924743652\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0881296396255493, embedding dim 128, hidden size 64, num layers 1, train loss 1.108015537261963, validation loss 1.074986457824707\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0860469341278076, embedding dim 128, hidden size 64, num layers 1, train loss 1.1011276245117188, validation loss 1.079798936843872\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0826759338378906, embedding dim 128, hidden size 64, num layers 1, train loss 1.0660510063171387, validation loss 1.0691924095153809\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0704857110977173, embedding dim 128, hidden size 64, num layers 1, train loss 0.9515156745910645, validation loss 1.009534478187561\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0581161975860596, embedding dim 128, hidden size 64, num layers 1, train loss 1.0655304193496704, validation loss 0.9838992953300476\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0432934761047363, embedding dim 128, hidden size 64, num layers 1, train loss 0.9384943842887878, validation loss 0.9395339488983154\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0174332857131958, embedding dim 128, hidden size 64, num layers 1, train loss 0.7928755879402161, validation loss 0.8888571262359619\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9885103106498718, embedding dim 128, hidden size 64, num layers 1, train loss 0.8722796440124512, validation loss 0.8622797131538391\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9591091871261597, embedding dim 128, hidden size 64, num layers 1, train loss 0.6725460290908813, validation loss 0.8397775292396545\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9283336400985718, embedding dim 128, hidden size 64, num layers 1, train loss 0.7146044969558716, validation loss 0.8335948586463928\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8986890316009521, embedding dim 128, hidden size 64, num layers 1, train loss 0.6322887539863586, validation loss 0.8320356011390686\n",
      "Epoch 130, current patience 30, model mean validation loss 0.87742018699646, embedding dim 128, hidden size 64, num layers 1, train loss 0.8158849477767944, validation loss 0.8393833041191101\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8580542802810669, embedding dim 128, hidden size 64, num layers 1, train loss 0.6775213479995728, validation loss 0.8289724588394165\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8413841128349304, embedding dim 128, hidden size 64, num layers 1, train loss 0.844526469707489, validation loss 0.806172251701355\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8290429711341858, embedding dim 128, hidden size 64, num layers 1, train loss 0.5555338263511658, validation loss 0.7901277542114258\n",
      "Epoch 170, current patience 30, model mean validation loss 0.819083571434021, embedding dim 128, hidden size 64, num layers 1, train loss 0.6899731755256653, validation loss 0.7826046943664551\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8102188110351562, embedding dim 128, hidden size 64, num layers 1, train loss 0.6478807330131531, validation loss 0.7688590288162231\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8018302917480469, embedding dim 128, hidden size 64, num layers 1, train loss 0.5256402492523193, validation loss 0.7664869427680969\n",
      "Epoch 200, current patience 30, model mean validation loss 0.796647846698761, embedding dim 128, hidden size 64, num layers 1, train loss 0.9558262825012207, validation loss 0.7905765771865845\n",
      "Epoch 210, current patience 30, model mean validation loss 0.7848547697067261, embedding dim 128, hidden size 64, num layers 1, train loss 0.8197247385978699, validation loss 0.7450387477874756\n",
      "Epoch 220, current patience 30, model mean validation loss 0.7780702710151672, embedding dim 128, hidden size 64, num layers 1, train loss 0.9036432504653931, validation loss 0.774695634841919\n",
      "Epoch 230, current patience 30, model mean validation loss 0.7748146057128906, embedding dim 128, hidden size 64, num layers 1, train loss 0.6087599396705627, validation loss 0.7801269292831421\n",
      "Epoch 240, current patience 30, model mean validation loss 0.765936553478241, embedding dim 128, hidden size 64, num layers 1, train loss 0.5707901120185852, validation loss 0.7191036939620972\n",
      "Epoch 250, current patience 30, model mean validation loss 0.7588182687759399, embedding dim 128, hidden size 64, num layers 1, train loss 0.7797237634658813, validation loss 0.7256583571434021\n",
      "Epoch 260, current patience 30, model mean validation loss 0.75960373878479, embedding dim 128, hidden size 64, num layers 1, train loss 0.6355816125869751, validation loss 0.7751426696777344\n",
      "Epoch 270, current patience 29, model mean validation loss 0.7584179043769836, embedding dim 128, hidden size 64, num layers 1, train loss 0.3925982713699341, validation loss 0.7570005655288696\n",
      "Epoch 280, current patience 30, model mean validation loss 0.7554287910461426, embedding dim 128, hidden size 64, num layers 1, train loss 0.5910900831222534, validation loss 0.7666633725166321\n",
      "Epoch 290, current patience 30, model mean validation loss 0.761737585067749, embedding dim 128, hidden size 64, num layers 1, train loss 0.33513450622558594, validation loss 0.7955092787742615\n",
      "Epoch 300, current patience 29, model mean validation loss 0.759491503238678, embedding dim 128, hidden size 64, num layers 1, train loss 0.5017110705375671, validation loss 0.7567271590232849\n",
      "Epoch 310, current patience 28, model mean validation loss 0.7576553225517273, embedding dim 128, hidden size 64, num layers 1, train loss 0.4231205880641937, validation loss 0.7654375433921814\n",
      "Epoch 320, current patience 27, model mean validation loss 0.7661949992179871, embedding dim 128, hidden size 64, num layers 1, train loss 0.8469743728637695, validation loss 0.7874209880828857\n",
      "Epoch 330, current patience 26, model mean validation loss 0.7697383761405945, embedding dim 128, hidden size 64, num layers 1, train loss 0.43739569187164307, validation loss 0.7540053725242615\n",
      "Epoch 340, current patience 25, model mean validation loss 0.7697873115539551, embedding dim 128, hidden size 64, num layers 1, train loss 0.4549804627895355, validation loss 0.7755345106124878\n",
      "Epoch 350, current patience 24, model mean validation loss 0.7748226523399353, embedding dim 128, hidden size 64, num layers 1, train loss 0.45277976989746094, validation loss 0.7972832918167114\n",
      "Epoch 360, current patience 23, model mean validation loss 0.772504985332489, embedding dim 128, hidden size 64, num layers 1, train loss 0.6182966232299805, validation loss 0.748121976852417\n",
      "Epoch 370, current patience 22, model mean validation loss 0.7629773616790771, embedding dim 128, hidden size 64, num layers 1, train loss 0.49427101016044617, validation loss 0.7192880511283875\n",
      "Epoch 380, current patience 21, model mean validation loss 0.7647090554237366, embedding dim 128, hidden size 64, num layers 1, train loss 0.45783933997154236, validation loss 0.7705808877944946\n",
      "Epoch 390, current patience 20, model mean validation loss 0.7766283750534058, embedding dim 128, hidden size 64, num layers 1, train loss 0.4526803195476532, validation loss 0.860792338848114\n",
      "Epoch 400, current patience 19, model mean validation loss 0.7796440124511719, embedding dim 128, hidden size 64, num layers 1, train loss 0.37264418601989746, validation loss 0.8115456104278564\n",
      "Epoch 410, current patience 18, model mean validation loss 0.7822767496109009, embedding dim 128, hidden size 64, num layers 1, train loss 0.3534357249736786, validation loss 0.7750673890113831\n",
      "Epoch 420, current patience 17, model mean validation loss 0.7850717306137085, embedding dim 128, hidden size 64, num layers 1, train loss 0.2641383409500122, validation loss 0.7978945970535278\n",
      "Epoch 430, current patience 16, model mean validation loss 0.7856521010398865, embedding dim 128, hidden size 64, num layers 1, train loss 0.3451659381389618, validation loss 0.8019258975982666\n",
      "Epoch 440, current patience 15, model mean validation loss 0.8009347319602966, embedding dim 128, hidden size 64, num layers 1, train loss 0.5901433229446411, validation loss 0.8703830242156982\n",
      "Epoch 450, current patience 14, model mean validation loss 0.8173714876174927, embedding dim 128, hidden size 64, num layers 1, train loss 0.22842159867286682, validation loss 0.8507821559906006\n",
      "Epoch 460, current patience 13, model mean validation loss 0.8254365921020508, embedding dim 128, hidden size 64, num layers 1, train loss 0.4705747961997986, validation loss 0.8351019620895386\n",
      "Epoch 470, current patience 12, model mean validation loss 0.8205264806747437, embedding dim 128, hidden size 64, num layers 1, train loss 0.180143803358078, validation loss 0.8215112090110779\n",
      "Epoch 480, current patience 11, model mean validation loss 0.835231363773346, embedding dim 128, hidden size 64, num layers 1, train loss 0.13273493945598602, validation loss 0.92918461561203\n",
      "Epoch 490, current patience 10, model mean validation loss 0.8497942090034485, embedding dim 128, hidden size 64, num layers 1, train loss 0.44865119457244873, validation loss 0.8915697336196899\n",
      "Epoch 500, current patience 9, model mean validation loss 0.858468770980835, embedding dim 128, hidden size 64, num layers 1, train loss 0.34903717041015625, validation loss 0.8672913908958435\n",
      "Epoch 510, current patience 8, model mean validation loss 0.868887722492218, embedding dim 128, hidden size 64, num layers 1, train loss 0.14172275364398956, validation loss 0.8852773904800415\n",
      "Epoch 520, current patience 7, model mean validation loss 0.8803431391716003, embedding dim 128, hidden size 64, num layers 1, train loss 0.59525066614151, validation loss 0.962026834487915\n",
      "Epoch 530, current patience 6, model mean validation loss 0.8900042772293091, embedding dim 128, hidden size 64, num layers 1, train loss 0.1664799451828003, validation loss 0.9280712008476257\n",
      "Epoch 540, current patience 5, model mean validation loss 0.9041046500205994, embedding dim 128, hidden size 64, num layers 1, train loss 0.23473232984542847, validation loss 0.9479051828384399\n",
      "Epoch 550, current patience 4, model mean validation loss 0.9164049029350281, embedding dim 128, hidden size 64, num layers 1, train loss 0.4841804504394531, validation loss 0.9199132323265076\n",
      "Epoch 560, current patience 3, model mean validation loss 0.9079026579856873, embedding dim 128, hidden size 64, num layers 1, train loss 0.14716115593910217, validation loss 0.86116623878479\n",
      "Epoch 570, current patience 2, model mean validation loss 0.9127988815307617, embedding dim 128, hidden size 64, num layers 1, train loss 0.3116752803325653, validation loss 0.9307395219802856\n",
      "Epoch 580, current patience 1, model mean validation loss 0.9293327927589417, embedding dim 128, hidden size 64, num layers 1, train loss 0.16383318603038788, validation loss 0.9995629787445068\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0930142402648926, embedding dim 128, hidden size 128, num layers 1, train loss 1.0977308750152588, validation loss 1.0930142402648926\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0938680171966553, embedding dim 128, hidden size 128, num layers 1, train loss 1.0965516567230225, validation loss 1.094721794128418\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0880407094955444, embedding dim 128, hidden size 128, num layers 1, train loss 1.0668764114379883, validation loss 1.0763862133026123\n",
      "Epoch 30, current patience 30, model mean validation loss 1.084469199180603, embedding dim 128, hidden size 128, num layers 1, train loss 1.0848971605300903, validation loss 1.0737546682357788\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0843983888626099, embedding dim 128, hidden size 128, num layers 1, train loss 1.045167088508606, validation loss 1.0841151475906372\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0982635021209717, embedding dim 128, hidden size 128, num layers 1, train loss 0.8086690306663513, validation loss 1.1675885915756226\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0844324827194214, embedding dim 128, hidden size 128, num layers 1, train loss 0.9499485492706299, validation loss 1.0014472007751465\n",
      "Epoch 70, current patience 28, model mean validation loss 1.073683500289917, embedding dim 128, hidden size 128, num layers 1, train loss 0.8602452874183655, validation loss 0.9984402060508728\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0547560453414917, embedding dim 128, hidden size 128, num layers 1, train loss 0.7941184043884277, validation loss 0.9415938258171082\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0278518199920654, embedding dim 128, hidden size 128, num layers 1, train loss 0.7435801029205322, validation loss 0.8794881105422974\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0049877166748047, embedding dim 128, hidden size 128, num layers 1, train loss 0.8068134784698486, validation loss 0.8934740424156189\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9764765501022339, embedding dim 128, hidden size 128, num layers 1, train loss 0.691267192363739, validation loss 0.845665693283081\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9450833797454834, embedding dim 128, hidden size 128, num layers 1, train loss 0.895942211151123, validation loss 0.8329692482948303\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9035636186599731, embedding dim 128, hidden size 128, num layers 1, train loss 0.64362633228302, validation loss 0.8354302644729614\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8807076215744019, embedding dim 128, hidden size 128, num layers 1, train loss 0.8260114192962646, validation loss 0.8185994625091553\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8617360591888428, embedding dim 128, hidden size 128, num layers 1, train loss 0.8208253383636475, validation loss 0.8466675877571106\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8456636667251587, embedding dim 128, hidden size 128, num layers 1, train loss 0.7828224897384644, validation loss 0.8130151033401489\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8470675945281982, embedding dim 128, hidden size 128, num layers 1, train loss 0.8398832082748413, validation loss 0.8907190561294556\n",
      "Epoch 180, current patience 29, model mean validation loss 0.8376032114028931, embedding dim 128, hidden size 128, num layers 1, train loss 0.4582887589931488, validation loss 0.8177589774131775\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8313614130020142, embedding dim 128, hidden size 128, num layers 1, train loss 1.0686490535736084, validation loss 0.7957311272621155\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8244268894195557, embedding dim 128, hidden size 128, num layers 1, train loss 0.5290126800537109, validation loss 0.7774930596351624\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8164023160934448, embedding dim 128, hidden size 128, num layers 1, train loss 0.6078754663467407, validation loss 0.7712336182594299\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8087916374206543, embedding dim 128, hidden size 128, num layers 1, train loss 0.5401107668876648, validation loss 0.7577149868011475\n",
      "Epoch 230, current patience 30, model mean validation loss 0.7953025102615356, embedding dim 128, hidden size 128, num layers 1, train loss 0.6004408597946167, validation loss 0.7387535572052002\n",
      "Epoch 240, current patience 30, model mean validation loss 0.7930983901023865, embedding dim 128, hidden size 128, num layers 1, train loss 0.611778736114502, validation loss 0.795382559299469\n",
      "Epoch 250, current patience 30, model mean validation loss 0.7764132618904114, embedding dim 128, hidden size 128, num layers 1, train loss 0.7315567135810852, validation loss 0.7572382092475891\n",
      "Epoch 260, current patience 30, model mean validation loss 0.7735903263092041, embedding dim 128, hidden size 128, num layers 1, train loss 0.751164436340332, validation loss 0.7951750755310059\n",
      "Epoch 270, current patience 30, model mean validation loss 0.7682467103004456, embedding dim 128, hidden size 128, num layers 1, train loss 0.7581408023834229, validation loss 0.752982497215271\n",
      "Epoch 280, current patience 30, model mean validation loss 0.7655014395713806, embedding dim 128, hidden size 128, num layers 1, train loss 0.5097254514694214, validation loss 0.7555312514305115\n",
      "Epoch 290, current patience 30, model mean validation loss 0.762948215007782, embedding dim 128, hidden size 128, num layers 1, train loss 0.427438884973526, validation loss 0.7508074045181274\n",
      "Epoch 300, current patience 30, model mean validation loss 0.769014835357666, embedding dim 128, hidden size 128, num layers 1, train loss 0.7431280612945557, validation loss 0.8062481880187988\n",
      "Epoch 310, current patience 29, model mean validation loss 0.7801178693771362, embedding dim 128, hidden size 128, num layers 1, train loss 0.4061667025089264, validation loss 0.8275774121284485\n",
      "Epoch 320, current patience 28, model mean validation loss 0.7822919487953186, embedding dim 128, hidden size 128, num layers 1, train loss 0.1631999909877777, validation loss 0.8127752542495728\n",
      "Epoch 330, current patience 27, model mean validation loss 0.7848186492919922, embedding dim 128, hidden size 128, num layers 1, train loss 0.4138607978820801, validation loss 0.7774518728256226\n",
      "Epoch 340, current patience 26, model mean validation loss 0.7885464429855347, embedding dim 128, hidden size 128, num layers 1, train loss 0.5410224795341492, validation loss 0.8249971270561218\n",
      "Epoch 350, current patience 25, model mean validation loss 0.799755334854126, embedding dim 128, hidden size 128, num layers 1, train loss 0.3713485598564148, validation loss 0.8426543474197388\n",
      "Epoch 360, current patience 24, model mean validation loss 0.8065270185470581, embedding dim 128, hidden size 128, num layers 1, train loss 0.6764916777610779, validation loss 0.8097041249275208\n",
      "Epoch 370, current patience 23, model mean validation loss 0.8086979389190674, embedding dim 128, hidden size 128, num layers 1, train loss 0.2762157917022705, validation loss 0.7681747078895569\n",
      "Epoch 380, current patience 22, model mean validation loss 0.8110129833221436, embedding dim 128, hidden size 128, num layers 1, train loss 0.2645857036113739, validation loss 0.8247689008712769\n",
      "Epoch 390, current patience 21, model mean validation loss 0.8146036267280579, embedding dim 128, hidden size 128, num layers 1, train loss 0.4879516065120697, validation loss 0.8563024997711182\n",
      "Epoch 400, current patience 20, model mean validation loss 0.8166927099227905, embedding dim 128, hidden size 128, num layers 1, train loss 0.34333324432373047, validation loss 0.8294877409934998\n",
      "Epoch 410, current patience 19, model mean validation loss 0.8228232860565186, embedding dim 128, hidden size 128, num layers 1, train loss 0.25702109932899475, validation loss 0.8264967799186707\n",
      "Epoch 420, current patience 18, model mean validation loss 0.8170667886734009, embedding dim 128, hidden size 128, num layers 1, train loss 0.2360054850578308, validation loss 0.7789452075958252\n",
      "Epoch 430, current patience 17, model mean validation loss 0.8195573091506958, embedding dim 128, hidden size 128, num layers 1, train loss 0.22920143604278564, validation loss 0.8625788688659668\n",
      "Epoch 440, current patience 16, model mean validation loss 0.8253256678581238, embedding dim 128, hidden size 128, num layers 1, train loss 0.7763032913208008, validation loss 0.8558506965637207\n",
      "Epoch 450, current patience 15, model mean validation loss 0.8316916227340698, embedding dim 128, hidden size 128, num layers 1, train loss 0.30886662006378174, validation loss 0.8191019296646118\n",
      "Epoch 460, current patience 14, model mean validation loss 0.8392637968063354, embedding dim 128, hidden size 128, num layers 1, train loss 0.28074872493743896, validation loss 0.8853466510772705\n",
      "Epoch 470, current patience 13, model mean validation loss 0.8537726998329163, embedding dim 128, hidden size 128, num layers 1, train loss 0.5841637849807739, validation loss 0.9723739624023438\n",
      "Epoch 480, current patience 12, model mean validation loss 0.860281765460968, embedding dim 128, hidden size 128, num layers 1, train loss 0.33578649163246155, validation loss 0.8815604448318481\n",
      "Epoch 490, current patience 11, model mean validation loss 0.8658734560012817, embedding dim 128, hidden size 128, num layers 1, train loss 0.25194233655929565, validation loss 0.871229887008667\n",
      "Epoch 500, current patience 10, model mean validation loss 0.8832942247390747, embedding dim 128, hidden size 128, num layers 1, train loss 0.2222593128681183, validation loss 0.9183111190795898\n",
      "Epoch 510, current patience 9, model mean validation loss 0.8879662752151489, embedding dim 128, hidden size 128, num layers 1, train loss 0.15189988911151886, validation loss 0.8999559879302979\n",
      "Epoch 520, current patience 8, model mean validation loss 0.9066968560218811, embedding dim 128, hidden size 128, num layers 1, train loss 0.3239297866821289, validation loss 1.0056947469711304\n",
      "Epoch 530, current patience 7, model mean validation loss 0.9218834638595581, embedding dim 128, hidden size 128, num layers 1, train loss 0.3162464201450348, validation loss 0.9405950307846069\n",
      "Epoch 540, current patience 6, model mean validation loss 0.9323238134384155, embedding dim 128, hidden size 128, num layers 1, train loss 0.492554247379303, validation loss 0.9688690900802612\n",
      "Epoch 550, current patience 5, model mean validation loss 0.913293182849884, embedding dim 128, hidden size 128, num layers 1, train loss 0.17124459147453308, validation loss 0.8201291561126709\n",
      "Epoch 560, current patience 4, model mean validation loss 0.921726644039154, embedding dim 128, hidden size 128, num layers 1, train loss 0.2696496844291687, validation loss 0.9490281939506531\n",
      "Epoch 570, current patience 3, model mean validation loss 0.9474837183952332, embedding dim 128, hidden size 128, num layers 1, train loss 0.2766616940498352, validation loss 1.0772862434387207\n",
      "Epoch 580, current patience 2, model mean validation loss 0.9555672407150269, embedding dim 128, hidden size 128, num layers 1, train loss 0.1487698256969452, validation loss 0.9829792976379395\n",
      "Epoch 590, current patience 1, model mean validation loss 0.9676578640937805, embedding dim 128, hidden size 128, num layers 1, train loss 0.11451413482427597, validation loss 0.9966810941696167\n",
      "Epoch 0, current patience 30, model mean validation loss 1.105034589767456, embedding dim 128, hidden size 256, num layers 1, train loss 1.1029516458511353, validation loss 1.105034589767456\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1015853881835938, embedding dim 128, hidden size 256, num layers 1, train loss 1.101865291595459, validation loss 1.0981361865997314\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0976823568344116, embedding dim 128, hidden size 256, num layers 1, train loss 1.1130342483520508, validation loss 1.0898760557174683\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0929301977157593, embedding dim 128, hidden size 256, num layers 1, train loss 1.0513331890106201, validation loss 1.0786737203598022\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0909913778305054, embedding dim 128, hidden size 256, num layers 1, train loss 1.0831570625305176, validation loss 1.0832363367080688\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0863699913024902, embedding dim 128, hidden size 256, num layers 1, train loss 1.0031408071517944, validation loss 1.063262939453125\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0798002481460571, embedding dim 128, hidden size 256, num layers 1, train loss 1.0869712829589844, validation loss 1.0403821468353271\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0672085285186768, embedding dim 128, hidden size 256, num layers 1, train loss 0.8370528221130371, validation loss 0.9790661931037903\n",
      "Epoch 80, current patience 30, model mean validation loss 1.04463529586792, embedding dim 128, hidden size 256, num layers 1, train loss 0.7720085382461548, validation loss 0.9244481325149536\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0195144414901733, embedding dim 128, hidden size 256, num layers 1, train loss 0.8626691102981567, validation loss 0.8971699476242065\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9907870292663574, embedding dim 128, hidden size 256, num layers 1, train loss 0.9008550643920898, validation loss 0.8600568175315857\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9601069688796997, embedding dim 128, hidden size 256, num layers 1, train loss 0.7060248255729675, validation loss 0.8332333564758301\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9327392578125, embedding dim 128, hidden size 256, num layers 1, train loss 0.6482203006744385, validation loss 0.8642948865890503\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9025267958641052, embedding dim 128, hidden size 256, num layers 1, train loss 0.687623143196106, validation loss 0.8215628862380981\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8744125366210938, embedding dim 128, hidden size 256, num layers 1, train loss 1.0090827941894531, validation loss 0.8154680728912354\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8530967235565186, embedding dim 128, hidden size 256, num layers 1, train loss 0.5733914375305176, validation loss 0.808539628982544\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8350679874420166, embedding dim 128, hidden size 256, num layers 1, train loss 0.8188276290893555, validation loss 0.780218243598938\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8218848705291748, embedding dim 128, hidden size 256, num layers 1, train loss 0.6827412843704224, validation loss 0.7917048931121826\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8137280941009521, embedding dim 128, hidden size 256, num layers 1, train loss 0.8637259006500244, validation loss 0.7948026657104492\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8064299821853638, embedding dim 128, hidden size 256, num layers 1, train loss 0.8245615363121033, validation loss 0.7748485207557678\n",
      "Epoch 200, current patience 30, model mean validation loss 0.7981023788452148, embedding dim 128, hidden size 256, num layers 1, train loss 0.6667585372924805, validation loss 0.7976743578910828\n",
      "Epoch 210, current patience 30, model mean validation loss 0.7913802266120911, embedding dim 128, hidden size 256, num layers 1, train loss 0.8478233814239502, validation loss 0.7677856683731079\n",
      "Epoch 220, current patience 30, model mean validation loss 0.7881286144256592, embedding dim 128, hidden size 256, num layers 1, train loss 0.7269052863121033, validation loss 0.7894548177719116\n",
      "Epoch 230, current patience 30, model mean validation loss 0.786351203918457, embedding dim 128, hidden size 256, num layers 1, train loss 0.3836624026298523, validation loss 0.7943205237388611\n",
      "Epoch 240, current patience 30, model mean validation loss 0.7882370948791504, embedding dim 128, hidden size 256, num layers 1, train loss 0.42295944690704346, validation loss 0.7953051924705505\n",
      "Epoch 250, current patience 29, model mean validation loss 0.7911362051963806, embedding dim 128, hidden size 256, num layers 1, train loss 0.6315133571624756, validation loss 0.8148980140686035\n",
      "Epoch 260, current patience 28, model mean validation loss 0.7869662642478943, embedding dim 128, hidden size 256, num layers 1, train loss 0.6322668790817261, validation loss 0.7614433169364929\n",
      "Epoch 270, current patience 27, model mean validation loss 0.7906198501586914, embedding dim 128, hidden size 256, num layers 1, train loss 0.4584040641784668, validation loss 0.8040768504142761\n",
      "Epoch 280, current patience 26, model mean validation loss 0.7885510921478271, embedding dim 128, hidden size 256, num layers 1, train loss 0.7402182817459106, validation loss 0.7811244130134583\n",
      "Epoch 290, current patience 25, model mean validation loss 0.7952699065208435, embedding dim 128, hidden size 256, num layers 1, train loss 0.43533360958099365, validation loss 0.821536123752594\n",
      "Epoch 300, current patience 24, model mean validation loss 0.7951090335845947, embedding dim 128, hidden size 256, num layers 1, train loss 0.39466285705566406, validation loss 0.7881675958633423\n",
      "Epoch 310, current patience 23, model mean validation loss 0.8077665567398071, embedding dim 128, hidden size 256, num layers 1, train loss 0.243891641497612, validation loss 0.8955808281898499\n",
      "Epoch 320, current patience 22, model mean validation loss 0.8225618600845337, embedding dim 128, hidden size 256, num layers 1, train loss 0.3762602210044861, validation loss 0.9136676788330078\n",
      "Epoch 330, current patience 21, model mean validation loss 0.818234920501709, embedding dim 128, hidden size 256, num layers 1, train loss 0.4098965525627136, validation loss 0.7802830934524536\n",
      "Epoch 340, current patience 20, model mean validation loss 0.8228776454925537, embedding dim 128, hidden size 256, num layers 1, train loss 0.405752956867218, validation loss 0.7985843420028687\n",
      "Epoch 350, current patience 19, model mean validation loss 0.826766848564148, embedding dim 128, hidden size 256, num layers 1, train loss 0.3679583966732025, validation loss 0.8351908326148987\n",
      "Epoch 360, current patience 18, model mean validation loss 0.8325908780097961, embedding dim 128, hidden size 256, num layers 1, train loss 0.23280391097068787, validation loss 0.8277163505554199\n",
      "Epoch 370, current patience 17, model mean validation loss 0.8380549550056458, embedding dim 128, hidden size 256, num layers 1, train loss 0.312968909740448, validation loss 0.8652490973472595\n",
      "Epoch 380, current patience 16, model mean validation loss 0.8423349261283875, embedding dim 128, hidden size 256, num layers 1, train loss 0.2378023862838745, validation loss 0.8224072456359863\n",
      "Epoch 390, current patience 15, model mean validation loss 0.8374218940734863, embedding dim 128, hidden size 256, num layers 1, train loss 0.45833486318588257, validation loss 0.8562766313552856\n",
      "Epoch 400, current patience 14, model mean validation loss 0.8367282152175903, embedding dim 128, hidden size 256, num layers 1, train loss 0.35115599632263184, validation loss 0.9081177711486816\n",
      "Epoch 410, current patience 13, model mean validation loss 0.8525566458702087, embedding dim 128, hidden size 256, num layers 1, train loss 0.17314346134662628, validation loss 0.9069110155105591\n",
      "Epoch 420, current patience 12, model mean validation loss 0.8637583255767822, embedding dim 128, hidden size 256, num layers 1, train loss 0.5912172794342041, validation loss 0.8881974220275879\n",
      "Epoch 430, current patience 11, model mean validation loss 0.8807258009910583, embedding dim 128, hidden size 256, num layers 1, train loss 0.08638367056846619, validation loss 0.9709309339523315\n",
      "Epoch 440, current patience 10, model mean validation loss 0.8959448337554932, embedding dim 128, hidden size 256, num layers 1, train loss 0.3116205334663391, validation loss 0.9494689106941223\n",
      "Epoch 450, current patience 9, model mean validation loss 0.896847665309906, embedding dim 128, hidden size 256, num layers 1, train loss 0.4249143898487091, validation loss 0.8724713325500488\n",
      "Epoch 460, current patience 8, model mean validation loss 0.9080913066864014, embedding dim 128, hidden size 256, num layers 1, train loss 0.3143582344055176, validation loss 0.9123561382293701\n",
      "Epoch 470, current patience 7, model mean validation loss 0.9252714514732361, embedding dim 128, hidden size 256, num layers 1, train loss 0.24327495694160461, validation loss 0.9937177896499634\n",
      "Epoch 480, current patience 6, model mean validation loss 0.9398616552352905, embedding dim 128, hidden size 256, num layers 1, train loss 0.40992307662963867, validation loss 1.0248396396636963\n",
      "Epoch 490, current patience 5, model mean validation loss 0.9385061264038086, embedding dim 128, hidden size 256, num layers 1, train loss 0.15961048007011414, validation loss 0.8960671424865723\n",
      "Epoch 500, current patience 4, model mean validation loss 0.9419082999229431, embedding dim 128, hidden size 256, num layers 1, train loss 0.30087774991989136, validation loss 0.915414571762085\n",
      "Epoch 510, current patience 3, model mean validation loss 0.9463104009628296, embedding dim 128, hidden size 256, num layers 1, train loss 0.2603762149810791, validation loss 1.0061479806900024\n",
      "Epoch 520, current patience 2, model mean validation loss 0.9447831511497498, embedding dim 128, hidden size 256, num layers 1, train loss 0.15993386507034302, validation loss 0.9372502565383911\n",
      "Epoch 530, current patience 1, model mean validation loss 0.9689955711364746, embedding dim 128, hidden size 256, num layers 1, train loss 0.0653294175863266, validation loss 1.0661711692810059\n",
      "Epoch 0, current patience 30, model mean validation loss 1.133535385131836, embedding dim 128, hidden size 512, num layers 1, train loss 1.0990452766418457, validation loss 1.133535385131836\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1165728569030762, embedding dim 128, hidden size 512, num layers 1, train loss 1.1056315898895264, validation loss 1.0996103286743164\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1065912246704102, embedding dim 128, hidden size 512, num layers 1, train loss 1.095555067062378, validation loss 1.0866279602050781\n",
      "Epoch 30, current patience 30, model mean validation loss 1.098903775215149, embedding dim 128, hidden size 512, num layers 1, train loss 1.3095914125442505, validation loss 1.0758413076400757\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0983712673187256, embedding dim 128, hidden size 512, num layers 1, train loss 1.0928223133087158, validation loss 1.0962414741516113\n",
      "Epoch 50, current patience 30, model mean validation loss 1.083147644996643, embedding dim 128, hidden size 512, num layers 1, train loss 0.9328517913818359, validation loss 1.00702965259552\n",
      "Epoch 60, current patience 30, model mean validation loss 1.069201946258545, embedding dim 128, hidden size 512, num layers 1, train loss 0.9241244792938232, validation loss 0.9855276346206665\n",
      "Epoch 70, current patience 30, model mean validation loss 1.051137089729309, embedding dim 128, hidden size 512, num layers 1, train loss 0.9899625778198242, validation loss 0.9246835112571716\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0210554599761963, embedding dim 128, hidden size 512, num layers 1, train loss 1.0153169631958008, validation loss 0.8928821086883545\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9943806529045105, embedding dim 128, hidden size 512, num layers 1, train loss 0.7448194026947021, validation loss 0.8862117528915405\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9631859660148621, embedding dim 128, hidden size 512, num layers 1, train loss 0.6348256468772888, validation loss 0.8370704054832458\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9321637153625488, embedding dim 128, hidden size 512, num layers 1, train loss 0.8380352258682251, validation loss 0.8276634216308594\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8997300863265991, embedding dim 128, hidden size 512, num layers 1, train loss 0.7804926633834839, validation loss 0.8367723226547241\n",
      "Epoch 130, current patience 30, model mean validation loss 0.875482439994812, embedding dim 128, hidden size 512, num layers 1, train loss 0.6835063695907593, validation loss 0.8130486011505127\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8540515303611755, embedding dim 128, hidden size 512, num layers 1, train loss 0.6805152893066406, validation loss 0.8140802383422852\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8395812511444092, embedding dim 128, hidden size 512, num layers 1, train loss 0.7094494104385376, validation loss 0.8089207410812378\n",
      "Epoch 160, current patience 30, model mean validation loss 0.829155445098877, embedding dim 128, hidden size 512, num layers 1, train loss 0.5751769542694092, validation loss 0.8094763159751892\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8205480575561523, embedding dim 128, hidden size 512, num layers 1, train loss 0.6700030565261841, validation loss 0.8173520565032959\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8192053437232971, embedding dim 128, hidden size 512, num layers 1, train loss 0.35968703031539917, validation loss 0.826329231262207\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8134284019470215, embedding dim 128, hidden size 512, num layers 1, train loss 0.5680500268936157, validation loss 0.7814472913742065\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8119998574256897, embedding dim 128, hidden size 512, num layers 1, train loss 0.6486929655075073, validation loss 0.8253441452980042\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8106424808502197, embedding dim 128, hidden size 512, num layers 1, train loss 0.49629732966423035, validation loss 0.8021899461746216\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8118777275085449, embedding dim 128, hidden size 512, num layers 1, train loss 0.7186959981918335, validation loss 0.8239622116088867\n",
      "Epoch 230, current patience 29, model mean validation loss 0.8199842572212219, embedding dim 128, hidden size 512, num layers 1, train loss 0.9209245443344116, validation loss 0.8737726807594299\n",
      "Epoch 240, current patience 28, model mean validation loss 0.8155218362808228, embedding dim 128, hidden size 512, num layers 1, train loss 0.20730215311050415, validation loss 0.7737768888473511\n",
      "Epoch 250, current patience 27, model mean validation loss 0.8124635219573975, embedding dim 128, hidden size 512, num layers 1, train loss 0.454571396112442, validation loss 0.7928853631019592\n",
      "Epoch 260, current patience 26, model mean validation loss 0.8172645568847656, embedding dim 128, hidden size 512, num layers 1, train loss 0.11886931955814362, validation loss 0.8647373914718628\n",
      "Epoch 270, current patience 25, model mean validation loss 0.828447163105011, embedding dim 128, hidden size 512, num layers 1, train loss 0.28330251574516296, validation loss 0.8709085583686829\n",
      "Epoch 280, current patience 24, model mean validation loss 0.8244246244430542, embedding dim 128, hidden size 512, num layers 1, train loss 0.6226624250411987, validation loss 0.7931637763977051\n",
      "Epoch 290, current patience 23, model mean validation loss 0.8272454738616943, embedding dim 128, hidden size 512, num layers 1, train loss 0.7333786487579346, validation loss 0.8247572779655457\n",
      "Epoch 300, current patience 22, model mean validation loss 0.8308611512184143, embedding dim 128, hidden size 512, num layers 1, train loss 0.26962438225746155, validation loss 0.8528871536254883\n",
      "Epoch 310, current patience 21, model mean validation loss 0.8286172151565552, embedding dim 128, hidden size 512, num layers 1, train loss 0.20031298696994781, validation loss 0.8558211326599121\n",
      "Epoch 320, current patience 20, model mean validation loss 0.8415311574935913, embedding dim 128, hidden size 512, num layers 1, train loss 0.979500949382782, validation loss 0.877089262008667\n",
      "Epoch 330, current patience 19, model mean validation loss 0.8440852165222168, embedding dim 128, hidden size 512, num layers 1, train loss 0.3534027338027954, validation loss 0.8133177757263184\n",
      "Epoch 340, current patience 18, model mean validation loss 0.8474149703979492, embedding dim 128, hidden size 512, num layers 1, train loss 0.18067196011543274, validation loss 0.891374409198761\n",
      "Epoch 350, current patience 17, model mean validation loss 0.8517873287200928, embedding dim 128, hidden size 512, num layers 1, train loss 0.14239206910133362, validation loss 0.9058879017829895\n",
      "Epoch 360, current patience 16, model mean validation loss 0.86872798204422, embedding dim 128, hidden size 512, num layers 1, train loss 0.3141390085220337, validation loss 0.928688645362854\n",
      "Epoch 370, current patience 15, model mean validation loss 0.8649252653121948, embedding dim 128, hidden size 512, num layers 1, train loss 0.22135937213897705, validation loss 0.7943361401557922\n",
      "Epoch 380, current patience 14, model mean validation loss 0.868928849697113, embedding dim 128, hidden size 512, num layers 1, train loss 0.13830968737602234, validation loss 0.8849158883094788\n",
      "Epoch 390, current patience 13, model mean validation loss 0.868874728679657, embedding dim 128, hidden size 512, num layers 1, train loss 0.22512564063072205, validation loss 0.855387806892395\n",
      "Epoch 400, current patience 12, model mean validation loss 0.8676817417144775, embedding dim 128, hidden size 512, num layers 1, train loss 0.47559982538223267, validation loss 0.8675451874732971\n",
      "Epoch 410, current patience 11, model mean validation loss 0.8788056969642639, embedding dim 128, hidden size 512, num layers 1, train loss 0.9137341976165771, validation loss 0.9023091197013855\n",
      "Epoch 420, current patience 10, model mean validation loss 0.8745805025100708, embedding dim 128, hidden size 512, num layers 1, train loss 0.1970275193452835, validation loss 0.8575731515884399\n",
      "Epoch 430, current patience 9, model mean validation loss 0.8720989227294922, embedding dim 128, hidden size 512, num layers 1, train loss 0.17934724688529968, validation loss 0.8860352635383606\n",
      "Epoch 440, current patience 8, model mean validation loss 0.8721840977668762, embedding dim 128, hidden size 512, num layers 1, train loss 0.36792734265327454, validation loss 0.9293704032897949\n",
      "Epoch 450, current patience 7, model mean validation loss 0.8996526002883911, embedding dim 128, hidden size 512, num layers 1, train loss 0.19008629024028778, validation loss 1.0140843391418457\n",
      "Epoch 460, current patience 6, model mean validation loss 0.9078686237335205, embedding dim 128, hidden size 512, num layers 1, train loss 0.1006564199924469, validation loss 0.9506440162658691\n",
      "Epoch 470, current patience 5, model mean validation loss 0.9243934154510498, embedding dim 128, hidden size 512, num layers 1, train loss 0.023268818855285645, validation loss 0.9875855445861816\n",
      "Epoch 480, current patience 4, model mean validation loss 0.9302068948745728, embedding dim 128, hidden size 512, num layers 1, train loss 0.1636723428964615, validation loss 0.9140535593032837\n",
      "Epoch 490, current patience 3, model mean validation loss 0.942377507686615, embedding dim 128, hidden size 512, num layers 1, train loss 0.3215644657611847, validation loss 0.9996738433837891\n",
      "Epoch 500, current patience 2, model mean validation loss 0.9519067406654358, embedding dim 128, hidden size 512, num layers 1, train loss 0.17339400947093964, validation loss 0.933806836605072\n",
      "Epoch 510, current patience 1, model mean validation loss 0.9615755081176758, embedding dim 128, hidden size 512, num layers 1, train loss 0.1331622302532196, validation loss 0.9633854627609253\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2479970455169678, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0979363918304443, validation loss 1.2479970455169678\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1727088689804077, embedding dim 128, hidden size 1024, num layers 1, train loss 1.1612157821655273, validation loss 1.0974206924438477\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1490448713302612, embedding dim 128, hidden size 1024, num layers 1, train loss 1.122418999671936, validation loss 1.1017168760299683\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1351757049560547, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0863656997680664, validation loss 1.0935680866241455\n",
      "Epoch 40, current patience 30, model mean validation loss 1.129263162612915, embedding dim 128, hidden size 1024, num layers 1, train loss 1.120137095451355, validation loss 1.1056132316589355\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1233420372009277, embedding dim 128, hidden size 1024, num layers 1, train loss 1.1272284984588623, validation loss 1.093735933303833\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1173762083053589, embedding dim 128, hidden size 1024, num layers 1, train loss 1.120324730873108, validation loss 1.0815815925598145\n",
      "Epoch 70, current patience 30, model mean validation loss 1.109838843345642, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0210680961608887, validation loss 1.057077407836914\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0866668224334717, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0710397958755493, validation loss 1.0626211166381836\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0835179090499878, embedding dim 128, hidden size 1024, num layers 1, train loss 1.085585117340088, validation loss 1.0722284317016602\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0797696113586426, embedding dim 128, hidden size 1024, num layers 1, train loss 0.979773998260498, validation loss 1.0717307329177856\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0748172998428345, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0538873672485352, validation loss 1.0539495944976807\n",
      "Epoch 120, current patience 30, model mean validation loss 1.067529559135437, embedding dim 128, hidden size 1024, num layers 1, train loss 1.028609275817871, validation loss 1.0473119020462036\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0626674890518188, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0092248916625977, validation loss 1.0548388957977295\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0561022758483887, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0363547801971436, validation loss 1.029059648513794\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0518038272857666, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0094678401947021, validation loss 1.022689700126648\n",
      "Epoch 160, current patience 30, model mean validation loss 1.049269676208496, embedding dim 128, hidden size 1024, num layers 1, train loss 1.00290846824646, validation loss 1.042348861694336\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0461678504943848, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0317344665527344, validation loss 1.0474135875701904\n",
      "Epoch 180, current patience 30, model mean validation loss 1.039306402206421, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0508012771606445, validation loss 1.016839861869812\n",
      "Epoch 190, current patience 30, model mean validation loss 1.036893606185913, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9079375267028809, validation loss 1.0346472263336182\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0368376970291138, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8774096965789795, validation loss 1.0468640327453613\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0364158153533936, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9497177004814148, validation loss 1.051464319229126\n",
      "Epoch 220, current patience 30, model mean validation loss 1.038394808769226, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7554761171340942, validation loss 1.0448908805847168\n",
      "Epoch 230, current patience 29, model mean validation loss 1.038231611251831, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0557820796966553, validation loss 1.0213837623596191\n",
      "Epoch 240, current patience 28, model mean validation loss 1.037523627281189, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8163653016090393, validation loss 1.0366854667663574\n",
      "Epoch 250, current patience 27, model mean validation loss 1.0327166318893433, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8203331232070923, validation loss 1.0089575052261353\n",
      "Epoch 260, current patience 30, model mean validation loss 1.036024808883667, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8621401190757751, validation loss 1.043305516242981\n",
      "Epoch 270, current patience 29, model mean validation loss 1.0346381664276123, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9994968175888062, validation loss 1.0235539674758911\n",
      "Epoch 280, current patience 28, model mean validation loss 1.0316314697265625, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9659773111343384, validation loss 1.0228099822998047\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0258996486663818, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9119490385055542, validation loss 1.0056098699569702\n",
      "Epoch 300, current patience 30, model mean validation loss 1.022376537322998, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9719038605690002, validation loss 1.0167063474655151\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0245614051818848, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9907155632972717, validation loss 1.038862943649292\n",
      "Epoch 320, current patience 29, model mean validation loss 1.0262174606323242, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6866896748542786, validation loss 1.0499334335327148\n",
      "Epoch 330, current patience 28, model mean validation loss 1.029310703277588, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9070892333984375, validation loss 1.0337028503417969\n",
      "Epoch 340, current patience 27, model mean validation loss 1.0272175073623657, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6943255066871643, validation loss 1.0265601873397827\n",
      "Epoch 350, current patience 26, model mean validation loss 1.0301777124404907, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8940697908401489, validation loss 1.0472359657287598\n",
      "Epoch 360, current patience 25, model mean validation loss 1.032466173171997, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9521526098251343, validation loss 1.0411171913146973\n",
      "Epoch 370, current patience 24, model mean validation loss 1.0395745038986206, embedding dim 128, hidden size 1024, num layers 1, train loss 0.931475043296814, validation loss 1.0624773502349854\n",
      "Epoch 380, current patience 23, model mean validation loss 1.0433475971221924, embedding dim 128, hidden size 1024, num layers 1, train loss 1.1457903385162354, validation loss 1.046891212463379\n",
      "Epoch 390, current patience 22, model mean validation loss 1.0409032106399536, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7973621487617493, validation loss 1.0193073749542236\n",
      "Epoch 400, current patience 21, model mean validation loss 1.0388859510421753, embedding dim 128, hidden size 1024, num layers 1, train loss 0.9866625666618347, validation loss 1.0337949991226196\n",
      "Epoch 410, current patience 20, model mean validation loss 1.0364797115325928, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6447036862373352, validation loss 1.0144531726837158\n",
      "Epoch 420, current patience 19, model mean validation loss 1.0366971492767334, embedding dim 128, hidden size 1024, num layers 1, train loss 0.845626711845398, validation loss 1.0282999277114868\n",
      "Epoch 430, current patience 18, model mean validation loss 1.0341501235961914, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7716168165206909, validation loss 1.0268598794937134\n",
      "Epoch 440, current patience 17, model mean validation loss 1.0340266227722168, embedding dim 128, hidden size 1024, num layers 1, train loss 1.0070477724075317, validation loss 1.0401296615600586\n",
      "Epoch 450, current patience 16, model mean validation loss 1.0323100090026855, embedding dim 128, hidden size 1024, num layers 1, train loss 0.860592246055603, validation loss 1.0487443208694458\n",
      "Epoch 460, current patience 15, model mean validation loss 1.0334765911102295, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8986701965332031, validation loss 1.0562227964401245\n",
      "Epoch 470, current patience 14, model mean validation loss 1.0388901233673096, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7390941977500916, validation loss 1.0626168251037598\n",
      "Epoch 480, current patience 13, model mean validation loss 1.0427639484405518, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8078643679618835, validation loss 1.0647854804992676\n",
      "Epoch 490, current patience 12, model mean validation loss 1.0432920455932617, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6734523773193359, validation loss 1.0186779499053955\n",
      "Epoch 500, current patience 11, model mean validation loss 1.0472297668457031, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8050913214683533, validation loss 1.0598011016845703\n",
      "Epoch 510, current patience 10, model mean validation loss 1.0507521629333496, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6631696224212646, validation loss 1.055038332939148\n",
      "Epoch 520, current patience 9, model mean validation loss 1.0555707216262817, embedding dim 128, hidden size 1024, num layers 1, train loss 0.688944399356842, validation loss 1.0786784887313843\n",
      "Epoch 530, current patience 8, model mean validation loss 1.0557899475097656, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7283281087875366, validation loss 1.0504984855651855\n",
      "Epoch 540, current patience 7, model mean validation loss 1.054626226425171, embedding dim 128, hidden size 1024, num layers 1, train loss 0.691413164138794, validation loss 1.0469136238098145\n",
      "Epoch 550, current patience 6, model mean validation loss 1.0529680252075195, embedding dim 128, hidden size 1024, num layers 1, train loss 0.8286713361740112, validation loss 1.0493509769439697\n",
      "Epoch 560, current patience 5, model mean validation loss 1.05146324634552, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7817049026489258, validation loss 1.0527474880218506\n",
      "Epoch 570, current patience 4, model mean validation loss 1.0543274879455566, embedding dim 128, hidden size 1024, num layers 1, train loss 0.6306819915771484, validation loss 1.041591763496399\n",
      "Epoch 580, current patience 3, model mean validation loss 1.0537604093551636, embedding dim 128, hidden size 1024, num layers 1, train loss 0.7464795112609863, validation loss 1.0552647113800049\n",
      "Epoch 590, current patience 2, model mean validation loss 1.0570783615112305, embedding dim 128, hidden size 1024, num layers 1, train loss 0.669650673866272, validation loss 1.0815813541412354\n",
      "Epoch 600, current patience 1, model mean validation loss 1.0559325218200684, embedding dim 128, hidden size 1024, num layers 1, train loss 0.809109091758728, validation loss 1.069512128829956\n",
      "Epoch 0, current patience 30, model mean validation loss 1.376349687576294, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0975561141967773, validation loss 1.376349687576294\n",
      "Epoch 10, current patience 30, model mean validation loss 1.308810830116272, embedding dim 128, hidden size 2048, num layers 1, train loss 1.154040813446045, validation loss 1.24127197265625\n",
      "Epoch 20, current patience 30, model mean validation loss 1.2997416257858276, embedding dim 128, hidden size 2048, num layers 1, train loss 1.4798247814178467, validation loss 1.2816030979156494\n",
      "Epoch 30, current patience 30, model mean validation loss 1.2777636051177979, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1660935878753662, validation loss 1.2118297815322876\n",
      "Epoch 40, current patience 30, model mean validation loss 1.250041127204895, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1340291500091553, validation loss 1.1391509771347046\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2360881567001343, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1781325340270996, validation loss 1.1663239002227783\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2220790386199951, embedding dim 128, hidden size 2048, num layers 1, train loss 1.2090520858764648, validation loss 1.138023853302002\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2107348442077637, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1455025672912598, validation loss 1.1313245296478271\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1874806880950928, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1298964023590088, validation loss 1.1903172731399536\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1712453365325928, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1486403942108154, validation loss 1.1113899946212769\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1495760679244995, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0383145809173584, validation loss 1.108248233795166\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1365230083465576, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0884778499603271, validation loss 1.1074053049087524\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1329259872436523, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1267235279083252, validation loss 1.1103743314743042\n",
      "Epoch 130, current patience 30, model mean validation loss 1.1245940923690796, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0710537433624268, validation loss 1.099669098854065\n",
      "Epoch 140, current patience 30, model mean validation loss 1.121559739112854, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9558066129684448, validation loss 1.1137490272521973\n",
      "Epoch 150, current patience 30, model mean validation loss 1.1404393911361694, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1499862670898438, validation loss 1.282361626625061\n",
      "Epoch 160, current patience 29, model mean validation loss 1.1270573139190674, embedding dim 128, hidden size 2048, num layers 1, train loss 1.230210781097412, validation loss 1.083261251449585\n",
      "Epoch 170, current patience 28, model mean validation loss 1.1241159439086914, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9762917757034302, validation loss 1.0878589153289795\n",
      "Epoch 180, current patience 27, model mean validation loss 1.1228231191635132, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1275171041488647, validation loss 1.0979053974151611\n",
      "Epoch 190, current patience 26, model mean validation loss 1.1217303276062012, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0966837406158447, validation loss 1.0986626148223877\n",
      "Epoch 200, current patience 25, model mean validation loss 1.1269006729125977, embedding dim 128, hidden size 2048, num layers 1, train loss 1.088738203048706, validation loss 1.151737093925476\n",
      "Epoch 210, current patience 24, model mean validation loss 1.129777193069458, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1052651405334473, validation loss 1.122680902481079\n",
      "Epoch 220, current patience 23, model mean validation loss 1.1281555891036987, embedding dim 128, hidden size 2048, num layers 1, train loss 1.107358694076538, validation loss 1.1007769107818604\n",
      "Epoch 230, current patience 22, model mean validation loss 1.1164493560791016, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9713313579559326, validation loss 1.1887118816375732\n",
      "Epoch 240, current patience 30, model mean validation loss 1.126682162284851, embedding dim 128, hidden size 2048, num layers 1, train loss 1.088459849357605, validation loss 1.1651235818862915\n",
      "Epoch 250, current patience 29, model mean validation loss 1.1258758306503296, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0560507774353027, validation loss 1.0814083814620972\n",
      "Epoch 260, current patience 28, model mean validation loss 1.1281670331954956, embedding dim 128, hidden size 2048, num layers 1, train loss 1.02799391746521, validation loss 1.1162347793579102\n",
      "Epoch 270, current patience 27, model mean validation loss 1.1284873485565186, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0617129802703857, validation loss 1.1012247800827026\n",
      "Epoch 280, current patience 26, model mean validation loss 1.12283194065094, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0426139831542969, validation loss 1.1064947843551636\n",
      "Epoch 290, current patience 25, model mean validation loss 1.126908302307129, embedding dim 128, hidden size 2048, num layers 1, train loss 1.14519202709198, validation loss 1.1552908420562744\n",
      "Epoch 300, current patience 24, model mean validation loss 1.1430726051330566, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9723935723304749, validation loss 1.2300918102264404\n",
      "Epoch 310, current patience 23, model mean validation loss 1.1307222843170166, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0338870286941528, validation loss 1.089909553527832\n",
      "Epoch 320, current patience 22, model mean validation loss 1.1271229982376099, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0691295862197876, validation loss 1.136328935623169\n",
      "Epoch 330, current patience 21, model mean validation loss 1.1304751634597778, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0528266429901123, validation loss 1.1082258224487305\n",
      "Epoch 340, current patience 20, model mean validation loss 1.12495756149292, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9403388500213623, validation loss 1.0720947980880737\n",
      "Epoch 350, current patience 19, model mean validation loss 1.1260076761245728, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9337080121040344, validation loss 1.1096253395080566\n",
      "Epoch 360, current patience 18, model mean validation loss 1.1217596530914307, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0914151668548584, validation loss 1.0725101232528687\n",
      "Epoch 370, current patience 17, model mean validation loss 1.1111197471618652, embedding dim 128, hidden size 2048, num layers 1, train loss 0.8993531465530396, validation loss 1.0701713562011719\n",
      "Epoch 380, current patience 30, model mean validation loss 1.1092159748077393, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9338060617446899, validation loss 1.2148622274398804\n",
      "Epoch 390, current patience 30, model mean validation loss 1.1128032207489014, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9578170776367188, validation loss 1.1186070442199707\n",
      "Epoch 400, current patience 29, model mean validation loss 1.1161985397338867, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0754637718200684, validation loss 1.1634914875030518\n",
      "Epoch 410, current patience 28, model mean validation loss 1.113886833190918, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0330754518508911, validation loss 1.0897324085235596\n",
      "Epoch 420, current patience 27, model mean validation loss 1.115868091583252, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0816307067871094, validation loss 1.087944746017456\n",
      "Epoch 430, current patience 26, model mean validation loss 1.1119714975357056, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1537001132965088, validation loss 1.0784525871276855\n",
      "Epoch 440, current patience 25, model mean validation loss 1.1295584440231323, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0067702531814575, validation loss 1.2132060527801514\n",
      "Epoch 450, current patience 24, model mean validation loss 1.136008858680725, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0808781385421753, validation loss 1.1217743158340454\n",
      "Epoch 460, current patience 23, model mean validation loss 1.1409406661987305, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0541412830352783, validation loss 1.2543165683746338\n",
      "Epoch 470, current patience 22, model mean validation loss 1.149457335472107, embedding dim 128, hidden size 2048, num layers 1, train loss 1.259958028793335, validation loss 1.1867402791976929\n",
      "Epoch 480, current patience 21, model mean validation loss 1.1515337228775024, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9499043226242065, validation loss 1.180102825164795\n",
      "Epoch 490, current patience 20, model mean validation loss 1.1504435539245605, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1149855852127075, validation loss 1.0810106992721558\n",
      "Epoch 500, current patience 19, model mean validation loss 1.1557881832122803, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0626839399337769, validation loss 1.130702257156372\n",
      "Epoch 510, current patience 18, model mean validation loss 1.1611913442611694, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9163902997970581, validation loss 1.1216773986816406\n",
      "Epoch 520, current patience 17, model mean validation loss 1.14454185962677, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0920944213867188, validation loss 1.0800106525421143\n",
      "Epoch 530, current patience 16, model mean validation loss 1.149834156036377, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9260435700416565, validation loss 1.1641123294830322\n",
      "Epoch 540, current patience 15, model mean validation loss 1.1338741779327393, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0789034366607666, validation loss 1.1266374588012695\n",
      "Epoch 550, current patience 14, model mean validation loss 1.1214489936828613, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0156629085540771, validation loss 1.087338924407959\n",
      "Epoch 560, current patience 13, model mean validation loss 1.1160917282104492, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9321120977401733, validation loss 1.1372442245483398\n",
      "Epoch 570, current patience 12, model mean validation loss 1.1276230812072754, embedding dim 128, hidden size 2048, num layers 1, train loss 0.965546727180481, validation loss 1.1732620000839233\n",
      "Epoch 580, current patience 11, model mean validation loss 1.1294444799423218, embedding dim 128, hidden size 2048, num layers 1, train loss 1.0357915163040161, validation loss 1.1452724933624268\n",
      "Epoch 590, current patience 10, model mean validation loss 1.153907299041748, embedding dim 128, hidden size 2048, num layers 1, train loss 0.976420521736145, validation loss 1.317380666732788\n",
      "Epoch 600, current patience 9, model mean validation loss 1.1606966257095337, embedding dim 128, hidden size 2048, num layers 1, train loss 1.2038862705230713, validation loss 1.1343249082565308\n",
      "Epoch 610, current patience 8, model mean validation loss 1.1550235748291016, embedding dim 128, hidden size 2048, num layers 1, train loss 1.1232815980911255, validation loss 1.1187273263931274\n",
      "Epoch 620, current patience 7, model mean validation loss 1.1582919359207153, embedding dim 128, hidden size 2048, num layers 1, train loss 0.8680172562599182, validation loss 1.152785301208496\n",
      "Epoch 630, current patience 6, model mean validation loss 1.1680103540420532, embedding dim 128, hidden size 2048, num layers 1, train loss 0.8849951028823853, validation loss 1.165086269378662\n",
      "Epoch 640, current patience 5, model mean validation loss 1.1657295227050781, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9423280954360962, validation loss 1.1189978122711182\n",
      "Epoch 650, current patience 4, model mean validation loss 1.16242516040802, embedding dim 128, hidden size 2048, num layers 1, train loss 0.8719490766525269, validation loss 1.1468265056610107\n",
      "Epoch 660, current patience 3, model mean validation loss 1.1581981182098389, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9439091682434082, validation loss 1.1114559173583984\n",
      "Epoch 670, current patience 2, model mean validation loss 1.1306779384613037, embedding dim 128, hidden size 2048, num layers 1, train loss 0.8919380903244019, validation loss 1.0972189903259277\n",
      "Epoch 680, current patience 1, model mean validation loss 1.121724247932434, embedding dim 128, hidden size 2048, num layers 1, train loss 0.9108870029449463, validation loss 1.0626959800720215\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1974358558654785, embedding dim 256, hidden size 1, num layers 1, train loss 1.226731538772583, validation loss 1.1974358558654785\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1753932237625122, embedding dim 256, hidden size 1, num layers 1, train loss 1.1767356395721436, validation loss 1.153350591659546\n",
      "Epoch 20, current patience 30, model mean validation loss 1.161218285560608, embedding dim 256, hidden size 1, num layers 1, train loss 1.1312791109085083, validation loss 1.1328682899475098\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1485174894332886, embedding dim 256, hidden size 1, num layers 1, train loss 1.083735704421997, validation loss 1.1104153394699097\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1391128301620483, embedding dim 256, hidden size 1, num layers 1, train loss 1.0992121696472168, validation loss 1.1014938354492188\n",
      "Epoch 50, current patience 30, model mean validation loss 1.131617784500122, embedding dim 256, hidden size 1, num layers 1, train loss 1.086022973060608, validation loss 1.0941429138183594\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1257978677749634, embedding dim 256, hidden size 1, num layers 1, train loss 1.09369695186615, validation loss 1.0908777713775635\n",
      "Epoch 70, current patience 30, model mean validation loss 1.121500015258789, embedding dim 256, hidden size 1, num layers 1, train loss 1.063741683959961, validation loss 1.0914161205291748\n",
      "Epoch 80, current patience 30, model mean validation loss 1.107300043106079, embedding dim 256, hidden size 1, num layers 1, train loss 1.0831257104873657, validation loss 1.0838353633880615\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0991483926773071, embedding dim 256, hidden size 1, num layers 1, train loss 1.103560447692871, validation loss 1.0881376266479492\n",
      "Epoch 100, current patience 30, model mean validation loss 1.093704104423523, embedding dim 256, hidden size 1, num layers 1, train loss 1.0906507968902588, validation loss 1.0893142223358154\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0913289785385132, embedding dim 256, hidden size 1, num layers 1, train loss 1.076913595199585, validation loss 1.0914137363433838\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0886274576187134, embedding dim 256, hidden size 1, num layers 1, train loss 1.0821117162704468, validation loss 1.0798816680908203\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0872743129730225, embedding dim 256, hidden size 1, num layers 1, train loss 1.0911505222320557, validation loss 1.0833182334899902\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0865516662597656, embedding dim 256, hidden size 1, num layers 1, train loss 1.0778708457946777, validation loss 1.0850965976715088\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0861928462982178, embedding dim 256, hidden size 1, num layers 1, train loss 1.062857747077942, validation loss 1.0885450839996338\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0859602689743042, embedding dim 256, hidden size 1, num layers 1, train loss 1.0978600978851318, validation loss 1.0819748640060425\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0853434801101685, embedding dim 256, hidden size 1, num layers 1, train loss 1.1002001762390137, validation loss 1.0832033157348633\n",
      "Epoch 180, current patience 30, model mean validation loss 1.08486008644104, embedding dim 256, hidden size 1, num layers 1, train loss 1.0739753246307373, validation loss 1.0854467153549194\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0839803218841553, embedding dim 256, hidden size 1, num layers 1, train loss 1.0483407974243164, validation loss 1.0843757390975952\n",
      "Epoch 200, current patience 30, model mean validation loss 1.084458827972412, embedding dim 256, hidden size 1, num layers 1, train loss 1.0711508989334106, validation loss 1.0837101936340332\n",
      "Epoch 210, current patience 29, model mean validation loss 1.0839899778366089, embedding dim 256, hidden size 1, num layers 1, train loss 1.0965577363967896, validation loss 1.0795676708221436\n",
      "Epoch 220, current patience 28, model mean validation loss 1.0838940143585205, embedding dim 256, hidden size 1, num layers 1, train loss 1.0582754611968994, validation loss 1.084328055381775\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0830355882644653, embedding dim 256, hidden size 1, num layers 1, train loss 1.0665040016174316, validation loss 1.0816782712936401\n",
      "Epoch 240, current patience 30, model mean validation loss 1.0821809768676758, embedding dim 256, hidden size 1, num layers 1, train loss 1.0612255334854126, validation loss 1.0751380920410156\n",
      "Epoch 250, current patience 30, model mean validation loss 1.081321120262146, embedding dim 256, hidden size 1, num layers 1, train loss 1.0870463848114014, validation loss 1.0763243436813354\n",
      "Epoch 260, current patience 30, model mean validation loss 1.080935001373291, embedding dim 256, hidden size 1, num layers 1, train loss 1.007376790046692, validation loss 1.0823581218719482\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0795845985412598, embedding dim 256, hidden size 1, num layers 1, train loss 0.9964049458503723, validation loss 1.0735725164413452\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0782231092453003, embedding dim 256, hidden size 1, num layers 1, train loss 1.0648924112319946, validation loss 1.0728180408477783\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0778710842132568, embedding dim 256, hidden size 1, num layers 1, train loss 1.100558876991272, validation loss 1.076751708984375\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0762712955474854, embedding dim 256, hidden size 1, num layers 1, train loss 1.049456000328064, validation loss 1.0715296268463135\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0738015174865723, embedding dim 256, hidden size 1, num layers 1, train loss 0.9892901182174683, validation loss 1.0619192123413086\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0722780227661133, embedding dim 256, hidden size 1, num layers 1, train loss 1.0787469148635864, validation loss 1.0629504919052124\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0710906982421875, embedding dim 256, hidden size 1, num layers 1, train loss 1.0496087074279785, validation loss 1.0668256282806396\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0701045989990234, embedding dim 256, hidden size 1, num layers 1, train loss 1.0312013626098633, validation loss 1.0744693279266357\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0703572034835815, embedding dim 256, hidden size 1, num layers 1, train loss 1.0177347660064697, validation loss 1.0755937099456787\n",
      "Epoch 360, current patience 29, model mean validation loss 1.071349859237671, embedding dim 256, hidden size 1, num layers 1, train loss 1.0800845623016357, validation loss 1.0807583332061768\n",
      "Epoch 370, current patience 28, model mean validation loss 1.0719873905181885, embedding dim 256, hidden size 1, num layers 1, train loss 1.0084311962127686, validation loss 1.0818520784378052\n",
      "Epoch 380, current patience 27, model mean validation loss 1.0723938941955566, embedding dim 256, hidden size 1, num layers 1, train loss 1.046907901763916, validation loss 1.0747830867767334\n",
      "Epoch 390, current patience 26, model mean validation loss 1.074232816696167, embedding dim 256, hidden size 1, num layers 1, train loss 1.0301001071929932, validation loss 1.0766301155090332\n",
      "Epoch 400, current patience 25, model mean validation loss 1.074881911277771, embedding dim 256, hidden size 1, num layers 1, train loss 1.0293807983398438, validation loss 1.0681427717208862\n",
      "Epoch 410, current patience 24, model mean validation loss 1.0749022960662842, embedding dim 256, hidden size 1, num layers 1, train loss 0.9998453259468079, validation loss 1.066988468170166\n",
      "Epoch 420, current patience 23, model mean validation loss 1.073871374130249, embedding dim 256, hidden size 1, num layers 1, train loss 1.022047996520996, validation loss 1.066223382949829\n",
      "Epoch 430, current patience 22, model mean validation loss 1.0734782218933105, embedding dim 256, hidden size 1, num layers 1, train loss 1.11480712890625, validation loss 1.0724478960037231\n",
      "Epoch 440, current patience 21, model mean validation loss 1.0724759101867676, embedding dim 256, hidden size 1, num layers 1, train loss 0.9316716194152832, validation loss 1.0727392435073853\n",
      "Epoch 450, current patience 20, model mean validation loss 1.0720009803771973, embedding dim 256, hidden size 1, num layers 1, train loss 1.042382001876831, validation loss 1.0780534744262695\n",
      "Epoch 460, current patience 19, model mean validation loss 1.0717082023620605, embedding dim 256, hidden size 1, num layers 1, train loss 1.0289605855941772, validation loss 1.0724403858184814\n",
      "Epoch 470, current patience 18, model mean validation loss 1.071164608001709, embedding dim 256, hidden size 1, num layers 1, train loss 1.0255811214447021, validation loss 1.0722811222076416\n",
      "Epoch 480, current patience 17, model mean validation loss 1.071993112564087, embedding dim 256, hidden size 1, num layers 1, train loss 1.05366849899292, validation loss 1.0747708082199097\n",
      "Epoch 490, current patience 16, model mean validation loss 1.0741246938705444, embedding dim 256, hidden size 1, num layers 1, train loss 1.0254542827606201, validation loss 1.084040880203247\n",
      "Epoch 500, current patience 15, model mean validation loss 1.076176404953003, embedding dim 256, hidden size 1, num layers 1, train loss 1.0313146114349365, validation loss 1.0826375484466553\n",
      "Epoch 510, current patience 14, model mean validation loss 1.0752509832382202, embedding dim 256, hidden size 1, num layers 1, train loss 1.0122747421264648, validation loss 1.0650442838668823\n",
      "Epoch 520, current patience 13, model mean validation loss 1.075832486152649, embedding dim 256, hidden size 1, num layers 1, train loss 1.0070513486862183, validation loss 1.0773916244506836\n",
      "Epoch 530, current patience 12, model mean validation loss 1.0761291980743408, embedding dim 256, hidden size 1, num layers 1, train loss 0.9885486364364624, validation loss 1.0804264545440674\n",
      "Epoch 540, current patience 11, model mean validation loss 1.0754618644714355, embedding dim 256, hidden size 1, num layers 1, train loss 1.0129342079162598, validation loss 1.0671024322509766\n",
      "Epoch 550, current patience 10, model mean validation loss 1.0747907161712646, embedding dim 256, hidden size 1, num layers 1, train loss 1.0196232795715332, validation loss 1.0669115781784058\n",
      "Epoch 560, current patience 9, model mean validation loss 1.074442744255066, embedding dim 256, hidden size 1, num layers 1, train loss 0.9313626885414124, validation loss 1.0719870328903198\n",
      "Epoch 570, current patience 8, model mean validation loss 1.0750192403793335, embedding dim 256, hidden size 1, num layers 1, train loss 1.0332088470458984, validation loss 1.0886528491973877\n",
      "Epoch 580, current patience 7, model mean validation loss 1.0737159252166748, embedding dim 256, hidden size 1, num layers 1, train loss 0.9988342523574829, validation loss 1.0722112655639648\n",
      "Epoch 590, current patience 6, model mean validation loss 1.0774370431900024, embedding dim 256, hidden size 1, num layers 1, train loss 1.0274991989135742, validation loss 1.0948129892349243\n",
      "Epoch 600, current patience 5, model mean validation loss 1.0764797925949097, embedding dim 256, hidden size 1, num layers 1, train loss 0.9260787963867188, validation loss 1.0697336196899414\n",
      "Epoch 610, current patience 4, model mean validation loss 1.0768258571624756, embedding dim 256, hidden size 1, num layers 1, train loss 1.0396294593811035, validation loss 1.0831944942474365\n",
      "Epoch 620, current patience 3, model mean validation loss 1.0789787769317627, embedding dim 256, hidden size 1, num layers 1, train loss 0.9972381591796875, validation loss 1.0843266248703003\n",
      "Epoch 630, current patience 2, model mean validation loss 1.0819032192230225, embedding dim 256, hidden size 1, num layers 1, train loss 1.0388758182525635, validation loss 1.0903072357177734\n",
      "Epoch 640, current patience 1, model mean validation loss 1.0832595825195312, embedding dim 256, hidden size 1, num layers 1, train loss 1.01857590675354, validation loss 1.0828375816345215\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2239587306976318, embedding dim 256, hidden size 2, num layers 1, train loss 1.198474645614624, validation loss 1.2239587306976318\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1904001235961914, embedding dim 256, hidden size 2, num layers 1, train loss 1.217103362083435, validation loss 1.1568413972854614\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1699371337890625, embedding dim 256, hidden size 2, num layers 1, train loss 1.1058549880981445, validation loss 1.1290111541748047\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1554609537124634, embedding dim 256, hidden size 2, num layers 1, train loss 1.119115948677063, validation loss 1.112032413482666\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1438239812850952, embedding dim 256, hidden size 2, num layers 1, train loss 1.1015958786010742, validation loss 1.097276210784912\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1364535093307495, embedding dim 256, hidden size 2, num layers 1, train loss 1.0966897010803223, validation loss 1.0996015071868896\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1299831867218018, embedding dim 256, hidden size 2, num layers 1, train loss 1.0858210325241089, validation loss 1.0911606550216675\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1254403591156006, embedding dim 256, hidden size 2, num layers 1, train loss 1.0958003997802734, validation loss 1.0936403274536133\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1086311340332031, embedding dim 256, hidden size 2, num layers 1, train loss 1.1013059616088867, validation loss 1.0894848108291626\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1003438234329224, embedding dim 256, hidden size 2, num layers 1, train loss 1.1013479232788086, validation loss 1.0905437469482422\n",
      "Epoch 100, current patience 30, model mean validation loss 1.095608115196228, embedding dim 256, hidden size 2, num layers 1, train loss 1.0984327793121338, validation loss 1.091125726699829\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0935264825820923, embedding dim 256, hidden size 2, num layers 1, train loss 1.0824249982833862, validation loss 1.095379114151001\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0929017066955566, embedding dim 256, hidden size 2, num layers 1, train loss 1.0483014583587646, validation loss 1.0922777652740479\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0922166109085083, embedding dim 256, hidden size 2, num layers 1, train loss 1.0802215337753296, validation loss 1.094120740890503\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0916467905044556, embedding dim 256, hidden size 2, num layers 1, train loss 1.0913983583450317, validation loss 1.0866020917892456\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0907691717147827, embedding dim 256, hidden size 2, num layers 1, train loss 1.0744788646697998, validation loss 1.0866189002990723\n",
      "Epoch 160, current patience 30, model mean validation loss 1.090053677558899, embedding dim 256, hidden size 2, num layers 1, train loss 1.07350492477417, validation loss 1.083761215209961\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0903369188308716, embedding dim 256, hidden size 2, num layers 1, train loss 1.0930593013763428, validation loss 1.0928096771240234\n",
      "Epoch 180, current patience 29, model mean validation loss 1.090036153793335, embedding dim 256, hidden size 2, num layers 1, train loss 1.0869914293289185, validation loss 1.0887200832366943\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0894396305084229, embedding dim 256, hidden size 2, num layers 1, train loss 1.1010239124298096, validation loss 1.0906070470809937\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0895185470581055, embedding dim 256, hidden size 2, num layers 1, train loss 1.0954160690307617, validation loss 1.0929092168807983\n",
      "Epoch 210, current patience 29, model mean validation loss 1.0894814729690552, embedding dim 256, hidden size 2, num layers 1, train loss 1.1057133674621582, validation loss 1.0938235521316528\n",
      "Epoch 220, current patience 28, model mean validation loss 1.0896778106689453, embedding dim 256, hidden size 2, num layers 1, train loss 1.067002773284912, validation loss 1.0881729125976562\n",
      "Epoch 230, current patience 27, model mean validation loss 1.089904546737671, embedding dim 256, hidden size 2, num layers 1, train loss 1.036967158317566, validation loss 1.0884329080581665\n",
      "Epoch 240, current patience 26, model mean validation loss 1.0905616283416748, embedding dim 256, hidden size 2, num layers 1, train loss 1.0622353553771973, validation loss 1.0890177488327026\n",
      "Epoch 250, current patience 25, model mean validation loss 1.090116262435913, embedding dim 256, hidden size 2, num layers 1, train loss 1.0359508991241455, validation loss 1.0892465114593506\n",
      "Epoch 260, current patience 24, model mean validation loss 1.090165376663208, embedding dim 256, hidden size 2, num layers 1, train loss 1.0822852849960327, validation loss 1.0891138315200806\n",
      "Epoch 270, current patience 23, model mean validation loss 1.090099811553955, embedding dim 256, hidden size 2, num layers 1, train loss 1.1081465482711792, validation loss 1.0900814533233643\n",
      "Epoch 280, current patience 22, model mean validation loss 1.0900781154632568, embedding dim 256, hidden size 2, num layers 1, train loss 1.0842156410217285, validation loss 1.0927355289459229\n",
      "Epoch 290, current patience 21, model mean validation loss 1.088710904121399, embedding dim 256, hidden size 2, num layers 1, train loss 1.0969963073730469, validation loss 1.0828864574432373\n",
      "Epoch 300, current patience 30, model mean validation loss 1.088636875152588, embedding dim 256, hidden size 2, num layers 1, train loss 1.0794018507003784, validation loss 1.087580680847168\n",
      "Epoch 310, current patience 30, model mean validation loss 1.088451862335205, embedding dim 256, hidden size 2, num layers 1, train loss 1.04044771194458, validation loss 1.0869529247283936\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0874545574188232, embedding dim 256, hidden size 2, num layers 1, train loss 1.110591173171997, validation loss 1.0810394287109375\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0869826078414917, embedding dim 256, hidden size 2, num layers 1, train loss 1.022596836090088, validation loss 1.0854703187942505\n",
      "Epoch 340, current patience 30, model mean validation loss 1.0867658853530884, embedding dim 256, hidden size 2, num layers 1, train loss 1.070889949798584, validation loss 1.0873805284500122\n",
      "Epoch 350, current patience 30, model mean validation loss 1.0858154296875, embedding dim 256, hidden size 2, num layers 1, train loss 1.100638747215271, validation loss 1.0824776887893677\n",
      "Epoch 360, current patience 30, model mean validation loss 1.0856870412826538, embedding dim 256, hidden size 2, num layers 1, train loss 1.0903818607330322, validation loss 1.0917084217071533\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0865731239318848, embedding dim 256, hidden size 2, num layers 1, train loss 1.0578416585922241, validation loss 1.0899746417999268\n",
      "Epoch 380, current patience 29, model mean validation loss 1.086547613143921, embedding dim 256, hidden size 2, num layers 1, train loss 1.063650131225586, validation loss 1.0873771905899048\n",
      "Epoch 390, current patience 28, model mean validation loss 1.0876446962356567, embedding dim 256, hidden size 2, num layers 1, train loss 1.0594444274902344, validation loss 1.0957287549972534\n",
      "Epoch 400, current patience 27, model mean validation loss 1.088293433189392, embedding dim 256, hidden size 2, num layers 1, train loss 1.10271155834198, validation loss 1.0862298011779785\n",
      "Epoch 410, current patience 26, model mean validation loss 1.0894675254821777, embedding dim 256, hidden size 2, num layers 1, train loss 1.0274358987808228, validation loss 1.0948622226715088\n",
      "Epoch 420, current patience 25, model mean validation loss 1.0902318954467773, embedding dim 256, hidden size 2, num layers 1, train loss 1.0454097986221313, validation loss 1.0934967994689941\n",
      "Epoch 430, current patience 24, model mean validation loss 1.0910353660583496, embedding dim 256, hidden size 2, num layers 1, train loss 1.0117828845977783, validation loss 1.0889050960540771\n",
      "Epoch 440, current patience 23, model mean validation loss 1.0917634963989258, embedding dim 256, hidden size 2, num layers 1, train loss 1.0359207391738892, validation loss 1.0975334644317627\n",
      "Epoch 450, current patience 22, model mean validation loss 1.0924627780914307, embedding dim 256, hidden size 2, num layers 1, train loss 1.0375208854675293, validation loss 1.0955690145492554\n",
      "Epoch 460, current patience 21, model mean validation loss 1.0934619903564453, embedding dim 256, hidden size 2, num layers 1, train loss 0.9661520719528198, validation loss 1.0953712463378906\n",
      "Epoch 470, current patience 20, model mean validation loss 1.0940110683441162, embedding dim 256, hidden size 2, num layers 1, train loss 1.0255632400512695, validation loss 1.100121259689331\n",
      "Epoch 480, current patience 19, model mean validation loss 1.0957880020141602, embedding dim 256, hidden size 2, num layers 1, train loss 1.0920348167419434, validation loss 1.1004453897476196\n",
      "Epoch 490, current patience 18, model mean validation loss 1.0950510501861572, embedding dim 256, hidden size 2, num layers 1, train loss 1.0632870197296143, validation loss 1.0889662504196167\n",
      "Epoch 500, current patience 17, model mean validation loss 1.0964959859848022, embedding dim 256, hidden size 2, num layers 1, train loss 1.0457431077957153, validation loss 1.1050556898117065\n",
      "Epoch 510, current patience 16, model mean validation loss 1.0973843336105347, embedding dim 256, hidden size 2, num layers 1, train loss 1.0768362283706665, validation loss 1.0960123538970947\n",
      "Epoch 520, current patience 15, model mean validation loss 1.0980424880981445, embedding dim 256, hidden size 2, num layers 1, train loss 1.0921344757080078, validation loss 1.1027984619140625\n",
      "Epoch 530, current patience 14, model mean validation loss 1.0987071990966797, embedding dim 256, hidden size 2, num layers 1, train loss 1.0417207479476929, validation loss 1.1008868217468262\n",
      "Epoch 540, current patience 13, model mean validation loss 1.0985313653945923, embedding dim 256, hidden size 2, num layers 1, train loss 1.0250383615493774, validation loss 1.0939645767211914\n",
      "Epoch 550, current patience 12, model mean validation loss 1.0973830223083496, embedding dim 256, hidden size 2, num layers 1, train loss 1.0828602313995361, validation loss 1.0909340381622314\n",
      "Epoch 560, current patience 11, model mean validation loss 1.098076343536377, embedding dim 256, hidden size 2, num layers 1, train loss 0.9946305751800537, validation loss 1.1059918403625488\n",
      "Epoch 570, current patience 10, model mean validation loss 1.0993608236312866, embedding dim 256, hidden size 2, num layers 1, train loss 1.056465983390808, validation loss 1.099242925643921\n",
      "Epoch 580, current patience 9, model mean validation loss 1.0979185104370117, embedding dim 256, hidden size 2, num layers 1, train loss 1.0701022148132324, validation loss 1.093517541885376\n",
      "Epoch 590, current patience 8, model mean validation loss 1.0980594158172607, embedding dim 256, hidden size 2, num layers 1, train loss 1.0476562976837158, validation loss 1.0971394777297974\n",
      "Epoch 600, current patience 7, model mean validation loss 1.0974419116973877, embedding dim 256, hidden size 2, num layers 1, train loss 1.05653977394104, validation loss 1.0978575944900513\n",
      "Epoch 610, current patience 6, model mean validation loss 1.0964243412017822, embedding dim 256, hidden size 2, num layers 1, train loss 1.09791898727417, validation loss 1.092746376991272\n",
      "Epoch 620, current patience 5, model mean validation loss 1.0969321727752686, embedding dim 256, hidden size 2, num layers 1, train loss 1.057012677192688, validation loss 1.0980273485183716\n",
      "Epoch 630, current patience 4, model mean validation loss 1.0973470211029053, embedding dim 256, hidden size 2, num layers 1, train loss 1.0299694538116455, validation loss 1.0942528247833252\n",
      "Epoch 640, current patience 3, model mean validation loss 1.0959322452545166, embedding dim 256, hidden size 2, num layers 1, train loss 1.071929931640625, validation loss 1.0946732759475708\n",
      "Epoch 650, current patience 2, model mean validation loss 1.095112681388855, embedding dim 256, hidden size 2, num layers 1, train loss 1.0198543071746826, validation loss 1.0926868915557861\n",
      "Epoch 660, current patience 1, model mean validation loss 1.096317172050476, embedding dim 256, hidden size 2, num layers 1, train loss 1.0461362600326538, validation loss 1.103153109550476\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1394942998886108, embedding dim 256, hidden size 4, num layers 1, train loss 1.147297739982605, validation loss 1.1394942998886108\n",
      "Epoch 10, current patience 30, model mean validation loss 1.12376070022583, embedding dim 256, hidden size 4, num layers 1, train loss 1.1277775764465332, validation loss 1.1080272197723389\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1141387224197388, embedding dim 256, hidden size 4, num layers 1, train loss 1.094702959060669, validation loss 1.0948950052261353\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1094310283660889, embedding dim 256, hidden size 4, num layers 1, train loss 1.0940721035003662, validation loss 1.0953080654144287\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1056572198867798, embedding dim 256, hidden size 4, num layers 1, train loss 1.0636019706726074, validation loss 1.0905611515045166\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1039053201675415, embedding dim 256, hidden size 4, num layers 1, train loss 1.1044374704360962, validation loss 1.0951464176177979\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1021766662597656, embedding dim 256, hidden size 4, num layers 1, train loss 1.0962398052215576, validation loss 1.0918043851852417\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1009011268615723, embedding dim 256, hidden size 4, num layers 1, train loss 1.1064870357513428, validation loss 1.0919729471206665\n",
      "Epoch 80, current patience 30, model mean validation loss 1.094983696937561, embedding dim 256, hidden size 4, num layers 1, train loss 1.0915402173995972, validation loss 1.0921545028686523\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0923528671264648, embedding dim 256, hidden size 4, num layers 1, train loss 1.0928372144699097, validation loss 1.0869802236557007\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0914859771728516, embedding dim 256, hidden size 4, num layers 1, train loss 1.0530319213867188, validation loss 1.087959885597229\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0898551940917969, embedding dim 256, hidden size 4, num layers 1, train loss 1.063690185546875, validation loss 1.082261323928833\n",
      "Epoch 120, current patience 30, model mean validation loss 1.089773416519165, embedding dim 256, hidden size 4, num layers 1, train loss 1.0126488208770752, validation loss 1.0899077653884888\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0889618396759033, embedding dim 256, hidden size 4, num layers 1, train loss 1.068629503250122, validation loss 1.0886536836624146\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0889314413070679, embedding dim 256, hidden size 4, num layers 1, train loss 0.982811689376831, validation loss 1.091560959815979\n",
      "Epoch 150, current patience 30, model mean validation loss 1.088952898979187, embedding dim 256, hidden size 4, num layers 1, train loss 0.9924337863922119, validation loss 1.0921449661254883\n",
      "Epoch 160, current patience 29, model mean validation loss 1.0901614427566528, embedding dim 256, hidden size 4, num layers 1, train loss 1.0621529817581177, validation loss 1.1018229722976685\n",
      "Epoch 170, current patience 28, model mean validation loss 1.0924317836761475, embedding dim 256, hidden size 4, num layers 1, train loss 1.0021653175354004, validation loss 1.1051430702209473\n",
      "Epoch 180, current patience 27, model mean validation loss 1.0950318574905396, embedding dim 256, hidden size 4, num layers 1, train loss 1.0466986894607544, validation loss 1.1087604761123657\n",
      "Epoch 190, current patience 26, model mean validation loss 1.0982489585876465, embedding dim 256, hidden size 4, num layers 1, train loss 1.0239098072052002, validation loss 1.1079974174499512\n",
      "Epoch 200, current patience 25, model mean validation loss 1.0983235836029053, embedding dim 256, hidden size 4, num layers 1, train loss 1.0344147682189941, validation loss 1.0905051231384277\n",
      "Epoch 210, current patience 24, model mean validation loss 1.098061442375183, embedding dim 256, hidden size 4, num layers 1, train loss 1.117902398109436, validation loss 1.0865561962127686\n",
      "Epoch 220, current patience 23, model mean validation loss 1.0988178253173828, embedding dim 256, hidden size 4, num layers 1, train loss 1.0358383655548096, validation loss 1.0976133346557617\n",
      "Epoch 230, current patience 22, model mean validation loss 1.0993926525115967, embedding dim 256, hidden size 4, num layers 1, train loss 0.9466261863708496, validation loss 1.0967423915863037\n",
      "Epoch 240, current patience 21, model mean validation loss 1.0997976064682007, embedding dim 256, hidden size 4, num layers 1, train loss 1.005637764930725, validation loss 1.10506272315979\n",
      "Epoch 250, current patience 20, model mean validation loss 1.1001248359680176, embedding dim 256, hidden size 4, num layers 1, train loss 0.9335843324661255, validation loss 1.1077604293823242\n",
      "Epoch 260, current patience 19, model mean validation loss 1.0995237827301025, embedding dim 256, hidden size 4, num layers 1, train loss 1.011461615562439, validation loss 1.1039520502090454\n",
      "Epoch 270, current patience 18, model mean validation loss 1.09783935546875, embedding dim 256, hidden size 4, num layers 1, train loss 0.9216626286506653, validation loss 1.0945231914520264\n",
      "Epoch 280, current patience 17, model mean validation loss 1.0996023416519165, embedding dim 256, hidden size 4, num layers 1, train loss 1.1390793323516846, validation loss 1.1046085357666016\n",
      "Epoch 290, current patience 16, model mean validation loss 1.1026968955993652, embedding dim 256, hidden size 4, num layers 1, train loss 0.9462970495223999, validation loss 1.1113131046295166\n",
      "Epoch 300, current patience 15, model mean validation loss 1.1032602787017822, embedding dim 256, hidden size 4, num layers 1, train loss 1.0420687198638916, validation loss 1.1021195650100708\n",
      "Epoch 310, current patience 14, model mean validation loss 1.103508710861206, embedding dim 256, hidden size 4, num layers 1, train loss 0.9949210286140442, validation loss 1.0987300872802734\n",
      "Epoch 320, current patience 13, model mean validation loss 1.1035584211349487, embedding dim 256, hidden size 4, num layers 1, train loss 1.1085485219955444, validation loss 1.1054604053497314\n",
      "Epoch 330, current patience 12, model mean validation loss 1.1022944450378418, embedding dim 256, hidden size 4, num layers 1, train loss 0.9598718881607056, validation loss 1.0976479053497314\n",
      "Epoch 340, current patience 11, model mean validation loss 1.1029205322265625, embedding dim 256, hidden size 4, num layers 1, train loss 0.8750449419021606, validation loss 1.1089613437652588\n",
      "Epoch 350, current patience 10, model mean validation loss 1.1047042608261108, embedding dim 256, hidden size 4, num layers 1, train loss 0.9747006893157959, validation loss 1.1087926626205444\n",
      "Epoch 360, current patience 9, model mean validation loss 1.1065963506698608, embedding dim 256, hidden size 4, num layers 1, train loss 0.8980391025543213, validation loss 1.1197457313537598\n",
      "Epoch 370, current patience 8, model mean validation loss 1.1076467037200928, embedding dim 256, hidden size 4, num layers 1, train loss 1.0020012855529785, validation loss 1.1197154521942139\n",
      "Epoch 380, current patience 7, model mean validation loss 1.1093943119049072, embedding dim 256, hidden size 4, num layers 1, train loss 1.1049082279205322, validation loss 1.116100788116455\n",
      "Epoch 390, current patience 6, model mean validation loss 1.109832763671875, embedding dim 256, hidden size 4, num layers 1, train loss 0.8947725296020508, validation loss 1.1022369861602783\n",
      "Epoch 400, current patience 5, model mean validation loss 1.111882209777832, embedding dim 256, hidden size 4, num layers 1, train loss 0.9869624972343445, validation loss 1.1218571662902832\n",
      "Epoch 410, current patience 4, model mean validation loss 1.1139779090881348, embedding dim 256, hidden size 4, num layers 1, train loss 0.896146297454834, validation loss 1.1144139766693115\n",
      "Epoch 420, current patience 3, model mean validation loss 1.1162285804748535, embedding dim 256, hidden size 4, num layers 1, train loss 0.9320569038391113, validation loss 1.1269665956497192\n",
      "Epoch 430, current patience 2, model mean validation loss 1.1231062412261963, embedding dim 256, hidden size 4, num layers 1, train loss 0.9926393032073975, validation loss 1.163813829421997\n",
      "Epoch 440, current patience 1, model mean validation loss 1.1268541812896729, embedding dim 256, hidden size 4, num layers 1, train loss 0.8912084102630615, validation loss 1.149728775024414\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1338789463043213, embedding dim 256, hidden size 8, num layers 1, train loss 1.1367456912994385, validation loss 1.1338789463043213\n",
      "Epoch 10, current patience 30, model mean validation loss 1.11647629737854, embedding dim 256, hidden size 8, num layers 1, train loss 1.102480173110962, validation loss 1.0990736484527588\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1096423864364624, embedding dim 256, hidden size 8, num layers 1, train loss 1.124237060546875, validation loss 1.0959746837615967\n",
      "Epoch 30, current patience 30, model mean validation loss 1.10575270652771, embedding dim 256, hidden size 8, num layers 1, train loss 1.1005253791809082, validation loss 1.0940837860107422\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1034640073776245, embedding dim 256, hidden size 8, num layers 1, train loss 1.090173363685608, validation loss 1.0943090915679932\n",
      "Epoch 50, current patience 30, model mean validation loss 1.101655125617981, embedding dim 256, hidden size 8, num layers 1, train loss 1.081295132637024, validation loss 1.0926110744476318\n",
      "Epoch 60, current patience 30, model mean validation loss 1.100088357925415, embedding dim 256, hidden size 8, num layers 1, train loss 1.100658893585205, validation loss 1.09068763256073\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0992431640625, embedding dim 256, hidden size 8, num layers 1, train loss 1.0901033878326416, validation loss 1.0933263301849365\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0929319858551025, embedding dim 256, hidden size 8, num layers 1, train loss 1.0990641117095947, validation loss 1.0833898782730103\n",
      "Epoch 90, current patience 30, model mean validation loss 1.090869665145874, embedding dim 256, hidden size 8, num layers 1, train loss 1.058530569076538, validation loss 1.0825753211975098\n",
      "Epoch 100, current patience 30, model mean validation loss 1.08724045753479, embedding dim 256, hidden size 8, num layers 1, train loss 0.9806159734725952, validation loss 1.0669406652450562\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0829834938049316, embedding dim 256, hidden size 8, num layers 1, train loss 1.0117127895355225, validation loss 1.0600285530090332\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0789084434509277, embedding dim 256, hidden size 8, num layers 1, train loss 1.0557342767715454, validation loss 1.061707615852356\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0726895332336426, embedding dim 256, hidden size 8, num layers 1, train loss 0.9712036848068237, validation loss 1.0428601503372192\n",
      "Epoch 140, current patience 30, model mean validation loss 1.066814661026001, embedding dim 256, hidden size 8, num layers 1, train loss 0.8570815324783325, validation loss 1.0436885356903076\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0564935207366943, embedding dim 256, hidden size 8, num layers 1, train loss 1.0066877603530884, validation loss 1.010757565498352\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0481868982315063, embedding dim 256, hidden size 8, num layers 1, train loss 0.9956856966018677, validation loss 1.016937017440796\n",
      "Epoch 170, current patience 30, model mean validation loss 1.037643551826477, embedding dim 256, hidden size 8, num layers 1, train loss 1.0914790630340576, validation loss 0.9982281923294067\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0267001390457153, embedding dim 256, hidden size 8, num layers 1, train loss 0.7960613965988159, validation loss 0.9793933629989624\n",
      "Epoch 190, current patience 30, model mean validation loss 1.019045352935791, embedding dim 256, hidden size 8, num layers 1, train loss 0.9250655174255371, validation loss 0.9987902641296387\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0130598545074463, embedding dim 256, hidden size 8, num layers 1, train loss 0.7992722988128662, validation loss 1.0138237476348877\n",
      "Epoch 210, current patience 30, model mean validation loss 1.005448818206787, embedding dim 256, hidden size 8, num layers 1, train loss 0.701788604259491, validation loss 0.9819721579551697\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0011152029037476, embedding dim 256, hidden size 8, num layers 1, train loss 0.8834022283554077, validation loss 1.009019136428833\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9990237951278687, embedding dim 256, hidden size 8, num layers 1, train loss 0.6358311772346497, validation loss 0.9940264821052551\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9978564977645874, embedding dim 256, hidden size 8, num layers 1, train loss 0.6777946352958679, validation loss 1.007598876953125\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9997804164886475, embedding dim 256, hidden size 8, num layers 1, train loss 0.7544596195220947, validation loss 1.0136189460754395\n",
      "Epoch 260, current patience 29, model mean validation loss 1.0030326843261719, embedding dim 256, hidden size 8, num layers 1, train loss 0.6455360651016235, validation loss 1.0054118633270264\n",
      "Epoch 270, current patience 28, model mean validation loss 1.005864143371582, embedding dim 256, hidden size 8, num layers 1, train loss 0.7686797380447388, validation loss 1.0214426517486572\n",
      "Epoch 280, current patience 27, model mean validation loss 1.0041866302490234, embedding dim 256, hidden size 8, num layers 1, train loss 0.96163010597229, validation loss 1.0004026889801025\n",
      "Epoch 290, current patience 26, model mean validation loss 1.0064584016799927, embedding dim 256, hidden size 8, num layers 1, train loss 0.787477433681488, validation loss 1.0001463890075684\n",
      "Epoch 300, current patience 25, model mean validation loss 1.0037215948104858, embedding dim 256, hidden size 8, num layers 1, train loss 1.0285780429840088, validation loss 0.9871248006820679\n",
      "Epoch 310, current patience 24, model mean validation loss 1.003206729888916, embedding dim 256, hidden size 8, num layers 1, train loss 0.7562893629074097, validation loss 0.98990797996521\n",
      "Epoch 320, current patience 23, model mean validation loss 1.000272512435913, embedding dim 256, hidden size 8, num layers 1, train loss 0.6468640565872192, validation loss 0.9841253757476807\n",
      "Epoch 330, current patience 22, model mean validation loss 0.9937832355499268, embedding dim 256, hidden size 8, num layers 1, train loss 0.7722901701927185, validation loss 0.9617044925689697\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9908020496368408, embedding dim 256, hidden size 8, num layers 1, train loss 0.9059591889381409, validation loss 0.9815621376037598\n",
      "Epoch 350, current patience 30, model mean validation loss 0.9848613739013672, embedding dim 256, hidden size 8, num layers 1, train loss 0.7890889644622803, validation loss 0.9739170074462891\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9832810163497925, embedding dim 256, hidden size 8, num layers 1, train loss 0.6032236814498901, validation loss 0.9877601861953735\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9758617281913757, embedding dim 256, hidden size 8, num layers 1, train loss 0.7613958120346069, validation loss 0.9407919645309448\n",
      "Epoch 380, current patience 30, model mean validation loss 0.9725626707077026, embedding dim 256, hidden size 8, num layers 1, train loss 0.6803731918334961, validation loss 0.9607324600219727\n",
      "Epoch 390, current patience 30, model mean validation loss 0.9762494564056396, embedding dim 256, hidden size 8, num layers 1, train loss 0.5584566593170166, validation loss 1.0194019079208374\n",
      "Epoch 400, current patience 29, model mean validation loss 0.9773491621017456, embedding dim 256, hidden size 8, num layers 1, train loss 1.0185105800628662, validation loss 0.992923378944397\n",
      "Epoch 410, current patience 28, model mean validation loss 0.9794617295265198, embedding dim 256, hidden size 8, num layers 1, train loss 0.6640642881393433, validation loss 0.9786050319671631\n",
      "Epoch 420, current patience 27, model mean validation loss 0.9784790277481079, embedding dim 256, hidden size 8, num layers 1, train loss 0.8616546392440796, validation loss 0.9737006425857544\n",
      "Epoch 430, current patience 26, model mean validation loss 0.9772118926048279, embedding dim 256, hidden size 8, num layers 1, train loss 0.4856632947921753, validation loss 0.9637795686721802\n",
      "Epoch 440, current patience 25, model mean validation loss 0.9825956225395203, embedding dim 256, hidden size 8, num layers 1, train loss 0.6667242050170898, validation loss 1.0308301448822021\n",
      "Epoch 450, current patience 24, model mean validation loss 0.9907503128051758, embedding dim 256, hidden size 8, num layers 1, train loss 0.6730921268463135, validation loss 1.0060296058654785\n",
      "Epoch 460, current patience 23, model mean validation loss 0.9961649179458618, embedding dim 256, hidden size 8, num layers 1, train loss 0.5892888307571411, validation loss 1.004049301147461\n",
      "Epoch 470, current patience 22, model mean validation loss 0.992212176322937, embedding dim 256, hidden size 8, num layers 1, train loss 0.7335696220397949, validation loss 0.9877792596817017\n",
      "Epoch 480, current patience 21, model mean validation loss 0.9920226335525513, embedding dim 256, hidden size 8, num layers 1, train loss 0.59858638048172, validation loss 0.9914073348045349\n",
      "Epoch 490, current patience 20, model mean validation loss 0.9939168691635132, embedding dim 256, hidden size 8, num layers 1, train loss 0.5300397276878357, validation loss 0.9937588572502136\n",
      "Epoch 500, current patience 19, model mean validation loss 0.9963725805282593, embedding dim 256, hidden size 8, num layers 1, train loss 0.6155052185058594, validation loss 0.993346095085144\n",
      "Epoch 510, current patience 18, model mean validation loss 0.9942743182182312, embedding dim 256, hidden size 8, num layers 1, train loss 0.8758091926574707, validation loss 0.9469937086105347\n",
      "Epoch 520, current patience 17, model mean validation loss 0.9891866445541382, embedding dim 256, hidden size 8, num layers 1, train loss 0.5811007022857666, validation loss 0.9901293516159058\n",
      "Epoch 530, current patience 16, model mean validation loss 0.9894158840179443, embedding dim 256, hidden size 8, num layers 1, train loss 0.6561581492424011, validation loss 1.0078630447387695\n",
      "Epoch 540, current patience 15, model mean validation loss 0.9904394149780273, embedding dim 256, hidden size 8, num layers 1, train loss 0.5867375731468201, validation loss 1.0122374296188354\n",
      "Epoch 550, current patience 14, model mean validation loss 0.9946534037590027, embedding dim 256, hidden size 8, num layers 1, train loss 0.7140216827392578, validation loss 1.021491527557373\n",
      "Epoch 560, current patience 13, model mean validation loss 0.9976555109024048, embedding dim 256, hidden size 8, num layers 1, train loss 0.4182547926902771, validation loss 1.0154236555099487\n",
      "Epoch 570, current patience 12, model mean validation loss 1.0042780637741089, embedding dim 256, hidden size 8, num layers 1, train loss 0.44989800453186035, validation loss 1.0467395782470703\n",
      "Epoch 580, current patience 11, model mean validation loss 1.0138295888900757, embedding dim 256, hidden size 8, num layers 1, train loss 0.46684104204177856, validation loss 1.0697587728500366\n",
      "Epoch 590, current patience 10, model mean validation loss 1.0253955125808716, embedding dim 256, hidden size 8, num layers 1, train loss 0.5711259841918945, validation loss 1.039520502090454\n",
      "Epoch 600, current patience 9, model mean validation loss 1.0294592380523682, embedding dim 256, hidden size 8, num layers 1, train loss 0.5630463361740112, validation loss 1.0226389169692993\n",
      "Epoch 610, current patience 8, model mean validation loss 1.0404385328292847, embedding dim 256, hidden size 8, num layers 1, train loss 0.36440056562423706, validation loss 1.0956979990005493\n",
      "Epoch 620, current patience 7, model mean validation loss 1.0429925918579102, embedding dim 256, hidden size 8, num layers 1, train loss 0.7846561074256897, validation loss 1.0326699018478394\n",
      "Epoch 630, current patience 6, model mean validation loss 1.0356221199035645, embedding dim 256, hidden size 8, num layers 1, train loss 0.6499632596969604, validation loss 0.9625284671783447\n",
      "Epoch 640, current patience 5, model mean validation loss 1.0377941131591797, embedding dim 256, hidden size 8, num layers 1, train loss 0.6810972094535828, validation loss 1.0327990055084229\n",
      "Epoch 650, current patience 4, model mean validation loss 1.0324535369873047, embedding dim 256, hidden size 8, num layers 1, train loss 0.5906331539154053, validation loss 1.004014492034912\n",
      "Epoch 660, current patience 3, model mean validation loss 1.0262470245361328, embedding dim 256, hidden size 8, num layers 1, train loss 0.5285216569900513, validation loss 1.0201070308685303\n",
      "Epoch 670, current patience 2, model mean validation loss 1.0272698402404785, embedding dim 256, hidden size 8, num layers 1, train loss 0.603195309638977, validation loss 1.047702670097351\n",
      "Epoch 680, current patience 1, model mean validation loss 1.0214139223098755, embedding dim 256, hidden size 8, num layers 1, train loss 0.4078647792339325, validation loss 0.9757923483848572\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0951542854309082, embedding dim 256, hidden size 16, num layers 1, train loss 1.0928013324737549, validation loss 1.0951542854309082\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0958068370819092, embedding dim 256, hidden size 16, num layers 1, train loss 1.0980687141418457, validation loss 1.0964595079421997\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0945104360580444, embedding dim 256, hidden size 16, num layers 1, train loss 1.0933265686035156, validation loss 1.0919177532196045\n",
      "Epoch 30, current patience 30, model mean validation loss 1.092832326889038, embedding dim 256, hidden size 16, num layers 1, train loss 1.0953943729400635, validation loss 1.08779776096344\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0903689861297607, embedding dim 256, hidden size 16, num layers 1, train loss 1.0661486387252808, validation loss 1.0805151462554932\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0838178396224976, embedding dim 256, hidden size 16, num layers 1, train loss 1.0460636615753174, validation loss 1.051062822341919\n",
      "Epoch 60, current patience 30, model mean validation loss 1.078452229499817, embedding dim 256, hidden size 16, num layers 1, train loss 0.9409323334693909, validation loss 1.0462579727172852\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0698174238204956, embedding dim 256, hidden size 16, num layers 1, train loss 1.0345592498779297, validation loss 1.0093740224838257\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0593464374542236, embedding dim 256, hidden size 16, num layers 1, train loss 0.8805855512619019, validation loss 1.0113866329193115\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0474915504455566, embedding dim 256, hidden size 16, num layers 1, train loss 1.1089632511138916, validation loss 1.0016205310821533\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0291306972503662, embedding dim 256, hidden size 16, num layers 1, train loss 1.091994047164917, validation loss 0.9450305700302124\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0143684148788452, embedding dim 256, hidden size 16, num layers 1, train loss 0.9689521193504333, validation loss 0.9696993827819824\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9982773065567017, embedding dim 256, hidden size 16, num layers 1, train loss 0.8134565353393555, validation loss 0.9517865180969238\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9868450164794922, embedding dim 256, hidden size 16, num layers 1, train loss 0.888667106628418, validation loss 0.9596043229103088\n",
      "Epoch 140, current patience 30, model mean validation loss 0.973395824432373, embedding dim 256, hidden size 16, num layers 1, train loss 0.6717824935913086, validation loss 0.9386647939682007\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9694656729698181, embedding dim 256, hidden size 16, num layers 1, train loss 0.6397413015365601, validation loss 0.977932870388031\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9663064479827881, embedding dim 256, hidden size 16, num layers 1, train loss 0.7028226256370544, validation loss 0.9861124157905579\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9540757536888123, embedding dim 256, hidden size 16, num layers 1, train loss 0.7695654630661011, validation loss 0.903775155544281\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9557175636291504, embedding dim 256, hidden size 16, num layers 1, train loss 0.8083755970001221, validation loss 0.9581650495529175\n",
      "Epoch 190, current patience 29, model mean validation loss 0.9542087316513062, embedding dim 256, hidden size 16, num layers 1, train loss 0.4140170216560364, validation loss 0.9576288461685181\n",
      "Epoch 200, current patience 28, model mean validation loss 0.9537588357925415, embedding dim 256, hidden size 16, num layers 1, train loss 1.1932461261749268, validation loss 0.948186993598938\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9456562995910645, embedding dim 256, hidden size 16, num layers 1, train loss 0.6543750762939453, validation loss 0.8947842121124268\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9424686431884766, embedding dim 256, hidden size 16, num layers 1, train loss 0.9301576614379883, validation loss 0.913163423538208\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9305617809295654, embedding dim 256, hidden size 16, num layers 1, train loss 0.5634632110595703, validation loss 0.8826781511306763\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9199867844581604, embedding dim 256, hidden size 16, num layers 1, train loss 0.8407073020935059, validation loss 0.9015123844146729\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9204208850860596, embedding dim 256, hidden size 16, num layers 1, train loss 0.7367596626281738, validation loss 0.9072479009628296\n",
      "Epoch 260, current patience 29, model mean validation loss 0.9155188798904419, embedding dim 256, hidden size 16, num layers 1, train loss 0.7251290678977966, validation loss 0.9189494848251343\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9178189039230347, embedding dim 256, hidden size 16, num layers 1, train loss 0.49634361267089844, validation loss 0.9760288000106812\n",
      "Epoch 280, current patience 29, model mean validation loss 0.9225539565086365, embedding dim 256, hidden size 16, num layers 1, train loss 0.6942379474639893, validation loss 0.986066997051239\n",
      "Epoch 290, current patience 28, model mean validation loss 0.933845043182373, embedding dim 256, hidden size 16, num layers 1, train loss 0.6587144136428833, validation loss 0.9851131439208984\n",
      "Epoch 300, current patience 27, model mean validation loss 0.9365415573120117, embedding dim 256, hidden size 16, num layers 1, train loss 0.5504217743873596, validation loss 0.9347356557846069\n",
      "Epoch 310, current patience 26, model mean validation loss 0.9505288600921631, embedding dim 256, hidden size 16, num layers 1, train loss 0.43584123253822327, validation loss 0.9945762157440186\n",
      "Epoch 320, current patience 25, model mean validation loss 0.954862117767334, embedding dim 256, hidden size 16, num layers 1, train loss 0.6589002013206482, validation loss 0.9361791610717773\n",
      "Epoch 330, current patience 24, model mean validation loss 0.9610206484794617, embedding dim 256, hidden size 16, num layers 1, train loss 0.6640717387199402, validation loss 0.9565157890319824\n",
      "Epoch 340, current patience 23, model mean validation loss 0.9643966555595398, embedding dim 256, hidden size 16, num layers 1, train loss 0.6941908597946167, validation loss 0.945957362651825\n",
      "Epoch 350, current patience 22, model mean validation loss 0.9585623741149902, embedding dim 256, hidden size 16, num layers 1, train loss 0.8791747093200684, validation loss 0.9293550252914429\n",
      "Epoch 360, current patience 21, model mean validation loss 0.9505347013473511, embedding dim 256, hidden size 16, num layers 1, train loss 0.7123731970787048, validation loss 0.9218452572822571\n",
      "Epoch 370, current patience 20, model mean validation loss 0.9467734098434448, embedding dim 256, hidden size 16, num layers 1, train loss 0.5439591407775879, validation loss 0.9550231099128723\n",
      "Epoch 380, current patience 19, model mean validation loss 0.9432220458984375, embedding dim 256, hidden size 16, num layers 1, train loss 0.5316067337989807, validation loss 0.9063242077827454\n",
      "Epoch 390, current patience 18, model mean validation loss 0.9420098066329956, embedding dim 256, hidden size 16, num layers 1, train loss 0.63181471824646, validation loss 0.984878420829773\n",
      "Epoch 400, current patience 17, model mean validation loss 0.9457072019577026, embedding dim 256, hidden size 16, num layers 1, train loss 0.5232924222946167, validation loss 0.9657583832740784\n",
      "Epoch 410, current patience 16, model mean validation loss 0.9409237504005432, embedding dim 256, hidden size 16, num layers 1, train loss 0.5312275886535645, validation loss 0.9182483553886414\n",
      "Epoch 420, current patience 15, model mean validation loss 0.9416593313217163, embedding dim 256, hidden size 16, num layers 1, train loss 0.32127487659454346, validation loss 0.9518417119979858\n",
      "Epoch 430, current patience 14, model mean validation loss 0.944719672203064, embedding dim 256, hidden size 16, num layers 1, train loss 0.3891379237174988, validation loss 0.9538372159004211\n",
      "Epoch 440, current patience 13, model mean validation loss 0.9565520286560059, embedding dim 256, hidden size 16, num layers 1, train loss 0.4387168884277344, validation loss 1.0165047645568848\n",
      "Epoch 450, current patience 12, model mean validation loss 0.9565565586090088, embedding dim 256, hidden size 16, num layers 1, train loss 0.42063042521476746, validation loss 0.9550595879554749\n",
      "Epoch 460, current patience 11, model mean validation loss 0.9686404466629028, embedding dim 256, hidden size 16, num layers 1, train loss 0.2886859178543091, validation loss 1.002995252609253\n",
      "Epoch 470, current patience 10, model mean validation loss 0.965070366859436, embedding dim 256, hidden size 16, num layers 1, train loss 1.0611813068389893, validation loss 0.9563175439834595\n",
      "Epoch 480, current patience 9, model mean validation loss 0.963532567024231, embedding dim 256, hidden size 16, num layers 1, train loss 0.33593058586120605, validation loss 0.9534557461738586\n",
      "Epoch 490, current patience 8, model mean validation loss 0.9772999882698059, embedding dim 256, hidden size 16, num layers 1, train loss 0.428722083568573, validation loss 1.0283880233764648\n",
      "Epoch 500, current patience 7, model mean validation loss 0.9822237491607666, embedding dim 256, hidden size 16, num layers 1, train loss 0.39088234305381775, validation loss 0.99123215675354\n",
      "Epoch 510, current patience 6, model mean validation loss 0.9869513511657715, embedding dim 256, hidden size 16, num layers 1, train loss 0.4979010820388794, validation loss 0.9916574954986572\n",
      "Epoch 520, current patience 5, model mean validation loss 0.9860703945159912, embedding dim 256, hidden size 16, num layers 1, train loss 0.30225157737731934, validation loss 1.009456992149353\n",
      "Epoch 530, current patience 4, model mean validation loss 0.9946132898330688, embedding dim 256, hidden size 16, num layers 1, train loss 0.42168205976486206, validation loss 1.0234029293060303\n",
      "Epoch 540, current patience 3, model mean validation loss 0.9962024688720703, embedding dim 256, hidden size 16, num layers 1, train loss 0.3235619068145752, validation loss 1.0157084465026855\n",
      "Epoch 550, current patience 2, model mean validation loss 1.005079984664917, embedding dim 256, hidden size 16, num layers 1, train loss 0.4415062963962555, validation loss 1.0273373126983643\n",
      "Epoch 560, current patience 1, model mean validation loss 1.0155168771743774, embedding dim 256, hidden size 16, num layers 1, train loss 0.29290762543678284, validation loss 1.0369515419006348\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0991913080215454, embedding dim 256, hidden size 32, num layers 1, train loss 1.1046350002288818, validation loss 1.0991913080215454\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0957140922546387, embedding dim 256, hidden size 32, num layers 1, train loss 1.0838993787765503, validation loss 1.0922369956970215\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0930947065353394, embedding dim 256, hidden size 32, num layers 1, train loss 1.100362777709961, validation loss 1.0878558158874512\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0895564556121826, embedding dim 256, hidden size 32, num layers 1, train loss 1.094517707824707, validation loss 1.078941822052002\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0831499099731445, embedding dim 256, hidden size 32, num layers 1, train loss 1.0657949447631836, validation loss 1.057523488998413\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0710378885269165, embedding dim 256, hidden size 32, num layers 1, train loss 0.8642839193344116, validation loss 1.0104782581329346\n",
      "Epoch 60, current patience 30, model mean validation loss 1.063048005104065, embedding dim 256, hidden size 32, num layers 1, train loss 1.0916873216629028, validation loss 1.0151079893112183\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0531129837036133, embedding dim 256, hidden size 32, num layers 1, train loss 0.971007764339447, validation loss 0.9835686683654785\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0350607633590698, embedding dim 256, hidden size 32, num layers 1, train loss 1.0026429891586304, validation loss 0.95477294921875\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0161352157592773, embedding dim 256, hidden size 32, num layers 1, train loss 0.8452125787734985, validation loss 0.9408331513404846\n",
      "Epoch 100, current patience 30, model mean validation loss 0.997033953666687, embedding dim 256, hidden size 32, num layers 1, train loss 0.9558168053627014, validation loss 0.9350451827049255\n",
      "Epoch 110, current patience 30, model mean validation loss 0.975891649723053, embedding dim 256, hidden size 32, num layers 1, train loss 0.693100094795227, validation loss 0.9098032712936401\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9603666067123413, embedding dim 256, hidden size 32, num layers 1, train loss 0.8566834926605225, validation loss 0.933323085308075\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9447218179702759, embedding dim 256, hidden size 32, num layers 1, train loss 0.8326588273048401, validation loss 0.8853208422660828\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9297078847885132, embedding dim 256, hidden size 32, num layers 1, train loss 0.934137225151062, validation loss 0.8949958682060242\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9199491143226624, embedding dim 256, hidden size 32, num layers 1, train loss 0.7561870813369751, validation loss 0.905498743057251\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9099247455596924, embedding dim 256, hidden size 32, num layers 1, train loss 0.6869998574256897, validation loss 0.8745778799057007\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8986477851867676, embedding dim 256, hidden size 32, num layers 1, train loss 0.6972067356109619, validation loss 0.850617527961731\n",
      "Epoch 180, current patience 30, model mean validation loss 0.890516996383667, embedding dim 256, hidden size 32, num layers 1, train loss 0.7741235494613647, validation loss 0.8699987530708313\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8838527798652649, embedding dim 256, hidden size 32, num layers 1, train loss 0.6844939589500427, validation loss 0.8564895391464233\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8751361966133118, embedding dim 256, hidden size 32, num layers 1, train loss 0.831619143486023, validation loss 0.8635902404785156\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8693915605545044, embedding dim 256, hidden size 32, num layers 1, train loss 0.6013268828392029, validation loss 0.8393641710281372\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8636629581451416, embedding dim 256, hidden size 32, num layers 1, train loss 0.5294244885444641, validation loss 0.8491668701171875\n",
      "Epoch 230, current patience 30, model mean validation loss 0.858801007270813, embedding dim 256, hidden size 32, num layers 1, train loss 1.1527413129806519, validation loss 0.8666037321090698\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8536288142204285, embedding dim 256, hidden size 32, num layers 1, train loss 0.4898982346057892, validation loss 0.8331999778747559\n",
      "Epoch 250, current patience 30, model mean validation loss 0.8636707067489624, embedding dim 256, hidden size 32, num layers 1, train loss 0.790084719657898, validation loss 0.9309524297714233\n",
      "Epoch 260, current patience 29, model mean validation loss 0.8586692810058594, embedding dim 256, hidden size 32, num layers 1, train loss 0.6569415926933289, validation loss 0.829987645149231\n",
      "Epoch 270, current patience 28, model mean validation loss 0.865999162197113, embedding dim 256, hidden size 32, num layers 1, train loss 0.5702111721038818, validation loss 0.9151284694671631\n",
      "Epoch 280, current patience 27, model mean validation loss 0.8658640384674072, embedding dim 256, hidden size 32, num layers 1, train loss 0.5462396740913391, validation loss 0.8625094294548035\n",
      "Epoch 290, current patience 26, model mean validation loss 0.8688234090805054, embedding dim 256, hidden size 32, num layers 1, train loss 0.4697980284690857, validation loss 0.8630388975143433\n",
      "Epoch 300, current patience 25, model mean validation loss 0.8669793605804443, embedding dim 256, hidden size 32, num layers 1, train loss 0.3594348728656769, validation loss 0.8344142436981201\n",
      "Epoch 310, current patience 24, model mean validation loss 0.8595698475837708, embedding dim 256, hidden size 32, num layers 1, train loss 0.46882903575897217, validation loss 0.8073275685310364\n",
      "Epoch 320, current patience 23, model mean validation loss 0.8623939752578735, embedding dim 256, hidden size 32, num layers 1, train loss 0.6721157431602478, validation loss 0.8557930588722229\n",
      "Epoch 330, current patience 22, model mean validation loss 0.8556310534477234, embedding dim 256, hidden size 32, num layers 1, train loss 0.5442920923233032, validation loss 0.8768488168716431\n",
      "Epoch 340, current patience 21, model mean validation loss 0.8641909956932068, embedding dim 256, hidden size 32, num layers 1, train loss 0.45415154099464417, validation loss 0.8984678983688354\n",
      "Epoch 350, current patience 20, model mean validation loss 0.8643115758895874, embedding dim 256, hidden size 32, num layers 1, train loss 0.2868191599845886, validation loss 0.9160928726196289\n",
      "Epoch 360, current patience 19, model mean validation loss 0.866446852684021, embedding dim 256, hidden size 32, num layers 1, train loss 0.43322038650512695, validation loss 0.879591703414917\n",
      "Epoch 370, current patience 18, model mean validation loss 0.8749037981033325, embedding dim 256, hidden size 32, num layers 1, train loss 0.3846002221107483, validation loss 0.930694043636322\n",
      "Epoch 380, current patience 17, model mean validation loss 0.8860667943954468, embedding dim 256, hidden size 32, num layers 1, train loss 0.3866463303565979, validation loss 0.9237184524536133\n",
      "Epoch 390, current patience 16, model mean validation loss 0.892814040184021, embedding dim 256, hidden size 32, num layers 1, train loss 0.27875417470932007, validation loss 0.8613054156303406\n",
      "Epoch 400, current patience 15, model mean validation loss 0.8885752558708191, embedding dim 256, hidden size 32, num layers 1, train loss 0.9794512987136841, validation loss 0.8218829035758972\n",
      "Epoch 410, current patience 14, model mean validation loss 0.8893383741378784, embedding dim 256, hidden size 32, num layers 1, train loss 0.3126893639564514, validation loss 0.8829538822174072\n",
      "Epoch 420, current patience 13, model mean validation loss 0.8941983580589294, embedding dim 256, hidden size 32, num layers 1, train loss 0.8096382021903992, validation loss 0.9373474717140198\n",
      "Epoch 430, current patience 12, model mean validation loss 0.8963334560394287, embedding dim 256, hidden size 32, num layers 1, train loss 0.7425825595855713, validation loss 0.9331738948822021\n",
      "Epoch 440, current patience 11, model mean validation loss 0.8991644382476807, embedding dim 256, hidden size 32, num layers 1, train loss 0.5803380012512207, validation loss 0.9022393226623535\n",
      "Epoch 450, current patience 10, model mean validation loss 0.8953118324279785, embedding dim 256, hidden size 32, num layers 1, train loss 0.31176289916038513, validation loss 0.8998735547065735\n",
      "Epoch 460, current patience 9, model mean validation loss 0.8997994065284729, embedding dim 256, hidden size 32, num layers 1, train loss 0.34801051020622253, validation loss 0.9596189856529236\n",
      "Epoch 470, current patience 8, model mean validation loss 0.9171204566955566, embedding dim 256, hidden size 32, num layers 1, train loss 0.6691448092460632, validation loss 0.999873161315918\n",
      "Epoch 480, current patience 7, model mean validation loss 0.9368597865104675, embedding dim 256, hidden size 32, num layers 1, train loss 0.47201547026634216, validation loss 0.979798436164856\n",
      "Epoch 490, current patience 6, model mean validation loss 0.9450492858886719, embedding dim 256, hidden size 32, num layers 1, train loss 0.3526883125305176, validation loss 0.9484690427780151\n",
      "Epoch 500, current patience 5, model mean validation loss 0.9433513879776001, embedding dim 256, hidden size 32, num layers 1, train loss 0.3028133809566498, validation loss 0.9237648844718933\n",
      "Epoch 510, current patience 4, model mean validation loss 0.9427598118782043, embedding dim 256, hidden size 32, num layers 1, train loss 0.6376248002052307, validation loss 0.9284411668777466\n",
      "Epoch 520, current patience 3, model mean validation loss 0.9571912288665771, embedding dim 256, hidden size 32, num layers 1, train loss 0.16584725677967072, validation loss 1.0176903009414673\n",
      "Epoch 530, current patience 2, model mean validation loss 0.9717857241630554, embedding dim 256, hidden size 32, num layers 1, train loss 0.45321887731552124, validation loss 1.016629695892334\n",
      "Epoch 540, current patience 1, model mean validation loss 0.986672043800354, embedding dim 256, hidden size 32, num layers 1, train loss 0.14449217915534973, validation loss 1.078709602355957\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0932319164276123, embedding dim 256, hidden size 64, num layers 1, train loss 1.0941336154937744, validation loss 1.0932319164276123\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0937070846557617, embedding dim 256, hidden size 64, num layers 1, train loss 1.0905194282531738, validation loss 1.0941822528839111\n",
      "Epoch 20, current patience 29, model mean validation loss 1.0877876281738281, embedding dim 256, hidden size 64, num layers 1, train loss 1.0874074697494507, validation loss 1.0759488344192505\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0746252536773682, embedding dim 256, hidden size 64, num layers 1, train loss 1.0532785654067993, validation loss 1.0351383686065674\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0633916854858398, embedding dim 256, hidden size 64, num layers 1, train loss 0.9463459849357605, validation loss 1.0184566974639893\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0531492233276367, embedding dim 256, hidden size 64, num layers 1, train loss 0.9170019626617432, validation loss 1.001937747001648\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0422484874725342, embedding dim 256, hidden size 64, num layers 1, train loss 0.8012857437133789, validation loss 0.9768438935279846\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0304901599884033, embedding dim 256, hidden size 64, num layers 1, train loss 0.9091179370880127, validation loss 0.9481819868087769\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0072274208068848, embedding dim 256, hidden size 64, num layers 1, train loss 0.8387502431869507, validation loss 0.9071304202079773\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9804829359054565, embedding dim 256, hidden size 64, num layers 1, train loss 0.8201507925987244, validation loss 0.8802250623703003\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9581504464149475, embedding dim 256, hidden size 64, num layers 1, train loss 0.7593421936035156, validation loss 0.8972895741462708\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9333404302597046, embedding dim 256, hidden size 64, num layers 1, train loss 0.9379425048828125, validation loss 0.8366579413414001\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9079912900924683, embedding dim 256, hidden size 64, num layers 1, train loss 0.6997443437576294, validation loss 0.8156639933586121\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8849954605102539, embedding dim 256, hidden size 64, num layers 1, train loss 0.8888238668441772, validation loss 0.8179709315299988\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8597602844238281, embedding dim 256, hidden size 64, num layers 1, train loss 1.0267703533172607, validation loss 0.7749627232551575\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8423730134963989, embedding dim 256, hidden size 64, num layers 1, train loss 0.9465490579605103, validation loss 0.8090836405754089\n",
      "Epoch 160, current patience 30, model mean validation loss 0.830585777759552, embedding dim 256, hidden size 64, num layers 1, train loss 0.6528245210647583, validation loss 0.8128325343132019\n",
      "Epoch 170, current patience 30, model mean validation loss 0.820946455001831, embedding dim 256, hidden size 64, num layers 1, train loss 0.7318434119224548, validation loss 0.8031103610992432\n",
      "Epoch 180, current patience 30, model mean validation loss 0.810454249382019, embedding dim 256, hidden size 64, num layers 1, train loss 0.7639907598495483, validation loss 0.8133517503738403\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8088903427124023, embedding dim 256, hidden size 64, num layers 1, train loss 0.6557962894439697, validation loss 0.8241465091705322\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8088425397872925, embedding dim 256, hidden size 64, num layers 1, train loss 0.8346948623657227, validation loss 0.8152816295623779\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8179136514663696, embedding dim 256, hidden size 64, num layers 1, train loss 0.3999320864677429, validation loss 0.8905400037765503\n",
      "Epoch 220, current patience 29, model mean validation loss 0.8240992426872253, embedding dim 256, hidden size 64, num layers 1, train loss 0.33447548747062683, validation loss 0.8244473934173584\n",
      "Epoch 230, current patience 28, model mean validation loss 0.8218921422958374, embedding dim 256, hidden size 64, num layers 1, train loss 0.5873631238937378, validation loss 0.7914270162582397\n",
      "Epoch 240, current patience 27, model mean validation loss 0.8206037282943726, embedding dim 256, hidden size 64, num layers 1, train loss 0.5172210335731506, validation loss 0.8025250434875488\n",
      "Epoch 250, current patience 26, model mean validation loss 0.825394868850708, embedding dim 256, hidden size 64, num layers 1, train loss 0.7238430976867676, validation loss 0.8414394855499268\n",
      "Epoch 260, current patience 25, model mean validation loss 0.8195679187774658, embedding dim 256, hidden size 64, num layers 1, train loss 0.6949062347412109, validation loss 0.7667362689971924\n",
      "Epoch 270, current patience 24, model mean validation loss 0.8167165517807007, embedding dim 256, hidden size 64, num layers 1, train loss 0.4632936716079712, validation loss 0.8013354539871216\n",
      "Epoch 280, current patience 23, model mean validation loss 0.8210762143135071, embedding dim 256, hidden size 64, num layers 1, train loss 0.4962689280509949, validation loss 0.8501592874526978\n",
      "Epoch 290, current patience 22, model mean validation loss 0.8158173561096191, embedding dim 256, hidden size 64, num layers 1, train loss 0.30755841732025146, validation loss 0.8484687209129333\n",
      "Epoch 300, current patience 21, model mean validation loss 0.8118234276771545, embedding dim 256, hidden size 64, num layers 1, train loss 0.6645690202713013, validation loss 0.7924959063529968\n",
      "Epoch 310, current patience 20, model mean validation loss 0.8104265928268433, embedding dim 256, hidden size 64, num layers 1, train loss 0.41833147406578064, validation loss 0.7802525758743286\n",
      "Epoch 320, current patience 19, model mean validation loss 0.8184120059013367, embedding dim 256, hidden size 64, num layers 1, train loss 0.3847448229789734, validation loss 0.8664083480834961\n",
      "Epoch 330, current patience 18, model mean validation loss 0.816208004951477, embedding dim 256, hidden size 64, num layers 1, train loss 0.3588399887084961, validation loss 0.8238072991371155\n",
      "Epoch 340, current patience 17, model mean validation loss 0.8347839713096619, embedding dim 256, hidden size 64, num layers 1, train loss 0.3963460922241211, validation loss 0.9153439998626709\n",
      "Epoch 350, current patience 16, model mean validation loss 0.836593747138977, embedding dim 256, hidden size 64, num layers 1, train loss 0.6277506351470947, validation loss 0.8158138394355774\n",
      "Epoch 360, current patience 15, model mean validation loss 0.8334721326828003, embedding dim 256, hidden size 64, num layers 1, train loss 0.4492584466934204, validation loss 0.8251864910125732\n",
      "Epoch 370, current patience 14, model mean validation loss 0.8340746164321899, embedding dim 256, hidden size 64, num layers 1, train loss 0.4880514144897461, validation loss 0.8532884120941162\n",
      "Epoch 380, current patience 13, model mean validation loss 0.8457331657409668, embedding dim 256, hidden size 64, num layers 1, train loss 0.823511004447937, validation loss 0.8857641816139221\n",
      "Epoch 390, current patience 12, model mean validation loss 0.8625938296318054, embedding dim 256, hidden size 64, num layers 1, train loss 0.18498297035694122, validation loss 0.9151378870010376\n",
      "Epoch 400, current patience 11, model mean validation loss 0.8553663492202759, embedding dim 256, hidden size 64, num layers 1, train loss 0.4375185966491699, validation loss 0.8085887432098389\n",
      "Epoch 410, current patience 10, model mean validation loss 0.8591504693031311, embedding dim 256, hidden size 64, num layers 1, train loss 0.5479427576065063, validation loss 0.8540798425674438\n",
      "Epoch 420, current patience 9, model mean validation loss 0.8486679196357727, embedding dim 256, hidden size 64, num layers 1, train loss 0.4520101845264435, validation loss 0.8314836621284485\n",
      "Epoch 430, current patience 8, model mean validation loss 0.8494424819946289, embedding dim 256, hidden size 64, num layers 1, train loss 0.4139966368675232, validation loss 0.8220106959342957\n",
      "Epoch 440, current patience 7, model mean validation loss 0.8531028628349304, embedding dim 256, hidden size 64, num layers 1, train loss 0.6588101983070374, validation loss 0.8544694781303406\n",
      "Epoch 450, current patience 6, model mean validation loss 0.8566427230834961, embedding dim 256, hidden size 64, num layers 1, train loss 0.3744584321975708, validation loss 0.8816074728965759\n",
      "Epoch 460, current patience 5, model mean validation loss 0.8570334911346436, embedding dim 256, hidden size 64, num layers 1, train loss 0.19164499640464783, validation loss 0.8888904452323914\n",
      "Epoch 470, current patience 4, model mean validation loss 0.8508931398391724, embedding dim 256, hidden size 64, num layers 1, train loss 0.10768963396549225, validation loss 0.8660150766372681\n",
      "Epoch 480, current patience 3, model mean validation loss 0.8667764663696289, embedding dim 256, hidden size 64, num layers 1, train loss 0.40633800625801086, validation loss 0.9356555938720703\n",
      "Epoch 490, current patience 2, model mean validation loss 0.8695986270904541, embedding dim 256, hidden size 64, num layers 1, train loss 0.20170968770980835, validation loss 0.8766566514968872\n",
      "Epoch 500, current patience 1, model mean validation loss 0.8846373558044434, embedding dim 256, hidden size 64, num layers 1, train loss 0.4671216607093811, validation loss 0.9517933130264282\n",
      "Epoch 0, current patience 30, model mean validation loss 1.096447467803955, embedding dim 256, hidden size 128, num layers 1, train loss 1.10184907913208, validation loss 1.096447467803955\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0926544666290283, embedding dim 256, hidden size 128, num layers 1, train loss 1.0936533212661743, validation loss 1.0888614654541016\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0816820859909058, embedding dim 256, hidden size 128, num layers 1, train loss 0.9894002676010132, validation loss 1.0597374439239502\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0713456869125366, embedding dim 256, hidden size 128, num layers 1, train loss 1.0119385719299316, validation loss 1.0403363704681396\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0589851140975952, embedding dim 256, hidden size 128, num layers 1, train loss 0.918253481388092, validation loss 1.0095431804656982\n",
      "Epoch 50, current patience 30, model mean validation loss 1.044175624847412, embedding dim 256, hidden size 128, num layers 1, train loss 0.9570703506469727, validation loss 0.970127522945404\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0322407484054565, embedding dim 256, hidden size 128, num layers 1, train loss 0.9608414173126221, validation loss 0.9606316685676575\n",
      "Epoch 70, current patience 30, model mean validation loss 1.014851450920105, embedding dim 256, hidden size 128, num layers 1, train loss 0.8891217708587646, validation loss 0.8931261301040649\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9896416664123535, embedding dim 256, hidden size 128, num layers 1, train loss 0.8574769496917725, validation loss 0.894769549369812\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9623217582702637, embedding dim 256, hidden size 128, num layers 1, train loss 0.7842010259628296, validation loss 0.8703022003173828\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9358007907867432, embedding dim 256, hidden size 128, num layers 1, train loss 0.9200477600097656, validation loss 0.847569465637207\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9109401702880859, embedding dim 256, hidden size 128, num layers 1, train loss 0.6222666501998901, validation loss 0.8414520621299744\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8925306797027588, embedding dim 256, hidden size 128, num layers 1, train loss 0.6296665072441101, validation loss 0.8622665405273438\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8725159168243408, embedding dim 256, hidden size 128, num layers 1, train loss 0.719481885433197, validation loss 0.8100097179412842\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8503628373146057, embedding dim 256, hidden size 128, num layers 1, train loss 0.644574761390686, validation loss 0.7834068536758423\n",
      "Epoch 150, current patience 30, model mean validation loss 0.831925630569458, embedding dim 256, hidden size 128, num layers 1, train loss 0.7390037775039673, validation loss 0.7456290125846863\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8290842771530151, embedding dim 256, hidden size 128, num layers 1, train loss 0.7580428123474121, validation loss 0.8720383048057556\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8227848410606384, embedding dim 256, hidden size 128, num layers 1, train loss 0.836047887802124, validation loss 0.8199069499969482\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8124759793281555, embedding dim 256, hidden size 128, num layers 1, train loss 0.7675015926361084, validation loss 0.7650985717773438\n",
      "Epoch 190, current patience 30, model mean validation loss 0.802721381187439, embedding dim 256, hidden size 128, num layers 1, train loss 0.9714668989181519, validation loss 0.7634148597717285\n",
      "Epoch 200, current patience 30, model mean validation loss 0.7967495918273926, embedding dim 256, hidden size 128, num layers 1, train loss 0.6827971339225769, validation loss 0.8144924640655518\n",
      "Epoch 210, current patience 30, model mean validation loss 0.7980947494506836, embedding dim 256, hidden size 128, num layers 1, train loss 0.46450766921043396, validation loss 0.8207706212997437\n",
      "Epoch 220, current patience 29, model mean validation loss 0.7979408502578735, embedding dim 256, hidden size 128, num layers 1, train loss 0.6087378263473511, validation loss 0.7821760177612305\n",
      "Epoch 230, current patience 28, model mean validation loss 0.8026248216629028, embedding dim 256, hidden size 128, num layers 1, train loss 0.3724187910556793, validation loss 0.7831006050109863\n",
      "Epoch 240, current patience 27, model mean validation loss 0.7934157848358154, embedding dim 256, hidden size 128, num layers 1, train loss 0.4565717279911041, validation loss 0.7983663082122803\n",
      "Epoch 250, current patience 30, model mean validation loss 0.7901716232299805, embedding dim 256, hidden size 128, num layers 1, train loss 0.8548769354820251, validation loss 0.7939534187316895\n",
      "Epoch 260, current patience 30, model mean validation loss 0.7885779142379761, embedding dim 256, hidden size 128, num layers 1, train loss 0.5288110971450806, validation loss 0.7523491382598877\n",
      "Epoch 270, current patience 30, model mean validation loss 0.7907700538635254, embedding dim 256, hidden size 128, num layers 1, train loss 0.5366834402084351, validation loss 0.7809516787528992\n",
      "Epoch 280, current patience 29, model mean validation loss 0.7850708365440369, embedding dim 256, hidden size 128, num layers 1, train loss 0.8883948922157288, validation loss 0.7688988447189331\n",
      "Epoch 290, current patience 30, model mean validation loss 0.7774845361709595, embedding dim 256, hidden size 128, num layers 1, train loss 0.6036676168441772, validation loss 0.7600803375244141\n",
      "Epoch 300, current patience 30, model mean validation loss 0.7774507999420166, embedding dim 256, hidden size 128, num layers 1, train loss 0.9517838954925537, validation loss 0.7819059491157532\n",
      "Epoch 310, current patience 30, model mean validation loss 0.7793805599212646, embedding dim 256, hidden size 128, num layers 1, train loss 0.37283480167388916, validation loss 0.7985391616821289\n",
      "Epoch 320, current patience 29, model mean validation loss 0.7843999266624451, embedding dim 256, hidden size 128, num layers 1, train loss 0.5616971254348755, validation loss 0.8385205268859863\n",
      "Epoch 330, current patience 28, model mean validation loss 0.7877581119537354, embedding dim 256, hidden size 128, num layers 1, train loss 0.6732603311538696, validation loss 0.8208191990852356\n",
      "Epoch 340, current patience 27, model mean validation loss 0.802120566368103, embedding dim 256, hidden size 128, num layers 1, train loss 0.6384183764457703, validation loss 0.8672486543655396\n",
      "Epoch 350, current patience 26, model mean validation loss 0.8093210458755493, embedding dim 256, hidden size 128, num layers 1, train loss 0.2331613153219223, validation loss 0.8385560512542725\n",
      "Epoch 360, current patience 25, model mean validation loss 0.8172600269317627, embedding dim 256, hidden size 128, num layers 1, train loss 0.3654237985610962, validation loss 0.8324101567268372\n",
      "Epoch 370, current patience 24, model mean validation loss 0.8313320875167847, embedding dim 256, hidden size 128, num layers 1, train loss 0.4200150966644287, validation loss 0.8726570010185242\n",
      "Epoch 380, current patience 23, model mean validation loss 0.845655620098114, embedding dim 256, hidden size 128, num layers 1, train loss 0.42297372221946716, validation loss 0.8964941501617432\n",
      "Epoch 390, current patience 22, model mean validation loss 0.8676639795303345, embedding dim 256, hidden size 128, num layers 1, train loss 0.5614722967147827, validation loss 0.9746065139770508\n",
      "Epoch 400, current patience 21, model mean validation loss 0.872660756111145, embedding dim 256, hidden size 128, num layers 1, train loss 0.18420860171318054, validation loss 0.8784940838813782\n",
      "Epoch 410, current patience 20, model mean validation loss 0.8760448694229126, embedding dim 256, hidden size 128, num layers 1, train loss 0.24469421803951263, validation loss 0.847892701625824\n",
      "Epoch 420, current patience 19, model mean validation loss 0.8837952613830566, embedding dim 256, hidden size 128, num layers 1, train loss 0.14926442503929138, validation loss 0.9292514324188232\n",
      "Epoch 430, current patience 18, model mean validation loss 0.8939194083213806, embedding dim 256, hidden size 128, num layers 1, train loss 0.41498252749443054, validation loss 0.9195493459701538\n",
      "Epoch 440, current patience 17, model mean validation loss 0.9058057069778442, embedding dim 256, hidden size 128, num layers 1, train loss 0.6704953908920288, validation loss 0.9275004267692566\n",
      "Epoch 450, current patience 16, model mean validation loss 0.9135146141052246, embedding dim 256, hidden size 128, num layers 1, train loss 0.32577964663505554, validation loss 0.9343280792236328\n",
      "Epoch 460, current patience 15, model mean validation loss 0.9097777009010315, embedding dim 256, hidden size 128, num layers 1, train loss 0.32183438539505005, validation loss 0.8665988445281982\n",
      "Epoch 470, current patience 14, model mean validation loss 0.8971946835517883, embedding dim 256, hidden size 128, num layers 1, train loss 0.5062224864959717, validation loss 0.8739426136016846\n",
      "Epoch 480, current patience 13, model mean validation loss 0.9153895378112793, embedding dim 256, hidden size 128, num layers 1, train loss 0.5088496208190918, validation loss 1.0240529775619507\n",
      "Epoch 490, current patience 12, model mean validation loss 0.9287093877792358, embedding dim 256, hidden size 128, num layers 1, train loss 0.19643175601959229, validation loss 0.9544515609741211\n",
      "Epoch 500, current patience 11, model mean validation loss 0.9357014894485474, embedding dim 256, hidden size 128, num layers 1, train loss 0.11609954386949539, validation loss 0.9851883053779602\n",
      "Epoch 510, current patience 10, model mean validation loss 0.9434840083122253, embedding dim 256, hidden size 128, num layers 1, train loss 0.24388949573040009, validation loss 0.9818094968795776\n",
      "Epoch 520, current patience 9, model mean validation loss 0.9516604542732239, embedding dim 256, hidden size 128, num layers 1, train loss 0.43951812386512756, validation loss 0.9929118156433105\n",
      "Epoch 530, current patience 8, model mean validation loss 0.9620701670646667, embedding dim 256, hidden size 128, num layers 1, train loss 0.09468565136194229, validation loss 1.0176057815551758\n",
      "Epoch 540, current patience 7, model mean validation loss 0.9808070659637451, embedding dim 256, hidden size 128, num layers 1, train loss 0.7528483867645264, validation loss 1.0164940357208252\n",
      "Epoch 550, current patience 6, model mean validation loss 0.9926809668540955, embedding dim 256, hidden size 128, num layers 1, train loss 0.25218626856803894, validation loss 0.9689335823059082\n",
      "Epoch 560, current patience 5, model mean validation loss 0.9875684976577759, embedding dim 256, hidden size 128, num layers 1, train loss 0.18885260820388794, validation loss 0.9831532835960388\n",
      "Epoch 570, current patience 4, model mean validation loss 0.9943271279335022, embedding dim 256, hidden size 128, num layers 1, train loss 0.09818296134471893, validation loss 1.008520483970642\n",
      "Epoch 580, current patience 3, model mean validation loss 0.9981861114501953, embedding dim 256, hidden size 128, num layers 1, train loss 0.28877687454223633, validation loss 1.01606023311615\n",
      "Epoch 590, current patience 2, model mean validation loss 1.0023040771484375, embedding dim 256, hidden size 128, num layers 1, train loss 0.12978389859199524, validation loss 1.0147531032562256\n",
      "Epoch 600, current patience 1, model mean validation loss 0.9955973625183105, embedding dim 256, hidden size 128, num layers 1, train loss 0.16960811614990234, validation loss 0.9392587542533875\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0972392559051514, embedding dim 256, hidden size 256, num layers 1, train loss 1.09675133228302, validation loss 1.0972392559051514\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0935338735580444, embedding dim 256, hidden size 256, num layers 1, train loss 1.1065394878387451, validation loss 1.0898284912109375\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0868288278579712, embedding dim 256, hidden size 256, num layers 1, train loss 1.0400605201721191, validation loss 1.0734188556671143\n",
      "Epoch 30, current patience 30, model mean validation loss 1.092806339263916, embedding dim 256, hidden size 256, num layers 1, train loss 0.9244479537010193, validation loss 1.110738754272461\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0685564279556274, embedding dim 256, hidden size 256, num layers 1, train loss 0.9808648228645325, validation loss 0.9715570211410522\n",
      "Epoch 50, current patience 30, model mean validation loss 1.050392985343933, embedding dim 256, hidden size 256, num layers 1, train loss 0.9212101101875305, validation loss 0.9595756530761719\n",
      "Epoch 60, current patience 30, model mean validation loss 1.027000069618225, embedding dim 256, hidden size 256, num layers 1, train loss 0.8739868998527527, validation loss 0.8866421580314636\n",
      "Epoch 70, current patience 30, model mean validation loss 1.005253553390503, embedding dim 256, hidden size 256, num layers 1, train loss 0.8489184379577637, validation loss 0.8530281782150269\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9715750217437744, embedding dim 256, hidden size 256, num layers 1, train loss 1.0190198421478271, validation loss 0.8278107047080994\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9352967739105225, embedding dim 256, hidden size 256, num layers 1, train loss 0.8230078220367432, validation loss 0.7996025681495667\n",
      "Epoch 100, current patience 30, model mean validation loss 0.903852105140686, embedding dim 256, hidden size 256, num layers 1, train loss 0.7717137336730957, validation loss 0.8218621611595154\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8742393255233765, embedding dim 256, hidden size 256, num layers 1, train loss 0.7804641723632812, validation loss 0.8738361597061157\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8521943092346191, embedding dim 256, hidden size 256, num layers 1, train loss 0.7984012365341187, validation loss 0.7951968908309937\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8301199078559875, embedding dim 256, hidden size 256, num layers 1, train loss 0.8432996273040771, validation loss 0.7829802632331848\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8191683888435364, embedding dim 256, hidden size 256, num layers 1, train loss 0.6720479130744934, validation loss 0.7990302443504333\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8117383122444153, embedding dim 256, hidden size 256, num layers 1, train loss 0.5520679950714111, validation loss 0.7935876250267029\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8143272399902344, embedding dim 256, hidden size 256, num layers 1, train loss 0.3811025023460388, validation loss 0.8485217094421387\n",
      "Epoch 170, current patience 29, model mean validation loss 0.8083904981613159, embedding dim 256, hidden size 256, num layers 1, train loss 0.38233116269111633, validation loss 0.7521085739135742\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8052448034286499, embedding dim 256, hidden size 256, num layers 1, train loss 0.6135129332542419, validation loss 0.7966967821121216\n",
      "Epoch 190, current patience 30, model mean validation loss 0.793127179145813, embedding dim 256, hidden size 256, num layers 1, train loss 0.578005313873291, validation loss 0.7768958806991577\n",
      "Epoch 200, current patience 30, model mean validation loss 0.7862421274185181, embedding dim 256, hidden size 256, num layers 1, train loss 0.6554403305053711, validation loss 0.7401164174079895\n",
      "Epoch 210, current patience 30, model mean validation loss 0.7920357584953308, embedding dim 256, hidden size 256, num layers 1, train loss 0.1978476345539093, validation loss 0.8293290138244629\n",
      "Epoch 220, current patience 29, model mean validation loss 0.791557788848877, embedding dim 256, hidden size 256, num layers 1, train loss 0.3659169673919678, validation loss 0.7952061891555786\n",
      "Epoch 230, current patience 28, model mean validation loss 0.7911767959594727, embedding dim 256, hidden size 256, num layers 1, train loss 0.31997543573379517, validation loss 0.7905401587486267\n",
      "Epoch 240, current patience 27, model mean validation loss 0.7845429182052612, embedding dim 256, hidden size 256, num layers 1, train loss 0.44245344400405884, validation loss 0.7954504489898682\n",
      "Epoch 250, current patience 30, model mean validation loss 0.7933112978935242, embedding dim 256, hidden size 256, num layers 1, train loss 0.22621335089206696, validation loss 0.8222554922103882\n",
      "Epoch 260, current patience 29, model mean validation loss 0.7873103618621826, embedding dim 256, hidden size 256, num layers 1, train loss 0.6932275295257568, validation loss 0.7486892938613892\n",
      "Epoch 270, current patience 28, model mean validation loss 0.7879530191421509, embedding dim 256, hidden size 256, num layers 1, train loss 0.39095982909202576, validation loss 0.7820372581481934\n",
      "Epoch 280, current patience 27, model mean validation loss 0.7984098792076111, embedding dim 256, hidden size 256, num layers 1, train loss 0.34927523136138916, validation loss 0.8237712979316711\n",
      "Epoch 290, current patience 26, model mean validation loss 0.7983793616294861, embedding dim 256, hidden size 256, num layers 1, train loss 0.19690540432929993, validation loss 0.8290846347808838\n",
      "Epoch 300, current patience 25, model mean validation loss 0.8022732138633728, embedding dim 256, hidden size 256, num layers 1, train loss 0.3609016239643097, validation loss 0.8263572454452515\n",
      "Epoch 310, current patience 24, model mean validation loss 0.8080645203590393, embedding dim 256, hidden size 256, num layers 1, train loss 0.4266085922718048, validation loss 0.836870551109314\n",
      "Epoch 320, current patience 23, model mean validation loss 0.8116191625595093, embedding dim 256, hidden size 256, num layers 1, train loss 0.5519850254058838, validation loss 0.8238877654075623\n",
      "Epoch 330, current patience 22, model mean validation loss 0.812249481678009, embedding dim 256, hidden size 256, num layers 1, train loss 0.20236489176750183, validation loss 0.8272973895072937\n",
      "Epoch 340, current patience 21, model mean validation loss 0.8151950836181641, embedding dim 256, hidden size 256, num layers 1, train loss 0.4217650592327118, validation loss 0.7722547054290771\n",
      "Epoch 350, current patience 20, model mean validation loss 0.8241177797317505, embedding dim 256, hidden size 256, num layers 1, train loss 0.4636439085006714, validation loss 0.85341876745224\n",
      "Epoch 360, current patience 19, model mean validation loss 0.829256534576416, embedding dim 256, hidden size 256, num layers 1, train loss 0.23267343640327454, validation loss 0.8648813962936401\n",
      "Epoch 370, current patience 18, model mean validation loss 0.8352123498916626, embedding dim 256, hidden size 256, num layers 1, train loss 0.4618580937385559, validation loss 0.8767306208610535\n",
      "Epoch 380, current patience 17, model mean validation loss 0.8376978635787964, embedding dim 256, hidden size 256, num layers 1, train loss 0.2840971350669861, validation loss 0.8462416529655457\n",
      "Epoch 390, current patience 16, model mean validation loss 0.8463762998580933, embedding dim 256, hidden size 256, num layers 1, train loss 0.1834414005279541, validation loss 0.9062983989715576\n",
      "Epoch 400, current patience 15, model mean validation loss 0.8555268049240112, embedding dim 256, hidden size 256, num layers 1, train loss 0.12674376368522644, validation loss 0.8970907926559448\n",
      "Epoch 410, current patience 14, model mean validation loss 0.8758957386016846, embedding dim 256, hidden size 256, num layers 1, train loss 0.12471434473991394, validation loss 0.9902492761611938\n",
      "Epoch 420, current patience 13, model mean validation loss 0.8925604820251465, embedding dim 256, hidden size 256, num layers 1, train loss 0.11576402187347412, validation loss 0.9055734872817993\n",
      "Epoch 430, current patience 12, model mean validation loss 0.8964003324508667, embedding dim 256, hidden size 256, num layers 1, train loss 0.09429346024990082, validation loss 0.8841373920440674\n",
      "Epoch 440, current patience 11, model mean validation loss 0.9026045799255371, embedding dim 256, hidden size 256, num layers 1, train loss 0.3543000817298889, validation loss 0.9145152568817139\n",
      "Epoch 450, current patience 10, model mean validation loss 0.9135141968727112, embedding dim 256, hidden size 256, num layers 1, train loss 0.3278186321258545, validation loss 0.9640073776245117\n",
      "Epoch 460, current patience 9, model mean validation loss 0.919766902923584, embedding dim 256, hidden size 256, num layers 1, train loss 0.17387543618679047, validation loss 0.8962634205818176\n",
      "Epoch 470, current patience 8, model mean validation loss 0.919834554195404, embedding dim 256, hidden size 256, num layers 1, train loss 0.044755350798368454, validation loss 0.9068396687507629\n",
      "Epoch 480, current patience 7, model mean validation loss 0.9402293562889099, embedding dim 256, hidden size 256, num layers 1, train loss 0.46817463636398315, validation loss 1.0602490901947021\n",
      "Epoch 490, current patience 6, model mean validation loss 0.9217464923858643, embedding dim 256, hidden size 256, num layers 1, train loss 0.4059617221355438, validation loss 0.8423861265182495\n",
      "Epoch 500, current patience 5, model mean validation loss 0.9220484495162964, embedding dim 256, hidden size 256, num layers 1, train loss 0.28208649158477783, validation loss 0.9079893827438354\n",
      "Epoch 510, current patience 4, model mean validation loss 0.9375873804092407, embedding dim 256, hidden size 256, num layers 1, train loss 0.2301030158996582, validation loss 1.0084482431411743\n",
      "Epoch 520, current patience 3, model mean validation loss 0.949163556098938, embedding dim 256, hidden size 256, num layers 1, train loss 0.08738236874341965, validation loss 1.0071253776550293\n",
      "Epoch 530, current patience 2, model mean validation loss 0.950777530670166, embedding dim 256, hidden size 256, num layers 1, train loss 0.2624182403087616, validation loss 0.9769185781478882\n",
      "Epoch 540, current patience 1, model mean validation loss 0.9609668254852295, embedding dim 256, hidden size 256, num layers 1, train loss 0.045133303850889206, validation loss 0.9777781367301941\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1133161783218384, embedding dim 256, hidden size 512, num layers 1, train loss 1.0980517864227295, validation loss 1.1133161783218384\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0968749523162842, embedding dim 256, hidden size 512, num layers 1, train loss 1.109309196472168, validation loss 1.0804338455200195\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0950837135314941, embedding dim 256, hidden size 512, num layers 1, train loss 1.1078437566757202, validation loss 1.091501235961914\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0984179973602295, embedding dim 256, hidden size 512, num layers 1, train loss 0.963695764541626, validation loss 1.1084206104278564\n",
      "Epoch 40, current patience 29, model mean validation loss 1.0872312784194946, embedding dim 256, hidden size 512, num layers 1, train loss 0.9365655183792114, validation loss 1.0424845218658447\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0604076385498047, embedding dim 256, hidden size 512, num layers 1, train loss 0.9066659808158875, validation loss 0.9262895584106445\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0341118574142456, embedding dim 256, hidden size 512, num layers 1, train loss 0.7531412839889526, validation loss 0.8763370513916016\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0106391906738281, embedding dim 256, hidden size 512, num layers 1, train loss 0.9270304441452026, validation loss 0.8463307619094849\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9797026515007019, embedding dim 256, hidden size 512, num layers 1, train loss 0.746412992477417, validation loss 0.8658236265182495\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9463601112365723, embedding dim 256, hidden size 512, num layers 1, train loss 0.8322678208351135, validation loss 0.8136937022209167\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9095392227172852, embedding dim 256, hidden size 512, num layers 1, train loss 0.6339185237884521, validation loss 0.7969340085983276\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8697718977928162, embedding dim 256, hidden size 512, num layers 1, train loss 0.8133405447006226, validation loss 0.7902816534042358\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8406692147254944, embedding dim 256, hidden size 512, num layers 1, train loss 0.8482324481010437, validation loss 0.8096635341644287\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8220212459564209, embedding dim 256, hidden size 512, num layers 1, train loss 0.7227252721786499, validation loss 0.7771058082580566\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8096054196357727, embedding dim 256, hidden size 512, num layers 1, train loss 0.7391393184661865, validation loss 0.7770105600357056\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8001290559768677, embedding dim 256, hidden size 512, num layers 1, train loss 0.4725050926208496, validation loss 0.7705196142196655\n",
      "Epoch 160, current patience 30, model mean validation loss 0.7959260940551758, embedding dim 256, hidden size 512, num layers 1, train loss 0.6485697627067566, validation loss 0.8322001099586487\n",
      "Epoch 170, current patience 30, model mean validation loss 0.7965426445007324, embedding dim 256, hidden size 512, num layers 1, train loss 0.950977087020874, validation loss 0.8186260461807251\n",
      "Epoch 180, current patience 29, model mean validation loss 0.7976642847061157, embedding dim 256, hidden size 512, num layers 1, train loss 0.38606882095336914, validation loss 0.8059071898460388\n",
      "Epoch 190, current patience 28, model mean validation loss 0.7955790758132935, embedding dim 256, hidden size 512, num layers 1, train loss 0.4645358920097351, validation loss 0.7735995054244995\n",
      "Epoch 200, current patience 30, model mean validation loss 0.796996533870697, embedding dim 256, hidden size 512, num layers 1, train loss 0.26817458868026733, validation loss 0.8210033178329468\n",
      "Epoch 210, current patience 29, model mean validation loss 0.8047068119049072, embedding dim 256, hidden size 512, num layers 1, train loss 0.16661962866783142, validation loss 0.8387883305549622\n",
      "Epoch 220, current patience 28, model mean validation loss 0.8057851791381836, embedding dim 256, hidden size 512, num layers 1, train loss 0.5446809530258179, validation loss 0.7856370210647583\n",
      "Epoch 230, current patience 27, model mean validation loss 0.8061453700065613, embedding dim 256, hidden size 512, num layers 1, train loss 0.5589481592178345, validation loss 0.7734013795852661\n",
      "Epoch 240, current patience 26, model mean validation loss 0.8001643419265747, embedding dim 256, hidden size 512, num layers 1, train loss 0.5057268142700195, validation loss 0.7843520641326904\n",
      "Epoch 250, current patience 25, model mean validation loss 0.7971428036689758, embedding dim 256, hidden size 512, num layers 1, train loss 0.5278551578521729, validation loss 0.7944538593292236\n",
      "Epoch 260, current patience 24, model mean validation loss 0.8082718849182129, embedding dim 256, hidden size 512, num layers 1, train loss 0.1351286768913269, validation loss 0.894939661026001\n",
      "Epoch 270, current patience 23, model mean validation loss 0.8186790943145752, embedding dim 256, hidden size 512, num layers 1, train loss 0.7545028924942017, validation loss 0.8568571209907532\n",
      "Epoch 280, current patience 22, model mean validation loss 0.812751293182373, embedding dim 256, hidden size 512, num layers 1, train loss 0.7025308609008789, validation loss 0.77358078956604\n",
      "Epoch 290, current patience 21, model mean validation loss 0.8083164095878601, embedding dim 256, hidden size 512, num layers 1, train loss 0.2461591213941574, validation loss 0.8033090829849243\n",
      "Epoch 300, current patience 20, model mean validation loss 0.8219040632247925, embedding dim 256, hidden size 512, num layers 1, train loss 0.6114814281463623, validation loss 0.8943382501602173\n",
      "Epoch 310, current patience 19, model mean validation loss 0.8361954092979431, embedding dim 256, hidden size 512, num layers 1, train loss 0.5925145149230957, validation loss 0.8877321481704712\n",
      "Epoch 320, current patience 18, model mean validation loss 0.8536243438720703, embedding dim 256, hidden size 512, num layers 1, train loss 0.1889776885509491, validation loss 0.9237841367721558\n",
      "Epoch 330, current patience 17, model mean validation loss 0.8605321049690247, embedding dim 256, hidden size 512, num layers 1, train loss 0.7571570873260498, validation loss 0.8497155904769897\n",
      "Epoch 340, current patience 16, model mean validation loss 0.8578363656997681, embedding dim 256, hidden size 512, num layers 1, train loss 0.15069028735160828, validation loss 0.8733736872673035\n",
      "Epoch 350, current patience 15, model mean validation loss 0.8592315912246704, embedding dim 256, hidden size 512, num layers 1, train loss 0.12742510437965393, validation loss 0.8680192232131958\n",
      "Epoch 360, current patience 14, model mean validation loss 0.8750029802322388, embedding dim 256, hidden size 512, num layers 1, train loss 0.37273433804512024, validation loss 0.8997520804405212\n",
      "Epoch 370, current patience 13, model mean validation loss 0.890143632888794, embedding dim 256, hidden size 512, num layers 1, train loss 0.11000973731279373, validation loss 0.9244343042373657\n",
      "Epoch 380, current patience 12, model mean validation loss 0.8876848220825195, embedding dim 256, hidden size 512, num layers 1, train loss 0.039499346166849136, validation loss 0.8746675848960876\n",
      "Epoch 390, current patience 11, model mean validation loss 0.8942100405693054, embedding dim 256, hidden size 512, num layers 1, train loss 0.0735311210155487, validation loss 0.9399335384368896\n",
      "Epoch 400, current patience 10, model mean validation loss 0.8980857133865356, embedding dim 256, hidden size 512, num layers 1, train loss 0.4424814283847809, validation loss 0.9547896385192871\n",
      "Epoch 410, current patience 9, model mean validation loss 0.9170204401016235, embedding dim 256, hidden size 512, num layers 1, train loss 0.40742793679237366, validation loss 1.001193642616272\n",
      "Epoch 420, current patience 8, model mean validation loss 0.9247301816940308, embedding dim 256, hidden size 512, num layers 1, train loss 0.29635849595069885, validation loss 0.9350517392158508\n",
      "Epoch 430, current patience 7, model mean validation loss 0.9276766777038574, embedding dim 256, hidden size 512, num layers 1, train loss 0.07894279807806015, validation loss 0.8915910720825195\n",
      "Epoch 440, current patience 6, model mean validation loss 0.9326335191726685, embedding dim 256, hidden size 512, num layers 1, train loss 0.3706934452056885, validation loss 0.9394068717956543\n",
      "Epoch 450, current patience 5, model mean validation loss 0.948512852191925, embedding dim 256, hidden size 512, num layers 1, train loss 0.04633951187133789, validation loss 1.0514686107635498\n",
      "Epoch 460, current patience 4, model mean validation loss 0.9566323757171631, embedding dim 256, hidden size 512, num layers 1, train loss 0.022578775882720947, validation loss 0.9396241307258606\n",
      "Epoch 470, current patience 3, model mean validation loss 0.97146075963974, embedding dim 256, hidden size 512, num layers 1, train loss 0.18042153120040894, validation loss 1.0585602521896362\n",
      "Epoch 480, current patience 2, model mean validation loss 0.9686622619628906, embedding dim 256, hidden size 512, num layers 1, train loss 0.4004131853580475, validation loss 0.9324014186859131\n",
      "Epoch 490, current patience 1, model mean validation loss 0.9746798872947693, embedding dim 256, hidden size 512, num layers 1, train loss 0.23883074522018433, validation loss 1.0493353605270386\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1773037910461426, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0968618392944336, validation loss 1.1773037910461426\n",
      "Epoch 10, current patience 30, model mean validation loss 1.138768196105957, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0972036123275757, validation loss 1.100232481956482\n",
      "Epoch 20, current patience 30, model mean validation loss 1.13224196434021, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0482906103134155, validation loss 1.1191895008087158\n",
      "Epoch 30, current patience 30, model mean validation loss 1.145674705505371, embedding dim 256, hidden size 1024, num layers 1, train loss 1.270493984222412, validation loss 1.1859726905822754\n",
      "Epoch 40, current patience 29, model mean validation loss 1.1526240110397339, embedding dim 256, hidden size 1024, num layers 1, train loss 1.127601146697998, validation loss 1.1804218292236328\n",
      "Epoch 50, current patience 28, model mean validation loss 1.2157557010650635, embedding dim 256, hidden size 1024, num layers 1, train loss 1.4215551614761353, validation loss 1.5314135551452637\n",
      "Epoch 60, current patience 27, model mean validation loss 1.2497599124908447, embedding dim 256, hidden size 1024, num layers 1, train loss 1.2212269306182861, validation loss 1.4537851810455322\n",
      "Epoch 70, current patience 26, model mean validation loss 1.2483811378479004, embedding dim 256, hidden size 1024, num layers 1, train loss 1.162156343460083, validation loss 1.2387300729751587\n",
      "Epoch 80, current patience 25, model mean validation loss 1.241024136543274, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1679599285125732, validation loss 1.11844801902771\n",
      "Epoch 90, current patience 24, model mean validation loss 1.2429141998291016, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1049630641937256, validation loss 1.1153533458709717\n",
      "Epoch 100, current patience 23, model mean validation loss 1.2448194026947021, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1468950510025024, validation loss 1.1344304084777832\n",
      "Epoch 110, current patience 22, model mean validation loss 1.2350990772247314, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1459357738494873, validation loss 1.1082103252410889\n",
      "Epoch 120, current patience 21, model mean validation loss 1.2303882837295532, embedding dim 256, hidden size 1024, num layers 1, train loss 1.2285585403442383, validation loss 1.142735481262207\n",
      "Epoch 130, current patience 20, model mean validation loss 1.1791675090789795, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1464757919311523, validation loss 1.1216473579406738\n",
      "Epoch 140, current patience 19, model mean validation loss 1.1366932392120361, embedding dim 256, hidden size 1024, num layers 1, train loss 1.137813925743103, validation loss 1.1139912605285645\n",
      "Epoch 150, current patience 18, model mean validation loss 1.1183438301086426, embedding dim 256, hidden size 1024, num layers 1, train loss 1.218442440032959, validation loss 1.0919344425201416\n",
      "Epoch 160, current patience 30, model mean validation loss 1.1145825386047363, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0230554342269897, validation loss 1.08835768699646\n",
      "Epoch 170, current patience 30, model mean validation loss 1.108962059020996, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1199381351470947, validation loss 1.0703898668289185\n",
      "Epoch 180, current patience 30, model mean validation loss 1.1006476879119873, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0862927436828613, validation loss 1.0679149627685547\n",
      "Epoch 190, current patience 30, model mean validation loss 1.107846736907959, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0595214366912842, validation loss 1.1658025979995728\n",
      "Epoch 200, current patience 29, model mean validation loss 1.1169421672821045, embedding dim 256, hidden size 1024, num layers 1, train loss 1.103491187095642, validation loss 1.215498924255371\n",
      "Epoch 210, current patience 28, model mean validation loss 1.117408275604248, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1490581035614014, validation loss 1.125376582145691\n",
      "Epoch 220, current patience 27, model mean validation loss 1.1195924282073975, embedding dim 256, hidden size 1024, num layers 1, train loss 0.959528923034668, validation loss 1.1314646005630493\n",
      "Epoch 230, current patience 26, model mean validation loss 1.1208891868591309, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0567944049835205, validation loss 1.1023080348968506\n",
      "Epoch 240, current patience 25, model mean validation loss 1.118666172027588, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0338044166564941, validation loss 1.0705739259719849\n",
      "Epoch 250, current patience 24, model mean validation loss 1.1181501150131226, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0724916458129883, validation loss 1.0662615299224854\n",
      "Epoch 260, current patience 23, model mean validation loss 1.118912696838379, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1392223834991455, validation loss 1.0740149021148682\n",
      "Epoch 270, current patience 22, model mean validation loss 1.1138787269592285, embedding dim 256, hidden size 1024, num layers 1, train loss 1.049837589263916, validation loss 1.1255316734313965\n",
      "Epoch 280, current patience 21, model mean validation loss 1.109431505203247, embedding dim 256, hidden size 1024, num layers 1, train loss 0.899966299533844, validation loss 1.17992103099823\n",
      "Epoch 290, current patience 20, model mean validation loss 1.1036077737808228, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1497433185577393, validation loss 1.0787863731384277\n",
      "Epoch 300, current patience 19, model mean validation loss 1.0946149826049805, embedding dim 256, hidden size 1024, num layers 1, train loss 1.2046862840652466, validation loss 1.0595228672027588\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0882973670959473, embedding dim 256, hidden size 1024, num layers 1, train loss 1.0495010614395142, validation loss 1.051766037940979\n",
      "Epoch 320, current patience 30, model mean validation loss 1.105476975440979, embedding dim 256, hidden size 1024, num layers 1, train loss 0.8991276025772095, validation loss 1.2080116271972656\n",
      "Epoch 330, current patience 29, model mean validation loss 1.118023157119751, embedding dim 256, hidden size 1024, num layers 1, train loss 1.1159356832504272, validation loss 1.1666311025619507\n",
      "Epoch 340, current patience 28, model mean validation loss 1.1515194177627563, embedding dim 256, hidden size 1024, num layers 1, train loss 0.911126971244812, validation loss 1.341984510421753\n",
      "Epoch 350, current patience 27, model mean validation loss 1.1632068157196045, embedding dim 256, hidden size 1024, num layers 1, train loss 1.081791877746582, validation loss 1.2190313339233398\n",
      "Epoch 360, current patience 26, model mean validation loss 1.160006046295166, embedding dim 256, hidden size 1024, num layers 1, train loss 0.9303051233291626, validation loss 1.1543147563934326\n",
      "Epoch 370, current patience 25, model mean validation loss 1.1545634269714355, embedding dim 256, hidden size 1024, num layers 1, train loss 0.9717762470245361, validation loss 1.0352449417114258\n",
      "Epoch 380, current patience 24, model mean validation loss 1.1525930166244507, embedding dim 256, hidden size 1024, num layers 1, train loss 0.8316354155540466, validation loss 1.0437599420547485\n",
      "Epoch 390, current patience 23, model mean validation loss 1.1514958143234253, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7616434097290039, validation loss 1.0429884195327759\n",
      "Epoch 400, current patience 22, model mean validation loss 1.12546968460083, embedding dim 256, hidden size 1024, num layers 1, train loss 0.8661222457885742, validation loss 0.9998029470443726\n",
      "Epoch 410, current patience 21, model mean validation loss 1.1082895994186401, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7957475781440735, validation loss 1.0291903018951416\n",
      "Epoch 420, current patience 20, model mean validation loss 1.0721962451934814, embedding dim 256, hidden size 1024, num layers 1, train loss 0.8576581478118896, validation loss 1.0532376766204834\n",
      "Epoch 430, current patience 30, model mean validation loss 1.045666217803955, embedding dim 256, hidden size 1024, num layers 1, train loss 0.9346421957015991, validation loss 1.006791114807129\n",
      "Epoch 440, current patience 30, model mean validation loss 1.0244519710540771, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6019484996795654, validation loss 0.9845998287200928\n",
      "Epoch 450, current patience 30, model mean validation loss 1.0146256685256958, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7403473258018494, validation loss 0.9566352367401123\n",
      "Epoch 460, current patience 30, model mean validation loss 1.0422614812850952, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6273680925369263, validation loss 1.2648468017578125\n",
      "Epoch 470, current patience 29, model mean validation loss 1.0741796493530273, embedding dim 256, hidden size 1024, num layers 1, train loss 0.9900315403938293, validation loss 1.2983334064483643\n",
      "Epoch 480, current patience 28, model mean validation loss 1.0811375379562378, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6367212533950806, validation loss 1.0554661750793457\n",
      "Epoch 490, current patience 27, model mean validation loss 1.087241291999817, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7935197949409485, validation loss 1.078020453453064\n",
      "Epoch 500, current patience 26, model mean validation loss 1.083187460899353, embedding dim 256, hidden size 1024, num layers 1, train loss 0.8292146921157837, validation loss 1.0208067893981934\n",
      "Epoch 510, current patience 25, model mean validation loss 1.0805940628051758, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7433568239212036, validation loss 0.9860444068908691\n",
      "Epoch 520, current patience 24, model mean validation loss 1.0852985382080078, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7064056396484375, validation loss 1.0222358703613281\n",
      "Epoch 530, current patience 23, model mean validation loss 1.097012996673584, embedding dim 256, hidden size 1024, num layers 1, train loss 0.45420128107070923, validation loss 1.0503501892089844\n",
      "Epoch 540, current patience 22, model mean validation loss 1.0622384548187256, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6167764663696289, validation loss 0.9866510629653931\n",
      "Epoch 550, current patience 21, model mean validation loss 1.0195125341415405, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7451430559158325, validation loss 0.9565252065658569\n",
      "Epoch 560, current patience 20, model mean validation loss 1.0102097988128662, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5215864181518555, validation loss 0.9810446500778198\n",
      "Epoch 570, current patience 30, model mean validation loss 0.992535412311554, embedding dim 256, hidden size 1024, num layers 1, train loss 0.651052713394165, validation loss 0.9366251230239868\n",
      "Epoch 580, current patience 30, model mean validation loss 0.9862031936645508, embedding dim 256, hidden size 1024, num layers 1, train loss 0.3991783857345581, validation loss 0.9701489806175232\n",
      "Epoch 590, current patience 30, model mean validation loss 0.9848814010620117, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7132680416107178, validation loss 0.9754704236984253\n",
      "Epoch 600, current patience 30, model mean validation loss 0.9831109046936035, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7873550653457642, validation loss 1.008071780204773\n",
      "Epoch 610, current patience 30, model mean validation loss 0.9730491638183594, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5415653586387634, validation loss 0.969856321811676\n",
      "Epoch 620, current patience 30, model mean validation loss 0.9810791015625, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5813486576080322, validation loss 1.0508902072906494\n",
      "Epoch 630, current patience 29, model mean validation loss 0.9792743921279907, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7176228761672974, validation loss 0.9420869946479797\n",
      "Epoch 640, current patience 28, model mean validation loss 0.9814715385437012, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5907350778579712, validation loss 0.9986220598220825\n",
      "Epoch 650, current patience 27, model mean validation loss 0.9927789568901062, embedding dim 256, hidden size 1024, num layers 1, train loss 0.47754162549972534, validation loss 1.0270848274230957\n",
      "Epoch 660, current patience 26, model mean validation loss 0.9928008317947388, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5991171598434448, validation loss 0.9703243374824524\n",
      "Epoch 670, current patience 25, model mean validation loss 0.9969083666801453, embedding dim 256, hidden size 1024, num layers 1, train loss 0.893639087677002, validation loss 1.0083305835723877\n",
      "Epoch 680, current patience 24, model mean validation loss 0.9970449209213257, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6811671257019043, validation loss 1.0091644525527954\n",
      "Epoch 690, current patience 23, model mean validation loss 1.0040533542633057, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5616886615753174, validation loss 1.025923490524292\n",
      "Epoch 700, current patience 22, model mean validation loss 1.0037434101104736, embedding dim 256, hidden size 1024, num layers 1, train loss 0.34219276905059814, validation loss 1.0484102964401245\n",
      "Epoch 710, current patience 21, model mean validation loss 1.0189517736434937, embedding dim 256, hidden size 1024, num layers 1, train loss 0.9526652097702026, validation loss 1.063753604888916\n",
      "Epoch 720, current patience 20, model mean validation loss 1.0245275497436523, embedding dim 256, hidden size 1024, num layers 1, train loss 0.4591476321220398, validation loss 1.0432289838790894\n",
      "Epoch 730, current patience 19, model mean validation loss 1.0420012474060059, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6964436173439026, validation loss 1.1668741703033447\n",
      "Epoch 740, current patience 18, model mean validation loss 1.0491621494293213, embedding dim 256, hidden size 1024, num layers 1, train loss 0.43124157190322876, validation loss 1.027611255645752\n",
      "Epoch 750, current patience 17, model mean validation loss 1.0504004955291748, embedding dim 256, hidden size 1024, num layers 1, train loss 0.17254166305065155, validation loss 1.0182377099990845\n",
      "Epoch 760, current patience 16, model mean validation loss 1.0622550249099731, embedding dim 256, hidden size 1024, num layers 1, train loss 0.455142080783844, validation loss 1.1040008068084717\n",
      "Epoch 770, current patience 15, model mean validation loss 1.0644702911376953, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7199922800064087, validation loss 1.0436453819274902\n",
      "Epoch 780, current patience 14, model mean validation loss 1.061018466949463, embedding dim 256, hidden size 1024, num layers 1, train loss 0.397265762090683, validation loss 1.0207958221435547\n",
      "Epoch 790, current patience 13, model mean validation loss 1.0583807229995728, embedding dim 256, hidden size 1024, num layers 1, train loss 0.4721677899360657, validation loss 1.042651891708374\n",
      "Epoch 800, current patience 12, model mean validation loss 1.081613302230835, embedding dim 256, hidden size 1024, num layers 1, train loss 0.2765152156352997, validation loss 1.2290898561477661\n",
      "Epoch 810, current patience 11, model mean validation loss 1.070268988609314, embedding dim 256, hidden size 1024, num layers 1, train loss 0.37293577194213867, validation loss 1.07611882686615\n",
      "Epoch 820, current patience 10, model mean validation loss 1.095771074295044, embedding dim 256, hidden size 1024, num layers 1, train loss 0.44874027371406555, validation loss 1.2316280603408813\n",
      "Epoch 830, current patience 9, model mean validation loss 1.112410545349121, embedding dim 256, hidden size 1024, num layers 1, train loss 0.2443571239709854, validation loss 1.1513540744781494\n",
      "Epoch 840, current patience 8, model mean validation loss 1.1156420707702637, embedding dim 256, hidden size 1024, num layers 1, train loss 0.7121329307556152, validation loss 1.1298532485961914\n",
      "Epoch 850, current patience 7, model mean validation loss 1.1296303272247314, embedding dim 256, hidden size 1024, num layers 1, train loss 0.18355560302734375, validation loss 1.155550479888916\n",
      "Epoch 860, current patience 6, model mean validation loss 1.1477227210998535, embedding dim 256, hidden size 1024, num layers 1, train loss 0.333864688873291, validation loss 1.1655349731445312\n",
      "Epoch 870, current patience 5, model mean validation loss 1.1629700660705566, embedding dim 256, hidden size 1024, num layers 1, train loss 0.421117901802063, validation loss 1.1646313667297363\n",
      "Epoch 880, current patience 4, model mean validation loss 1.1731122732162476, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5115119218826294, validation loss 1.310227632522583\n",
      "Epoch 890, current patience 3, model mean validation loss 1.1739282608032227, embedding dim 256, hidden size 1024, num layers 1, train loss 0.5236246585845947, validation loss 1.0826466083526611\n",
      "Epoch 900, current patience 2, model mean validation loss 1.1595885753631592, embedding dim 256, hidden size 1024, num layers 1, train loss 0.6766500473022461, validation loss 1.1169102191925049\n",
      "Epoch 910, current patience 1, model mean validation loss 1.155341625213623, embedding dim 256, hidden size 1024, num layers 1, train loss 0.3495621681213379, validation loss 1.1173784732818604\n",
      "Epoch 0, current patience 30, model mean validation loss 1.467347264289856, embedding dim 256, hidden size 2048, num layers 1, train loss 1.098067045211792, validation loss 1.467347264289856\n",
      "Epoch 10, current patience 30, model mean validation loss 1.3850791454315186, embedding dim 256, hidden size 2048, num layers 1, train loss 1.6896355152130127, validation loss 1.3028111457824707\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3237462043762207, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0991400480270386, validation loss 1.2010804414749146\n",
      "Epoch 30, current patience 30, model mean validation loss 1.2738399505615234, embedding dim 256, hidden size 2048, num layers 1, train loss 1.095102310180664, validation loss 1.1241211891174316\n",
      "Epoch 40, current patience 30, model mean validation loss 1.232468605041504, embedding dim 256, hidden size 2048, num layers 1, train loss 1.1375656127929688, validation loss 1.0669828653335571\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2070575952529907, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0676794052124023, validation loss 1.080003023147583\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1881468296051025, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9997826814651489, validation loss 1.0746822357177734\n",
      "Epoch 70, current patience 30, model mean validation loss 1.174708366394043, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9785568714141846, validation loss 1.0806388854980469\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1220223903656006, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8940922021865845, validation loss 1.0458592176437378\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0876693725585938, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8935995101928711, validation loss 1.0279877185821533\n",
      "Epoch 100, current patience 30, model mean validation loss 1.061659336090088, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0478763580322266, validation loss 0.9929996728897095\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0430972576141357, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8942228555679321, validation loss 0.9756240844726562\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0336397886276245, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0573625564575195, validation loss 0.9913235902786255\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0286009311676025, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0558881759643555, validation loss 1.0396921634674072\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0193356275558472, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9404752850532532, validation loss 1.000559687614441\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0157936811447144, embedding dim 256, hidden size 2048, num layers 1, train loss 1.0386567115783691, validation loss 1.0523035526275635\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0142498016357422, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9715994596481323, validation loss 1.0335075855255127\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0063331127166748, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9647531509399414, validation loss 0.9646537899971008\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0033913850784302, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7513710260391235, validation loss 0.9694660902023315\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0024017095565796, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9311329126358032, validation loss 0.9677073955535889\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0082467794418335, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8695865273475647, validation loss 1.038083791732788\n",
      "Epoch 210, current patience 29, model mean validation loss 1.000502586364746, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7984364032745361, validation loss 0.9777384400367737\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9939326047897339, embedding dim 256, hidden size 2048, num layers 1, train loss 1.066495656967163, validation loss 0.9480003118515015\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9830846190452576, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7003673315048218, validation loss 0.9655197858810425\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9814120531082153, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8127596378326416, validation loss 1.020127296447754\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9841051697731018, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9679065942764282, validation loss 0.986197829246521\n",
      "Epoch 260, current patience 29, model mean validation loss 0.992316722869873, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7409182786941528, validation loss 1.035158634185791\n",
      "Epoch 270, current patience 28, model mean validation loss 0.9983662366867065, embedding dim 256, hidden size 2048, num layers 1, train loss 0.595860481262207, validation loss 1.016103744506836\n",
      "Epoch 280, current patience 27, model mean validation loss 0.9956328868865967, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7391605973243713, validation loss 1.0162168741226196\n",
      "Epoch 290, current patience 26, model mean validation loss 0.99216228723526, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7212942838668823, validation loss 0.9499742984771729\n",
      "Epoch 300, current patience 25, model mean validation loss 0.987869918346405, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8988361358642578, validation loss 0.9136611223220825\n",
      "Epoch 310, current patience 24, model mean validation loss 0.9824733138084412, embedding dim 256, hidden size 2048, num layers 1, train loss 0.35380059480667114, validation loss 0.9223471879959106\n",
      "Epoch 320, current patience 23, model mean validation loss 0.975891649723053, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6400290727615356, validation loss 0.9674734473228455\n",
      "Epoch 330, current patience 30, model mean validation loss 0.9722598195075989, embedding dim 256, hidden size 2048, num layers 1, train loss 0.42500796914100647, validation loss 0.9571430087089539\n",
      "Epoch 340, current patience 30, model mean validation loss 0.9635485410690308, embedding dim 256, hidden size 2048, num layers 1, train loss 0.340325266122818, validation loss 0.9654687643051147\n",
      "Epoch 350, current patience 30, model mean validation loss 0.953900158405304, embedding dim 256, hidden size 2048, num layers 1, train loss 0.5588812828063965, validation loss 0.9389165639877319\n",
      "Epoch 360, current patience 30, model mean validation loss 0.9469391107559204, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6372506618499756, validation loss 0.9605283737182617\n",
      "Epoch 370, current patience 30, model mean validation loss 0.9477599859237671, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6730266809463501, validation loss 0.9565410614013672\n",
      "Epoch 380, current patience 29, model mean validation loss 0.9588093757629395, embedding dim 256, hidden size 2048, num layers 1, train loss 0.3632389307022095, validation loss 1.0020568370819092\n",
      "Epoch 390, current patience 28, model mean validation loss 0.9621290564537048, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6076194643974304, validation loss 0.9489041566848755\n",
      "Epoch 400, current patience 27, model mean validation loss 0.9704707860946655, embedding dim 256, hidden size 2048, num layers 1, train loss 0.461090624332428, validation loss 1.0342073440551758\n",
      "Epoch 410, current patience 26, model mean validation loss 0.9693691730499268, embedding dim 256, hidden size 2048, num layers 1, train loss 0.9232866168022156, validation loss 0.9483306407928467\n",
      "Epoch 420, current patience 25, model mean validation loss 0.9708795547485352, embedding dim 256, hidden size 2048, num layers 1, train loss 0.5647696256637573, validation loss 0.9775518178939819\n",
      "Epoch 430, current patience 24, model mean validation loss 0.9762787222862244, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6544244289398193, validation loss 0.9821093082427979\n",
      "Epoch 440, current patience 23, model mean validation loss 0.9778866171836853, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6558336019515991, validation loss 0.9733915328979492\n",
      "Epoch 450, current patience 22, model mean validation loss 0.9806907176971436, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7363973259925842, validation loss 0.9789742827415466\n",
      "Epoch 460, current patience 21, model mean validation loss 0.9734292030334473, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8389917016029358, validation loss 0.943964421749115\n",
      "Epoch 470, current patience 20, model mean validation loss 0.9916679263114929, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6417138576507568, validation loss 1.0948141813278198\n",
      "Epoch 480, current patience 19, model mean validation loss 0.9886900186538696, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6181455850601196, validation loss 1.0103843212127686\n",
      "Epoch 490, current patience 18, model mean validation loss 0.994087815284729, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8757700324058533, validation loss 0.9915130138397217\n",
      "Epoch 500, current patience 17, model mean validation loss 0.9928341507911682, embedding dim 256, hidden size 2048, num layers 1, train loss 0.6089967489242554, validation loss 0.9675217270851135\n",
      "Epoch 510, current patience 16, model mean validation loss 0.9942870736122131, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8461313843727112, validation loss 0.9937330484390259\n",
      "Epoch 520, current patience 15, model mean validation loss 1.0016472339630127, embedding dim 256, hidden size 2048, num layers 1, train loss 0.4357028007507324, validation loss 1.0322721004486084\n",
      "Epoch 530, current patience 14, model mean validation loss 1.0053132772445679, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7919525504112244, validation loss 1.0083034038543701\n",
      "Epoch 540, current patience 13, model mean validation loss 1.0124770402908325, embedding dim 256, hidden size 2048, num layers 1, train loss 0.2310987412929535, validation loss 1.001274824142456\n",
      "Epoch 550, current patience 12, model mean validation loss 1.0024378299713135, embedding dim 256, hidden size 2048, num layers 1, train loss 0.4791094660758972, validation loss 1.014500617980957\n",
      "Epoch 560, current patience 11, model mean validation loss 1.0050110816955566, embedding dim 256, hidden size 2048, num layers 1, train loss 0.5894188284873962, validation loss 1.0309703350067139\n",
      "Epoch 570, current patience 10, model mean validation loss 1.0048660039901733, embedding dim 256, hidden size 2048, num layers 1, train loss 0.5212551951408386, validation loss 0.9903522729873657\n",
      "Epoch 580, current patience 9, model mean validation loss 1.039542555809021, embedding dim 256, hidden size 2048, num layers 1, train loss 0.500002920627594, validation loss 1.2449339628219604\n",
      "Epoch 590, current patience 8, model mean validation loss 1.0443414449691772, embedding dim 256, hidden size 2048, num layers 1, train loss 0.7286438941955566, validation loss 1.0321242809295654\n",
      "Epoch 600, current patience 7, model mean validation loss 1.0499989986419678, embedding dim 256, hidden size 2048, num layers 1, train loss 0.46062201261520386, validation loss 1.0775315761566162\n",
      "Epoch 610, current patience 6, model mean validation loss 1.0567086935043335, embedding dim 256, hidden size 2048, num layers 1, train loss 0.31878459453582764, validation loss 1.0619819164276123\n",
      "Epoch 620, current patience 5, model mean validation loss 1.0591588020324707, embedding dim 256, hidden size 2048, num layers 1, train loss 0.606494665145874, validation loss 1.0208759307861328\n",
      "Epoch 630, current patience 4, model mean validation loss 1.063995122909546, embedding dim 256, hidden size 2048, num layers 1, train loss 1.1368074417114258, validation loss 1.0531907081604004\n",
      "Epoch 640, current patience 3, model mean validation loss 1.0817023515701294, embedding dim 256, hidden size 2048, num layers 1, train loss 0.566572368144989, validation loss 1.1726278066635132\n",
      "Epoch 650, current patience 2, model mean validation loss 1.1244335174560547, embedding dim 256, hidden size 2048, num layers 1, train loss 0.5336775779724121, validation loss 1.3322017192840576\n",
      "Epoch 660, current patience 1, model mean validation loss 1.118493914604187, embedding dim 256, hidden size 2048, num layers 1, train loss 0.8028897047042847, validation loss 1.1974177360534668\n",
      "Epoch 0, current patience 30, model mean validation loss 1.125145435333252, embedding dim 512, hidden size 1, num layers 1, train loss 1.1412756443023682, validation loss 1.125145435333252\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1205012798309326, embedding dim 512, hidden size 1, num layers 1, train loss 1.110501766204834, validation loss 1.1158571243286133\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1174856424331665, embedding dim 512, hidden size 1, num layers 1, train loss 1.0987352132797241, validation loss 1.1114542484283447\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1131985187530518, embedding dim 512, hidden size 1, num layers 1, train loss 1.0826131105422974, validation loss 1.1003375053405762\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1096312999725342, embedding dim 512, hidden size 1, num layers 1, train loss 1.1126948595046997, validation loss 1.0953617095947266\n",
      "Epoch 50, current patience 30, model mean validation loss 1.106967568397522, embedding dim 512, hidden size 1, num layers 1, train loss 1.1115033626556396, validation loss 1.0936492681503296\n",
      "Epoch 60, current patience 30, model mean validation loss 1.104801893234253, embedding dim 512, hidden size 1, num layers 1, train loss 1.092625617980957, validation loss 1.0918080806732178\n",
      "Epoch 70, current patience 30, model mean validation loss 1.103271722793579, embedding dim 512, hidden size 1, num layers 1, train loss 1.044365406036377, validation loss 1.0925602912902832\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0990849733352661, embedding dim 512, hidden size 1, num layers 1, train loss 1.1040728092193604, validation loss 1.0916515588760376\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0959265232086182, embedding dim 512, hidden size 1, num layers 1, train loss 1.100306510925293, validation loss 1.090590000152588\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0935642719268799, embedding dim 512, hidden size 1, num layers 1, train loss 1.093540906906128, validation loss 1.0925556421279907\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0920934677124023, embedding dim 512, hidden size 1, num layers 1, train loss 1.0632661581039429, validation loss 1.0885705947875977\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0915820598602295, embedding dim 512, hidden size 1, num layers 1, train loss 1.1131677627563477, validation loss 1.0912705659866333\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0913952589035034, embedding dim 512, hidden size 1, num layers 1, train loss 1.0808591842651367, validation loss 1.0921552181243896\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0912959575653076, embedding dim 512, hidden size 1, num layers 1, train loss 1.0880539417266846, validation loss 1.0910148620605469\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0912220478057861, embedding dim 512, hidden size 1, num layers 1, train loss 1.0978716611862183, validation loss 1.0919679403305054\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0914645195007324, embedding dim 512, hidden size 1, num layers 1, train loss 1.097741961479187, validation loss 1.0935916900634766\n",
      "Epoch 170, current patience 29, model mean validation loss 1.0916483402252197, embedding dim 512, hidden size 1, num layers 1, train loss 1.102249264717102, validation loss 1.0920605659484863\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0913279056549072, embedding dim 512, hidden size 1, num layers 1, train loss 1.1016511917114258, validation loss 1.0899916887283325\n",
      "Epoch 190, current patience 27, model mean validation loss 1.0914883613586426, embedding dim 512, hidden size 1, num layers 1, train loss 1.0978338718414307, validation loss 1.0898542404174805\n",
      "Epoch 200, current patience 26, model mean validation loss 1.090958833694458, embedding dim 512, hidden size 1, num layers 1, train loss 1.0441291332244873, validation loss 1.087035059928894\n",
      "Epoch 210, current patience 30, model mean validation loss 1.0908122062683105, embedding dim 512, hidden size 1, num layers 1, train loss 1.0980775356292725, validation loss 1.0909814834594727\n",
      "Epoch 220, current patience 30, model mean validation loss 1.0911365747451782, embedding dim 512, hidden size 1, num layers 1, train loss 1.1083965301513672, validation loss 1.0936099290847778\n",
      "Epoch 230, current patience 29, model mean validation loss 1.091178297996521, embedding dim 512, hidden size 1, num layers 1, train loss 1.08048677444458, validation loss 1.092301368713379\n",
      "Epoch 240, current patience 28, model mean validation loss 1.0900156497955322, embedding dim 512, hidden size 1, num layers 1, train loss 1.0290979146957397, validation loss 1.0842907428741455\n",
      "Epoch 250, current patience 30, model mean validation loss 1.0902528762817383, embedding dim 512, hidden size 1, num layers 1, train loss 1.0878117084503174, validation loss 1.0939586162567139\n",
      "Epoch 260, current patience 29, model mean validation loss 1.0911738872528076, embedding dim 512, hidden size 1, num layers 1, train loss 1.0303384065628052, validation loss 1.0973589420318604\n",
      "Epoch 270, current patience 28, model mean validation loss 1.0914994478225708, embedding dim 512, hidden size 1, num layers 1, train loss 1.0852892398834229, validation loss 1.0924590826034546\n",
      "Epoch 280, current patience 27, model mean validation loss 1.0922547578811646, embedding dim 512, hidden size 1, num layers 1, train loss 1.08327317237854, validation loss 1.0930777788162231\n",
      "Epoch 290, current patience 26, model mean validation loss 1.0923830270767212, embedding dim 512, hidden size 1, num layers 1, train loss 1.0585135221481323, validation loss 1.0920073986053467\n",
      "Epoch 300, current patience 25, model mean validation loss 1.0918385982513428, embedding dim 512, hidden size 1, num layers 1, train loss 1.12028968334198, validation loss 1.08925461769104\n",
      "Epoch 310, current patience 24, model mean validation loss 1.091367483139038, embedding dim 512, hidden size 1, num layers 1, train loss 1.1066619157791138, validation loss 1.0885323286056519\n",
      "Epoch 320, current patience 23, model mean validation loss 1.0920183658599854, embedding dim 512, hidden size 1, num layers 1, train loss 1.0734308958053589, validation loss 1.0894986391067505\n",
      "Epoch 330, current patience 22, model mean validation loss 1.0921401977539062, embedding dim 512, hidden size 1, num layers 1, train loss 1.07757568359375, validation loss 1.094933271408081\n",
      "Epoch 340, current patience 21, model mean validation loss 1.0916399955749512, embedding dim 512, hidden size 1, num layers 1, train loss 1.1090028285980225, validation loss 1.0933563709259033\n",
      "Epoch 350, current patience 20, model mean validation loss 1.0911157131195068, embedding dim 512, hidden size 1, num layers 1, train loss 1.0477826595306396, validation loss 1.0882647037506104\n",
      "Epoch 360, current patience 19, model mean validation loss 1.0901777744293213, embedding dim 512, hidden size 1, num layers 1, train loss 1.0674219131469727, validation loss 1.0855745077133179\n",
      "Epoch 370, current patience 18, model mean validation loss 1.090193748474121, embedding dim 512, hidden size 1, num layers 1, train loss 1.0649185180664062, validation loss 1.0921351909637451\n",
      "Epoch 380, current patience 17, model mean validation loss 1.089937686920166, embedding dim 512, hidden size 1, num layers 1, train loss 1.0631402730941772, validation loss 1.0872066020965576\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0908615589141846, embedding dim 512, hidden size 1, num layers 1, train loss 1.100142478942871, validation loss 1.095922827720642\n",
      "Epoch 400, current patience 29, model mean validation loss 1.090699315071106, embedding dim 512, hidden size 1, num layers 1, train loss 1.0151433944702148, validation loss 1.0882010459899902\n",
      "Epoch 410, current patience 28, model mean validation loss 1.090915560722351, embedding dim 512, hidden size 1, num layers 1, train loss 1.0579833984375, validation loss 1.0966631174087524\n",
      "Epoch 420, current patience 27, model mean validation loss 1.090325117111206, embedding dim 512, hidden size 1, num layers 1, train loss 1.0382561683654785, validation loss 1.0886322259902954\n",
      "Epoch 430, current patience 26, model mean validation loss 1.090500831604004, embedding dim 512, hidden size 1, num layers 1, train loss 1.0382453203201294, validation loss 1.0896706581115723\n",
      "Epoch 440, current patience 25, model mean validation loss 1.0909982919692993, embedding dim 512, hidden size 1, num layers 1, train loss 1.0904593467712402, validation loss 1.0895543098449707\n",
      "Epoch 450, current patience 24, model mean validation loss 1.0912333726882935, embedding dim 512, hidden size 1, num layers 1, train loss 1.0402579307556152, validation loss 1.0940160751342773\n",
      "Epoch 460, current patience 23, model mean validation loss 1.092372179031372, embedding dim 512, hidden size 1, num layers 1, train loss 1.0702742338180542, validation loss 1.0963177680969238\n",
      "Epoch 470, current patience 22, model mean validation loss 1.0922996997833252, embedding dim 512, hidden size 1, num layers 1, train loss 1.0623637437820435, validation loss 1.0953428745269775\n",
      "Epoch 480, current patience 21, model mean validation loss 1.093407154083252, embedding dim 512, hidden size 1, num layers 1, train loss 1.095015048980713, validation loss 1.0970607995986938\n",
      "Epoch 490, current patience 20, model mean validation loss 1.0934892892837524, embedding dim 512, hidden size 1, num layers 1, train loss 1.0763845443725586, validation loss 1.0973193645477295\n",
      "Epoch 500, current patience 19, model mean validation loss 1.0941683053970337, embedding dim 512, hidden size 1, num layers 1, train loss 1.0923852920532227, validation loss 1.0940643548965454\n",
      "Epoch 510, current patience 18, model mean validation loss 1.0948841571807861, embedding dim 512, hidden size 1, num layers 1, train loss 1.076378345489502, validation loss 1.09539794921875\n",
      "Epoch 520, current patience 17, model mean validation loss 1.0956010818481445, embedding dim 512, hidden size 1, num layers 1, train loss 1.0775877237319946, validation loss 1.095289945602417\n",
      "Epoch 530, current patience 16, model mean validation loss 1.0951358079910278, embedding dim 512, hidden size 1, num layers 1, train loss 1.0782883167266846, validation loss 1.090293526649475\n",
      "Epoch 540, current patience 15, model mean validation loss 1.09490966796875, embedding dim 512, hidden size 1, num layers 1, train loss 1.0337798595428467, validation loss 1.0945085287094116\n",
      "Epoch 550, current patience 14, model mean validation loss 1.0954562425613403, embedding dim 512, hidden size 1, num layers 1, train loss 1.0745700597763062, validation loss 1.099715232849121\n",
      "Epoch 560, current patience 13, model mean validation loss 1.09458589553833, embedding dim 512, hidden size 1, num layers 1, train loss 1.092392921447754, validation loss 1.0900986194610596\n",
      "Epoch 570, current patience 12, model mean validation loss 1.094146490097046, embedding dim 512, hidden size 1, num layers 1, train loss 1.0336755514144897, validation loss 1.093803882598877\n",
      "Epoch 580, current patience 11, model mean validation loss 1.0938589572906494, embedding dim 512, hidden size 1, num layers 1, train loss 1.0110085010528564, validation loss 1.091764211654663\n",
      "Epoch 590, current patience 10, model mean validation loss 1.0932910442352295, embedding dim 512, hidden size 1, num layers 1, train loss 1.0710375308990479, validation loss 1.0908548831939697\n",
      "Epoch 600, current patience 9, model mean validation loss 1.0921475887298584, embedding dim 512, hidden size 1, num layers 1, train loss 1.065434455871582, validation loss 1.08614182472229\n",
      "Epoch 610, current patience 8, model mean validation loss 1.0926716327667236, embedding dim 512, hidden size 1, num layers 1, train loss 1.068014144897461, validation loss 1.0944859981536865\n",
      "Epoch 620, current patience 7, model mean validation loss 1.0917823314666748, embedding dim 512, hidden size 1, num layers 1, train loss 1.0473088026046753, validation loss 1.0873935222625732\n",
      "Epoch 630, current patience 6, model mean validation loss 1.0914185047149658, embedding dim 512, hidden size 1, num layers 1, train loss 1.0713118314743042, validation loss 1.0968043804168701\n",
      "Epoch 640, current patience 5, model mean validation loss 1.0919339656829834, embedding dim 512, hidden size 1, num layers 1, train loss 1.0890648365020752, validation loss 1.0942232608795166\n",
      "Epoch 650, current patience 4, model mean validation loss 1.0920761823654175, embedding dim 512, hidden size 1, num layers 1, train loss 1.0829405784606934, validation loss 1.0949411392211914\n",
      "Epoch 660, current patience 3, model mean validation loss 1.0927605628967285, embedding dim 512, hidden size 1, num layers 1, train loss 1.0671184062957764, validation loss 1.0972394943237305\n",
      "Epoch 670, current patience 2, model mean validation loss 1.0923686027526855, embedding dim 512, hidden size 1, num layers 1, train loss 1.0679445266723633, validation loss 1.0877195596694946\n",
      "Epoch 680, current patience 1, model mean validation loss 1.0933879613876343, embedding dim 512, hidden size 1, num layers 1, train loss 1.0619913339614868, validation loss 1.0942962169647217\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1891779899597168, embedding dim 512, hidden size 2, num layers 1, train loss 1.2019959688186646, validation loss 1.1891779899597168\n",
      "Epoch 10, current patience 30, model mean validation loss 1.16972017288208, embedding dim 512, hidden size 2, num layers 1, train loss 1.1906318664550781, validation loss 1.1502623558044434\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1553316116333008, embedding dim 512, hidden size 2, num layers 1, train loss 1.1255618333816528, validation loss 1.1265544891357422\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1455954313278198, embedding dim 512, hidden size 2, num layers 1, train loss 1.1006847620010376, validation loss 1.1163867712020874\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1373029947280884, embedding dim 512, hidden size 2, num layers 1, train loss 1.0971298217773438, validation loss 1.1041332483291626\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1312345266342163, embedding dim 512, hidden size 2, num layers 1, train loss 1.1100754737854004, validation loss 1.1008918285369873\n",
      "Epoch 60, current patience 30, model mean validation loss 1.126743197441101, embedding dim 512, hidden size 2, num layers 1, train loss 1.075221300125122, validation loss 1.0997954607009888\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1226913928985596, embedding dim 512, hidden size 2, num layers 1, train loss 1.120055913925171, validation loss 1.094330072402954\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1106071472167969, embedding dim 512, hidden size 2, num layers 1, train loss 1.0919314622879028, validation loss 1.0925036668777466\n",
      "Epoch 90, current patience 30, model mean validation loss 1.103532075881958, embedding dim 512, hidden size 2, num layers 1, train loss 1.0978620052337646, validation loss 1.093662142753601\n",
      "Epoch 100, current patience 30, model mean validation loss 1.099311351776123, embedding dim 512, hidden size 2, num layers 1, train loss 1.0824720859527588, validation loss 1.092787742614746\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0966465473175049, embedding dim 512, hidden size 2, num layers 1, train loss 1.1027803421020508, validation loss 1.0950685739517212\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0953876972198486, embedding dim 512, hidden size 2, num layers 1, train loss 1.0847406387329102, validation loss 1.0940622091293335\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0946125984191895, embedding dim 512, hidden size 2, num layers 1, train loss 1.0998226404190063, validation loss 1.0946904420852661\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0939667224884033, embedding dim 512, hidden size 2, num layers 1, train loss 1.1039756536483765, validation loss 1.0946292877197266\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0936039686203003, embedding dim 512, hidden size 2, num layers 1, train loss 1.0959986448287964, validation loss 1.0914274454116821\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0936648845672607, embedding dim 512, hidden size 2, num layers 1, train loss 1.0985362529754639, validation loss 1.0929913520812988\n",
      "Epoch 170, current patience 29, model mean validation loss 1.0938782691955566, embedding dim 512, hidden size 2, num layers 1, train loss 1.0857864618301392, validation loss 1.0953686237335205\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0939435958862305, embedding dim 512, hidden size 2, num layers 1, train loss 1.0910131931304932, validation loss 1.0933113098144531\n",
      "Epoch 190, current patience 27, model mean validation loss 1.0936601161956787, embedding dim 512, hidden size 2, num layers 1, train loss 1.1077507734298706, validation loss 1.092799425125122\n",
      "Epoch 200, current patience 26, model mean validation loss 1.093865156173706, embedding dim 512, hidden size 2, num layers 1, train loss 1.0886645317077637, validation loss 1.0957026481628418\n",
      "Epoch 210, current patience 25, model mean validation loss 1.0938650369644165, embedding dim 512, hidden size 2, num layers 1, train loss 1.0807081460952759, validation loss 1.094690203666687\n",
      "Epoch 220, current patience 24, model mean validation loss 1.09388267993927, embedding dim 512, hidden size 2, num layers 1, train loss 1.093582272529602, validation loss 1.0947706699371338\n",
      "Epoch 230, current patience 23, model mean validation loss 1.0942620038986206, embedding dim 512, hidden size 2, num layers 1, train loss 1.0781617164611816, validation loss 1.0944621562957764\n",
      "Epoch 240, current patience 22, model mean validation loss 1.0942699909210205, embedding dim 512, hidden size 2, num layers 1, train loss 1.0800213813781738, validation loss 1.0930547714233398\n",
      "Epoch 250, current patience 21, model mean validation loss 1.0938585996627808, embedding dim 512, hidden size 2, num layers 1, train loss 1.090523600578308, validation loss 1.092077612876892\n",
      "Epoch 260, current patience 20, model mean validation loss 1.0935418605804443, embedding dim 512, hidden size 2, num layers 1, train loss 1.0985779762268066, validation loss 1.0907765626907349\n",
      "Epoch 270, current patience 30, model mean validation loss 1.0932703018188477, embedding dim 512, hidden size 2, num layers 1, train loss 1.0858559608459473, validation loss 1.0906269550323486\n",
      "Epoch 280, current patience 30, model mean validation loss 1.092468023300171, embedding dim 512, hidden size 2, num layers 1, train loss 1.085211992263794, validation loss 1.0892844200134277\n",
      "Epoch 290, current patience 30, model mean validation loss 1.0920406579971313, embedding dim 512, hidden size 2, num layers 1, train loss 1.0936157703399658, validation loss 1.091271996498108\n",
      "Epoch 300, current patience 30, model mean validation loss 1.0916314125061035, embedding dim 512, hidden size 2, num layers 1, train loss 1.1110608577728271, validation loss 1.0914968252182007\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0914521217346191, embedding dim 512, hidden size 2, num layers 1, train loss 1.0726730823516846, validation loss 1.0930284261703491\n",
      "Epoch 320, current patience 30, model mean validation loss 1.0909383296966553, embedding dim 512, hidden size 2, num layers 1, train loss 1.0904321670532227, validation loss 1.0889440774917603\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0915195941925049, embedding dim 512, hidden size 2, num layers 1, train loss 1.0622751712799072, validation loss 1.0967273712158203\n",
      "Epoch 340, current patience 29, model mean validation loss 1.0911109447479248, embedding dim 512, hidden size 2, num layers 1, train loss 1.022698163986206, validation loss 1.087508201599121\n",
      "Epoch 350, current patience 28, model mean validation loss 1.091207504272461, embedding dim 512, hidden size 2, num layers 1, train loss 1.0557202100753784, validation loss 1.0913994312286377\n",
      "Epoch 360, current patience 27, model mean validation loss 1.0914740562438965, embedding dim 512, hidden size 2, num layers 1, train loss 1.0910652875900269, validation loss 1.0914156436920166\n",
      "Epoch 370, current patience 26, model mean validation loss 1.091583013534546, embedding dim 512, hidden size 2, num layers 1, train loss 1.0805108547210693, validation loss 1.092144250869751\n",
      "Epoch 380, current patience 25, model mean validation loss 1.0915557146072388, embedding dim 512, hidden size 2, num layers 1, train loss 1.0729408264160156, validation loss 1.0912779569625854\n",
      "Epoch 390, current patience 24, model mean validation loss 1.0917963981628418, embedding dim 512, hidden size 2, num layers 1, train loss 1.0285749435424805, validation loss 1.094954013824463\n",
      "Epoch 400, current patience 23, model mean validation loss 1.0920301675796509, embedding dim 512, hidden size 2, num layers 1, train loss 1.085934042930603, validation loss 1.0908143520355225\n",
      "Epoch 410, current patience 22, model mean validation loss 1.0920193195343018, embedding dim 512, hidden size 2, num layers 1, train loss 1.0474032163619995, validation loss 1.096640706062317\n",
      "Epoch 420, current patience 21, model mean validation loss 1.0918591022491455, embedding dim 512, hidden size 2, num layers 1, train loss 1.1180760860443115, validation loss 1.0862267017364502\n",
      "Epoch 430, current patience 20, model mean validation loss 1.0920884609222412, embedding dim 512, hidden size 2, num layers 1, train loss 1.043778657913208, validation loss 1.0932340621948242\n",
      "Epoch 440, current patience 19, model mean validation loss 1.0921869277954102, embedding dim 512, hidden size 2, num layers 1, train loss 1.0958595275878906, validation loss 1.0922033786773682\n",
      "Epoch 450, current patience 18, model mean validation loss 1.09295654296875, embedding dim 512, hidden size 2, num layers 1, train loss 1.043161392211914, validation loss 1.0983009338378906\n",
      "Epoch 460, current patience 17, model mean validation loss 1.0943609476089478, embedding dim 512, hidden size 2, num layers 1, train loss 1.0357393026351929, validation loss 1.1025135517120361\n",
      "Epoch 470, current patience 16, model mean validation loss 1.0945724248886108, embedding dim 512, hidden size 2, num layers 1, train loss 1.044205904006958, validation loss 1.096645712852478\n",
      "Epoch 480, current patience 15, model mean validation loss 1.0951128005981445, embedding dim 512, hidden size 2, num layers 1, train loss 1.0194966793060303, validation loss 1.0951377153396606\n",
      "Epoch 490, current patience 14, model mean validation loss 1.0954413414001465, embedding dim 512, hidden size 2, num layers 1, train loss 1.0447721481323242, validation loss 1.0992681980133057\n",
      "Epoch 500, current patience 13, model mean validation loss 1.0966382026672363, embedding dim 512, hidden size 2, num layers 1, train loss 1.0323082208633423, validation loss 1.0958014726638794\n",
      "Epoch 510, current patience 12, model mean validation loss 1.0985569953918457, embedding dim 512, hidden size 2, num layers 1, train loss 1.033176064491272, validation loss 1.1085848808288574\n",
      "Epoch 520, current patience 11, model mean validation loss 1.1007401943206787, embedding dim 512, hidden size 2, num layers 1, train loss 1.0978230237960815, validation loss 1.1096687316894531\n",
      "Epoch 530, current patience 10, model mean validation loss 1.1018575429916382, embedding dim 512, hidden size 2, num layers 1, train loss 1.0227108001708984, validation loss 1.1072399616241455\n",
      "Epoch 540, current patience 9, model mean validation loss 1.1021097898483276, embedding dim 512, hidden size 2, num layers 1, train loss 1.1108582019805908, validation loss 1.1045318841934204\n",
      "Epoch 550, current patience 8, model mean validation loss 1.1026724576950073, embedding dim 512, hidden size 2, num layers 1, train loss 1.0346221923828125, validation loss 1.1011472940444946\n",
      "Epoch 560, current patience 7, model mean validation loss 1.1017498970031738, embedding dim 512, hidden size 2, num layers 1, train loss 1.0533523559570312, validation loss 1.0877577066421509\n",
      "Epoch 570, current patience 6, model mean validation loss 1.1018133163452148, embedding dim 512, hidden size 2, num layers 1, train loss 1.068382978439331, validation loss 1.0997743606567383\n",
      "Epoch 580, current patience 5, model mean validation loss 1.1022992134094238, embedding dim 512, hidden size 2, num layers 1, train loss 1.1122530698776245, validation loss 1.0996894836425781\n",
      "Epoch 590, current patience 4, model mean validation loss 1.0997631549835205, embedding dim 512, hidden size 2, num layers 1, train loss 1.0263853073120117, validation loss 1.0882964134216309\n",
      "Epoch 600, current patience 3, model mean validation loss 1.097811222076416, embedding dim 512, hidden size 2, num layers 1, train loss 1.075534701347351, validation loss 1.0940525531768799\n",
      "Epoch 610, current patience 2, model mean validation loss 1.0955476760864258, embedding dim 512, hidden size 2, num layers 1, train loss 1.057399034500122, validation loss 1.089131474494934\n",
      "Epoch 620, current patience 1, model mean validation loss 1.0941739082336426, embedding dim 512, hidden size 2, num layers 1, train loss 1.0772113800048828, validation loss 1.093542218208313\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1293725967407227, embedding dim 512, hidden size 4, num layers 1, train loss 1.1476213932037354, validation loss 1.1293725967407227\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1172778606414795, embedding dim 512, hidden size 4, num layers 1, train loss 1.1188944578170776, validation loss 1.1051831245422363\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1116582155227661, embedding dim 512, hidden size 4, num layers 1, train loss 1.0763051509857178, validation loss 1.100419044494629\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1068462133407593, embedding dim 512, hidden size 4, num layers 1, train loss 1.0668282508850098, validation loss 1.0924100875854492\n",
      "Epoch 40, current patience 30, model mean validation loss 1.104286789894104, embedding dim 512, hidden size 4, num layers 1, train loss 1.1034832000732422, validation loss 1.094049096107483\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1027904748916626, embedding dim 512, hidden size 4, num layers 1, train loss 1.1024701595306396, validation loss 1.0953092575073242\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1019213199615479, embedding dim 512, hidden size 4, num layers 1, train loss 1.0990419387817383, validation loss 1.0967057943344116\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1015050411224365, embedding dim 512, hidden size 4, num layers 1, train loss 1.09047269821167, validation loss 1.0985910892486572\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0974256992340088, embedding dim 512, hidden size 4, num layers 1, train loss 1.089453935623169, validation loss 1.0967388153076172\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0961101055145264, embedding dim 512, hidden size 4, num layers 1, train loss 1.095266342163086, validation loss 1.094657301902771\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0955462455749512, embedding dim 512, hidden size 4, num layers 1, train loss 1.0921176671981812, validation loss 1.0959078073501587\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0953270196914673, embedding dim 512, hidden size 4, num layers 1, train loss 1.0913996696472168, validation loss 1.0906572341918945\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0952987670898438, embedding dim 512, hidden size 4, num layers 1, train loss 1.1180081367492676, validation loss 1.0938223600387573\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0952566862106323, embedding dim 512, hidden size 4, num layers 1, train loss 1.1001992225646973, validation loss 1.094973087310791\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0950915813446045, embedding dim 512, hidden size 4, num layers 1, train loss 1.0788637399673462, validation loss 1.0953855514526367\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0940523147583008, embedding dim 512, hidden size 4, num layers 1, train loss 1.0747137069702148, validation loss 1.0902760028839111\n",
      "Epoch 160, current patience 30, model mean validation loss 1.094130039215088, embedding dim 512, hidden size 4, num layers 1, train loss 1.0965328216552734, validation loss 1.0973608493804932\n",
      "Epoch 170, current patience 29, model mean validation loss 1.0940368175506592, embedding dim 512, hidden size 4, num layers 1, train loss 1.0885449647903442, validation loss 1.0939116477966309\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0937362909317017, embedding dim 512, hidden size 4, num layers 1, train loss 1.109738826751709, validation loss 1.0935039520263672\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0943653583526611, embedding dim 512, hidden size 4, num layers 1, train loss 1.0816535949707031, validation loss 1.095689058303833\n",
      "Epoch 200, current patience 29, model mean validation loss 1.09505033493042, embedding dim 512, hidden size 4, num layers 1, train loss 1.0298047065734863, validation loss 1.099302887916565\n",
      "Epoch 210, current patience 28, model mean validation loss 1.095445156097412, embedding dim 512, hidden size 4, num layers 1, train loss 1.0233840942382812, validation loss 1.0981305837631226\n",
      "Epoch 220, current patience 27, model mean validation loss 1.0949957370758057, embedding dim 512, hidden size 4, num layers 1, train loss 1.0714884996414185, validation loss 1.0917909145355225\n",
      "Epoch 230, current patience 26, model mean validation loss 1.095815658569336, embedding dim 512, hidden size 4, num layers 1, train loss 1.1038053035736084, validation loss 1.0968345403671265\n",
      "Epoch 240, current patience 25, model mean validation loss 1.0961841344833374, embedding dim 512, hidden size 4, num layers 1, train loss 1.1080543994903564, validation loss 1.1003090143203735\n",
      "Epoch 250, current patience 24, model mean validation loss 1.097153902053833, embedding dim 512, hidden size 4, num layers 1, train loss 1.101752758026123, validation loss 1.1016709804534912\n",
      "Epoch 260, current patience 23, model mean validation loss 1.0981709957122803, embedding dim 512, hidden size 4, num layers 1, train loss 1.066623568534851, validation loss 1.101639986038208\n",
      "Epoch 270, current patience 22, model mean validation loss 1.0974721908569336, embedding dim 512, hidden size 4, num layers 1, train loss 1.086431622505188, validation loss 1.0900994539260864\n",
      "Epoch 280, current patience 21, model mean validation loss 1.0962541103363037, embedding dim 512, hidden size 4, num layers 1, train loss 1.0406638383865356, validation loss 1.0895577669143677\n",
      "Epoch 290, current patience 20, model mean validation loss 1.096294641494751, embedding dim 512, hidden size 4, num layers 1, train loss 1.071265697479248, validation loss 1.0984549522399902\n",
      "Epoch 300, current patience 19, model mean validation loss 1.0968875885009766, embedding dim 512, hidden size 4, num layers 1, train loss 1.0142083168029785, validation loss 1.0965347290039062\n",
      "Epoch 310, current patience 18, model mean validation loss 1.0959081649780273, embedding dim 512, hidden size 4, num layers 1, train loss 1.0963400602340698, validation loss 1.0889990329742432\n",
      "Epoch 320, current patience 17, model mean validation loss 1.0948472023010254, embedding dim 512, hidden size 4, num layers 1, train loss 1.046571135520935, validation loss 1.0918210744857788\n",
      "Epoch 330, current patience 16, model mean validation loss 1.0943183898925781, embedding dim 512, hidden size 4, num layers 1, train loss 0.9991381764411926, validation loss 1.0974392890930176\n",
      "Epoch 340, current patience 15, model mean validation loss 1.0943033695220947, embedding dim 512, hidden size 4, num layers 1, train loss 1.0600976943969727, validation loss 1.1015208959579468\n",
      "Epoch 350, current patience 14, model mean validation loss 1.0937165021896362, embedding dim 512, hidden size 4, num layers 1, train loss 0.8989965319633484, validation loss 1.0854042768478394\n",
      "Epoch 360, current patience 30, model mean validation loss 1.092960000038147, embedding dim 512, hidden size 4, num layers 1, train loss 1.082358717918396, validation loss 1.0835058689117432\n",
      "Epoch 370, current patience 30, model mean validation loss 1.0919597148895264, embedding dim 512, hidden size 4, num layers 1, train loss 1.0488355159759521, validation loss 1.0904532670974731\n",
      "Epoch 380, current patience 30, model mean validation loss 1.0906294584274292, embedding dim 512, hidden size 4, num layers 1, train loss 1.0136613845825195, validation loss 1.0858924388885498\n",
      "Epoch 390, current patience 30, model mean validation loss 1.0901472568511963, embedding dim 512, hidden size 4, num layers 1, train loss 1.0191864967346191, validation loss 1.085141897201538\n",
      "Epoch 400, current patience 30, model mean validation loss 1.0890440940856934, embedding dim 512, hidden size 4, num layers 1, train loss 0.9469223618507385, validation loss 1.0829954147338867\n",
      "Epoch 410, current patience 30, model mean validation loss 1.0882954597473145, embedding dim 512, hidden size 4, num layers 1, train loss 0.9349616765975952, validation loss 1.0914490222930908\n",
      "Epoch 420, current patience 30, model mean validation loss 1.0862022638320923, embedding dim 512, hidden size 4, num layers 1, train loss 0.9255409836769104, validation loss 1.0847758054733276\n",
      "Epoch 430, current patience 30, model mean validation loss 1.0880258083343506, embedding dim 512, hidden size 4, num layers 1, train loss 1.0079424381256104, validation loss 1.099993109703064\n",
      "Epoch 440, current patience 29, model mean validation loss 1.0885262489318848, embedding dim 512, hidden size 4, num layers 1, train loss 0.927759051322937, validation loss 1.087509274482727\n",
      "Epoch 450, current patience 28, model mean validation loss 1.0885584354400635, embedding dim 512, hidden size 4, num layers 1, train loss 1.0116174221038818, validation loss 1.0907106399536133\n",
      "Epoch 460, current patience 27, model mean validation loss 1.0912296772003174, embedding dim 512, hidden size 4, num layers 1, train loss 0.9127392172813416, validation loss 1.1072628498077393\n",
      "Epoch 470, current patience 26, model mean validation loss 1.0921390056610107, embedding dim 512, hidden size 4, num layers 1, train loss 0.9737880229949951, validation loss 1.0924164056777954\n",
      "Epoch 480, current patience 25, model mean validation loss 1.0950849056243896, embedding dim 512, hidden size 4, num layers 1, train loss 1.0668288469314575, validation loss 1.106562852859497\n",
      "Epoch 490, current patience 24, model mean validation loss 1.0972235202789307, embedding dim 512, hidden size 4, num layers 1, train loss 1.0812464952468872, validation loss 1.1085578203201294\n",
      "Epoch 500, current patience 23, model mean validation loss 1.0983729362487793, embedding dim 512, hidden size 4, num layers 1, train loss 0.9598333835601807, validation loss 1.093970537185669\n",
      "Epoch 510, current patience 22, model mean validation loss 1.0969269275665283, embedding dim 512, hidden size 4, num layers 1, train loss 0.8691332936286926, validation loss 1.088424563407898\n",
      "Epoch 520, current patience 21, model mean validation loss 1.0981745719909668, embedding dim 512, hidden size 4, num layers 1, train loss 0.9156372547149658, validation loss 1.0974905490875244\n",
      "Epoch 530, current patience 20, model mean validation loss 1.0991041660308838, embedding dim 512, hidden size 4, num layers 1, train loss 1.1065884828567505, validation loss 1.0981473922729492\n",
      "Epoch 540, current patience 19, model mean validation loss 1.0988367795944214, embedding dim 512, hidden size 4, num layers 1, train loss 0.9672099351882935, validation loss 1.1051242351531982\n",
      "Epoch 550, current patience 18, model mean validation loss 1.102034091949463, embedding dim 512, hidden size 4, num layers 1, train loss 0.9514392614364624, validation loss 1.1179946660995483\n",
      "Epoch 560, current patience 17, model mean validation loss 1.1037166118621826, embedding dim 512, hidden size 4, num layers 1, train loss 0.9270184636116028, validation loss 1.1200239658355713\n",
      "Epoch 570, current patience 16, model mean validation loss 1.1022899150848389, embedding dim 512, hidden size 4, num layers 1, train loss 0.9704663753509521, validation loss 1.0971431732177734\n",
      "Epoch 580, current patience 15, model mean validation loss 1.1038159132003784, embedding dim 512, hidden size 4, num layers 1, train loss 0.9213530421257019, validation loss 1.1061782836914062\n",
      "Epoch 590, current patience 14, model mean validation loss 1.1059714555740356, embedding dim 512, hidden size 4, num layers 1, train loss 0.9232473969459534, validation loss 1.1056697368621826\n",
      "Epoch 600, current patience 13, model mean validation loss 1.1074445247650146, embedding dim 512, hidden size 4, num layers 1, train loss 1.0174272060394287, validation loss 1.1092743873596191\n",
      "Epoch 610, current patience 12, model mean validation loss 1.1083614826202393, embedding dim 512, hidden size 4, num layers 1, train loss 1.0059739351272583, validation loss 1.1054824590682983\n",
      "Epoch 620, current patience 11, model mean validation loss 1.108960747718811, embedding dim 512, hidden size 4, num layers 1, train loss 0.8561879396438599, validation loss 1.1099193096160889\n",
      "Epoch 630, current patience 10, model mean validation loss 1.109278917312622, embedding dim 512, hidden size 4, num layers 1, train loss 0.9887296557426453, validation loss 1.1205403804779053\n",
      "Epoch 640, current patience 9, model mean validation loss 1.106931447982788, embedding dim 512, hidden size 4, num layers 1, train loss 0.9280412197113037, validation loss 1.1012436151504517\n",
      "Epoch 650, current patience 8, model mean validation loss 1.1108067035675049, embedding dim 512, hidden size 4, num layers 1, train loss 0.9150121212005615, validation loss 1.1281464099884033\n",
      "Epoch 660, current patience 7, model mean validation loss 1.109865665435791, embedding dim 512, hidden size 4, num layers 1, train loss 0.9162285327911377, validation loss 1.0986487865447998\n",
      "Epoch 670, current patience 6, model mean validation loss 1.1102665662765503, embedding dim 512, hidden size 4, num layers 1, train loss 0.9605750441551208, validation loss 1.108877182006836\n",
      "Epoch 680, current patience 5, model mean validation loss 1.1119959354400635, embedding dim 512, hidden size 4, num layers 1, train loss 1.0344789028167725, validation loss 1.1231088638305664\n",
      "Epoch 690, current patience 4, model mean validation loss 1.1120835542678833, embedding dim 512, hidden size 4, num layers 1, train loss 0.8405101299285889, validation loss 1.106184482574463\n",
      "Epoch 700, current patience 3, model mean validation loss 1.113208293914795, embedding dim 512, hidden size 4, num layers 1, train loss 0.9341366291046143, validation loss 1.1189171075820923\n",
      "Epoch 710, current patience 2, model mean validation loss 1.1097252368927002, embedding dim 512, hidden size 4, num layers 1, train loss 0.9536094665527344, validation loss 1.0926755666732788\n",
      "Epoch 720, current patience 1, model mean validation loss 1.110539436340332, embedding dim 512, hidden size 4, num layers 1, train loss 0.9664664268493652, validation loss 1.1077569723129272\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0935425758361816, embedding dim 512, hidden size 8, num layers 1, train loss 1.103684663772583, validation loss 1.0935425758361816\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0925565958023071, embedding dim 512, hidden size 8, num layers 1, train loss 1.0924451351165771, validation loss 1.0915706157684326\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0907446146011353, embedding dim 512, hidden size 8, num layers 1, train loss 1.0941704511642456, validation loss 1.087120532989502\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0893449783325195, embedding dim 512, hidden size 8, num layers 1, train loss 1.1029226779937744, validation loss 1.085146427154541\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0874578952789307, embedding dim 512, hidden size 8, num layers 1, train loss 1.0870875120162964, validation loss 1.0799094438552856\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0862178802490234, embedding dim 512, hidden size 8, num layers 1, train loss 1.089735984802246, validation loss 1.0800180435180664\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0836734771728516, embedding dim 512, hidden size 8, num layers 1, train loss 1.0071296691894531, validation loss 1.0684064626693726\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0797345638275146, embedding dim 512, hidden size 8, num layers 1, train loss 0.981231689453125, validation loss 1.0521626472473145\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0754406452178955, embedding dim 512, hidden size 8, num layers 1, train loss 0.9312038421630859, validation loss 1.0591905117034912\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0674567222595215, embedding dim 512, hidden size 8, num layers 1, train loss 1.0085712671279907, validation loss 1.0277000665664673\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0599536895751953, embedding dim 512, hidden size 8, num layers 1, train loss 0.9821793437004089, validation loss 1.0270960330963135\n",
      "Epoch 110, current patience 30, model mean validation loss 1.056575059890747, embedding dim 512, hidden size 8, num layers 1, train loss 0.8830752372741699, validation loss 1.0581167936325073\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0468462705612183, embedding dim 512, hidden size 8, num layers 1, train loss 1.0833182334899902, validation loss 1.002079963684082\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0430941581726074, embedding dim 512, hidden size 8, num layers 1, train loss 1.0434155464172363, validation loss 1.0499999523162842\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0406336784362793, embedding dim 512, hidden size 8, num layers 1, train loss 1.0100233554840088, validation loss 1.0487240552902222\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0368236303329468, embedding dim 512, hidden size 8, num layers 1, train loss 1.006434440612793, validation loss 1.0216820240020752\n",
      "Epoch 160, current patience 30, model mean validation loss 1.029588222503662, embedding dim 512, hidden size 8, num layers 1, train loss 0.9734891057014465, validation loss 1.0013070106506348\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0270240306854248, embedding dim 512, hidden size 8, num layers 1, train loss 0.7463796138763428, validation loss 1.0071864128112793\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0316405296325684, embedding dim 512, hidden size 8, num layers 1, train loss 0.7832947373390198, validation loss 1.0640281438827515\n",
      "Epoch 190, current patience 29, model mean validation loss 1.034993290901184, embedding dim 512, hidden size 8, num layers 1, train loss 0.6624529361724854, validation loss 1.084938883781433\n",
      "Epoch 200, current patience 28, model mean validation loss 1.0399773120880127, embedding dim 512, hidden size 8, num layers 1, train loss 1.059214472770691, validation loss 1.04195237159729\n",
      "Epoch 210, current patience 27, model mean validation loss 1.035976529121399, embedding dim 512, hidden size 8, num layers 1, train loss 0.6928235292434692, validation loss 1.017993450164795\n",
      "Epoch 220, current patience 26, model mean validation loss 1.034419059753418, embedding dim 512, hidden size 8, num layers 1, train loss 1.1285245418548584, validation loss 1.0362637042999268\n",
      "Epoch 230, current patience 25, model mean validation loss 1.0351738929748535, embedding dim 512, hidden size 8, num layers 1, train loss 0.6308726072311401, validation loss 1.0277211666107178\n",
      "Epoch 240, current patience 24, model mean validation loss 1.0389633178710938, embedding dim 512, hidden size 8, num layers 1, train loss 0.8289687633514404, validation loss 1.0316224098205566\n",
      "Epoch 250, current patience 23, model mean validation loss 1.0421432256698608, embedding dim 512, hidden size 8, num layers 1, train loss 1.0141007900238037, validation loss 1.032625675201416\n",
      "Epoch 260, current patience 22, model mean validation loss 1.0419213771820068, embedding dim 512, hidden size 8, num layers 1, train loss 0.9634257555007935, validation loss 1.0622539520263672\n",
      "Epoch 270, current patience 21, model mean validation loss 1.0367374420166016, embedding dim 512, hidden size 8, num layers 1, train loss 0.660731315612793, validation loss 1.0434669256210327\n",
      "Epoch 280, current patience 20, model mean validation loss 1.036887764930725, embedding dim 512, hidden size 8, num layers 1, train loss 0.8940073847770691, validation loss 1.0431549549102783\n",
      "Epoch 290, current patience 19, model mean validation loss 1.0434436798095703, embedding dim 512, hidden size 8, num layers 1, train loss 0.808025598526001, validation loss 1.0704405307769775\n",
      "Epoch 300, current patience 18, model mean validation loss 1.0452324151992798, embedding dim 512, hidden size 8, num layers 1, train loss 0.7800178527832031, validation loss 1.0505735874176025\n",
      "Epoch 310, current patience 17, model mean validation loss 1.0499898195266724, embedding dim 512, hidden size 8, num layers 1, train loss 0.8974622488021851, validation loss 1.065780520439148\n",
      "Epoch 320, current patience 16, model mean validation loss 1.0477808713912964, embedding dim 512, hidden size 8, num layers 1, train loss 0.7075638771057129, validation loss 1.0139511823654175\n",
      "Epoch 330, current patience 15, model mean validation loss 1.0486441850662231, embedding dim 512, hidden size 8, num layers 1, train loss 0.7064064741134644, validation loss 1.0395317077636719\n",
      "Epoch 340, current patience 14, model mean validation loss 1.0491609573364258, embedding dim 512, hidden size 8, num layers 1, train loss 0.9519664645195007, validation loss 1.066388726234436\n",
      "Epoch 350, current patience 13, model mean validation loss 1.0499253273010254, embedding dim 512, hidden size 8, num layers 1, train loss 0.8004849553108215, validation loss 1.0495820045471191\n",
      "Epoch 360, current patience 12, model mean validation loss 1.0529534816741943, embedding dim 512, hidden size 8, num layers 1, train loss 0.8357275724411011, validation loss 1.067379117012024\n",
      "Epoch 370, current patience 11, model mean validation loss 1.0477657318115234, embedding dim 512, hidden size 8, num layers 1, train loss 0.7594959139823914, validation loss 1.0289382934570312\n",
      "Epoch 380, current patience 10, model mean validation loss 1.0502345561981201, embedding dim 512, hidden size 8, num layers 1, train loss 0.9860039949417114, validation loss 1.0703246593475342\n",
      "Epoch 390, current patience 9, model mean validation loss 1.051180362701416, embedding dim 512, hidden size 8, num layers 1, train loss 0.7192555665969849, validation loss 1.0733474493026733\n",
      "Epoch 400, current patience 8, model mean validation loss 1.0555540323257446, embedding dim 512, hidden size 8, num layers 1, train loss 0.5755335092544556, validation loss 1.048939824104309\n",
      "Epoch 410, current patience 7, model mean validation loss 1.0582969188690186, embedding dim 512, hidden size 8, num layers 1, train loss 1.1503593921661377, validation loss 1.0614748001098633\n",
      "Epoch 420, current patience 6, model mean validation loss 1.0558347702026367, embedding dim 512, hidden size 8, num layers 1, train loss 0.592761218547821, validation loss 1.046691656112671\n",
      "Epoch 430, current patience 5, model mean validation loss 1.0581821203231812, embedding dim 512, hidden size 8, num layers 1, train loss 0.6204469799995422, validation loss 1.068361520767212\n",
      "Epoch 440, current patience 4, model mean validation loss 1.05417799949646, embedding dim 512, hidden size 8, num layers 1, train loss 0.9293498992919922, validation loss 1.035346269607544\n",
      "Epoch 450, current patience 3, model mean validation loss 1.0618555545806885, embedding dim 512, hidden size 8, num layers 1, train loss 0.6521478891372681, validation loss 1.0903584957122803\n",
      "Epoch 460, current patience 2, model mean validation loss 1.0588998794555664, embedding dim 512, hidden size 8, num layers 1, train loss 0.592613935470581, validation loss 1.0466785430908203\n",
      "Epoch 470, current patience 1, model mean validation loss 1.0621528625488281, embedding dim 512, hidden size 8, num layers 1, train loss 0.9481641054153442, validation loss 1.0993719100952148\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0971143245697021, embedding dim 512, hidden size 16, num layers 1, train loss 1.1093335151672363, validation loss 1.0971143245697021\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0930911302566528, embedding dim 512, hidden size 16, num layers 1, train loss 1.109304428100586, validation loss 1.0890679359436035\n",
      "Epoch 20, current patience 30, model mean validation loss 1.093687891960144, embedding dim 512, hidden size 16, num layers 1, train loss 1.1004942655563354, validation loss 1.0948811769485474\n",
      "Epoch 30, current patience 29, model mean validation loss 1.0923608541488647, embedding dim 512, hidden size 16, num layers 1, train loss 1.0969271659851074, validation loss 1.0883797407150269\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0891884565353394, embedding dim 512, hidden size 16, num layers 1, train loss 1.0814756155014038, validation loss 1.0764992237091064\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0846147537231445, embedding dim 512, hidden size 16, num layers 1, train loss 1.078195333480835, validation loss 1.0617462396621704\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0764673948287964, embedding dim 512, hidden size 16, num layers 1, train loss 0.950221061706543, validation loss 1.0275828838348389\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0709035396575928, embedding dim 512, hidden size 16, num layers 1, train loss 0.9231468439102173, validation loss 1.0319561958312988\n",
      "Epoch 80, current patience 30, model mean validation loss 1.062410593032837, embedding dim 512, hidden size 16, num layers 1, train loss 0.9854164123535156, validation loss 1.0291714668273926\n",
      "Epoch 90, current patience 30, model mean validation loss 1.051971435546875, embedding dim 512, hidden size 16, num layers 1, train loss 0.8851308822631836, validation loss 1.00555419921875\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0419175624847412, embedding dim 512, hidden size 16, num layers 1, train loss 0.7797846794128418, validation loss 1.0144503116607666\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0354697704315186, embedding dim 512, hidden size 16, num layers 1, train loss 0.9873517751693726, validation loss 1.0367978811264038\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0254777669906616, embedding dim 512, hidden size 16, num layers 1, train loss 0.9694823026657104, validation loss 0.9965627193450928\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0161420106887817, embedding dim 512, hidden size 16, num layers 1, train loss 0.7913153171539307, validation loss 0.9870609045028687\n",
      "Epoch 140, current patience 30, model mean validation loss 1.01163649559021, embedding dim 512, hidden size 16, num layers 1, train loss 0.7950032949447632, validation loss 0.9915385246276855\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0071980953216553, embedding dim 512, hidden size 16, num layers 1, train loss 0.7577787637710571, validation loss 0.9964488744735718\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0084116458892822, embedding dim 512, hidden size 16, num layers 1, train loss 0.7226992845535278, validation loss 1.0388801097869873\n",
      "Epoch 170, current patience 29, model mean validation loss 1.009251594543457, embedding dim 512, hidden size 16, num layers 1, train loss 0.6497060060501099, validation loss 1.0122730731964111\n",
      "Epoch 180, current patience 28, model mean validation loss 1.0055625438690186, embedding dim 512, hidden size 16, num layers 1, train loss 0.7614494562149048, validation loss 0.984938383102417\n",
      "Epoch 190, current patience 30, model mean validation loss 1.003413438796997, embedding dim 512, hidden size 16, num layers 1, train loss 1.077110767364502, validation loss 1.0196049213409424\n",
      "Epoch 200, current patience 30, model mean validation loss 1.0038807392120361, embedding dim 512, hidden size 16, num layers 1, train loss 1.1756616830825806, validation loss 1.0003013610839844\n",
      "Epoch 210, current patience 29, model mean validation loss 1.0090526342391968, embedding dim 512, hidden size 16, num layers 1, train loss 0.8533949851989746, validation loss 1.0284360647201538\n",
      "Epoch 220, current patience 28, model mean validation loss 1.013098955154419, embedding dim 512, hidden size 16, num layers 1, train loss 0.7597532868385315, validation loss 1.0239087343215942\n",
      "Epoch 230, current patience 27, model mean validation loss 1.0217125415802002, embedding dim 512, hidden size 16, num layers 1, train loss 0.7835752964019775, validation loss 1.0653574466705322\n",
      "Epoch 240, current patience 26, model mean validation loss 1.0267325639724731, embedding dim 512, hidden size 16, num layers 1, train loss 0.8549578189849854, validation loss 1.079040288925171\n",
      "Epoch 250, current patience 25, model mean validation loss 1.0293320417404175, embedding dim 512, hidden size 16, num layers 1, train loss 0.6830824613571167, validation loss 1.0330692529678345\n",
      "Epoch 260, current patience 24, model mean validation loss 1.0336118936538696, embedding dim 512, hidden size 16, num layers 1, train loss 0.8327347040176392, validation loss 1.0191771984100342\n",
      "Epoch 270, current patience 23, model mean validation loss 1.037644624710083, embedding dim 512, hidden size 16, num layers 1, train loss 0.7497857809066772, validation loss 1.051866054534912\n",
      "Epoch 280, current patience 22, model mean validation loss 1.0394864082336426, embedding dim 512, hidden size 16, num layers 1, train loss 0.826431930065155, validation loss 1.0150362253189087\n",
      "Epoch 290, current patience 21, model mean validation loss 1.0470340251922607, embedding dim 512, hidden size 16, num layers 1, train loss 1.129645824432373, validation loss 1.0888170003890991\n",
      "Epoch 300, current patience 20, model mean validation loss 1.0493452548980713, embedding dim 512, hidden size 16, num layers 1, train loss 0.90953528881073, validation loss 1.042398452758789\n",
      "Epoch 310, current patience 19, model mean validation loss 1.0485351085662842, embedding dim 512, hidden size 16, num layers 1, train loss 0.5697453618049622, validation loss 1.0588769912719727\n",
      "Epoch 320, current patience 18, model mean validation loss 1.0434590578079224, embedding dim 512, hidden size 16, num layers 1, train loss 0.6090257167816162, validation loss 1.0384310483932495\n",
      "Epoch 330, current patience 17, model mean validation loss 1.0466084480285645, embedding dim 512, hidden size 16, num layers 1, train loss 0.5121397972106934, validation loss 1.058265209197998\n",
      "Epoch 340, current patience 16, model mean validation loss 1.0561134815216064, embedding dim 512, hidden size 16, num layers 1, train loss 0.6419875621795654, validation loss 1.0952167510986328\n",
      "Epoch 350, current patience 15, model mean validation loss 1.0565763711929321, embedding dim 512, hidden size 16, num layers 1, train loss 1.3029111623764038, validation loss 1.0555689334869385\n",
      "Epoch 360, current patience 14, model mean validation loss 1.0596801042556763, embedding dim 512, hidden size 16, num layers 1, train loss 0.9267404079437256, validation loss 1.0398666858673096\n",
      "Epoch 370, current patience 13, model mean validation loss 1.0472780466079712, embedding dim 512, hidden size 16, num layers 1, train loss 0.9215418100357056, validation loss 0.9896005988121033\n",
      "Epoch 380, current patience 12, model mean validation loss 1.053327202796936, embedding dim 512, hidden size 16, num layers 1, train loss 0.773138701915741, validation loss 1.0907917022705078\n",
      "Epoch 390, current patience 11, model mean validation loss 1.0518665313720703, embedding dim 512, hidden size 16, num layers 1, train loss 1.061948537826538, validation loss 1.0471916198730469\n",
      "Epoch 400, current patience 10, model mean validation loss 1.0590338706970215, embedding dim 512, hidden size 16, num layers 1, train loss 0.4442315697669983, validation loss 1.0957694053649902\n",
      "Epoch 410, current patience 9, model mean validation loss 1.0669758319854736, embedding dim 512, hidden size 16, num layers 1, train loss 0.441750168800354, validation loss 1.1218006610870361\n",
      "Epoch 420, current patience 8, model mean validation loss 1.0700660943984985, embedding dim 512, hidden size 16, num layers 1, train loss 0.4035643935203552, validation loss 1.119938611984253\n",
      "Epoch 430, current patience 7, model mean validation loss 1.0792306661605835, embedding dim 512, hidden size 16, num layers 1, train loss 0.8812501430511475, validation loss 1.1288859844207764\n",
      "Epoch 440, current patience 6, model mean validation loss 1.082710862159729, embedding dim 512, hidden size 16, num layers 1, train loss 0.5695139765739441, validation loss 1.0677087306976318\n",
      "Epoch 450, current patience 5, model mean validation loss 1.0930205583572388, embedding dim 512, hidden size 16, num layers 1, train loss 0.5228400826454163, validation loss 1.0720772743225098\n",
      "Epoch 460, current patience 4, model mean validation loss 1.0976210832595825, embedding dim 512, hidden size 16, num layers 1, train loss 0.6482443809509277, validation loss 1.1275960206985474\n",
      "Epoch 470, current patience 3, model mean validation loss 1.1053835153579712, embedding dim 512, hidden size 16, num layers 1, train loss 0.6132252216339111, validation loss 1.1092910766601562\n",
      "Epoch 480, current patience 2, model mean validation loss 1.1042073965072632, embedding dim 512, hidden size 16, num layers 1, train loss 0.8537803292274475, validation loss 1.086359977722168\n",
      "Epoch 490, current patience 1, model mean validation loss 1.1059613227844238, embedding dim 512, hidden size 16, num layers 1, train loss 0.9415491819381714, validation loss 1.1358320713043213\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0985016822814941, embedding dim 512, hidden size 32, num layers 1, train loss 1.098343849182129, validation loss 1.0985016822814941\n",
      "Epoch 10, current patience 30, model mean validation loss 1.095192313194275, embedding dim 512, hidden size 32, num layers 1, train loss 1.0864002704620361, validation loss 1.0918829441070557\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0939770936965942, embedding dim 512, hidden size 32, num layers 1, train loss 1.0854655504226685, validation loss 1.0915467739105225\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0879422426223755, embedding dim 512, hidden size 32, num layers 1, train loss 1.0804121494293213, validation loss 1.0698375701904297\n",
      "Epoch 40, current patience 30, model mean validation loss 1.078118085861206, embedding dim 512, hidden size 32, num layers 1, train loss 1.0295796394348145, validation loss 1.0388215780258179\n",
      "Epoch 50, current patience 30, model mean validation loss 1.074999451637268, embedding dim 512, hidden size 32, num layers 1, train loss 1.0151480436325073, validation loss 1.0594061613082886\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0667574405670166, embedding dim 512, hidden size 32, num layers 1, train loss 0.8685935139656067, validation loss 1.0173050165176392\n",
      "Epoch 70, current patience 30, model mean validation loss 1.061394214630127, embedding dim 512, hidden size 32, num layers 1, train loss 0.879888653755188, validation loss 1.0238521099090576\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0504274368286133, embedding dim 512, hidden size 32, num layers 1, train loss 1.075512409210205, validation loss 1.0107673406600952\n",
      "Epoch 90, current patience 30, model mean validation loss 1.036466121673584, embedding dim 512, hidden size 32, num layers 1, train loss 0.8746857047080994, validation loss 0.9801921844482422\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0200027227401733, embedding dim 512, hidden size 32, num layers 1, train loss 0.791418194770813, validation loss 0.9598396420478821\n",
      "Epoch 110, current patience 30, model mean validation loss 1.008507490158081, embedding dim 512, hidden size 32, num layers 1, train loss 0.7410160303115845, validation loss 0.9778759479522705\n",
      "Epoch 120, current patience 30, model mean validation loss 0.997694730758667, embedding dim 512, hidden size 32, num layers 1, train loss 1.1385087966918945, validation loss 0.9523189663887024\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9905043244361877, embedding dim 512, hidden size 32, num layers 1, train loss 0.7120010256767273, validation loss 1.0018829107284546\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9860223531723022, embedding dim 512, hidden size 32, num layers 1, train loss 1.0010199546813965, validation loss 0.9814499616622925\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9766088128089905, embedding dim 512, hidden size 32, num layers 1, train loss 0.9160232543945312, validation loss 0.9485438466072083\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9679728746414185, embedding dim 512, hidden size 32, num layers 1, train loss 0.6554257273674011, validation loss 0.9416795969009399\n",
      "Epoch 170, current patience 30, model mean validation loss 0.961968719959259, embedding dim 512, hidden size 32, num layers 1, train loss 1.0698912143707275, validation loss 0.9321587085723877\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9619449377059937, embedding dim 512, hidden size 32, num layers 1, train loss 0.96262526512146, validation loss 0.9596494436264038\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9562439322471619, embedding dim 512, hidden size 32, num layers 1, train loss 0.6419155597686768, validation loss 0.9322684407234192\n",
      "Epoch 200, current patience 30, model mean validation loss 0.9503648281097412, embedding dim 512, hidden size 32, num layers 1, train loss 0.7675557136535645, validation loss 0.9052854776382446\n",
      "Epoch 210, current patience 30, model mean validation loss 0.9464430212974548, embedding dim 512, hidden size 32, num layers 1, train loss 0.5384252071380615, validation loss 0.9705088138580322\n",
      "Epoch 220, current patience 30, model mean validation loss 0.9451744556427002, embedding dim 512, hidden size 32, num layers 1, train loss 0.6129512190818787, validation loss 0.9713014364242554\n",
      "Epoch 230, current patience 30, model mean validation loss 0.9409294724464417, embedding dim 512, hidden size 32, num layers 1, train loss 0.7434899806976318, validation loss 0.9145839810371399\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9376139640808105, embedding dim 512, hidden size 32, num layers 1, train loss 0.709002673625946, validation loss 0.9151554703712463\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9387599229812622, embedding dim 512, hidden size 32, num layers 1, train loss 0.6107138395309448, validation loss 0.9413256645202637\n",
      "Epoch 260, current patience 29, model mean validation loss 0.941519558429718, embedding dim 512, hidden size 32, num layers 1, train loss 0.6501792669296265, validation loss 0.981726884841919\n",
      "Epoch 270, current patience 28, model mean validation loss 0.9485353827476501, embedding dim 512, hidden size 32, num layers 1, train loss 0.523134708404541, validation loss 0.9883954524993896\n",
      "Epoch 280, current patience 27, model mean validation loss 0.9555690288543701, embedding dim 512, hidden size 32, num layers 1, train loss 0.8072810173034668, validation loss 0.961554765701294\n",
      "Epoch 290, current patience 26, model mean validation loss 0.9572036266326904, embedding dim 512, hidden size 32, num layers 1, train loss 0.6519001722335815, validation loss 0.9835858345031738\n",
      "Epoch 300, current patience 25, model mean validation loss 0.9555094242095947, embedding dim 512, hidden size 32, num layers 1, train loss 0.520178496837616, validation loss 0.9577471017837524\n",
      "Epoch 310, current patience 24, model mean validation loss 0.9578746557235718, embedding dim 512, hidden size 32, num layers 1, train loss 0.6167948246002197, validation loss 0.9335064888000488\n",
      "Epoch 320, current patience 23, model mean validation loss 0.9714877605438232, embedding dim 512, hidden size 32, num layers 1, train loss 0.5495319366455078, validation loss 1.0240601301193237\n",
      "Epoch 330, current patience 22, model mean validation loss 0.9815765619277954, embedding dim 512, hidden size 32, num layers 1, train loss 0.48580554127693176, validation loss 1.022035837173462\n",
      "Epoch 340, current patience 21, model mean validation loss 0.9835344552993774, embedding dim 512, hidden size 32, num layers 1, train loss 0.6607681512832642, validation loss 0.9973899126052856\n",
      "Epoch 350, current patience 20, model mean validation loss 0.9906670451164246, embedding dim 512, hidden size 32, num layers 1, train loss 0.6711841821670532, validation loss 1.0454559326171875\n",
      "Epoch 360, current patience 19, model mean validation loss 0.9976433515548706, embedding dim 512, hidden size 32, num layers 1, train loss 0.3393152356147766, validation loss 1.0173656940460205\n",
      "Epoch 370, current patience 18, model mean validation loss 1.003842830657959, embedding dim 512, hidden size 32, num layers 1, train loss 0.4920143187046051, validation loss 1.033182144165039\n",
      "Epoch 380, current patience 17, model mean validation loss 1.0318045616149902, embedding dim 512, hidden size 32, num layers 1, train loss 0.7875694036483765, validation loss 1.1814405918121338\n",
      "Epoch 390, current patience 16, model mean validation loss 1.0440614223480225, embedding dim 512, hidden size 32, num layers 1, train loss 0.3174281716346741, validation loss 1.0315614938735962\n",
      "Epoch 400, current patience 15, model mean validation loss 1.0424416065216064, embedding dim 512, hidden size 32, num layers 1, train loss 0.40353673696517944, validation loss 1.0111007690429688\n",
      "Epoch 410, current patience 14, model mean validation loss 1.045750617980957, embedding dim 512, hidden size 32, num layers 1, train loss 0.375240683555603, validation loss 1.0485085248947144\n",
      "Epoch 420, current patience 13, model mean validation loss 1.0548405647277832, embedding dim 512, hidden size 32, num layers 1, train loss 0.7701927423477173, validation loss 1.070109486579895\n",
      "Epoch 430, current patience 12, model mean validation loss 1.0555081367492676, embedding dim 512, hidden size 32, num layers 1, train loss 0.3159886598587036, validation loss 1.0507968664169312\n",
      "Epoch 440, current patience 11, model mean validation loss 1.0608956813812256, embedding dim 512, hidden size 32, num layers 1, train loss 0.3384009301662445, validation loss 1.0604658126831055\n",
      "Epoch 450, current patience 10, model mean validation loss 1.0562092065811157, embedding dim 512, hidden size 32, num layers 1, train loss 0.3950519561767578, validation loss 0.995690107345581\n",
      "Epoch 460, current patience 9, model mean validation loss 1.0341383218765259, embedding dim 512, hidden size 32, num layers 1, train loss 0.507041871547699, validation loss 1.004873514175415\n",
      "Epoch 470, current patience 8, model mean validation loss 1.0309948921203613, embedding dim 512, hidden size 32, num layers 1, train loss 0.34060296416282654, validation loss 1.0064135789871216\n",
      "Epoch 480, current patience 7, model mean validation loss 1.045577049255371, embedding dim 512, hidden size 32, num layers 1, train loss 0.8741388320922852, validation loss 1.127758264541626\n",
      "Epoch 490, current patience 6, model mean validation loss 1.0497238636016846, embedding dim 512, hidden size 32, num layers 1, train loss 0.6251733899116516, validation loss 1.081682801246643\n",
      "Epoch 500, current patience 5, model mean validation loss 1.0442777872085571, embedding dim 512, hidden size 32, num layers 1, train loss 0.31931233406066895, validation loss 1.026540994644165\n",
      "Epoch 510, current patience 4, model mean validation loss 1.0459678173065186, embedding dim 512, hidden size 32, num layers 1, train loss 0.6399564743041992, validation loss 1.0643171072006226\n",
      "Epoch 520, current patience 3, model mean validation loss 1.0361366271972656, embedding dim 512, hidden size 32, num layers 1, train loss 0.4153705835342407, validation loss 0.9818159341812134\n",
      "Epoch 530, current patience 2, model mean validation loss 1.046028733253479, embedding dim 512, hidden size 32, num layers 1, train loss 0.5557796955108643, validation loss 1.0748275518417358\n",
      "Epoch 540, current patience 1, model mean validation loss 1.062301516532898, embedding dim 512, hidden size 32, num layers 1, train loss 0.2550363540649414, validation loss 1.1350555419921875\n",
      "Epoch 0, current patience 30, model mean validation loss 1.098487377166748, embedding dim 512, hidden size 64, num layers 1, train loss 1.09696364402771, validation loss 1.098487377166748\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0998767614364624, embedding dim 512, hidden size 64, num layers 1, train loss 1.1035293340682983, validation loss 1.1012661457061768\n",
      "Epoch 20, current patience 29, model mean validation loss 1.099843144416809, embedding dim 512, hidden size 64, num layers 1, train loss 1.0873823165893555, validation loss 1.099776029586792\n",
      "Epoch 30, current patience 28, model mean validation loss 1.091516375541687, embedding dim 512, hidden size 64, num layers 1, train loss 1.0638525485992432, validation loss 1.0665359497070312\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0816469192504883, embedding dim 512, hidden size 64, num layers 1, train loss 1.059558629989624, validation loss 1.0421693325042725\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0730119943618774, embedding dim 512, hidden size 64, num layers 1, train loss 0.7087345123291016, validation loss 1.029836893081665\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0604057312011719, embedding dim 512, hidden size 64, num layers 1, train loss 1.0744894742965698, validation loss 0.9847683906555176\n",
      "Epoch 70, current patience 30, model mean validation loss 1.046875238418579, embedding dim 512, hidden size 64, num layers 1, train loss 1.0153799057006836, validation loss 0.9521617889404297\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0237761735916138, embedding dim 512, hidden size 64, num layers 1, train loss 0.823025107383728, validation loss 0.9136943817138672\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9997018575668335, embedding dim 512, hidden size 64, num layers 1, train loss 1.0683985948562622, validation loss 0.908672034740448\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9776022434234619, embedding dim 512, hidden size 64, num layers 1, train loss 0.8214150667190552, validation loss 0.9229791760444641\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9553107023239136, embedding dim 512, hidden size 64, num layers 1, train loss 0.8328976631164551, validation loss 0.8882037997245789\n",
      "Epoch 120, current patience 30, model mean validation loss 0.935484766960144, embedding dim 512, hidden size 64, num layers 1, train loss 0.790277361869812, validation loss 0.883561372756958\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9176927804946899, embedding dim 512, hidden size 64, num layers 1, train loss 0.8519477844238281, validation loss 0.8875008821487427\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8997411727905273, embedding dim 512, hidden size 64, num layers 1, train loss 0.4610632061958313, validation loss 0.8411561250686646\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8837798833847046, embedding dim 512, hidden size 64, num layers 1, train loss 0.5016533136367798, validation loss 0.8244712352752686\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8783375024795532, embedding dim 512, hidden size 64, num layers 1, train loss 0.8964982032775879, validation loss 0.870154857635498\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8789730072021484, embedding dim 512, hidden size 64, num layers 1, train loss 0.61328125, validation loss 0.9137560129165649\n",
      "Epoch 180, current patience 29, model mean validation loss 0.8830596208572388, embedding dim 512, hidden size 64, num layers 1, train loss 0.7180610299110413, validation loss 0.9556723833084106\n",
      "Epoch 190, current patience 28, model mean validation loss 0.8776336908340454, embedding dim 512, hidden size 64, num layers 1, train loss 0.516682505607605, validation loss 0.8447965383529663\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8721407651901245, embedding dim 512, hidden size 64, num layers 1, train loss 0.898118793964386, validation loss 0.8396185040473938\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8636940717697144, embedding dim 512, hidden size 64, num layers 1, train loss 0.6005990505218506, validation loss 0.8199265003204346\n",
      "Epoch 220, current patience 30, model mean validation loss 0.864378035068512, embedding dim 512, hidden size 64, num layers 1, train loss 0.676608681678772, validation loss 0.846627950668335\n",
      "Epoch 230, current patience 29, model mean validation loss 0.8735822439193726, embedding dim 512, hidden size 64, num layers 1, train loss 0.38343530893325806, validation loss 0.8981054425239563\n",
      "Epoch 240, current patience 28, model mean validation loss 0.8721585273742676, embedding dim 512, hidden size 64, num layers 1, train loss 0.3177953362464905, validation loss 0.8587645292282104\n",
      "Epoch 250, current patience 27, model mean validation loss 0.8742282390594482, embedding dim 512, hidden size 64, num layers 1, train loss 0.5900220274925232, validation loss 0.9303135871887207\n",
      "Epoch 260, current patience 26, model mean validation loss 0.8603042364120483, embedding dim 512, hidden size 64, num layers 1, train loss 0.7027487754821777, validation loss 0.8442804217338562\n",
      "Epoch 270, current patience 30, model mean validation loss 0.8590475916862488, embedding dim 512, hidden size 64, num layers 1, train loss 0.4965721368789673, validation loss 0.8347436189651489\n",
      "Epoch 280, current patience 30, model mean validation loss 0.8639023303985596, embedding dim 512, hidden size 64, num layers 1, train loss 0.34554237127304077, validation loss 0.8784565329551697\n",
      "Epoch 290, current patience 29, model mean validation loss 0.8663564920425415, embedding dim 512, hidden size 64, num layers 1, train loss 0.41275420784950256, validation loss 0.8395598530769348\n",
      "Epoch 300, current patience 28, model mean validation loss 0.8899657130241394, embedding dim 512, hidden size 64, num layers 1, train loss 0.45686712861061096, validation loss 1.0355018377304077\n",
      "Epoch 310, current patience 27, model mean validation loss 0.8968366384506226, embedding dim 512, hidden size 64, num layers 1, train loss 0.46989065408706665, validation loss 0.9530729055404663\n",
      "Epoch 320, current patience 26, model mean validation loss 0.8987520933151245, embedding dim 512, hidden size 64, num layers 1, train loss 0.2307451367378235, validation loss 0.8740878701210022\n",
      "Epoch 330, current patience 25, model mean validation loss 0.8964654803276062, embedding dim 512, hidden size 64, num layers 1, train loss 0.4611862003803253, validation loss 0.9120208024978638\n",
      "Epoch 340, current patience 24, model mean validation loss 0.9064961671829224, embedding dim 512, hidden size 64, num layers 1, train loss 0.18476508557796478, validation loss 0.9245260953903198\n",
      "Epoch 350, current patience 23, model mean validation loss 0.9353024959564209, embedding dim 512, hidden size 64, num layers 1, train loss 0.5450376272201538, validation loss 1.0651936531066895\n",
      "Epoch 360, current patience 22, model mean validation loss 0.9409729242324829, embedding dim 512, hidden size 64, num layers 1, train loss 0.5772103071212769, validation loss 0.9238198399543762\n",
      "Epoch 370, current patience 21, model mean validation loss 0.9592249393463135, embedding dim 512, hidden size 64, num layers 1, train loss 0.21245643496513367, validation loss 0.9855762124061584\n",
      "Epoch 380, current patience 20, model mean validation loss 0.9675278663635254, embedding dim 512, hidden size 64, num layers 1, train loss 0.6187770366668701, validation loss 1.1019248962402344\n",
      "Epoch 390, current patience 19, model mean validation loss 0.9692946076393127, embedding dim 512, hidden size 64, num layers 1, train loss 0.11390984803438187, validation loss 0.9672074317932129\n",
      "Epoch 400, current patience 18, model mean validation loss 0.9846046566963196, embedding dim 512, hidden size 64, num layers 1, train loss 0.3645075559616089, validation loss 0.9965677857398987\n",
      "Epoch 410, current patience 17, model mean validation loss 0.9947577714920044, embedding dim 512, hidden size 64, num layers 1, train loss 0.6815856099128723, validation loss 0.9932461977005005\n",
      "Epoch 420, current patience 16, model mean validation loss 0.997554361820221, embedding dim 512, hidden size 64, num layers 1, train loss 0.6574183702468872, validation loss 0.9468989968299866\n",
      "Epoch 430, current patience 15, model mean validation loss 0.9900455474853516, embedding dim 512, hidden size 64, num layers 1, train loss 0.47432446479797363, validation loss 1.0051231384277344\n",
      "Epoch 440, current patience 14, model mean validation loss 0.9907431602478027, embedding dim 512, hidden size 64, num layers 1, train loss 0.29765284061431885, validation loss 0.929401159286499\n",
      "Epoch 450, current patience 13, model mean validation loss 0.9830560684204102, embedding dim 512, hidden size 64, num layers 1, train loss 0.8889766931533813, validation loss 0.9240790605545044\n",
      "Epoch 460, current patience 12, model mean validation loss 0.9588587880134583, embedding dim 512, hidden size 64, num layers 1, train loss 0.2402927577495575, validation loss 0.9083465337753296\n",
      "Epoch 470, current patience 11, model mean validation loss 0.9629040956497192, embedding dim 512, hidden size 64, num layers 1, train loss 0.6850347518920898, validation loss 0.9995695948600769\n",
      "Epoch 480, current patience 10, model mean validation loss 0.9647629261016846, embedding dim 512, hidden size 64, num layers 1, train loss 0.264249712228775, validation loss 1.0114383697509766\n",
      "Epoch 490, current patience 9, model mean validation loss 0.9692870378494263, embedding dim 512, hidden size 64, num layers 1, train loss 0.08920104801654816, validation loss 1.0294394493103027\n",
      "Epoch 500, current patience 8, model mean validation loss 0.9909300804138184, embedding dim 512, hidden size 64, num layers 1, train loss 0.5913458466529846, validation loss 1.1200435161590576\n",
      "Epoch 510, current patience 7, model mean validation loss 1.0091073513031006, embedding dim 512, hidden size 64, num layers 1, train loss 0.524161696434021, validation loss 1.1505413055419922\n",
      "Epoch 520, current patience 6, model mean validation loss 1.0231633186340332, embedding dim 512, hidden size 64, num layers 1, train loss 0.3398720920085907, validation loss 1.04184889793396\n",
      "Epoch 530, current patience 5, model mean validation loss 1.0300099849700928, embedding dim 512, hidden size 64, num layers 1, train loss 0.18812641501426697, validation loss 0.978852391242981\n",
      "Epoch 540, current patience 4, model mean validation loss 1.0516343116760254, embedding dim 512, hidden size 64, num layers 1, train loss 0.22413542866706848, validation loss 1.0813411474227905\n",
      "Epoch 550, current patience 3, model mean validation loss 1.0564202070236206, embedding dim 512, hidden size 64, num layers 1, train loss 0.2677549719810486, validation loss 1.037856936454773\n",
      "Epoch 560, current patience 2, model mean validation loss 1.070572853088379, embedding dim 512, hidden size 64, num layers 1, train loss 0.09784621000289917, validation loss 1.1246598958969116\n",
      "Epoch 570, current patience 1, model mean validation loss 1.0835778713226318, embedding dim 512, hidden size 64, num layers 1, train loss 0.05894092470407486, validation loss 1.1334785223007202\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0974161624908447, embedding dim 512, hidden size 128, num layers 1, train loss 1.0891413688659668, validation loss 1.0974161624908447\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0901075601577759, embedding dim 512, hidden size 128, num layers 1, train loss 1.0859817266464233, validation loss 1.082798957824707\n",
      "Epoch 20, current patience 30, model mean validation loss 1.078500509262085, embedding dim 512, hidden size 128, num layers 1, train loss 1.0486729145050049, validation loss 1.0552864074707031\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0719544887542725, embedding dim 512, hidden size 128, num layers 1, train loss 1.0380394458770752, validation loss 1.052316665649414\n",
      "Epoch 40, current patience 30, model mean validation loss 1.063600778579712, embedding dim 512, hidden size 128, num layers 1, train loss 1.0447771549224854, validation loss 1.0301859378814697\n",
      "Epoch 50, current patience 30, model mean validation loss 1.048345923423767, embedding dim 512, hidden size 128, num layers 1, train loss 0.9097650051116943, validation loss 0.972071647644043\n",
      "Epoch 60, current patience 30, model mean validation loss 1.031320571899414, embedding dim 512, hidden size 128, num layers 1, train loss 0.9984001517295837, validation loss 0.9291684031486511\n",
      "Epoch 70, current patience 30, model mean validation loss 1.02126145362854, embedding dim 512, hidden size 128, num layers 1, train loss 1.0131443738937378, validation loss 0.9508473873138428\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9947291612625122, embedding dim 512, hidden size 128, num layers 1, train loss 0.6929253339767456, validation loss 0.8851573467254639\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9649493098258972, embedding dim 512, hidden size 128, num layers 1, train loss 0.8090885877609253, validation loss 0.8445607423782349\n",
      "Epoch 100, current patience 30, model mean validation loss 0.941161036491394, embedding dim 512, hidden size 128, num layers 1, train loss 0.8959434628486633, validation loss 0.8649803400039673\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9235018491744995, embedding dim 512, hidden size 128, num layers 1, train loss 0.5639036297798157, validation loss 0.9110431671142578\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9012875556945801, embedding dim 512, hidden size 128, num layers 1, train loss 0.36399829387664795, validation loss 0.8524715900421143\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8887606859207153, embedding dim 512, hidden size 128, num layers 1, train loss 0.35316991806030273, validation loss 0.871856689453125\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8852028846740723, embedding dim 512, hidden size 128, num layers 1, train loss 0.5800057649612427, validation loss 0.9007057547569275\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8683006763458252, embedding dim 512, hidden size 128, num layers 1, train loss 0.5642143487930298, validation loss 0.8156296610832214\n",
      "Epoch 160, current patience 30, model mean validation loss 0.856402575969696, embedding dim 512, hidden size 128, num layers 1, train loss 0.49251070618629456, validation loss 0.7899725437164307\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8448891639709473, embedding dim 512, hidden size 128, num layers 1, train loss 1.0465326309204102, validation loss 0.7524538636207581\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8355936408042908, embedding dim 512, hidden size 128, num layers 1, train loss 0.5785311460494995, validation loss 0.7906162142753601\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8214124441146851, embedding dim 512, hidden size 128, num layers 1, train loss 1.0106911659240723, validation loss 0.7975932359695435\n",
      "Epoch 200, current patience 30, model mean validation loss 0.8125740885734558, embedding dim 512, hidden size 128, num layers 1, train loss 0.41503405570983887, validation loss 0.7817651033401489\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8040169477462769, embedding dim 512, hidden size 128, num layers 1, train loss 0.5717325210571289, validation loss 0.8033990263938904\n",
      "Epoch 220, current patience 30, model mean validation loss 0.7910594344139099, embedding dim 512, hidden size 128, num layers 1, train loss 0.48885059356689453, validation loss 0.7970460653305054\n",
      "Epoch 230, current patience 30, model mean validation loss 0.7889291644096375, embedding dim 512, hidden size 128, num layers 1, train loss 0.5943560600280762, validation loss 0.7985873222351074\n",
      "Epoch 240, current patience 30, model mean validation loss 0.8053194880485535, embedding dim 512, hidden size 128, num layers 1, train loss 0.4506908655166626, validation loss 0.9210951328277588\n",
      "Epoch 250, current patience 29, model mean validation loss 0.8142837285995483, embedding dim 512, hidden size 128, num layers 1, train loss 0.6226490139961243, validation loss 0.8241678476333618\n",
      "Epoch 260, current patience 28, model mean validation loss 0.8144500255584717, embedding dim 512, hidden size 128, num layers 1, train loss 0.5176812410354614, validation loss 0.7919468283653259\n",
      "Epoch 270, current patience 27, model mean validation loss 0.8268998265266418, embedding dim 512, hidden size 128, num layers 1, train loss 0.5864464044570923, validation loss 0.8971911668777466\n",
      "Epoch 280, current patience 26, model mean validation loss 0.8355434536933899, embedding dim 512, hidden size 128, num layers 1, train loss 0.883602499961853, validation loss 0.8509141802787781\n",
      "Epoch 290, current patience 25, model mean validation loss 0.8408446311950684, embedding dim 512, hidden size 128, num layers 1, train loss 0.15897509455680847, validation loss 0.8458084464073181\n",
      "Epoch 300, current patience 24, model mean validation loss 0.8535009622573853, embedding dim 512, hidden size 128, num layers 1, train loss 0.3257899880409241, validation loss 0.898297131061554\n",
      "Epoch 310, current patience 23, model mean validation loss 0.869773268699646, embedding dim 512, hidden size 128, num layers 1, train loss 0.5160245299339294, validation loss 0.9287651777267456\n",
      "Epoch 320, current patience 22, model mean validation loss 0.8738477230072021, embedding dim 512, hidden size 128, num layers 1, train loss 0.20480453968048096, validation loss 0.9536911249160767\n",
      "Epoch 330, current patience 21, model mean validation loss 0.8830222487449646, embedding dim 512, hidden size 128, num layers 1, train loss 0.54273521900177, validation loss 0.8975640535354614\n",
      "Epoch 340, current patience 20, model mean validation loss 0.8914799690246582, embedding dim 512, hidden size 128, num layers 1, train loss 0.5175116062164307, validation loss 0.8596086502075195\n",
      "Epoch 350, current patience 19, model mean validation loss 0.8942761421203613, embedding dim 512, hidden size 128, num layers 1, train loss 0.5551167130470276, validation loss 0.9195605516433716\n",
      "Epoch 360, current patience 18, model mean validation loss 0.8985903859138489, embedding dim 512, hidden size 128, num layers 1, train loss 0.5104913711547852, validation loss 0.8854283690452576\n",
      "Epoch 370, current patience 17, model mean validation loss 0.8999341726303101, embedding dim 512, hidden size 128, num layers 1, train loss 0.5294731259346008, validation loss 0.8565585017204285\n",
      "Epoch 380, current patience 16, model mean validation loss 0.9133548736572266, embedding dim 512, hidden size 128, num layers 1, train loss 0.3439536988735199, validation loss 1.0056629180908203\n",
      "Epoch 390, current patience 15, model mean validation loss 0.9092010259628296, embedding dim 512, hidden size 128, num layers 1, train loss 0.19974178075790405, validation loss 0.895534098148346\n",
      "Epoch 400, current patience 14, model mean validation loss 0.9017152786254883, embedding dim 512, hidden size 128, num layers 1, train loss 0.41278010606765747, validation loss 0.8938053846359253\n",
      "Epoch 410, current patience 13, model mean validation loss 0.9142282605171204, embedding dim 512, hidden size 128, num layers 1, train loss 0.1243344098329544, validation loss 0.997667670249939\n",
      "Epoch 420, current patience 12, model mean validation loss 0.9334461688995361, embedding dim 512, hidden size 128, num layers 1, train loss 0.9160692095756531, validation loss 1.0133520364761353\n",
      "Epoch 430, current patience 11, model mean validation loss 0.9390090703964233, embedding dim 512, hidden size 128, num layers 1, train loss 0.32561516761779785, validation loss 0.9640638828277588\n",
      "Epoch 440, current patience 10, model mean validation loss 0.9504923820495605, embedding dim 512, hidden size 128, num layers 1, train loss 0.32246023416519165, validation loss 0.9772949814796448\n",
      "Epoch 450, current patience 9, model mean validation loss 0.9677401781082153, embedding dim 512, hidden size 128, num layers 1, train loss 0.563001275062561, validation loss 0.9945405125617981\n",
      "Epoch 460, current patience 8, model mean validation loss 0.9571969509124756, embedding dim 512, hidden size 128, num layers 1, train loss 0.29272180795669556, validation loss 0.9213166832923889\n",
      "Epoch 470, current patience 7, model mean validation loss 0.9630883932113647, embedding dim 512, hidden size 128, num layers 1, train loss 0.7268024682998657, validation loss 0.9426657557487488\n",
      "Epoch 480, current patience 6, model mean validation loss 0.9710086584091187, embedding dim 512, hidden size 128, num layers 1, train loss 0.20826545357704163, validation loss 0.9571675658226013\n",
      "Epoch 490, current patience 5, model mean validation loss 0.9767338633537292, embedding dim 512, hidden size 128, num layers 1, train loss 0.1574259102344513, validation loss 1.0434695482254028\n",
      "Epoch 500, current patience 4, model mean validation loss 0.9790385961532593, embedding dim 512, hidden size 128, num layers 1, train loss 0.07314035296440125, validation loss 1.0317898988723755\n",
      "Epoch 510, current patience 3, model mean validation loss 0.9927366375923157, embedding dim 512, hidden size 128, num layers 1, train loss 0.304886132478714, validation loss 1.07364821434021\n",
      "Epoch 520, current patience 2, model mean validation loss 1.0060352087020874, embedding dim 512, hidden size 128, num layers 1, train loss 0.22035866975784302, validation loss 1.0836832523345947\n",
      "Epoch 530, current patience 1, model mean validation loss 1.0253894329071045, embedding dim 512, hidden size 128, num layers 1, train loss 0.44410473108291626, validation loss 1.1493747234344482\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1196448802947998, embedding dim 512, hidden size 256, num layers 1, train loss 1.1006543636322021, validation loss 1.1196448802947998\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0873544216156006, embedding dim 512, hidden size 256, num layers 1, train loss 1.1816034317016602, validation loss 1.0550638437271118\n",
      "Epoch 20, current patience 30, model mean validation loss 1.080040454864502, embedding dim 512, hidden size 256, num layers 1, train loss 1.0955888032913208, validation loss 1.0654125213623047\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0560966730117798, embedding dim 512, hidden size 256, num layers 1, train loss 1.0342543125152588, validation loss 0.9842654466629028\n",
      "Epoch 40, current patience 30, model mean validation loss 1.029175877571106, embedding dim 512, hidden size 256, num layers 1, train loss 0.7862291932106018, validation loss 0.9214927554130554\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0079361200332642, embedding dim 512, hidden size 256, num layers 1, train loss 0.8464865684509277, validation loss 0.9017370343208313\n",
      "Epoch 60, current patience 30, model mean validation loss 0.9930413365364075, embedding dim 512, hidden size 256, num layers 1, train loss 0.6962310075759888, validation loss 0.9036725759506226\n",
      "Epoch 70, current patience 30, model mean validation loss 0.9741596579551697, embedding dim 512, hidden size 256, num layers 1, train loss 0.8501038551330566, validation loss 0.8419880867004395\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9348384737968445, embedding dim 512, hidden size 256, num layers 1, train loss 0.5341267585754395, validation loss 0.8050753474235535\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9035958647727966, embedding dim 512, hidden size 256, num layers 1, train loss 0.7494165897369385, validation loss 0.805122971534729\n",
      "Epoch 100, current patience 30, model mean validation loss 0.8691872954368591, embedding dim 512, hidden size 256, num layers 1, train loss 0.9615716934204102, validation loss 0.7901442050933838\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8426200151443481, embedding dim 512, hidden size 256, num layers 1, train loss 0.5785071849822998, validation loss 0.7717269659042358\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8259180784225464, embedding dim 512, hidden size 256, num layers 1, train loss 0.6975761651992798, validation loss 0.78787761926651\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8114500045776367, embedding dim 512, hidden size 256, num layers 1, train loss 0.388447105884552, validation loss 0.7859917879104614\n",
      "Epoch 140, current patience 30, model mean validation loss 0.793127179145813, embedding dim 512, hidden size 256, num layers 1, train loss 0.5845451354980469, validation loss 0.7570900321006775\n",
      "Epoch 150, current patience 30, model mean validation loss 0.7901417016983032, embedding dim 512, hidden size 256, num layers 1, train loss 0.5373716354370117, validation loss 0.8181046843528748\n",
      "Epoch 160, current patience 30, model mean validation loss 0.788726806640625, embedding dim 512, hidden size 256, num layers 1, train loss 0.7618448734283447, validation loss 0.7937561869621277\n",
      "Epoch 170, current patience 30, model mean validation loss 0.787632942199707, embedding dim 512, hidden size 256, num layers 1, train loss 0.5333819389343262, validation loss 0.7963724136352539\n",
      "Epoch 180, current patience 30, model mean validation loss 0.7975346446037292, embedding dim 512, hidden size 256, num layers 1, train loss 0.22815319895744324, validation loss 0.8693575859069824\n",
      "Epoch 190, current patience 29, model mean validation loss 0.8056991100311279, embedding dim 512, hidden size 256, num layers 1, train loss 0.6531990766525269, validation loss 0.8370425701141357\n",
      "Epoch 200, current patience 28, model mean validation loss 0.8061410188674927, embedding dim 512, hidden size 256, num layers 1, train loss 0.7663750648498535, validation loss 0.7914126515388489\n",
      "Epoch 210, current patience 27, model mean validation loss 0.8106083869934082, embedding dim 512, hidden size 256, num layers 1, train loss 0.4474177956581116, validation loss 0.8217303156852722\n",
      "Epoch 220, current patience 26, model mean validation loss 0.8185624480247498, embedding dim 512, hidden size 256, num layers 1, train loss 0.3265612721443176, validation loss 0.8207231163978577\n",
      "Epoch 230, current patience 25, model mean validation loss 0.8145586848258972, embedding dim 512, hidden size 256, num layers 1, train loss 0.570356011390686, validation loss 0.7860743999481201\n",
      "Epoch 240, current patience 24, model mean validation loss 0.8178383111953735, embedding dim 512, hidden size 256, num layers 1, train loss 0.8241738080978394, validation loss 0.8199936151504517\n",
      "Epoch 250, current patience 23, model mean validation loss 0.8167287111282349, embedding dim 512, hidden size 256, num layers 1, train loss 0.49559253454208374, validation loss 0.787495493888855\n",
      "Epoch 260, current patience 22, model mean validation loss 0.8228483200073242, embedding dim 512, hidden size 256, num layers 1, train loss 0.5009874701499939, validation loss 0.9183142185211182\n",
      "Epoch 270, current patience 21, model mean validation loss 0.8226081132888794, embedding dim 512, hidden size 256, num layers 1, train loss 0.4466495215892792, validation loss 0.8351213932037354\n",
      "Epoch 280, current patience 20, model mean validation loss 0.8199421167373657, embedding dim 512, hidden size 256, num layers 1, train loss 0.6604589819908142, validation loss 0.7700844407081604\n",
      "Epoch 290, current patience 19, model mean validation loss 0.81638503074646, embedding dim 512, hidden size 256, num layers 1, train loss 0.20467272400856018, validation loss 0.7932735681533813\n",
      "Epoch 300, current patience 18, model mean validation loss 0.8124536275863647, embedding dim 512, hidden size 256, num layers 1, train loss 0.4040985703468323, validation loss 0.7892720699310303\n",
      "Epoch 310, current patience 17, model mean validation loss 0.8290374279022217, embedding dim 512, hidden size 256, num layers 1, train loss 0.22697532176971436, validation loss 0.9187445640563965\n",
      "Epoch 320, current patience 16, model mean validation loss 0.8408924341201782, embedding dim 512, hidden size 256, num layers 1, train loss 0.3441837430000305, validation loss 0.9148339033126831\n",
      "Epoch 330, current patience 15, model mean validation loss 0.8657288551330566, embedding dim 512, hidden size 256, num layers 1, train loss 0.517208456993103, validation loss 0.9861865043640137\n",
      "Epoch 340, current patience 14, model mean validation loss 0.8611249327659607, embedding dim 512, hidden size 256, num layers 1, train loss 0.08291608095169067, validation loss 0.8814828395843506\n",
      "Epoch 350, current patience 13, model mean validation loss 0.8726456761360168, embedding dim 512, hidden size 256, num layers 1, train loss 0.16082710027694702, validation loss 0.9272875785827637\n",
      "Epoch 360, current patience 12, model mean validation loss 0.8969545960426331, embedding dim 512, hidden size 256, num layers 1, train loss 0.4877040386199951, validation loss 0.9645559191703796\n",
      "Epoch 370, current patience 11, model mean validation loss 0.9223480224609375, embedding dim 512, hidden size 256, num layers 1, train loss 0.2214958816766739, validation loss 0.9964209198951721\n",
      "Epoch 380, current patience 10, model mean validation loss 0.9302042722702026, embedding dim 512, hidden size 256, num layers 1, train loss 0.20403902232646942, validation loss 0.8521220684051514\n",
      "Epoch 390, current patience 9, model mean validation loss 0.9326536655426025, embedding dim 512, hidden size 256, num layers 1, train loss 0.26124346256256104, validation loss 0.9383395910263062\n",
      "Epoch 400, current patience 8, model mean validation loss 0.948974072933197, embedding dim 512, hidden size 256, num layers 1, train loss 0.03305608034133911, validation loss 1.0453970432281494\n",
      "Epoch 410, current patience 7, model mean validation loss 0.9543999433517456, embedding dim 512, hidden size 256, num layers 1, train loss 0.187140092253685, validation loss 1.0295937061309814\n",
      "Epoch 420, current patience 6, model mean validation loss 0.9724459648132324, embedding dim 512, hidden size 256, num layers 1, train loss 0.12484671175479889, validation loss 1.0258502960205078\n",
      "Epoch 430, current patience 5, model mean validation loss 0.9860213994979858, embedding dim 512, hidden size 256, num layers 1, train loss 0.1673043966293335, validation loss 1.0358914136886597\n",
      "Epoch 440, current patience 4, model mean validation loss 1.0078822374343872, embedding dim 512, hidden size 256, num layers 1, train loss 0.13296878337860107, validation loss 1.1394431591033936\n",
      "Epoch 450, current patience 3, model mean validation loss 1.0025917291641235, embedding dim 512, hidden size 256, num layers 1, train loss 0.12256814539432526, validation loss 0.9540964961051941\n",
      "Epoch 460, current patience 2, model mean validation loss 1.014103651046753, embedding dim 512, hidden size 256, num layers 1, train loss 0.2983332872390747, validation loss 0.9442174434661865\n",
      "Epoch 470, current patience 1, model mean validation loss 1.0179214477539062, embedding dim 512, hidden size 256, num layers 1, train loss 0.683437705039978, validation loss 0.9688818454742432\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1437366008758545, embedding dim 512, hidden size 512, num layers 1, train loss 1.0948541164398193, validation loss 1.1437366008758545\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1153197288513184, embedding dim 512, hidden size 512, num layers 1, train loss 1.1160831451416016, validation loss 1.0869027376174927\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1013239622116089, embedding dim 512, hidden size 512, num layers 1, train loss 1.0195841789245605, validation loss 1.0733325481414795\n",
      "Epoch 30, current patience 30, model mean validation loss 1.083548665046692, embedding dim 512, hidden size 512, num layers 1, train loss 1.0509493350982666, validation loss 1.0302226543426514\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0482451915740967, embedding dim 512, hidden size 512, num layers 1, train loss 0.9576195478439331, validation loss 0.9070314168930054\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0222578048706055, embedding dim 512, hidden size 512, num layers 1, train loss 0.8812264800071716, validation loss 0.8923203945159912\n",
      "Epoch 60, current patience 30, model mean validation loss 0.9948863983154297, embedding dim 512, hidden size 512, num layers 1, train loss 0.9496559500694275, validation loss 0.8306578397750854\n",
      "Epoch 70, current patience 30, model mean validation loss 0.9739795327186584, embedding dim 512, hidden size 512, num layers 1, train loss 0.8398116230964661, validation loss 0.8276321887969971\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9326481819152832, embedding dim 512, hidden size 512, num layers 1, train loss 0.5754282474517822, validation loss 0.8130854964256287\n",
      "Epoch 90, current patience 30, model mean validation loss 0.8942703008651733, embedding dim 512, hidden size 512, num layers 1, train loss 0.8588300943374634, validation loss 0.7798799276351929\n",
      "Epoch 100, current patience 30, model mean validation loss 0.8640177249908447, embedding dim 512, hidden size 512, num layers 1, train loss 0.7297811508178711, validation loss 0.8313120603561401\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8359673023223877, embedding dim 512, hidden size 512, num layers 1, train loss 0.5303836464881897, validation loss 0.805819034576416\n",
      "Epoch 120, current patience 30, model mean validation loss 0.820071816444397, embedding dim 512, hidden size 512, num layers 1, train loss 0.833087146282196, validation loss 0.7798671126365662\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8130081295967102, embedding dim 512, hidden size 512, num layers 1, train loss 0.8931039571762085, validation loss 0.8358113765716553\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8034886121749878, embedding dim 512, hidden size 512, num layers 1, train loss 0.40872547030448914, validation loss 0.7545019388198853\n",
      "Epoch 150, current patience 30, model mean validation loss 0.7905511856079102, embedding dim 512, hidden size 512, num layers 1, train loss 0.3086717128753662, validation loss 0.724132776260376\n",
      "Epoch 160, current patience 30, model mean validation loss 0.7849477529525757, embedding dim 512, hidden size 512, num layers 1, train loss 0.24625183641910553, validation loss 0.7682581543922424\n",
      "Epoch 170, current patience 30, model mean validation loss 0.7992342114448547, embedding dim 512, hidden size 512, num layers 1, train loss 0.3409864902496338, validation loss 0.8941715359687805\n",
      "Epoch 180, current patience 29, model mean validation loss 0.7972767949104309, embedding dim 512, hidden size 512, num layers 1, train loss 0.9677547812461853, validation loss 0.81565260887146\n",
      "Epoch 190, current patience 28, model mean validation loss 0.795540452003479, embedding dim 512, hidden size 512, num layers 1, train loss 0.5750949382781982, validation loss 0.7919277548789978\n",
      "Epoch 200, current patience 27, model mean validation loss 0.7962844371795654, embedding dim 512, hidden size 512, num layers 1, train loss 0.6879312992095947, validation loss 0.7858188152313232\n",
      "Epoch 210, current patience 26, model mean validation loss 0.7859950065612793, embedding dim 512, hidden size 512, num layers 1, train loss 0.15120214223861694, validation loss 0.7534964680671692\n",
      "Epoch 220, current patience 25, model mean validation loss 0.7942907214164734, embedding dim 512, hidden size 512, num layers 1, train loss 0.8316213488578796, validation loss 0.8208678960800171\n",
      "Epoch 230, current patience 24, model mean validation loss 0.8039438724517822, embedding dim 512, hidden size 512, num layers 1, train loss 0.7568852305412292, validation loss 0.8013575077056885\n",
      "Epoch 240, current patience 23, model mean validation loss 0.814698338508606, embedding dim 512, hidden size 512, num layers 1, train loss 0.24242326617240906, validation loss 0.8542940616607666\n",
      "Epoch 250, current patience 22, model mean validation loss 0.8169392347335815, embedding dim 512, hidden size 512, num layers 1, train loss 0.08223888278007507, validation loss 0.9120988845825195\n",
      "Epoch 260, current patience 21, model mean validation loss 0.8194044232368469, embedding dim 512, hidden size 512, num layers 1, train loss 0.43719443678855896, validation loss 0.835374116897583\n",
      "Epoch 270, current patience 20, model mean validation loss 0.8362655639648438, embedding dim 512, hidden size 512, num layers 1, train loss 0.681847870349884, validation loss 0.9268169403076172\n",
      "Epoch 280, current patience 19, model mean validation loss 0.8433669805526733, embedding dim 512, hidden size 512, num layers 1, train loss 0.424929141998291, validation loss 0.8426300287246704\n",
      "Epoch 290, current patience 18, model mean validation loss 0.8516315221786499, embedding dim 512, hidden size 512, num layers 1, train loss 0.28520604968070984, validation loss 0.8196126818656921\n",
      "Epoch 300, current patience 17, model mean validation loss 0.8584705591201782, embedding dim 512, hidden size 512, num layers 1, train loss 0.0566006600856781, validation loss 0.8755806684494019\n",
      "Epoch 310, current patience 16, model mean validation loss 0.8679283857345581, embedding dim 512, hidden size 512, num layers 1, train loss 0.25880998373031616, validation loss 0.8770195841789246\n",
      "Epoch 320, current patience 15, model mean validation loss 0.869417667388916, embedding dim 512, hidden size 512, num layers 1, train loss 0.1196359321475029, validation loss 0.8662083148956299\n",
      "Epoch 330, current patience 14, model mean validation loss 0.8686150908470154, embedding dim 512, hidden size 512, num layers 1, train loss 0.09966044127941132, validation loss 0.9056779742240906\n",
      "Epoch 340, current patience 13, model mean validation loss 0.8796631097793579, embedding dim 512, hidden size 512, num layers 1, train loss 0.23407721519470215, validation loss 0.923758327960968\n",
      "Epoch 350, current patience 12, model mean validation loss 0.8853676915168762, embedding dim 512, hidden size 512, num layers 1, train loss 0.08980400860309601, validation loss 0.9724538922309875\n",
      "Epoch 360, current patience 11, model mean validation loss 0.8909229636192322, embedding dim 512, hidden size 512, num layers 1, train loss 0.2688904106616974, validation loss 0.8870723247528076\n",
      "Epoch 370, current patience 10, model mean validation loss 0.9039567708969116, embedding dim 512, hidden size 512, num layers 1, train loss 0.5335894823074341, validation loss 0.9238835573196411\n",
      "Epoch 380, current patience 9, model mean validation loss 0.9040241241455078, embedding dim 512, hidden size 512, num layers 1, train loss 0.36922529339790344, validation loss 0.8761188983917236\n",
      "Epoch 390, current patience 8, model mean validation loss 0.8999008536338806, embedding dim 512, hidden size 512, num layers 1, train loss 0.2534610331058502, validation loss 0.8440338373184204\n",
      "Epoch 400, current patience 7, model mean validation loss 0.9029834270477295, embedding dim 512, hidden size 512, num layers 1, train loss 0.2260853350162506, validation loss 0.8908681273460388\n",
      "Epoch 410, current patience 6, model mean validation loss 0.8978757262229919, embedding dim 512, hidden size 512, num layers 1, train loss 0.19606487452983856, validation loss 0.8648170232772827\n",
      "Epoch 420, current patience 5, model mean validation loss 0.9020814895629883, embedding dim 512, hidden size 512, num layers 1, train loss 0.1768694519996643, validation loss 0.9574039578437805\n",
      "Epoch 430, current patience 4, model mean validation loss 0.8990136384963989, embedding dim 512, hidden size 512, num layers 1, train loss 0.3199291527271271, validation loss 0.9479118585586548\n",
      "Epoch 440, current patience 3, model mean validation loss 0.9114949703216553, embedding dim 512, hidden size 512, num layers 1, train loss 0.4384388327598572, validation loss 0.9869224429130554\n",
      "Epoch 450, current patience 2, model mean validation loss 0.920056939125061, embedding dim 512, hidden size 512, num layers 1, train loss 0.21690402925014496, validation loss 0.9923794865608215\n",
      "Epoch 460, current patience 1, model mean validation loss 0.9374229311943054, embedding dim 512, hidden size 512, num layers 1, train loss 0.1759384274482727, validation loss 1.0150467157363892\n",
      "Epoch 0, current patience 30, model mean validation loss 1.157013177871704, embedding dim 512, hidden size 1024, num layers 1, train loss 1.1012423038482666, validation loss 1.157013177871704\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1379272937774658, embedding dim 512, hidden size 1024, num layers 1, train loss 1.1024041175842285, validation loss 1.118841528892517\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1233257055282593, embedding dim 512, hidden size 1024, num layers 1, train loss 1.0965702533721924, validation loss 1.094122290611267\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0800831317901611, embedding dim 512, hidden size 1024, num layers 1, train loss 1.0150686502456665, validation loss 0.9503554105758667\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0565910339355469, embedding dim 512, hidden size 1024, num layers 1, train loss 0.8864993453025818, validation loss 0.9626224040985107\n",
      "Epoch 50, current patience 30, model mean validation loss 1.027280330657959, embedding dim 512, hidden size 1024, num layers 1, train loss 0.9316442608833313, validation loss 0.8807270526885986\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0083351135253906, embedding dim 512, hidden size 1024, num layers 1, train loss 0.581882655620575, validation loss 0.8946635127067566\n",
      "Epoch 70, current patience 30, model mean validation loss 0.9933183193206787, embedding dim 512, hidden size 1024, num layers 1, train loss 0.8198541402816772, validation loss 0.8882015943527222\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9659911394119263, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4263884425163269, validation loss 0.9383959174156189\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9318224787712097, embedding dim 512, hidden size 1024, num layers 1, train loss 0.7543337345123291, validation loss 0.8454915285110474\n",
      "Epoch 100, current patience 30, model mean validation loss 0.8992996215820312, embedding dim 512, hidden size 1024, num layers 1, train loss 0.3171994984149933, validation loss 0.8339394330978394\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8812675476074219, embedding dim 512, hidden size 1024, num layers 1, train loss 0.711523711681366, validation loss 0.8060993552207947\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8633760213851929, embedding dim 512, hidden size 1024, num layers 1, train loss 0.2553597390651703, validation loss 0.8194899559020996\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8525822162628174, embedding dim 512, hidden size 1024, num layers 1, train loss 0.7258003950119019, validation loss 0.7943761348724365\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8368956446647644, embedding dim 512, hidden size 1024, num layers 1, train loss 0.8286227583885193, validation loss 0.7691712379455566\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8311425447463989, embedding dim 512, hidden size 1024, num layers 1, train loss 0.690975546836853, validation loss 0.8421763777732849\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8135417103767395, embedding dim 512, hidden size 1024, num layers 1, train loss 0.7148423790931702, validation loss 0.7975897789001465\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8115260601043701, embedding dim 512, hidden size 1024, num layers 1, train loss 0.22634777426719666, validation loss 0.8293662071228027\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8047311305999756, embedding dim 512, hidden size 1024, num layers 1, train loss 0.7520360350608826, validation loss 0.7795794606208801\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8097388744354248, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4555313289165497, validation loss 0.8461621403694153\n",
      "Epoch 200, current patience 29, model mean validation loss 0.8042192459106445, embedding dim 512, hidden size 1024, num layers 1, train loss 0.49752292037010193, validation loss 0.7753332257270813\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8038102388381958, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4110119342803955, validation loss 0.791103720664978\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8142749071121216, embedding dim 512, hidden size 1024, num layers 1, train loss 0.3514712452888489, validation loss 0.8528883457183838\n",
      "Epoch 230, current patience 29, model mean validation loss 0.813016414642334, embedding dim 512, hidden size 1024, num layers 1, train loss 0.24057795107364655, validation loss 0.8321084976196289\n",
      "Epoch 240, current patience 28, model mean validation loss 0.823891818523407, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4455421566963196, validation loss 0.8845928311347961\n",
      "Epoch 250, current patience 27, model mean validation loss 0.8324692249298096, embedding dim 512, hidden size 1024, num layers 1, train loss 0.6339198350906372, validation loss 0.8979853987693787\n",
      "Epoch 260, current patience 26, model mean validation loss 0.8387371301651001, embedding dim 512, hidden size 1024, num layers 1, train loss 0.1940828263759613, validation loss 0.8297228217124939\n",
      "Epoch 270, current patience 25, model mean validation loss 0.8434097766876221, embedding dim 512, hidden size 1024, num layers 1, train loss 0.1346779465675354, validation loss 0.8835428357124329\n",
      "Epoch 280, current patience 24, model mean validation loss 0.8592484593391418, embedding dim 512, hidden size 1024, num layers 1, train loss 0.07332440465688705, validation loss 0.9020431041717529\n",
      "Epoch 290, current patience 23, model mean validation loss 0.8680108785629272, embedding dim 512, hidden size 1024, num layers 1, train loss 0.10724121332168579, validation loss 0.8612035512924194\n",
      "Epoch 300, current patience 22, model mean validation loss 0.8692610263824463, embedding dim 512, hidden size 1024, num layers 1, train loss 0.44095829129219055, validation loss 0.8628895282745361\n",
      "Epoch 310, current patience 21, model mean validation loss 0.877417802810669, embedding dim 512, hidden size 1024, num layers 1, train loss 0.22814449667930603, validation loss 0.8973621129989624\n",
      "Epoch 320, current patience 20, model mean validation loss 0.8782482147216797, embedding dim 512, hidden size 1024, num layers 1, train loss 1.0117045640945435, validation loss 0.8912362456321716\n",
      "Epoch 330, current patience 19, model mean validation loss 0.8735123872756958, embedding dim 512, hidden size 1024, num layers 1, train loss 1.0172358751296997, validation loss 0.8600984215736389\n",
      "Epoch 340, current patience 18, model mean validation loss 0.8773050308227539, embedding dim 512, hidden size 1024, num layers 1, train loss 0.10485224425792694, validation loss 0.8600643873214722\n",
      "Epoch 350, current patience 17, model mean validation loss 0.8853073120117188, embedding dim 512, hidden size 1024, num layers 1, train loss 0.28518643975257874, validation loss 0.9475608468055725\n",
      "Epoch 360, current patience 16, model mean validation loss 0.8950977921485901, embedding dim 512, hidden size 1024, num layers 1, train loss 0.1907576620578766, validation loss 0.980367124080658\n",
      "Epoch 370, current patience 15, model mean validation loss 0.8966706395149231, embedding dim 512, hidden size 1024, num layers 1, train loss 0.47456252574920654, validation loss 0.8737865090370178\n",
      "Epoch 380, current patience 14, model mean validation loss 0.8983964323997498, embedding dim 512, hidden size 1024, num layers 1, train loss 0.29454904794692993, validation loss 0.8766957521438599\n",
      "Epoch 390, current patience 13, model mean validation loss 0.9048659801483154, embedding dim 512, hidden size 1024, num layers 1, train loss 0.22802823781967163, validation loss 0.9491186141967773\n",
      "Epoch 400, current patience 12, model mean validation loss 0.9051336050033569, embedding dim 512, hidden size 1024, num layers 1, train loss 0.335124671459198, validation loss 0.8933773636817932\n",
      "Epoch 410, current patience 11, model mean validation loss 0.9144083261489868, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4908408522605896, validation loss 0.9342961311340332\n",
      "Epoch 420, current patience 10, model mean validation loss 0.9268122315406799, embedding dim 512, hidden size 1024, num layers 1, train loss 0.039993032813072205, validation loss 0.9592956304550171\n",
      "Epoch 430, current patience 9, model mean validation loss 0.9252303242683411, embedding dim 512, hidden size 1024, num layers 1, train loss 0.35992515087127686, validation loss 0.9349055290222168\n",
      "Epoch 440, current patience 8, model mean validation loss 0.9198722839355469, embedding dim 512, hidden size 1024, num layers 1, train loss 0.14875063300132751, validation loss 0.9375026226043701\n",
      "Epoch 450, current patience 7, model mean validation loss 0.9383031129837036, embedding dim 512, hidden size 1024, num layers 1, train loss 0.22448286414146423, validation loss 1.021233320236206\n",
      "Epoch 460, current patience 6, model mean validation loss 0.9468797445297241, embedding dim 512, hidden size 1024, num layers 1, train loss 0.37432897090911865, validation loss 0.9453087449073792\n",
      "Epoch 470, current patience 5, model mean validation loss 0.9538475275039673, embedding dim 512, hidden size 1024, num layers 1, train loss 0.4046626389026642, validation loss 1.0048609972000122\n",
      "Epoch 480, current patience 4, model mean validation loss 0.9678667187690735, embedding dim 512, hidden size 1024, num layers 1, train loss 0.44366681575775146, validation loss 1.0055307149887085\n",
      "Epoch 490, current patience 3, model mean validation loss 0.9739860892295837, embedding dim 512, hidden size 1024, num layers 1, train loss 0.5673080682754517, validation loss 0.9832514524459839\n",
      "Epoch 500, current patience 2, model mean validation loss 0.9790242910385132, embedding dim 512, hidden size 1024, num layers 1, train loss 0.7193212509155273, validation loss 0.9996012449264526\n",
      "Epoch 510, current patience 1, model mean validation loss 0.9906583428382874, embedding dim 512, hidden size 1024, num layers 1, train loss 0.8103939294815063, validation loss 1.0279779434204102\n",
      "Epoch 0, current patience 30, model mean validation loss 1.4463615417480469, embedding dim 512, hidden size 2048, num layers 1, train loss 1.100823998451233, validation loss 1.4463615417480469\n",
      "Epoch 10, current patience 30, model mean validation loss 1.3912341594696045, embedding dim 512, hidden size 2048, num layers 1, train loss 1.1492958068847656, validation loss 1.336106777191162\n",
      "Epoch 20, current patience 30, model mean validation loss 1.31778883934021, embedding dim 512, hidden size 2048, num layers 1, train loss 1.2308955192565918, validation loss 1.170898199081421\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3286716938018799, embedding dim 512, hidden size 2048, num layers 1, train loss 1.488616943359375, validation loss 1.3613201379776\n",
      "Epoch 40, current patience 29, model mean validation loss 1.3281972408294678, embedding dim 512, hidden size 2048, num layers 1, train loss 1.1001909971237183, validation loss 1.3262991905212402\n",
      "Epoch 50, current patience 28, model mean validation loss 1.2831250429153442, embedding dim 512, hidden size 2048, num layers 1, train loss 1.1996972560882568, validation loss 1.0577641725540161\n",
      "Epoch 60, current patience 30, model mean validation loss 1.2587919235229492, embedding dim 512, hidden size 2048, num layers 1, train loss 1.0767766237258911, validation loss 1.1127936840057373\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2275893688201904, embedding dim 512, hidden size 2048, num layers 1, train loss 0.914579451084137, validation loss 1.0091716051101685\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1723549365997314, embedding dim 512, hidden size 2048, num layers 1, train loss 1.0471023321151733, validation loss 1.0044851303100586\n",
      "Epoch 90, current patience 30, model mean validation loss 1.129152536392212, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8796469569206238, validation loss 0.9904890060424805\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1076772212982178, embedding dim 512, hidden size 2048, num layers 1, train loss 1.0555646419525146, validation loss 0.999095618724823\n",
      "Epoch 110, current patience 30, model mean validation loss 1.064652919769287, embedding dim 512, hidden size 2048, num layers 1, train loss 1.0212222337722778, validation loss 1.0171246528625488\n",
      "Epoch 120, current patience 30, model mean validation loss 1.01817786693573, embedding dim 512, hidden size 2048, num layers 1, train loss 0.94404137134552, validation loss 0.9544990062713623\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0102391242980957, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8236925601959229, validation loss 0.9942538142204285\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0060292482376099, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8702471256256104, validation loss 1.0791150331497192\n",
      "Epoch 150, current patience 30, model mean validation loss 1.007755994796753, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8914991617202759, validation loss 1.0229861736297607\n",
      "Epoch 160, current patience 29, model mean validation loss 1.0047831535339355, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8605561256408691, validation loss 0.9807018637657166\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0376434326171875, embedding dim 512, hidden size 2048, num layers 1, train loss 0.34657448530197144, validation loss 1.253371238708496\n",
      "Epoch 180, current patience 29, model mean validation loss 1.032422661781311, embedding dim 512, hidden size 2048, num layers 1, train loss 0.9296499490737915, validation loss 0.9573298096656799\n",
      "Epoch 190, current patience 28, model mean validation loss 1.035261869430542, embedding dim 512, hidden size 2048, num layers 1, train loss 0.8481572866439819, validation loss 1.0398385524749756\n",
      "Epoch 200, current patience 27, model mean validation loss 1.0381345748901367, embedding dim 512, hidden size 2048, num layers 1, train loss 0.40514686703681946, validation loss 0.977480411529541\n",
      "Epoch 210, current patience 26, model mean validation loss 1.0352890491485596, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5245684385299683, validation loss 0.9714890718460083\n",
      "Epoch 220, current patience 25, model mean validation loss 1.0146327018737793, embedding dim 512, hidden size 2048, num layers 1, train loss 0.44690337777137756, validation loss 0.913864016532898\n",
      "Epoch 230, current patience 24, model mean validation loss 1.0035393238067627, embedding dim 512, hidden size 2048, num layers 1, train loss 0.6248915791511536, validation loss 0.934239387512207\n",
      "Epoch 240, current patience 30, model mean validation loss 0.9965006113052368, embedding dim 512, hidden size 2048, num layers 1, train loss 0.608859658241272, validation loss 0.9243924617767334\n",
      "Epoch 250, current patience 30, model mean validation loss 0.9544457793235779, embedding dim 512, hidden size 2048, num layers 1, train loss 0.41530367732048035, validation loss 0.9169324040412903\n",
      "Epoch 260, current patience 30, model mean validation loss 0.954139232635498, embedding dim 512, hidden size 2048, num layers 1, train loss 0.41030219197273254, validation loss 0.954877495765686\n",
      "Epoch 270, current patience 30, model mean validation loss 0.9383944272994995, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5206261873245239, validation loss 0.9138804078102112\n",
      "Epoch 280, current patience 30, model mean validation loss 0.9266932010650635, embedding dim 512, hidden size 2048, num layers 1, train loss 0.39922425150871277, validation loss 0.8838704228401184\n",
      "Epoch 290, current patience 30, model mean validation loss 0.9230057001113892, embedding dim 512, hidden size 2048, num layers 1, train loss 0.6365135908126831, validation loss 0.9419891238212585\n",
      "Epoch 300, current patience 30, model mean validation loss 0.9266912341117859, embedding dim 512, hidden size 2048, num layers 1, train loss 0.45751333236694336, validation loss 0.9433484077453613\n",
      "Epoch 310, current patience 29, model mean validation loss 0.9305775165557861, embedding dim 512, hidden size 2048, num layers 1, train loss 0.48211801052093506, validation loss 0.965329647064209\n",
      "Epoch 320, current patience 28, model mean validation loss 0.9524930715560913, embedding dim 512, hidden size 2048, num layers 1, train loss 0.27408480644226074, validation loss 1.099717140197754\n",
      "Epoch 330, current patience 27, model mean validation loss 0.9587056636810303, embedding dim 512, hidden size 2048, num layers 1, train loss 0.9828423857688904, validation loss 0.966632604598999\n",
      "Epoch 340, current patience 26, model mean validation loss 0.9618372321128845, embedding dim 512, hidden size 2048, num layers 1, train loss 0.48889994621276855, validation loss 0.97993004322052\n",
      "Epoch 350, current patience 25, model mean validation loss 0.9696637392044067, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5276126265525818, validation loss 0.9764922857284546\n",
      "Epoch 360, current patience 24, model mean validation loss 0.9659684896469116, embedding dim 512, hidden size 2048, num layers 1, train loss 0.2577676773071289, validation loss 0.8543086647987366\n",
      "Epoch 370, current patience 23, model mean validation loss 0.9702485203742981, embedding dim 512, hidden size 2048, num layers 1, train loss 0.37596553564071655, validation loss 0.9762295484542847\n",
      "Epoch 380, current patience 22, model mean validation loss 0.9764924049377441, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5264434218406677, validation loss 0.9932993650436401\n",
      "Epoch 390, current patience 21, model mean validation loss 0.9791443347930908, embedding dim 512, hidden size 2048, num layers 1, train loss 0.43514126539230347, validation loss 0.9865449070930481\n",
      "Epoch 400, current patience 20, model mean validation loss 0.9502531290054321, embedding dim 512, hidden size 2048, num layers 1, train loss 0.9330766201019287, validation loss 0.8685879111289978\n",
      "Epoch 410, current patience 19, model mean validation loss 0.9398729205131531, embedding dim 512, hidden size 2048, num layers 1, train loss 0.38311395049095154, validation loss 0.8835904598236084\n",
      "Epoch 420, current patience 18, model mean validation loss 0.9285586476325989, embedding dim 512, hidden size 2048, num layers 1, train loss 0.6063162088394165, validation loss 0.8894158601760864\n",
      "Epoch 430, current patience 17, model mean validation loss 0.9243316650390625, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5528306365013123, validation loss 0.9426764249801636\n",
      "Epoch 440, current patience 16, model mean validation loss 0.9373214840888977, embedding dim 512, hidden size 2048, num layers 1, train loss 0.11944073438644409, validation loss 0.9582270979881287\n",
      "Epoch 450, current patience 15, model mean validation loss 0.9354463219642639, embedding dim 512, hidden size 2048, num layers 1, train loss 0.4383087456226349, validation loss 0.9612284898757935\n",
      "Epoch 460, current patience 14, model mean validation loss 0.9305194616317749, embedding dim 512, hidden size 2048, num layers 1, train loss 0.41757407784461975, validation loss 0.9538846611976624\n",
      "Epoch 470, current patience 13, model mean validation loss 0.9218529462814331, embedding dim 512, hidden size 2048, num layers 1, train loss 0.4237978160381317, validation loss 0.9172126650810242\n",
      "Epoch 480, current patience 30, model mean validation loss 0.9270097017288208, embedding dim 512, hidden size 2048, num layers 1, train loss 0.9182682633399963, validation loss 0.9098423719406128\n",
      "Epoch 490, current patience 29, model mean validation loss 0.9492111206054688, embedding dim 512, hidden size 2048, num layers 1, train loss 0.3742639422416687, validation loss 1.061201572418213\n",
      "Epoch 500, current patience 28, model mean validation loss 0.9569050073623657, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5527576208114624, validation loss 0.9509674310684204\n",
      "Epoch 510, current patience 27, model mean validation loss 0.9694236516952515, embedding dim 512, hidden size 2048, num layers 1, train loss 0.641342282295227, validation loss 1.0428252220153809\n",
      "Epoch 520, current patience 26, model mean validation loss 0.9698984622955322, embedding dim 512, hidden size 2048, num layers 1, train loss 0.1633925437927246, validation loss 0.9620252251625061\n",
      "Epoch 530, current patience 25, model mean validation loss 0.9785048961639404, embedding dim 512, hidden size 2048, num layers 1, train loss 0.4206114411354065, validation loss 1.0300800800323486\n",
      "Epoch 540, current patience 24, model mean validation loss 1.015424370765686, embedding dim 512, hidden size 2048, num layers 1, train loss 0.21511836349964142, validation loss 1.2492403984069824\n",
      "Epoch 550, current patience 23, model mean validation loss 1.0300006866455078, embedding dim 512, hidden size 2048, num layers 1, train loss 0.18010641634464264, validation loss 1.0338237285614014\n",
      "Epoch 560, current patience 22, model mean validation loss 1.0594041347503662, embedding dim 512, hidden size 2048, num layers 1, train loss 0.45799732208251953, validation loss 1.1450691223144531\n",
      "Epoch 570, current patience 21, model mean validation loss 1.0588141679763794, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5897530317306519, validation loss 1.0564827919006348\n",
      "Epoch 580, current patience 20, model mean validation loss 1.0831267833709717, embedding dim 512, hidden size 2048, num layers 1, train loss 0.3960321843624115, validation loss 1.1454678773880005\n",
      "Epoch 590, current patience 19, model mean validation loss 1.091031789779663, embedding dim 512, hidden size 2048, num layers 1, train loss 0.35765331983566284, validation loss 1.106065034866333\n",
      "Epoch 600, current patience 18, model mean validation loss 1.113023042678833, embedding dim 512, hidden size 2048, num layers 1, train loss 0.2843880355358124, validation loss 1.1379555463790894\n",
      "Epoch 610, current patience 17, model mean validation loss 1.1264311075210571, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5680052638053894, validation loss 1.1373443603515625\n",
      "Epoch 620, current patience 16, model mean validation loss 1.1038144826889038, embedding dim 512, hidden size 2048, num layers 1, train loss 0.30726781487464905, validation loss 1.0683073997497559\n",
      "Epoch 630, current patience 15, model mean validation loss 1.1111913919448853, embedding dim 512, hidden size 2048, num layers 1, train loss 0.11668331921100616, validation loss 1.092839002609253\n",
      "Epoch 640, current patience 14, model mean validation loss 1.113556146621704, embedding dim 512, hidden size 2048, num layers 1, train loss 0.5504128336906433, validation loss 1.163987398147583\n",
      "Epoch 650, current patience 13, model mean validation loss 1.1107553243637085, embedding dim 512, hidden size 2048, num layers 1, train loss 0.43143534660339355, validation loss 1.0340759754180908\n",
      "Epoch 660, current patience 12, model mean validation loss 1.1013193130493164, embedding dim 512, hidden size 2048, num layers 1, train loss 0.11981342732906342, validation loss 1.0699799060821533\n",
      "Epoch 670, current patience 11, model mean validation loss 1.09791898727417, embedding dim 512, hidden size 2048, num layers 1, train loss 0.4172635078430176, validation loss 1.0788630247116089\n",
      "Epoch 680, current patience 10, model mean validation loss 1.0918488502502441, embedding dim 512, hidden size 2048, num layers 1, train loss 0.3111259341239929, validation loss 1.0893936157226562\n",
      "Epoch 690, current patience 9, model mean validation loss 1.0847320556640625, embedding dim 512, hidden size 2048, num layers 1, train loss 0.35916775465011597, validation loss 1.0804110765457153\n",
      "Epoch 700, current patience 8, model mean validation loss 1.0802743434906006, embedding dim 512, hidden size 2048, num layers 1, train loss 0.2494027465581894, validation loss 1.0326447486877441\n",
      "Epoch 710, current patience 7, model mean validation loss 1.0942060947418213, embedding dim 512, hidden size 2048, num layers 1, train loss 0.1710461974143982, validation loss 1.204291820526123\n",
      "Epoch 720, current patience 6, model mean validation loss 1.0921874046325684, embedding dim 512, hidden size 2048, num layers 1, train loss 0.3206450939178467, validation loss 1.1478393077850342\n",
      "Epoch 730, current patience 5, model mean validation loss 1.1009056568145752, embedding dim 512, hidden size 2048, num layers 1, train loss 0.2806864380836487, validation loss 1.1038222312927246\n",
      "Epoch 740, current patience 4, model mean validation loss 1.104149341583252, embedding dim 512, hidden size 2048, num layers 1, train loss 0.25697582960128784, validation loss 1.095929503440857\n",
      "Epoch 750, current patience 3, model mean validation loss 1.1224912405014038, embedding dim 512, hidden size 2048, num layers 1, train loss 0.37427636981010437, validation loss 1.225597620010376\n",
      "Epoch 760, current patience 2, model mean validation loss 1.1327509880065918, embedding dim 512, hidden size 2048, num layers 1, train loss 0.08820396661758423, validation loss 1.1714723110198975\n",
      "Epoch 770, current patience 1, model mean validation loss 1.1386468410491943, embedding dim 512, hidden size 2048, num layers 1, train loss 0.4523363709449768, validation loss 1.127576470375061\n",
      "Epoch 0, current patience 30, model mean validation loss 1.3752003908157349, embedding dim 1024, hidden size 1, num layers 1, train loss 1.3471676111221313, validation loss 1.3752003908157349\n",
      "Epoch 10, current patience 30, model mean validation loss 1.3499927520751953, embedding dim 1024, hidden size 1, num layers 1, train loss 1.4112602472305298, validation loss 1.3247852325439453\n",
      "Epoch 20, current patience 30, model mean validation loss 1.3328020572662354, embedding dim 1024, hidden size 1, num layers 1, train loss 1.334886074066162, validation loss 1.2984206676483154\n",
      "Epoch 30, current patience 30, model mean validation loss 1.3151707649230957, embedding dim 1024, hidden size 1, num layers 1, train loss 1.242020606994629, validation loss 1.2622767686843872\n",
      "Epoch 40, current patience 30, model mean validation loss 1.2952340841293335, embedding dim 1024, hidden size 1, num layers 1, train loss 1.2172505855560303, validation loss 1.2154879570007324\n",
      "Epoch 50, current patience 30, model mean validation loss 1.2748862504959106, embedding dim 1024, hidden size 1, num layers 1, train loss 1.2104432582855225, validation loss 1.1731470823287964\n",
      "Epoch 60, current patience 30, model mean validation loss 1.254948377609253, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1098392009735107, validation loss 1.1353199481964111\n",
      "Epoch 70, current patience 30, model mean validation loss 1.2372255325317383, embedding dim 1024, hidden size 1, num layers 1, train loss 1.106889247894287, validation loss 1.1131666898727417\n",
      "Epoch 80, current patience 30, model mean validation loss 1.203048825263977, embedding dim 1024, hidden size 1, num layers 1, train loss 1.107107400894165, validation loss 1.1017861366271973\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1745601892471313, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1017975807189941, validation loss 1.0968763828277588\n",
      "Epoch 100, current patience 30, model mean validation loss 1.1494114398956299, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0957196950912476, validation loss 1.0972309112548828\n",
      "Epoch 110, current patience 30, model mean validation loss 1.1282553672790527, embedding dim 1024, hidden size 1, num layers 1, train loss 1.109365463256836, validation loss 1.0930275917053223\n",
      "Epoch 120, current patience 30, model mean validation loss 1.1131552457809448, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1009325981140137, validation loss 1.094687581062317\n",
      "Epoch 130, current patience 30, model mean validation loss 1.103468418121338, embedding dim 1024, hidden size 1, num layers 1, train loss 1.09075927734375, validation loss 1.0956517457962036\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0984896421432495, embedding dim 1024, hidden size 1, num layers 1, train loss 1.088404893875122, validation loss 1.0954899787902832\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0961977243423462, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0852231979370117, validation loss 1.0948317050933838\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0955488681793213, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0911356210708618, validation loss 1.0965940952301025\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0950663089752197, embedding dim 1024, hidden size 1, num layers 1, train loss 1.095047950744629, validation loss 1.0930166244506836\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0947264432907104, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0833170413970947, validation loss 1.0945125818252563\n",
      "Epoch 190, current patience 30, model mean validation loss 1.0951504707336426, embedding dim 1024, hidden size 1, num layers 1, train loss 1.083536148071289, validation loss 1.096419095993042\n",
      "Epoch 200, current patience 29, model mean validation loss 1.0951330661773682, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0935938358306885, validation loss 1.094549298286438\n",
      "Epoch 210, current patience 28, model mean validation loss 1.0949554443359375, embedding dim 1024, hidden size 1, num layers 1, train loss 1.083851933479309, validation loss 1.0942299365997314\n",
      "Epoch 220, current patience 27, model mean validation loss 1.095283031463623, embedding dim 1024, hidden size 1, num layers 1, train loss 1.090564250946045, validation loss 1.0981109142303467\n",
      "Epoch 230, current patience 26, model mean validation loss 1.0954697132110596, embedding dim 1024, hidden size 1, num layers 1, train loss 1.095139741897583, validation loss 1.0963249206542969\n",
      "Epoch 240, current patience 25, model mean validation loss 1.0952184200286865, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1033343076705933, validation loss 1.094583511352539\n",
      "Epoch 250, current patience 24, model mean validation loss 1.0948941707611084, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0994031429290771, validation loss 1.090423583984375\n",
      "Epoch 260, current patience 23, model mean validation loss 1.0948485136032104, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1056166887283325, validation loss 1.0941472053527832\n",
      "Epoch 270, current patience 22, model mean validation loss 1.0942277908325195, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0900638103485107, validation loss 1.0914534330368042\n",
      "Epoch 280, current patience 30, model mean validation loss 1.0945018529891968, embedding dim 1024, hidden size 1, num layers 1, train loss 1.083439588546753, validation loss 1.0967411994934082\n",
      "Epoch 290, current patience 29, model mean validation loss 1.0944938659667969, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0840022563934326, validation loss 1.0941667556762695\n",
      "Epoch 300, current patience 28, model mean validation loss 1.094151258468628, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0991597175598145, validation loss 1.0953694581985474\n",
      "Epoch 310, current patience 30, model mean validation loss 1.0942825078964233, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0904769897460938, validation loss 1.0973747968673706\n",
      "Epoch 320, current patience 29, model mean validation loss 1.0940430164337158, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0699341297149658, validation loss 1.0926682949066162\n",
      "Epoch 330, current patience 30, model mean validation loss 1.0942726135253906, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0762815475463867, validation loss 1.0922598838806152\n",
      "Epoch 340, current patience 29, model mean validation loss 1.094053030014038, embedding dim 1024, hidden size 1, num layers 1, train loss 1.088671088218689, validation loss 1.0923902988433838\n",
      "Epoch 350, current patience 28, model mean validation loss 1.0948203802108765, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0830233097076416, validation loss 1.0975918769836426\n",
      "Epoch 360, current patience 27, model mean validation loss 1.0944359302520752, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0720596313476562, validation loss 1.093665361404419\n",
      "Epoch 370, current patience 26, model mean validation loss 1.0943562984466553, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1002379655838013, validation loss 1.0935307741165161\n",
      "Epoch 380, current patience 25, model mean validation loss 1.0945320129394531, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1048743724822998, validation loss 1.0967750549316406\n",
      "Epoch 390, current patience 24, model mean validation loss 1.0941896438598633, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0961904525756836, validation loss 1.0946358442306519\n",
      "Epoch 400, current patience 23, model mean validation loss 1.0942943096160889, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1041277647018433, validation loss 1.0935051441192627\n",
      "Epoch 410, current patience 22, model mean validation loss 1.0947718620300293, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0809603929519653, validation loss 1.0960803031921387\n",
      "Epoch 420, current patience 21, model mean validation loss 1.0952825546264648, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0745089054107666, validation loss 1.0964765548706055\n",
      "Epoch 430, current patience 20, model mean validation loss 1.0950679779052734, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0896857976913452, validation loss 1.095874309539795\n",
      "Epoch 440, current patience 19, model mean validation loss 1.0948179960250854, embedding dim 1024, hidden size 1, num layers 1, train loss 1.092745304107666, validation loss 1.0916661024093628\n",
      "Epoch 450, current patience 18, model mean validation loss 1.095165729522705, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0899097919464111, validation loss 1.0963126420974731\n",
      "Epoch 460, current patience 17, model mean validation loss 1.0949013233184814, embedding dim 1024, hidden size 1, num layers 1, train loss 1.100328803062439, validation loss 1.0946593284606934\n",
      "Epoch 470, current patience 16, model mean validation loss 1.0956650972366333, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1069309711456299, validation loss 1.1007463932037354\n",
      "Epoch 480, current patience 15, model mean validation loss 1.096172571182251, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0930509567260742, validation loss 1.0975652933120728\n",
      "Epoch 490, current patience 14, model mean validation loss 1.096367597579956, embedding dim 1024, hidden size 1, num layers 1, train loss 1.082366704940796, validation loss 1.0976407527923584\n",
      "Epoch 500, current patience 13, model mean validation loss 1.0958786010742188, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1016138792037964, validation loss 1.0925641059875488\n",
      "Epoch 510, current patience 12, model mean validation loss 1.0958573818206787, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0921783447265625, validation loss 1.0957040786743164\n",
      "Epoch 520, current patience 11, model mean validation loss 1.0964306592941284, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0845341682434082, validation loss 1.0962527990341187\n",
      "Epoch 530, current patience 10, model mean validation loss 1.0959603786468506, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1039599180221558, validation loss 1.0925499200820923\n",
      "Epoch 540, current patience 9, model mean validation loss 1.0961158275604248, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0883203744888306, validation loss 1.0959038734436035\n",
      "Epoch 550, current patience 8, model mean validation loss 1.0960099697113037, embedding dim 1024, hidden size 1, num layers 1, train loss 1.090108036994934, validation loss 1.0998986959457397\n",
      "Epoch 560, current patience 7, model mean validation loss 1.0956153869628906, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1070305109024048, validation loss 1.0944082736968994\n",
      "Epoch 570, current patience 6, model mean validation loss 1.0952973365783691, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0916359424591064, validation loss 1.095097541809082\n",
      "Epoch 580, current patience 5, model mean validation loss 1.0953311920166016, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1128897666931152, validation loss 1.0928349494934082\n",
      "Epoch 590, current patience 4, model mean validation loss 1.0951893329620361, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0861101150512695, validation loss 1.0945687294006348\n",
      "Epoch 600, current patience 3, model mean validation loss 1.0950250625610352, embedding dim 1024, hidden size 1, num layers 1, train loss 1.0903170108795166, validation loss 1.094938039779663\n",
      "Epoch 610, current patience 2, model mean validation loss 1.095470905303955, embedding dim 1024, hidden size 1, num layers 1, train loss 1.110183596611023, validation loss 1.0961170196533203\n",
      "Epoch 620, current patience 1, model mean validation loss 1.0953090190887451, embedding dim 1024, hidden size 1, num layers 1, train loss 1.1035887002944946, validation loss 1.094609022140503\n",
      "Epoch 0, current patience 30, model mean validation loss 1.097904920578003, embedding dim 1024, hidden size 2, num layers 1, train loss 1.102952480316162, validation loss 1.097904920578003\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0977632999420166, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1328065395355225, validation loss 1.0976216793060303\n",
      "Epoch 20, current patience 30, model mean validation loss 1.097853660583496, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0906895399093628, validation loss 1.0980345010757446\n",
      "Epoch 30, current patience 29, model mean validation loss 1.0974400043487549, embedding dim 1024, hidden size 2, num layers 1, train loss 1.097505807876587, validation loss 1.0961991548538208\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0967289209365845, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1058440208435059, validation loss 1.0938844680786133\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0965907573699951, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0923391580581665, validation loss 1.0958999395370483\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0966511964797974, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0917599201202393, validation loss 1.097013235092163\n",
      "Epoch 70, current patience 29, model mean validation loss 1.0964847803115845, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0459201335906982, validation loss 1.095320224761963\n",
      "Epoch 80, current patience 30, model mean validation loss 1.096031904220581, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0829896926879883, validation loss 1.094282627105713\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0952775478363037, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1119024753570557, validation loss 1.091586709022522\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0948009490966797, embedding dim 1024, hidden size 2, num layers 1, train loss 1.105072259902954, validation loss 1.0942213535308838\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0947414636611938, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1000943183898926, validation loss 1.0957233905792236\n",
      "Epoch 120, current patience 30, model mean validation loss 1.095160961151123, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0885807275772095, validation loss 1.0972394943237305\n",
      "Epoch 130, current patience 29, model mean validation loss 1.0951296091079712, embedding dim 1024, hidden size 2, num layers 1, train loss 1.095017671585083, validation loss 1.0956497192382812\n",
      "Epoch 140, current patience 28, model mean validation loss 1.0948556661605835, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0821346044540405, validation loss 1.0948221683502197\n",
      "Epoch 150, current patience 27, model mean validation loss 1.095022201538086, embedding dim 1024, hidden size 2, num layers 1, train loss 1.064565658569336, validation loss 1.0966520309448242\n",
      "Epoch 160, current patience 26, model mean validation loss 1.095314383506775, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0738130807876587, validation loss 1.0966203212738037\n",
      "Epoch 170, current patience 25, model mean validation loss 1.0958914756774902, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0788815021514893, validation loss 1.096203088760376\n",
      "Epoch 180, current patience 24, model mean validation loss 1.095700979232788, embedding dim 1024, hidden size 2, num layers 1, train loss 1.076185941696167, validation loss 1.092698097229004\n",
      "Epoch 190, current patience 23, model mean validation loss 1.0954537391662598, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0844531059265137, validation loss 1.0937447547912598\n",
      "Epoch 200, current patience 22, model mean validation loss 1.0955415964126587, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1117843389511108, validation loss 1.09794282913208\n",
      "Epoch 210, current patience 21, model mean validation loss 1.0948450565338135, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0642600059509277, validation loss 1.0900769233703613\n",
      "Epoch 220, current patience 20, model mean validation loss 1.0957472324371338, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1008843183517456, validation loss 1.1020398139953613\n",
      "Epoch 230, current patience 19, model mean validation loss 1.096272349357605, embedding dim 1024, hidden size 2, num layers 1, train loss 1.1083099842071533, validation loss 1.1008529663085938\n",
      "Epoch 240, current patience 18, model mean validation loss 1.096429705619812, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0769739151000977, validation loss 1.09787917137146\n",
      "Epoch 250, current patience 17, model mean validation loss 1.096500277519226, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0525470972061157, validation loss 1.0967681407928467\n",
      "Epoch 260, current patience 16, model mean validation loss 1.0970964431762695, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0638763904571533, validation loss 1.0974665880203247\n",
      "Epoch 270, current patience 15, model mean validation loss 1.0979763269424438, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0901250839233398, validation loss 1.1007840633392334\n",
      "Epoch 280, current patience 14, model mean validation loss 1.0973941087722778, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0953435897827148, validation loss 1.0932849645614624\n",
      "Epoch 290, current patience 13, model mean validation loss 1.098628044128418, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0588407516479492, validation loss 1.0999491214752197\n",
      "Epoch 300, current patience 12, model mean validation loss 1.0985307693481445, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0352987051010132, validation loss 1.101261019706726\n",
      "Epoch 310, current patience 11, model mean validation loss 1.0985352993011475, embedding dim 1024, hidden size 2, num layers 1, train loss 1.054455041885376, validation loss 1.1008896827697754\n",
      "Epoch 320, current patience 10, model mean validation loss 1.099360704421997, embedding dim 1024, hidden size 2, num layers 1, train loss 1.091975212097168, validation loss 1.1044816970825195\n",
      "Epoch 330, current patience 9, model mean validation loss 1.100722074508667, embedding dim 1024, hidden size 2, num layers 1, train loss 0.9919538497924805, validation loss 1.1076594591140747\n",
      "Epoch 340, current patience 8, model mean validation loss 1.1012001037597656, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0929789543151855, validation loss 1.101289987564087\n",
      "Epoch 350, current patience 7, model mean validation loss 1.1010854244232178, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0562386512756348, validation loss 1.0998674631118774\n",
      "Epoch 360, current patience 6, model mean validation loss 1.10264253616333, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0421888828277588, validation loss 1.1057417392730713\n",
      "Epoch 370, current patience 5, model mean validation loss 1.1027069091796875, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0699868202209473, validation loss 1.1004643440246582\n",
      "Epoch 380, current patience 4, model mean validation loss 1.1030941009521484, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0541497468948364, validation loss 1.1043586730957031\n",
      "Epoch 390, current patience 3, model mean validation loss 1.1034690141677856, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0143498182296753, validation loss 1.103888750076294\n",
      "Epoch 400, current patience 2, model mean validation loss 1.1031954288482666, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0703859329223633, validation loss 1.1022933721542358\n",
      "Epoch 410, current patience 1, model mean validation loss 1.103308916091919, embedding dim 1024, hidden size 2, num layers 1, train loss 1.0705339908599854, validation loss 1.1085666418075562\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1053169965744019, embedding dim 1024, hidden size 4, num layers 1, train loss 1.1335844993591309, validation loss 1.1053169965744019\n",
      "Epoch 10, current patience 30, model mean validation loss 1.100212812423706, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0946389436721802, validation loss 1.0951085090637207\n",
      "Epoch 20, current patience 30, model mean validation loss 1.098124623298645, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0787039995193481, validation loss 1.093948483467102\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0972226858139038, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0858525037765503, validation loss 1.0945167541503906\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0961384773254395, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0953514575958252, validation loss 1.0918018817901611\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0962194204330444, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0712511539459229, validation loss 1.0966238975524902\n",
      "Epoch 60, current patience 29, model mean validation loss 1.0951610803604126, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0845588445663452, validation loss 1.088810682296753\n",
      "Epoch 70, current patience 30, model mean validation loss 1.094334363937378, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0914255380630493, validation loss 1.088548183441162\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0920720100402832, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0628048181533813, validation loss 1.0872178077697754\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0906102657318115, embedding dim 1024, hidden size 4, num layers 1, train loss 1.08909010887146, validation loss 1.083414077758789\n",
      "Epoch 100, current patience 30, model mean validation loss 1.089469075202942, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0748703479766846, validation loss 1.0848197937011719\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0886447429656982, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0682628154754639, validation loss 1.0879220962524414\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0873792171478271, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0339057445526123, validation loss 1.0816770792007446\n",
      "Epoch 130, current patience 30, model mean validation loss 1.086567997932434, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0839481353759766, validation loss 1.090134620666504\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0874691009521484, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0039911270141602, validation loss 1.0960193872451782\n",
      "Epoch 150, current patience 29, model mean validation loss 1.0859880447387695, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9907897114753723, validation loss 1.07669997215271\n",
      "Epoch 160, current patience 30, model mean validation loss 1.0854899883270264, embedding dim 1024, hidden size 4, num layers 1, train loss 0.985098659992218, validation loss 1.0832338333129883\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0870147943496704, embedding dim 1024, hidden size 4, num layers 1, train loss 1.1067622900009155, validation loss 1.0956120491027832\n",
      "Epoch 180, current patience 29, model mean validation loss 1.0868923664093018, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9458308219909668, validation loss 1.083839774131775\n",
      "Epoch 190, current patience 28, model mean validation loss 1.0867189168930054, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0617913007736206, validation loss 1.0865345001220703\n",
      "Epoch 200, current patience 27, model mean validation loss 1.0865145921707153, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0238091945648193, validation loss 1.0800426006317139\n",
      "Epoch 210, current patience 26, model mean validation loss 1.0864794254302979, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0680615901947021, validation loss 1.0898534059524536\n",
      "Epoch 220, current patience 25, model mean validation loss 1.0852782726287842, embedding dim 1024, hidden size 4, num layers 1, train loss 1.070047378540039, validation loss 1.086409568786621\n",
      "Epoch 230, current patience 30, model mean validation loss 1.0866941213607788, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0331432819366455, validation loss 1.0880275964736938\n",
      "Epoch 240, current patience 29, model mean validation loss 1.0868639945983887, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9467605352401733, validation loss 1.0845924615859985\n",
      "Epoch 250, current patience 28, model mean validation loss 1.0857577323913574, embedding dim 1024, hidden size 4, num layers 1, train loss 1.076202154159546, validation loss 1.0867621898651123\n",
      "Epoch 260, current patience 27, model mean validation loss 1.0871484279632568, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0294077396392822, validation loss 1.0949647426605225\n",
      "Epoch 270, current patience 26, model mean validation loss 1.0873380899429321, embedding dim 1024, hidden size 4, num layers 1, train loss 1.1311962604522705, validation loss 1.0880523920059204\n",
      "Epoch 280, current patience 25, model mean validation loss 1.0897691249847412, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9896422624588013, validation loss 1.0994908809661865\n",
      "Epoch 290, current patience 24, model mean validation loss 1.089379906654358, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9318834543228149, validation loss 1.0867393016815186\n",
      "Epoch 300, current patience 23, model mean validation loss 1.0896472930908203, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0715941190719604, validation loss 1.088547945022583\n",
      "Epoch 310, current patience 22, model mean validation loss 1.0907232761383057, embedding dim 1024, hidden size 4, num layers 1, train loss 0.886242687702179, validation loss 1.0966366529464722\n",
      "Epoch 320, current patience 21, model mean validation loss 1.0895644426345825, embedding dim 1024, hidden size 4, num layers 1, train loss 0.904911458492279, validation loss 1.0753215551376343\n",
      "Epoch 330, current patience 20, model mean validation loss 1.0891013145446777, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0296204090118408, validation loss 1.0830568075180054\n",
      "Epoch 340, current patience 19, model mean validation loss 1.088815689086914, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0669158697128296, validation loss 1.0926799774169922\n",
      "Epoch 350, current patience 18, model mean validation loss 1.0897948741912842, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9607981443405151, validation loss 1.0958857536315918\n",
      "Epoch 360, current patience 17, model mean validation loss 1.091261863708496, embedding dim 1024, hidden size 4, num layers 1, train loss 0.8869491219520569, validation loss 1.1112269163131714\n",
      "Epoch 370, current patience 16, model mean validation loss 1.0937237739562988, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9298301935195923, validation loss 1.1064338684082031\n",
      "Epoch 380, current patience 15, model mean validation loss 1.0956755876541138, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9434816837310791, validation loss 1.1041626930236816\n",
      "Epoch 390, current patience 14, model mean validation loss 1.096832275390625, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0247541666030884, validation loss 1.1058907508850098\n",
      "Epoch 400, current patience 13, model mean validation loss 1.0989325046539307, embedding dim 1024, hidden size 4, num layers 1, train loss 1.019579529762268, validation loss 1.0921233892440796\n",
      "Epoch 410, current patience 12, model mean validation loss 1.1000162363052368, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9909778833389282, validation loss 1.091726541519165\n",
      "Epoch 420, current patience 11, model mean validation loss 1.103194236755371, embedding dim 1024, hidden size 4, num layers 1, train loss 0.960671067237854, validation loss 1.1181048154830933\n",
      "Epoch 430, current patience 10, model mean validation loss 1.1051052808761597, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0197439193725586, validation loss 1.111173152923584\n",
      "Epoch 440, current patience 9, model mean validation loss 1.102574110031128, embedding dim 1024, hidden size 4, num layers 1, train loss 0.8590027093887329, validation loss 1.0909768342971802\n",
      "Epoch 450, current patience 8, model mean validation loss 1.100610375404358, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9937304854393005, validation loss 1.0907248258590698\n",
      "Epoch 460, current patience 7, model mean validation loss 1.098923683166504, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9850813746452332, validation loss 1.0906693935394287\n",
      "Epoch 470, current patience 6, model mean validation loss 1.0989128351211548, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9428406953811646, validation loss 1.1058037281036377\n",
      "Epoch 480, current patience 5, model mean validation loss 1.0992330312728882, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0334317684173584, validation loss 1.0946853160858154\n",
      "Epoch 490, current patience 4, model mean validation loss 1.0998051166534424, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9561558365821838, validation loss 1.0963037014007568\n",
      "Epoch 500, current patience 3, model mean validation loss 1.0982520580291748, embedding dim 1024, hidden size 4, num layers 1, train loss 0.9390686750411987, validation loss 1.1056796312332153\n",
      "Epoch 510, current patience 2, model mean validation loss 1.0968668460845947, embedding dim 1024, hidden size 4, num layers 1, train loss 0.8898960947990417, validation loss 1.1000914573669434\n",
      "Epoch 520, current patience 1, model mean validation loss 1.0987075567245483, embedding dim 1024, hidden size 4, num layers 1, train loss 1.0342607498168945, validation loss 1.105702519416809\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1132020950317383, embedding dim 1024, hidden size 8, num layers 1, train loss 1.1336677074432373, validation loss 1.1132020950317383\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1016076803207397, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0860595703125, validation loss 1.0900132656097412\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0994744300842285, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0876466035842896, validation loss 1.0952078104019165\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0978639125823975, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0211182832717896, validation loss 1.0930321216583252\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0970863103866577, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0802463293075562, validation loss 1.0939762592315674\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0947160720825195, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0817201137542725, validation loss 1.082864761352539\n",
      "Epoch 60, current patience 30, model mean validation loss 1.092045545578003, embedding dim 1024, hidden size 8, num layers 1, train loss 1.101218819618225, validation loss 1.0760222673416138\n",
      "Epoch 70, current patience 30, model mean validation loss 1.089741587638855, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0128992795944214, validation loss 1.0736137628555298\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0854647159576416, embedding dim 1024, hidden size 8, num layers 1, train loss 1.080838918685913, validation loss 1.0789878368377686\n",
      "Epoch 90, current patience 30, model mean validation loss 1.084412693977356, embedding dim 1024, hidden size 8, num layers 1, train loss 1.123234510421753, validation loss 1.0815964937210083\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0799294710159302, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0832092761993408, validation loss 1.059342384338379\n",
      "Epoch 110, current patience 30, model mean validation loss 1.075533151626587, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9665604829788208, validation loss 1.0578620433807373\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0717506408691406, embedding dim 1024, hidden size 8, num layers 1, train loss 1.1330056190490723, validation loss 1.063715934753418\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0692613124847412, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9182837009429932, validation loss 1.0629502534866333\n",
      "Epoch 140, current patience 30, model mean validation loss 1.067164421081543, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9662283062934875, validation loss 1.0592466592788696\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0693517923355103, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9689143896102905, validation loss 1.0911130905151367\n",
      "Epoch 160, current patience 29, model mean validation loss 1.0734362602233887, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9444964528083801, validation loss 1.1116633415222168\n",
      "Epoch 170, current patience 28, model mean validation loss 1.074940800666809, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9347866177558899, validation loss 1.0936329364776611\n",
      "Epoch 180, current patience 27, model mean validation loss 1.0775573253631592, embedding dim 1024, hidden size 8, num layers 1, train loss 1.1578714847564697, validation loss 1.0802745819091797\n",
      "Epoch 190, current patience 26, model mean validation loss 1.07902991771698, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9387922286987305, validation loss 1.0696427822113037\n",
      "Epoch 200, current patience 25, model mean validation loss 1.082073450088501, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9788317680358887, validation loss 1.088064193725586\n",
      "Epoch 210, current patience 24, model mean validation loss 1.0839684009552002, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9880646467208862, validation loss 1.0781095027923584\n",
      "Epoch 220, current patience 23, model mean validation loss 1.0848489999771118, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0075879096984863, validation loss 1.0662918090820312\n",
      "Epoch 230, current patience 22, model mean validation loss 1.0849140882492065, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9109945893287659, validation loss 1.0916337966918945\n",
      "Epoch 240, current patience 21, model mean validation loss 1.0834124088287354, embedding dim 1024, hidden size 8, num layers 1, train loss 1.042060375213623, validation loss 1.0996496677398682\n",
      "Epoch 250, current patience 20, model mean validation loss 1.0820484161376953, embedding dim 1024, hidden size 8, num layers 1, train loss 0.8492661714553833, validation loss 1.0827209949493408\n",
      "Epoch 260, current patience 19, model mean validation loss 1.0822467803955078, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9099602699279785, validation loss 1.0818617343902588\n",
      "Epoch 270, current patience 18, model mean validation loss 1.0858299732208252, embedding dim 1024, hidden size 8, num layers 1, train loss 0.8810308575630188, validation loss 1.0983085632324219\n",
      "Epoch 280, current patience 17, model mean validation loss 1.0868428945541382, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9676607847213745, validation loss 1.0961675643920898\n",
      "Epoch 290, current patience 16, model mean validation loss 1.087156057357788, embedding dim 1024, hidden size 8, num layers 1, train loss 0.98659348487854, validation loss 1.0806152820587158\n",
      "Epoch 300, current patience 15, model mean validation loss 1.0874266624450684, embedding dim 1024, hidden size 8, num layers 1, train loss 1.087885856628418, validation loss 1.0684561729431152\n",
      "Epoch 310, current patience 14, model mean validation loss 1.0865578651428223, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9027019739151001, validation loss 1.0846818685531616\n",
      "Epoch 320, current patience 13, model mean validation loss 1.0878373384475708, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9983434677124023, validation loss 1.1098865270614624\n",
      "Epoch 330, current patience 12, model mean validation loss 1.0920156240463257, embedding dim 1024, hidden size 8, num layers 1, train loss 0.8107841610908508, validation loss 1.1161470413208008\n",
      "Epoch 340, current patience 11, model mean validation loss 1.0966559648513794, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9174096584320068, validation loss 1.1189844608306885\n",
      "Epoch 350, current patience 10, model mean validation loss 1.096574306488037, embedding dim 1024, hidden size 8, num layers 1, train loss 1.1194695234298706, validation loss 1.0976550579071045\n",
      "Epoch 360, current patience 9, model mean validation loss 1.094728708267212, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9882509112358093, validation loss 1.0814036130905151\n",
      "Epoch 370, current patience 8, model mean validation loss 1.0992422103881836, embedding dim 1024, hidden size 8, num layers 1, train loss 1.0057700872421265, validation loss 1.116722583770752\n",
      "Epoch 380, current patience 7, model mean validation loss 1.1055939197540283, embedding dim 1024, hidden size 8, num layers 1, train loss 0.7762898206710815, validation loss 1.1192710399627686\n",
      "Epoch 390, current patience 6, model mean validation loss 1.1122968196868896, embedding dim 1024, hidden size 8, num layers 1, train loss 1.012520670890808, validation loss 1.138304352760315\n",
      "Epoch 400, current patience 5, model mean validation loss 1.1143128871917725, embedding dim 1024, hidden size 8, num layers 1, train loss 0.8053549528121948, validation loss 1.1260147094726562\n",
      "Epoch 410, current patience 4, model mean validation loss 1.1161800622940063, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9425112009048462, validation loss 1.1310844421386719\n",
      "Epoch 420, current patience 3, model mean validation loss 1.1135494709014893, embedding dim 1024, hidden size 8, num layers 1, train loss 0.9209981560707092, validation loss 1.09794020652771\n",
      "Epoch 430, current patience 2, model mean validation loss 1.1140947341918945, embedding dim 1024, hidden size 8, num layers 1, train loss 0.8172988891601562, validation loss 1.1020166873931885\n",
      "Epoch 440, current patience 1, model mean validation loss 1.1151483058929443, embedding dim 1024, hidden size 8, num layers 1, train loss 0.822731614112854, validation loss 1.0898329019546509\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0983725786209106, embedding dim 1024, hidden size 16, num layers 1, train loss 1.093639612197876, validation loss 1.0983725786209106\n",
      "Epoch 10, current patience 30, model mean validation loss 1.095320224761963, embedding dim 1024, hidden size 16, num layers 1, train loss 1.099794626235962, validation loss 1.0922678709030151\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0943650007247925, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0991183519363403, validation loss 1.0924545526504517\n",
      "Epoch 30, current patience 30, model mean validation loss 1.093869924545288, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0735529661178589, validation loss 1.092384696006775\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0914440155029297, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0210440158843994, validation loss 1.081740140914917\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0889426469802856, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0041449069976807, validation loss 1.0764355659484863\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0906646251678467, embedding dim 1024, hidden size 16, num layers 1, train loss 1.1382896900177002, validation loss 1.1009970903396606\n",
      "Epoch 70, current patience 29, model mean validation loss 1.085945725440979, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0549240112304688, validation loss 1.0529133081436157\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0838823318481445, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0269088745117188, validation loss 1.081865668296814\n",
      "Epoch 90, current patience 30, model mean validation loss 1.079007863998413, embedding dim 1024, hidden size 16, num layers 1, train loss 0.964712917804718, validation loss 1.0532718896865845\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0741453170776367, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9920003414154053, validation loss 1.0535545349121094\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0746874809265137, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9835368394851685, validation loss 1.0967214107513428\n",
      "Epoch 120, current patience 29, model mean validation loss 1.076033115386963, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7610119581222534, validation loss 1.092505931854248\n",
      "Epoch 130, current patience 28, model mean validation loss 1.0738046169281006, embedding dim 1024, hidden size 16, num layers 1, train loss 1.1318938732147217, validation loss 1.0586068630218506\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0674327611923218, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0278805494308472, validation loss 1.050022006034851\n",
      "Epoch 150, current patience 30, model mean validation loss 1.0696721076965332, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7806823253631592, validation loss 1.0708281993865967\n",
      "Epoch 160, current patience 29, model mean validation loss 1.0655838251113892, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9288407564163208, validation loss 1.0491597652435303\n",
      "Epoch 170, current patience 30, model mean validation loss 1.0638041496276855, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9677168130874634, validation loss 1.039034128189087\n",
      "Epoch 180, current patience 30, model mean validation loss 1.0720824003219604, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8240183591842651, validation loss 1.1197806596755981\n",
      "Epoch 190, current patience 29, model mean validation loss 1.0734138488769531, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0382957458496094, validation loss 1.107373595237732\n",
      "Epoch 200, current patience 28, model mean validation loss 1.0706623792648315, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9373770356178284, validation loss 1.0704941749572754\n",
      "Epoch 210, current patience 27, model mean validation loss 1.0722941160202026, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0216941833496094, validation loss 1.0716608762741089\n",
      "Epoch 220, current patience 26, model mean validation loss 1.0758845806121826, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8392704725265503, validation loss 1.0787463188171387\n",
      "Epoch 230, current patience 25, model mean validation loss 1.0834934711456299, embedding dim 1024, hidden size 16, num layers 1, train loss 1.0204150676727295, validation loss 1.1316993236541748\n",
      "Epoch 240, current patience 24, model mean validation loss 1.0836732387542725, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8481612801551819, validation loss 1.0505969524383545\n",
      "Epoch 250, current patience 23, model mean validation loss 1.0952552556991577, embedding dim 1024, hidden size 16, num layers 1, train loss 0.6294245719909668, validation loss 1.1316900253295898\n",
      "Epoch 260, current patience 22, model mean validation loss 1.0867373943328857, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9287122488021851, validation loss 1.0516383647918701\n",
      "Epoch 270, current patience 21, model mean validation loss 1.0820773839950562, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7381768822669983, validation loss 1.0700935125350952\n",
      "Epoch 280, current patience 20, model mean validation loss 1.0807323455810547, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8831939697265625, validation loss 1.0597330331802368\n",
      "Epoch 290, current patience 19, model mean validation loss 1.084983229637146, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7517222166061401, validation loss 1.1056687831878662\n",
      "Epoch 300, current patience 18, model mean validation loss 1.0844687223434448, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8837218880653381, validation loss 1.0746301412582397\n",
      "Epoch 310, current patience 17, model mean validation loss 1.0741242170333862, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8354156017303467, validation loss 1.048943042755127\n",
      "Epoch 320, current patience 16, model mean validation loss 1.078523874282837, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8373539447784424, validation loss 1.08579421043396\n",
      "Epoch 330, current patience 15, model mean validation loss 1.0768903493881226, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7045320272445679, validation loss 1.118621826171875\n",
      "Epoch 340, current patience 14, model mean validation loss 1.0811901092529297, embedding dim 1024, hidden size 16, num layers 1, train loss 0.831519603729248, validation loss 1.0860369205474854\n",
      "Epoch 350, current patience 13, model mean validation loss 1.0806726217269897, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9549810886383057, validation loss 1.065953254699707\n",
      "Epoch 360, current patience 12, model mean validation loss 1.0894137620925903, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7656519412994385, validation loss 1.129662036895752\n",
      "Epoch 370, current patience 11, model mean validation loss 1.089100956916809, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8971065282821655, validation loss 1.1031668186187744\n",
      "Epoch 380, current patience 10, model mean validation loss 1.0905101299285889, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8723416328430176, validation loss 1.0859028100967407\n",
      "Epoch 390, current patience 9, model mean validation loss 1.0971555709838867, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8386605978012085, validation loss 1.102105975151062\n",
      "Epoch 400, current patience 8, model mean validation loss 1.0994277000427246, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8929030299186707, validation loss 1.1039714813232422\n",
      "Epoch 410, current patience 7, model mean validation loss 1.116976022720337, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7192848920822144, validation loss 1.259008526802063\n",
      "Epoch 420, current patience 6, model mean validation loss 1.126132607460022, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7922753691673279, validation loss 1.159289836883545\n",
      "Epoch 430, current patience 5, model mean validation loss 1.129218578338623, embedding dim 1024, hidden size 16, num layers 1, train loss 0.9087183475494385, validation loss 1.090641736984253\n",
      "Epoch 440, current patience 4, model mean validation loss 1.1223835945129395, embedding dim 1024, hidden size 16, num layers 1, train loss 0.597847580909729, validation loss 1.0749818086624146\n",
      "Epoch 450, current patience 3, model mean validation loss 1.126163125038147, embedding dim 1024, hidden size 16, num layers 1, train loss 0.8432635068893433, validation loss 1.133402943611145\n",
      "Epoch 460, current patience 2, model mean validation loss 1.1403281688690186, embedding dim 1024, hidden size 16, num layers 1, train loss 0.6265430450439453, validation loss 1.1992225646972656\n",
      "Epoch 470, current patience 1, model mean validation loss 1.1434431076049805, embedding dim 1024, hidden size 16, num layers 1, train loss 0.7931588888168335, validation loss 1.127026081085205\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1220800876617432, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0927040576934814, validation loss 1.1220800876617432\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1113260984420776, embedding dim 1024, hidden size 32, num layers 1, train loss 1.087815523147583, validation loss 1.100572109222412\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1043869256973267, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0830049514770508, validation loss 1.0905084609985352\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0983977317810059, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0744774341583252, validation loss 1.080430269241333\n",
      "Epoch 40, current patience 30, model mean validation loss 1.089742660522461, embedding dim 1024, hidden size 32, num layers 1, train loss 0.9143010377883911, validation loss 1.0551224946975708\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0814861059188843, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0884156227111816, validation loss 1.0402028560638428\n",
      "Epoch 60, current patience 30, model mean validation loss 1.081214189529419, embedding dim 1024, hidden size 32, num layers 1, train loss 0.9272617697715759, validation loss 1.079582691192627\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0737075805664062, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8757811188697815, validation loss 1.0211613178253174\n",
      "Epoch 80, current patience 30, model mean validation loss 1.060616135597229, embedding dim 1024, hidden size 32, num layers 1, train loss 0.9421705007553101, validation loss 1.0173486471176147\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0499544143676758, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0821046829223633, validation loss 1.0152784585952759\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0409250259399414, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0860798358917236, validation loss 1.0182732343673706\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0458985567092896, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7680755853652954, validation loss 1.1202186346054077\n",
      "Epoch 120, current patience 29, model mean validation loss 1.040655255317688, embedding dim 1024, hidden size 32, num layers 1, train loss 1.081152081489563, validation loss 1.0131758451461792\n",
      "Epoch 130, current patience 30, model mean validation loss 1.0354230403900146, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0135294198989868, validation loss 0.9983459115028381\n",
      "Epoch 140, current patience 30, model mean validation loss 1.0321354866027832, embedding dim 1024, hidden size 32, num layers 1, train loss 0.9144301414489746, validation loss 1.0532822608947754\n",
      "Epoch 150, current patience 30, model mean validation loss 1.035369873046875, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8151640892028809, validation loss 1.0470356941223145\n",
      "Epoch 160, current patience 29, model mean validation loss 1.0346863269805908, embedding dim 1024, hidden size 32, num layers 1, train loss 1.0564038753509521, validation loss 1.0118801593780518\n",
      "Epoch 170, current patience 28, model mean validation loss 1.0383307933807373, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6033774018287659, validation loss 1.044434905052185\n",
      "Epoch 180, current patience 27, model mean validation loss 1.043543815612793, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7134342193603516, validation loss 1.0599772930145264\n",
      "Epoch 190, current patience 26, model mean validation loss 1.0353896617889404, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8869572281837463, validation loss 1.0549852848052979\n",
      "Epoch 200, current patience 25, model mean validation loss 1.0400665998458862, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6593081951141357, validation loss 1.050591230392456\n",
      "Epoch 210, current patience 24, model mean validation loss 1.0421364307403564, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6607287526130676, validation loss 1.014904260635376\n",
      "Epoch 220, current patience 23, model mean validation loss 1.0453661680221558, embedding dim 1024, hidden size 32, num layers 1, train loss 0.5988941192626953, validation loss 1.0791202783584595\n",
      "Epoch 230, current patience 22, model mean validation loss 1.0453331470489502, embedding dim 1024, hidden size 32, num layers 1, train loss 0.713151216506958, validation loss 1.0467722415924072\n",
      "Epoch 240, current patience 21, model mean validation loss 1.057068109512329, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6311623454093933, validation loss 1.1057595014572144\n",
      "Epoch 250, current patience 20, model mean validation loss 1.0716578960418701, embedding dim 1024, hidden size 32, num layers 1, train loss 0.33557572960853577, validation loss 1.1611526012420654\n",
      "Epoch 260, current patience 19, model mean validation loss 1.0793312788009644, embedding dim 1024, hidden size 32, num layers 1, train loss 0.36287546157836914, validation loss 1.1213648319244385\n",
      "Epoch 270, current patience 18, model mean validation loss 1.0838942527770996, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6036355495452881, validation loss 1.091489315032959\n",
      "Epoch 280, current patience 17, model mean validation loss 1.0922632217407227, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8125871419906616, validation loss 1.117542028427124\n",
      "Epoch 290, current patience 16, model mean validation loss 1.0998785495758057, embedding dim 1024, hidden size 32, num layers 1, train loss 0.5094329118728638, validation loss 1.0758271217346191\n",
      "Epoch 300, current patience 15, model mean validation loss 1.1058857440948486, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7123197317123413, validation loss 1.1271789073944092\n",
      "Epoch 310, current patience 14, model mean validation loss 1.1182379722595215, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7657198309898376, validation loss 1.1455897092819214\n",
      "Epoch 320, current patience 13, model mean validation loss 1.1266565322875977, embedding dim 1024, hidden size 32, num layers 1, train loss 0.3752927780151367, validation loss 1.1731078624725342\n",
      "Epoch 330, current patience 12, model mean validation loss 1.1122965812683105, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7777212858200073, validation loss 1.0462722778320312\n",
      "Epoch 340, current patience 11, model mean validation loss 1.1031287908554077, embedding dim 1024, hidden size 32, num layers 1, train loss 0.5613974332809448, validation loss 1.0480232238769531\n",
      "Epoch 350, current patience 10, model mean validation loss 1.0993750095367432, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8179786801338196, validation loss 1.0614585876464844\n",
      "Epoch 360, current patience 9, model mean validation loss 1.0995569229125977, embedding dim 1024, hidden size 32, num layers 1, train loss 0.587971568107605, validation loss 1.1189980506896973\n",
      "Epoch 370, current patience 8, model mean validation loss 1.10279381275177, embedding dim 1024, hidden size 32, num layers 1, train loss 0.5904963612556458, validation loss 1.1017215251922607\n",
      "Epoch 380, current patience 7, model mean validation loss 1.0952200889587402, embedding dim 1024, hidden size 32, num layers 1, train loss 0.5973985195159912, validation loss 1.0665889978408813\n",
      "Epoch 390, current patience 6, model mean validation loss 1.0882408618927002, embedding dim 1024, hidden size 32, num layers 1, train loss 0.7757951021194458, validation loss 1.0897564888000488\n",
      "Epoch 400, current patience 5, model mean validation loss 1.0710904598236084, embedding dim 1024, hidden size 32, num layers 1, train loss 0.8461791276931763, validation loss 1.035904884338379\n",
      "Epoch 410, current patience 4, model mean validation loss 1.0880558490753174, embedding dim 1024, hidden size 32, num layers 1, train loss 0.6683053970336914, validation loss 1.181994915008545\n",
      "Epoch 420, current patience 3, model mean validation loss 1.0978628396987915, embedding dim 1024, hidden size 32, num layers 1, train loss 0.44335585832595825, validation loss 1.1264793872833252\n",
      "Epoch 430, current patience 2, model mean validation loss 1.103102445602417, embedding dim 1024, hidden size 32, num layers 1, train loss 1.1092000007629395, validation loss 1.1033753156661987\n",
      "Epoch 440, current patience 1, model mean validation loss 1.0971158742904663, embedding dim 1024, hidden size 32, num layers 1, train loss 0.543907880783081, validation loss 1.0711053609848022\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1023375988006592, embedding dim 1024, hidden size 64, num layers 1, train loss 1.08760666847229, validation loss 1.1023375988006592\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0968589782714844, embedding dim 1024, hidden size 64, num layers 1, train loss 1.0864381790161133, validation loss 1.0913804769515991\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0918432474136353, embedding dim 1024, hidden size 64, num layers 1, train loss 1.103554606437683, validation loss 1.0818119049072266\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0833786725997925, embedding dim 1024, hidden size 64, num layers 1, train loss 0.9055477380752563, validation loss 1.057984709739685\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0673277378082275, embedding dim 1024, hidden size 64, num layers 1, train loss 0.89122074842453, validation loss 1.0031236410140991\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0581432580947876, embedding dim 1024, hidden size 64, num layers 1, train loss 1.1136126518249512, validation loss 1.0122214555740356\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0487871170043945, embedding dim 1024, hidden size 64, num layers 1, train loss 0.8859047889709473, validation loss 0.9926495552062988\n",
      "Epoch 70, current patience 30, model mean validation loss 1.042759895324707, embedding dim 1024, hidden size 64, num layers 1, train loss 0.8282086253166199, validation loss 1.0005697011947632\n",
      "Epoch 80, current patience 30, model mean validation loss 1.027457594871521, embedding dim 1024, hidden size 64, num layers 1, train loss 1.0085318088531494, validation loss 0.9799188375473022\n",
      "Epoch 90, current patience 30, model mean validation loss 1.0138150453567505, embedding dim 1024, hidden size 64, num layers 1, train loss 0.9137980937957764, validation loss 0.9822405576705933\n",
      "Epoch 100, current patience 30, model mean validation loss 1.000685453414917, embedding dim 1024, hidden size 64, num layers 1, train loss 0.4547837972640991, validation loss 0.9767756462097168\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9936628341674805, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6959419250488281, validation loss 1.001802921295166\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9906823039054871, embedding dim 1024, hidden size 64, num layers 1, train loss 0.5914279222488403, validation loss 0.9792795181274414\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9910039305686951, embedding dim 1024, hidden size 64, num layers 1, train loss 0.3569224774837494, validation loss 1.0147944688796997\n",
      "Epoch 140, current patience 29, model mean validation loss 0.9883371591567993, embedding dim 1024, hidden size 64, num layers 1, train loss 0.7336435317993164, validation loss 0.9713151454925537\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9841492176055908, embedding dim 1024, hidden size 64, num layers 1, train loss 0.8760921359062195, validation loss 0.9670660495758057\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9907369017601013, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6529781222343445, validation loss 1.0326207876205444\n",
      "Epoch 170, current patience 29, model mean validation loss 0.9828298091888428, embedding dim 1024, hidden size 64, num layers 1, train loss 1.0090445280075073, validation loss 0.9189835786819458\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9778933525085449, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6211304068565369, validation loss 0.9372841715812683\n",
      "Epoch 190, current patience 30, model mean validation loss 0.9930154085159302, embedding dim 1024, hidden size 64, num layers 1, train loss 0.46767619252204895, validation loss 1.1227798461914062\n",
      "Epoch 200, current patience 29, model mean validation loss 1.005812644958496, embedding dim 1024, hidden size 64, num layers 1, train loss 0.43943193554878235, validation loss 1.081656575202942\n",
      "Epoch 210, current patience 28, model mean validation loss 1.0049455165863037, embedding dim 1024, hidden size 64, num layers 1, train loss 0.8143095374107361, validation loss 1.0078577995300293\n",
      "Epoch 220, current patience 27, model mean validation loss 1.0133905410766602, embedding dim 1024, hidden size 64, num layers 1, train loss 0.7165969014167786, validation loss 1.0388755798339844\n",
      "Epoch 230, current patience 26, model mean validation loss 1.0225145816802979, embedding dim 1024, hidden size 64, num layers 1, train loss 0.8221487998962402, validation loss 1.0400584936141968\n",
      "Epoch 240, current patience 25, model mean validation loss 1.025602102279663, embedding dim 1024, hidden size 64, num layers 1, train loss 0.49903756380081177, validation loss 1.0573210716247559\n",
      "Epoch 250, current patience 24, model mean validation loss 1.0394905805587769, embedding dim 1024, hidden size 64, num layers 1, train loss 0.864651620388031, validation loss 1.0300910472869873\n",
      "Epoch 260, current patience 23, model mean validation loss 1.0484895706176758, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6753585338592529, validation loss 1.0092766284942627\n",
      "Epoch 270, current patience 22, model mean validation loss 1.0401740074157715, embedding dim 1024, hidden size 64, num layers 1, train loss 1.1004672050476074, validation loss 1.0562553405761719\n",
      "Epoch 280, current patience 21, model mean validation loss 1.0237140655517578, embedding dim 1024, hidden size 64, num layers 1, train loss 0.52055823802948, validation loss 0.9499768018722534\n",
      "Epoch 290, current patience 20, model mean validation loss 1.0294287204742432, embedding dim 1024, hidden size 64, num layers 1, train loss 0.41263651847839355, validation loss 1.053573727607727\n",
      "Epoch 300, current patience 19, model mean validation loss 1.0333404541015625, embedding dim 1024, hidden size 64, num layers 1, train loss 0.5118685364723206, validation loss 1.0701701641082764\n",
      "Epoch 310, current patience 18, model mean validation loss 1.0546274185180664, embedding dim 1024, hidden size 64, num layers 1, train loss 0.25335246324539185, validation loss 1.2103540897369385\n",
      "Epoch 320, current patience 17, model mean validation loss 1.0524866580963135, embedding dim 1024, hidden size 64, num layers 1, train loss 0.42739975452423096, validation loss 1.0401960611343384\n",
      "Epoch 330, current patience 16, model mean validation loss 1.0595322847366333, embedding dim 1024, hidden size 64, num layers 1, train loss 0.5256699919700623, validation loss 1.0864554643630981\n",
      "Epoch 340, current patience 15, model mean validation loss 1.069395661354065, embedding dim 1024, hidden size 64, num layers 1, train loss 0.33731281757354736, validation loss 1.088183879852295\n",
      "Epoch 350, current patience 14, model mean validation loss 1.0819387435913086, embedding dim 1024, hidden size 64, num layers 1, train loss 0.2874273657798767, validation loss 1.156599998474121\n",
      "Epoch 360, current patience 13, model mean validation loss 1.0966835021972656, embedding dim 1024, hidden size 64, num layers 1, train loss 0.24141886830329895, validation loss 1.0679349899291992\n",
      "Epoch 370, current patience 12, model mean validation loss 1.1033952236175537, embedding dim 1024, hidden size 64, num layers 1, train loss 0.177260160446167, validation loss 1.107266902923584\n",
      "Epoch 380, current patience 11, model mean validation loss 1.107764720916748, embedding dim 1024, hidden size 64, num layers 1, train loss 0.48660895228385925, validation loss 1.105126142501831\n",
      "Epoch 390, current patience 10, model mean validation loss 1.0790348052978516, embedding dim 1024, hidden size 64, num layers 1, train loss 0.3486500382423401, validation loss 0.980515718460083\n",
      "Epoch 400, current patience 9, model mean validation loss 1.0734810829162598, embedding dim 1024, hidden size 64, num layers 1, train loss 0.4528767168521881, validation loss 0.9957661628723145\n",
      "Epoch 410, current patience 8, model mean validation loss 1.0805034637451172, embedding dim 1024, hidden size 64, num layers 1, train loss 0.5411249399185181, validation loss 1.1426334381103516\n",
      "Epoch 420, current patience 7, model mean validation loss 1.0868971347808838, embedding dim 1024, hidden size 64, num layers 1, train loss 0.21921643614768982, validation loss 1.1393334865570068\n",
      "Epoch 430, current patience 6, model mean validation loss 1.0839506387710571, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6660773754119873, validation loss 1.133028268814087\n",
      "Epoch 440, current patience 5, model mean validation loss 1.0815191268920898, embedding dim 1024, hidden size 64, num layers 1, train loss 0.23980310559272766, validation loss 1.0484830141067505\n",
      "Epoch 450, current patience 4, model mean validation loss 1.0947784185409546, embedding dim 1024, hidden size 64, num layers 1, train loss 0.2514873147010803, validation loss 1.2133411169052124\n",
      "Epoch 460, current patience 3, model mean validation loss 1.086807370185852, embedding dim 1024, hidden size 64, num layers 1, train loss 0.6798958778381348, validation loss 1.0413576364517212\n",
      "Epoch 470, current patience 2, model mean validation loss 1.0960294008255005, embedding dim 1024, hidden size 64, num layers 1, train loss 0.31791311502456665, validation loss 1.0542919635772705\n",
      "Epoch 480, current patience 1, model mean validation loss 1.1053136587142944, embedding dim 1024, hidden size 64, num layers 1, train loss 0.42278653383255005, validation loss 1.070040225982666\n",
      "Epoch 0, current patience 30, model mean validation loss 1.0941818952560425, embedding dim 1024, hidden size 128, num layers 1, train loss 1.1052815914154053, validation loss 1.0941818952560425\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0820560455322266, embedding dim 1024, hidden size 128, num layers 1, train loss 1.1117925643920898, validation loss 1.0699301958084106\n",
      "Epoch 20, current patience 30, model mean validation loss 1.067897915840149, embedding dim 1024, hidden size 128, num layers 1, train loss 1.0903024673461914, validation loss 1.0395818948745728\n",
      "Epoch 30, current patience 30, model mean validation loss 1.060286283493042, embedding dim 1024, hidden size 128, num layers 1, train loss 0.813887357711792, validation loss 1.0374512672424316\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0401307344436646, embedding dim 1024, hidden size 128, num layers 1, train loss 0.9440737962722778, validation loss 0.9595085382461548\n",
      "Epoch 50, current patience 30, model mean validation loss 1.0239076614379883, embedding dim 1024, hidden size 128, num layers 1, train loss 0.9082003831863403, validation loss 0.9427921772003174\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0103496313095093, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7559149265289307, validation loss 0.929002046585083\n",
      "Epoch 70, current patience 30, model mean validation loss 0.9998610019683838, embedding dim 1024, hidden size 128, num layers 1, train loss 0.9030796885490417, validation loss 0.9264398813247681\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9802767038345337, embedding dim 1024, hidden size 128, num layers 1, train loss 0.8398069739341736, validation loss 0.9375073909759521\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9555237293243408, embedding dim 1024, hidden size 128, num layers 1, train loss 0.9391320943832397, validation loss 0.8719065189361572\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9380457997322083, embedding dim 1024, hidden size 128, num layers 1, train loss 0.6579644083976746, validation loss 0.8997586965560913\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9197416305541992, embedding dim 1024, hidden size 128, num layers 1, train loss 1.1359153985977173, validation loss 0.8910177946090698\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9112288355827332, embedding dim 1024, hidden size 128, num layers 1, train loss 0.772097647190094, validation loss 0.8914061784744263\n",
      "Epoch 130, current patience 30, model mean validation loss 0.904633641242981, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7869362831115723, validation loss 0.8900309205055237\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9024746417999268, embedding dim 1024, hidden size 128, num layers 1, train loss 0.6706956624984741, validation loss 0.9117293953895569\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8974037170410156, embedding dim 1024, hidden size 128, num layers 1, train loss 0.8107302784919739, validation loss 0.8858726620674133\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9032537937164307, embedding dim 1024, hidden size 128, num layers 1, train loss 0.46000349521636963, validation loss 0.9843082427978516\n",
      "Epoch 170, current patience 29, model mean validation loss 0.903342068195343, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7356442809104919, validation loss 0.872612476348877\n",
      "Epoch 180, current patience 28, model mean validation loss 0.90538489818573, embedding dim 1024, hidden size 128, num layers 1, train loss 0.5093122720718384, validation loss 0.9161011576652527\n",
      "Epoch 190, current patience 27, model mean validation loss 0.9176808595657349, embedding dim 1024, hidden size 128, num layers 1, train loss 0.4398799538612366, validation loss 0.9893855452537537\n",
      "Epoch 200, current patience 26, model mean validation loss 0.9321873188018799, embedding dim 1024, hidden size 128, num layers 1, train loss 0.8152443766593933, validation loss 1.007458209991455\n",
      "Epoch 210, current patience 25, model mean validation loss 0.9415081739425659, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7411876916885376, validation loss 0.9645980000495911\n",
      "Epoch 220, current patience 24, model mean validation loss 0.9364463686943054, embedding dim 1024, hidden size 128, num layers 1, train loss 0.48399755358695984, validation loss 0.871234655380249\n",
      "Epoch 230, current patience 23, model mean validation loss 0.9360952377319336, embedding dim 1024, hidden size 128, num layers 1, train loss 0.4825665056705475, validation loss 0.8830634355545044\n",
      "Epoch 240, current patience 22, model mean validation loss 0.9342743158340454, embedding dim 1024, hidden size 128, num layers 1, train loss 0.5811806917190552, validation loss 0.9697414040565491\n",
      "Epoch 250, current patience 21, model mean validation loss 0.9547151923179626, embedding dim 1024, hidden size 128, num layers 1, train loss 0.3319801092147827, validation loss 1.0361392498016357\n",
      "Epoch 260, current patience 20, model mean validation loss 0.9546652436256409, embedding dim 1024, hidden size 128, num layers 1, train loss 0.877895712852478, validation loss 0.9157015085220337\n",
      "Epoch 270, current patience 19, model mean validation loss 0.9507541656494141, embedding dim 1024, hidden size 128, num layers 1, train loss 0.8441542387008667, validation loss 0.9580967426300049\n",
      "Epoch 280, current patience 18, model mean validation loss 0.9425277709960938, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7491983771324158, validation loss 0.9416471123695374\n",
      "Epoch 290, current patience 17, model mean validation loss 0.9434975981712341, embedding dim 1024, hidden size 128, num layers 1, train loss 0.32879623770713806, validation loss 0.9723565578460693\n",
      "Epoch 300, current patience 16, model mean validation loss 0.9620912075042725, embedding dim 1024, hidden size 128, num layers 1, train loss 0.7311934232711792, validation loss 1.0199838876724243\n",
      "Epoch 310, current patience 15, model mean validation loss 0.9776730537414551, embedding dim 1024, hidden size 128, num layers 1, train loss 0.23318710923194885, validation loss 1.0077179670333862\n",
      "Epoch 320, current patience 14, model mean validation loss 0.9772011041641235, embedding dim 1024, hidden size 128, num layers 1, train loss 0.1514006406068802, validation loss 0.9659654498100281\n",
      "Epoch 330, current patience 13, model mean validation loss 0.9681803584098816, embedding dim 1024, hidden size 128, num layers 1, train loss 0.38172221183776855, validation loss 0.9639736413955688\n",
      "Epoch 340, current patience 12, model mean validation loss 0.988569974899292, embedding dim 1024, hidden size 128, num layers 1, train loss 0.2724745273590088, validation loss 1.0788183212280273\n",
      "Epoch 350, current patience 11, model mean validation loss 1.0113741159439087, embedding dim 1024, hidden size 128, num layers 1, train loss 0.10249970853328705, validation loss 1.1405304670333862\n",
      "Epoch 360, current patience 10, model mean validation loss 1.0280414819717407, embedding dim 1024, hidden size 128, num layers 1, train loss 0.6400781869888306, validation loss 1.0749856233596802\n",
      "Epoch 370, current patience 9, model mean validation loss 1.0360020399093628, embedding dim 1024, hidden size 128, num layers 1, train loss 0.17245270311832428, validation loss 1.0360413789749146\n",
      "Epoch 380, current patience 8, model mean validation loss 1.043615460395813, embedding dim 1024, hidden size 128, num layers 1, train loss 0.8035337924957275, validation loss 1.0808905363082886\n",
      "Epoch 390, current patience 7, model mean validation loss 1.0455281734466553, embedding dim 1024, hidden size 128, num layers 1, train loss 0.2670586109161377, validation loss 1.0230193138122559\n",
      "Epoch 400, current patience 6, model mean validation loss 1.0554293394088745, embedding dim 1024, hidden size 128, num layers 1, train loss 0.31722450256347656, validation loss 1.0451750755310059\n",
      "Epoch 410, current patience 5, model mean validation loss 1.056196928024292, embedding dim 1024, hidden size 128, num layers 1, train loss 0.3433724641799927, validation loss 0.9701143503189087\n",
      "Epoch 420, current patience 4, model mean validation loss 1.051115870475769, embedding dim 1024, hidden size 128, num layers 1, train loss 0.39433377981185913, validation loss 1.0381702184677124\n",
      "Epoch 430, current patience 3, model mean validation loss 1.0376578569412231, embedding dim 1024, hidden size 128, num layers 1, train loss 0.07849618792533875, validation loss 1.0328667163848877\n",
      "Epoch 440, current patience 2, model mean validation loss 1.0224418640136719, embedding dim 1024, hidden size 128, num layers 1, train loss 0.4366731643676758, validation loss 0.9532575607299805\n",
      "Epoch 450, current patience 1, model mean validation loss 1.0186774730682373, embedding dim 1024, hidden size 128, num layers 1, train loss 0.3432424068450928, validation loss 1.0059261322021484\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1140949726104736, embedding dim 1024, hidden size 256, num layers 1, train loss 1.0989853143692017, validation loss 1.1140949726104736\n",
      "Epoch 10, current patience 30, model mean validation loss 1.0915751457214355, embedding dim 1024, hidden size 256, num layers 1, train loss 1.0383495092391968, validation loss 1.0690553188323975\n",
      "Epoch 20, current patience 30, model mean validation loss 1.0892510414123535, embedding dim 1024, hidden size 256, num layers 1, train loss 1.0782355070114136, validation loss 1.084602952003479\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0725466012954712, embedding dim 1024, hidden size 256, num layers 1, train loss 1.0915606021881104, validation loss 1.0224332809448242\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0657767057418823, embedding dim 1024, hidden size 256, num layers 1, train loss 1.081186294555664, validation loss 1.0386972427368164\n",
      "Epoch 50, current patience 30, model mean validation loss 1.058363914489746, embedding dim 1024, hidden size 256, num layers 1, train loss 0.9258108139038086, validation loss 1.0212997198104858\n",
      "Epoch 60, current patience 30, model mean validation loss 1.0456546545028687, embedding dim 1024, hidden size 256, num layers 1, train loss 0.81749427318573, validation loss 0.9693991541862488\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0315454006195068, embedding dim 1024, hidden size 256, num layers 1, train loss 0.872744083404541, validation loss 0.9327811002731323\n",
      "Epoch 80, current patience 30, model mean validation loss 1.0046639442443848, embedding dim 1024, hidden size 256, num layers 1, train loss 0.9986655116081238, validation loss 0.8990428447723389\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9870219826698303, embedding dim 1024, hidden size 256, num layers 1, train loss 0.6550061106681824, validation loss 0.9279193878173828\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9623591303825378, embedding dim 1024, hidden size 256, num layers 1, train loss 0.8002679347991943, validation loss 0.8873003721237183\n",
      "Epoch 110, current patience 30, model mean validation loss 0.9432199001312256, embedding dim 1024, hidden size 256, num layers 1, train loss 0.568816065788269, validation loss 0.8693193793296814\n",
      "Epoch 120, current patience 30, model mean validation loss 0.9303387403488159, embedding dim 1024, hidden size 256, num layers 1, train loss 0.466846764087677, validation loss 0.9356483817100525\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9163349270820618, embedding dim 1024, hidden size 256, num layers 1, train loss 1.033402919769287, validation loss 0.9092689156532288\n",
      "Epoch 140, current patience 30, model mean validation loss 0.903675377368927, embedding dim 1024, hidden size 256, num layers 1, train loss 0.47436219453811646, validation loss 0.8681225776672363\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8963609933853149, embedding dim 1024, hidden size 256, num layers 1, train loss 0.9174517393112183, validation loss 0.8742662668228149\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8869118690490723, embedding dim 1024, hidden size 256, num layers 1, train loss 0.4439619183540344, validation loss 0.8234494924545288\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8812284469604492, embedding dim 1024, hidden size 256, num layers 1, train loss 0.8134798407554626, validation loss 0.8824527263641357\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8782904148101807, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3990275263786316, validation loss 0.8637959361076355\n",
      "Epoch 190, current patience 30, model mean validation loss 0.8818495273590088, embedding dim 1024, hidden size 256, num layers 1, train loss 0.2776928246021271, validation loss 0.897792398929596\n",
      "Epoch 200, current patience 29, model mean validation loss 0.8734038472175598, embedding dim 1024, hidden size 256, num layers 1, train loss 0.36730241775512695, validation loss 0.8680821657180786\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8723679780960083, embedding dim 1024, hidden size 256, num layers 1, train loss 0.9504650235176086, validation loss 0.9009822607040405\n",
      "Epoch 220, current patience 30, model mean validation loss 0.8718067407608032, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3172985315322876, validation loss 0.8636325001716614\n",
      "Epoch 230, current patience 30, model mean validation loss 0.8728851675987244, embedding dim 1024, hidden size 256, num layers 1, train loss 0.4243372082710266, validation loss 0.8828940391540527\n",
      "Epoch 240, current patience 29, model mean validation loss 0.8762801289558411, embedding dim 1024, hidden size 256, num layers 1, train loss 0.6679534912109375, validation loss 0.8506090641021729\n",
      "Epoch 250, current patience 28, model mean validation loss 0.8674013614654541, embedding dim 1024, hidden size 256, num layers 1, train loss 0.4873840808868408, validation loss 0.8114223480224609\n",
      "Epoch 260, current patience 30, model mean validation loss 0.8729754090309143, embedding dim 1024, hidden size 256, num layers 1, train loss 0.6465221643447876, validation loss 0.9083882570266724\n",
      "Epoch 270, current patience 29, model mean validation loss 0.8772678971290588, embedding dim 1024, hidden size 256, num layers 1, train loss 0.6599807739257812, validation loss 0.9321326017379761\n",
      "Epoch 280, current patience 28, model mean validation loss 0.8894299268722534, embedding dim 1024, hidden size 256, num layers 1, train loss 0.17460045218467712, validation loss 0.9653783440589905\n",
      "Epoch 290, current patience 27, model mean validation loss 0.8876814842224121, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3839000463485718, validation loss 0.8869943022727966\n",
      "Epoch 300, current patience 26, model mean validation loss 0.8903483152389526, embedding dim 1024, hidden size 256, num layers 1, train loss 0.4992225170135498, validation loss 0.8849678635597229\n",
      "Epoch 310, current patience 25, model mean validation loss 0.8895848393440247, embedding dim 1024, hidden size 256, num layers 1, train loss 0.2893776595592499, validation loss 0.8767858743667603\n",
      "Epoch 320, current patience 24, model mean validation loss 0.8996908664703369, embedding dim 1024, hidden size 256, num layers 1, train loss 0.2302459180355072, validation loss 0.9314572811126709\n",
      "Epoch 330, current patience 23, model mean validation loss 0.9327371120452881, embedding dim 1024, hidden size 256, num layers 1, train loss 0.6072988510131836, validation loss 1.0757920742034912\n",
      "Epoch 340, current patience 22, model mean validation loss 0.9416978359222412, embedding dim 1024, hidden size 256, num layers 1, train loss 0.16881063580513, validation loss 0.9800740480422974\n",
      "Epoch 350, current patience 21, model mean validation loss 0.9404495358467102, embedding dim 1024, hidden size 256, num layers 1, train loss 0.12694644927978516, validation loss 0.9221466779708862\n",
      "Epoch 360, current patience 20, model mean validation loss 0.9442223906517029, embedding dim 1024, hidden size 256, num layers 1, train loss 0.24003273248672485, validation loss 0.995560884475708\n",
      "Epoch 370, current patience 19, model mean validation loss 0.9610092043876648, embedding dim 1024, hidden size 256, num layers 1, train loss 0.4225248694419861, validation loss 1.021288514137268\n",
      "Epoch 380, current patience 18, model mean validation loss 0.9771369695663452, embedding dim 1024, hidden size 256, num layers 1, train loss 0.09318654239177704, validation loss 1.0139904022216797\n",
      "Epoch 390, current patience 17, model mean validation loss 0.9903289079666138, embedding dim 1024, hidden size 256, num layers 1, train loss 0.29878658056259155, validation loss 0.9823210835456848\n",
      "Epoch 400, current patience 16, model mean validation loss 1.0126957893371582, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3403705954551697, validation loss 1.1103920936584473\n",
      "Epoch 410, current patience 15, model mean validation loss 1.0091105699539185, embedding dim 1024, hidden size 256, num layers 1, train loss 0.17542266845703125, validation loss 1.0471110343933105\n",
      "Epoch 420, current patience 14, model mean validation loss 1.0164480209350586, embedding dim 1024, hidden size 256, num layers 1, train loss 0.09379319101572037, validation loss 1.0387741327285767\n",
      "Epoch 430, current patience 13, model mean validation loss 1.0227036476135254, embedding dim 1024, hidden size 256, num layers 1, train loss 0.18348896503448486, validation loss 0.972190797328949\n",
      "Epoch 440, current patience 12, model mean validation loss 1.0305345058441162, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3182739019393921, validation loss 1.0582078695297241\n",
      "Epoch 450, current patience 11, model mean validation loss 1.0261178016662598, embedding dim 1024, hidden size 256, num layers 1, train loss 0.16716495156288147, validation loss 0.9859545826911926\n",
      "Epoch 460, current patience 10, model mean validation loss 1.0352544784545898, embedding dim 1024, hidden size 256, num layers 1, train loss 0.276265949010849, validation loss 1.0870842933654785\n",
      "Epoch 470, current patience 9, model mean validation loss 1.039208173751831, embedding dim 1024, hidden size 256, num layers 1, train loss 0.07239793986082077, validation loss 1.0139509439468384\n",
      "Epoch 480, current patience 8, model mean validation loss 1.028652548789978, embedding dim 1024, hidden size 256, num layers 1, train loss 0.28072524070739746, validation loss 1.0259467363357544\n",
      "Epoch 490, current patience 7, model mean validation loss 1.0317261219024658, embedding dim 1024, hidden size 256, num layers 1, train loss 0.2775912284851074, validation loss 1.071699619293213\n",
      "Epoch 500, current patience 6, model mean validation loss 1.038962960243225, embedding dim 1024, hidden size 256, num layers 1, train loss 0.361011803150177, validation loss 1.0966688394546509\n",
      "Epoch 510, current patience 5, model mean validation loss 1.0579771995544434, embedding dim 1024, hidden size 256, num layers 1, train loss 0.04231271147727966, validation loss 1.1243047714233398\n",
      "Epoch 520, current patience 4, model mean validation loss 1.0832587480545044, embedding dim 1024, hidden size 256, num layers 1, train loss 0.22099852561950684, validation loss 1.260460376739502\n",
      "Epoch 530, current patience 3, model mean validation loss 1.1174629926681519, embedding dim 1024, hidden size 256, num layers 1, train loss 0.06498286128044128, validation loss 1.2595889568328857\n",
      "Epoch 540, current patience 2, model mean validation loss 1.1309226751327515, embedding dim 1024, hidden size 256, num layers 1, train loss 0.18120363354682922, validation loss 1.1947617530822754\n",
      "Epoch 550, current patience 1, model mean validation loss 1.1565306186676025, embedding dim 1024, hidden size 256, num layers 1, train loss 0.3176463842391968, validation loss 1.2188135385513306\n",
      "Epoch 0, current patience 30, model mean validation loss 1.110011339187622, embedding dim 1024, hidden size 512, num layers 1, train loss 1.104504108428955, validation loss 1.110011339187622\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1036769151687622, embedding dim 1024, hidden size 512, num layers 1, train loss 1.0833282470703125, validation loss 1.0973424911499023\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1003777980804443, embedding dim 1024, hidden size 512, num layers 1, train loss 1.091858148574829, validation loss 1.0937795639038086\n",
      "Epoch 30, current patience 30, model mean validation loss 1.0866812467575073, embedding dim 1024, hidden size 512, num layers 1, train loss 1.102057933807373, validation loss 1.0455915927886963\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0692832469940186, embedding dim 1024, hidden size 512, num layers 1, train loss 0.9752748012542725, validation loss 0.9996917247772217\n",
      "Epoch 50, current patience 30, model mean validation loss 1.051660418510437, embedding dim 1024, hidden size 512, num layers 1, train loss 0.8164048790931702, validation loss 0.9635454416275024\n",
      "Epoch 60, current patience 30, model mean validation loss 1.026685357093811, embedding dim 1024, hidden size 512, num layers 1, train loss 0.9779095649719238, validation loss 0.8768354654312134\n",
      "Epoch 70, current patience 30, model mean validation loss 1.0038566589355469, embedding dim 1024, hidden size 512, num layers 1, train loss 0.8446186780929565, validation loss 0.8440557718276978\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9690348505973816, embedding dim 1024, hidden size 512, num layers 1, train loss 0.9255689978599548, validation loss 0.8314369916915894\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9410490989685059, embedding dim 1024, hidden size 512, num layers 1, train loss 0.7484748363494873, validation loss 0.8734564185142517\n",
      "Epoch 100, current patience 30, model mean validation loss 0.9125936627388, embedding dim 1024, hidden size 512, num layers 1, train loss 0.29079824686050415, validation loss 0.866135835647583\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8823914527893066, embedding dim 1024, hidden size 512, num layers 1, train loss 0.5892064571380615, validation loss 0.8039742708206177\n",
      "Epoch 120, current patience 30, model mean validation loss 0.8583426475524902, embedding dim 1024, hidden size 512, num layers 1, train loss 0.5763505697250366, validation loss 0.8073009252548218\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8392359018325806, embedding dim 1024, hidden size 512, num layers 1, train loss 0.5313364863395691, validation loss 0.8106915950775146\n",
      "Epoch 140, current patience 30, model mean validation loss 0.8323347568511963, embedding dim 1024, hidden size 512, num layers 1, train loss 0.38717952370643616, validation loss 0.8216263055801392\n",
      "Epoch 150, current patience 30, model mean validation loss 0.8254415988922119, embedding dim 1024, hidden size 512, num layers 1, train loss 0.4352551996707916, validation loss 0.7889102697372437\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8251331448554993, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3612578511238098, validation loss 0.8289694786071777\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8225459456443787, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3964883089065552, validation loss 0.8527587652206421\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8122340440750122, embedding dim 1024, hidden size 512, num layers 1, train loss 0.2890491783618927, validation loss 0.7836405038833618\n",
      "Epoch 190, current patience 30, model mean validation loss 0.816027820110321, embedding dim 1024, hidden size 512, num layers 1, train loss 0.43967893719673157, validation loss 0.834324836730957\n",
      "Epoch 200, current patience 29, model mean validation loss 0.8099166750907898, embedding dim 1024, hidden size 512, num layers 1, train loss 0.1688419133424759, validation loss 0.7584115266799927\n",
      "Epoch 210, current patience 30, model mean validation loss 0.8124136924743652, embedding dim 1024, hidden size 512, num layers 1, train loss 0.580066978931427, validation loss 0.8306683301925659\n",
      "Epoch 220, current patience 29, model mean validation loss 0.8184649348258972, embedding dim 1024, hidden size 512, num layers 1, train loss 0.2308497577905655, validation loss 0.8700360655784607\n",
      "Epoch 230, current patience 28, model mean validation loss 0.8264808058738708, embedding dim 1024, hidden size 512, num layers 1, train loss 0.4214513301849365, validation loss 0.8530369400978088\n",
      "Epoch 240, current patience 27, model mean validation loss 0.8270295858383179, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3276670575141907, validation loss 0.8333596587181091\n",
      "Epoch 250, current patience 26, model mean validation loss 0.8259530663490295, embedding dim 1024, hidden size 512, num layers 1, train loss 0.7707655429840088, validation loss 0.8441467881202698\n",
      "Epoch 260, current patience 25, model mean validation loss 0.8403702974319458, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3102515935897827, validation loss 0.8989785313606262\n",
      "Epoch 270, current patience 24, model mean validation loss 0.850545346736908, embedding dim 1024, hidden size 512, num layers 1, train loss 0.04493911191821098, validation loss 0.9157251715660095\n",
      "Epoch 280, current patience 23, model mean validation loss 0.8651617765426636, embedding dim 1024, hidden size 512, num layers 1, train loss 0.14418599009513855, validation loss 0.8753423690795898\n",
      "Epoch 290, current patience 22, model mean validation loss 0.8642371296882629, embedding dim 1024, hidden size 512, num layers 1, train loss 0.2723558843135834, validation loss 0.8232710957527161\n",
      "Epoch 300, current patience 21, model mean validation loss 0.8684741258621216, embedding dim 1024, hidden size 512, num layers 1, train loss 0.31076478958129883, validation loss 0.9039322137832642\n",
      "Epoch 310, current patience 20, model mean validation loss 0.8700805902481079, embedding dim 1024, hidden size 512, num layers 1, train loss 0.4358596205711365, validation loss 0.8658887147903442\n",
      "Epoch 320, current patience 19, model mean validation loss 0.8855368494987488, embedding dim 1024, hidden size 512, num layers 1, train loss 0.8242857456207275, validation loss 0.9570099115371704\n",
      "Epoch 330, current patience 18, model mean validation loss 0.8946820497512817, embedding dim 1024, hidden size 512, num layers 1, train loss 0.13840627670288086, validation loss 0.9173088073730469\n",
      "Epoch 340, current patience 17, model mean validation loss 0.9053189754486084, embedding dim 1024, hidden size 512, num layers 1, train loss 0.1032366082072258, validation loss 0.9840739965438843\n",
      "Epoch 350, current patience 16, model mean validation loss 0.9178159832954407, embedding dim 1024, hidden size 512, num layers 1, train loss 0.4165310859680176, validation loss 1.0157006978988647\n",
      "Epoch 360, current patience 15, model mean validation loss 0.9238580465316772, embedding dim 1024, hidden size 512, num layers 1, train loss 0.6907056570053101, validation loss 0.9236789345741272\n",
      "Epoch 370, current patience 14, model mean validation loss 0.9379509687423706, embedding dim 1024, hidden size 512, num layers 1, train loss 0.1427018642425537, validation loss 0.9360142350196838\n",
      "Epoch 380, current patience 13, model mean validation loss 0.9488124847412109, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3914274275302887, validation loss 0.9908244013786316\n",
      "Epoch 390, current patience 12, model mean validation loss 0.9619896411895752, embedding dim 1024, hidden size 512, num layers 1, train loss 0.07052667438983917, validation loss 0.971306324005127\n",
      "Epoch 400, current patience 11, model mean validation loss 0.9544411301612854, embedding dim 1024, hidden size 512, num layers 1, train loss 0.32038408517837524, validation loss 0.8966217041015625\n",
      "Epoch 410, current patience 10, model mean validation loss 0.9510347843170166, embedding dim 1024, hidden size 512, num layers 1, train loss 0.15794095396995544, validation loss 0.8900578022003174\n",
      "Epoch 420, current patience 9, model mean validation loss 0.9428956508636475, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3619067668914795, validation loss 0.9189605712890625\n",
      "Epoch 430, current patience 8, model mean validation loss 0.9430598616600037, embedding dim 1024, hidden size 512, num layers 1, train loss 0.2225552350282669, validation loss 1.017014980316162\n",
      "Epoch 440, current patience 7, model mean validation loss 0.9502654075622559, embedding dim 1024, hidden size 512, num layers 1, train loss 0.36343148350715637, validation loss 0.9813234210014343\n",
      "Epoch 450, current patience 6, model mean validation loss 0.9592131972312927, embedding dim 1024, hidden size 512, num layers 1, train loss 0.7472884654998779, validation loss 1.0075963735580444\n",
      "Epoch 460, current patience 5, model mean validation loss 0.9627172946929932, embedding dim 1024, hidden size 512, num layers 1, train loss 0.3764423429965973, validation loss 1.0188570022583008\n",
      "Epoch 470, current patience 4, model mean validation loss 0.9837055206298828, embedding dim 1024, hidden size 512, num layers 1, train loss 0.47888731956481934, validation loss 1.1392121315002441\n",
      "Epoch 480, current patience 3, model mean validation loss 1.0078668594360352, embedding dim 1024, hidden size 512, num layers 1, train loss 0.43968766927719116, validation loss 1.089913249015808\n",
      "Epoch 490, current patience 2, model mean validation loss 1.0256867408752441, embedding dim 1024, hidden size 512, num layers 1, train loss 0.04268272966146469, validation loss 1.0326166152954102\n",
      "Epoch 500, current patience 1, model mean validation loss 1.042539119720459, embedding dim 1024, hidden size 512, num layers 1, train loss 0.11968216300010681, validation loss 1.0537790060043335\n",
      "Epoch 0, current patience 30, model mean validation loss 1.1955792903900146, embedding dim 1024, hidden size 1024, num layers 1, train loss 1.097858190536499, validation loss 1.1955792903900146\n",
      "Epoch 10, current patience 30, model mean validation loss 1.1762990951538086, embedding dim 1024, hidden size 1024, num layers 1, train loss 1.0945398807525635, validation loss 1.1570188999176025\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1376910209655762, embedding dim 1024, hidden size 1024, num layers 1, train loss 1.0759797096252441, validation loss 1.0604749917984009\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1133884191513062, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.8398382663726807, validation loss 1.0404804944992065\n",
      "Epoch 40, current patience 30, model mean validation loss 1.0699712038040161, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.8394511342048645, validation loss 0.8963021039962769\n",
      "Epoch 50, current patience 30, model mean validation loss 1.039164423942566, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.9470157027244568, validation loss 0.8851310610771179\n",
      "Epoch 60, current patience 30, model mean validation loss 1.012715458869934, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.5822286605834961, validation loss 0.8540209531784058\n",
      "Epoch 70, current patience 30, model mean validation loss 0.9990737438201904, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.7948342561721802, validation loss 0.9035822153091431\n",
      "Epoch 80, current patience 30, model mean validation loss 0.9557717442512512, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.6340058445930481, validation loss 0.849163293838501\n",
      "Epoch 90, current patience 30, model mean validation loss 0.9187309145927429, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.5779072642326355, validation loss 0.8606924414634705\n",
      "Epoch 100, current patience 30, model mean validation loss 0.8918436765670776, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.8741004467010498, validation loss 0.8453773260116577\n",
      "Epoch 110, current patience 30, model mean validation loss 0.8663384318351746, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.9394782185554504, validation loss 0.8364379405975342\n",
      "Epoch 120, current patience 30, model mean validation loss 0.853384256362915, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.356581449508667, validation loss 0.7926688194274902\n",
      "Epoch 130, current patience 30, model mean validation loss 0.8583385944366455, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.4396378993988037, validation loss 0.924765944480896\n",
      "Epoch 140, current patience 29, model mean validation loss 0.8541715145111084, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.6459677219390869, validation loss 0.8206840753555298\n",
      "Epoch 150, current patience 28, model mean validation loss 0.8497570753097534, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.5184855461120605, validation loss 0.8682668209075928\n",
      "Epoch 160, current patience 30, model mean validation loss 0.8482999205589294, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.5444172620773315, validation loss 0.8375061750411987\n",
      "Epoch 170, current patience 30, model mean validation loss 0.8453192114830017, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.3636508584022522, validation loss 0.8368465900421143\n",
      "Epoch 180, current patience 30, model mean validation loss 0.8499268293380737, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.4201135039329529, validation loss 0.8822382688522339\n",
      "Epoch 190, current patience 29, model mean validation loss 0.8514115214347839, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.14860567450523376, validation loss 0.8483155369758606\n",
      "Epoch 200, current patience 28, model mean validation loss 0.8578165769577026, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.49207180738449097, validation loss 0.8439092636108398\n",
      "Epoch 210, current patience 27, model mean validation loss 0.8511414527893066, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.34830617904663086, validation loss 0.8713645935058594\n",
      "Epoch 220, current patience 26, model mean validation loss 0.8627687692642212, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.4181070923805237, validation loss 0.9137029647827148\n",
      "Epoch 230, current patience 25, model mean validation loss 0.8631850481033325, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.31235271692276, validation loss 0.871597170829773\n",
      "Epoch 240, current patience 24, model mean validation loss 0.8662216663360596, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.8402576446533203, validation loss 0.8617992997169495\n",
      "Epoch 250, current patience 23, model mean validation loss 0.8733845353126526, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.42368295788764954, validation loss 0.8941494226455688\n",
      "Epoch 260, current patience 22, model mean validation loss 0.8751953840255737, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.4947352409362793, validation loss 0.8967247605323792\n",
      "Epoch 270, current patience 21, model mean validation loss 0.880398154258728, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.2602474093437195, validation loss 0.8899381756782532\n",
      "Epoch 280, current patience 20, model mean validation loss 0.8930907249450684, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.23277941346168518, validation loss 0.945449948310852\n",
      "Epoch 290, current patience 19, model mean validation loss 0.9186532497406006, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.766599714756012, validation loss 1.0758639574050903\n",
      "Epoch 300, current patience 18, model mean validation loss 0.9190400838851929, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.5724748373031616, validation loss 0.916797399520874\n",
      "Epoch 310, current patience 17, model mean validation loss 0.9245144128799438, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.6855082511901855, validation loss 0.9153919219970703\n",
      "Epoch 320, current patience 16, model mean validation loss 0.9344923496246338, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.04850932955741882, validation loss 0.9416237473487854\n",
      "Epoch 330, current patience 15, model mean validation loss 0.9404523372650146, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.10545127093791962, validation loss 0.9418283700942993\n",
      "Epoch 340, current patience 14, model mean validation loss 0.9489554166793823, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.1721877008676529, validation loss 0.9647493958473206\n",
      "Epoch 350, current patience 13, model mean validation loss 0.9634772539138794, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.10371698439121246, validation loss 1.0061131715774536\n",
      "Epoch 360, current patience 12, model mean validation loss 0.9672152996063232, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.19954687356948853, validation loss 0.9753547310829163\n",
      "Epoch 370, current patience 11, model mean validation loss 0.9463242292404175, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.07955905050039291, validation loss 0.908734917640686\n",
      "Epoch 380, current patience 10, model mean validation loss 0.9621635675430298, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.20219120383262634, validation loss 1.043512225151062\n",
      "Epoch 390, current patience 9, model mean validation loss 0.965207576751709, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.29058361053466797, validation loss 0.93974369764328\n",
      "Epoch 400, current patience 8, model mean validation loss 0.9751888513565063, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.10350676625967026, validation loss 1.0214743614196777\n",
      "Epoch 410, current patience 7, model mean validation loss 0.9903697967529297, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.4191395044326782, validation loss 1.0632758140563965\n",
      "Epoch 420, current patience 6, model mean validation loss 1.0078742504119873, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.017979638651013374, validation loss 1.1047852039337158\n",
      "Epoch 430, current patience 5, model mean validation loss 1.0106438398361206, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.031680405139923096, validation loss 1.02826988697052\n",
      "Epoch 440, current patience 4, model mean validation loss 1.0145756006240845, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.31172800064086914, validation loss 1.0068085193634033\n",
      "Epoch 450, current patience 3, model mean validation loss 1.0357091426849365, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.29514026641845703, validation loss 1.0778025388717651\n",
      "Epoch 460, current patience 2, model mean validation loss 1.0365110635757446, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.13418573141098022, validation loss 1.0499286651611328\n",
      "Epoch 470, current patience 1, model mean validation loss 1.0554137229919434, embedding dim 1024, hidden size 1024, num layers 1, train loss 0.8376559615135193, validation loss 1.0909652709960938\n",
      "Epoch 0, current patience 30, model mean validation loss 1.2188589572906494, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.0992705821990967, validation loss 1.2188589572906494\n",
      "Epoch 10, current patience 30, model mean validation loss 1.2270773649215698, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.1824564933776855, validation loss 1.2352957725524902\n",
      "Epoch 20, current patience 29, model mean validation loss 1.266562819480896, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.3086516857147217, validation loss 1.345533847808838\n",
      "Epoch 30, current patience 28, model mean validation loss 1.301321268081665, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.5270264148712158, validation loss 1.4055962562561035\n",
      "Epoch 40, current patience 27, model mean validation loss 1.2638055086135864, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.8920270204544067, validation loss 1.1137423515319824\n",
      "Epoch 50, current patience 26, model mean validation loss 1.2404299974441528, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.9912393093109131, validation loss 1.1235531568527222\n",
      "Epoch 60, current patience 25, model mean validation loss 1.2120802402496338, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.1916693449020386, validation loss 1.0419812202453613\n",
      "Epoch 70, current patience 30, model mean validation loss 1.1997615098953247, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.0503289699554443, validation loss 1.1135305166244507\n",
      "Epoch 80, current patience 30, model mean validation loss 1.1729984283447266, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.1070505380630493, validation loss 1.004754662513733\n",
      "Epoch 90, current patience 30, model mean validation loss 1.1407337188720703, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7264477014541626, validation loss 0.9771771430969238\n",
      "Epoch 100, current patience 30, model mean validation loss 1.0901131629943848, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.8615303039550781, validation loss 0.9405698180198669\n",
      "Epoch 110, current patience 30, model mean validation loss 1.0296381711959839, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.1086609363555908, validation loss 0.9217962026596069\n",
      "Epoch 120, current patience 30, model mean validation loss 1.0085521936416626, embedding dim 1024, hidden size 2048, num layers 1, train loss 1.1589264869689941, validation loss 0.9450541734695435\n",
      "Epoch 130, current patience 30, model mean validation loss 0.9888057112693787, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.9741605520248413, validation loss 0.965582013130188\n",
      "Epoch 140, current patience 30, model mean validation loss 0.9743798971176147, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.6633148193359375, validation loss 0.9265750050544739\n",
      "Epoch 150, current patience 30, model mean validation loss 0.9487786293029785, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.17202511429786682, validation loss 0.9087199568748474\n",
      "Epoch 160, current patience 30, model mean validation loss 0.9307326674461365, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.5151899456977844, validation loss 0.8603870868682861\n",
      "Epoch 170, current patience 30, model mean validation loss 0.9212276935577393, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7461574077606201, validation loss 0.9011369943618774\n",
      "Epoch 180, current patience 30, model mean validation loss 0.9327520132064819, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.6228442788124084, validation loss 1.03276526927948\n",
      "Epoch 190, current patience 29, model mean validation loss 0.9385408163070679, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.654833197593689, validation loss 0.9681060314178467\n",
      "Epoch 200, current patience 28, model mean validation loss 0.9347862601280212, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.9857787489891052, validation loss 0.9150174260139465\n",
      "Epoch 210, current patience 27, model mean validation loss 0.9312868714332581, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7805392146110535, validation loss 0.9375872611999512\n",
      "Epoch 220, current patience 26, model mean validation loss 0.9330492615699768, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.32609084248542786, validation loss 0.9406739473342896\n",
      "Epoch 230, current patience 25, model mean validation loss 0.93312007188797, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.8194189667701721, validation loss 0.9092868566513062\n",
      "Epoch 240, current patience 24, model mean validation loss 0.9461432099342346, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7819163799285889, validation loss 0.9645720720291138\n",
      "Epoch 250, current patience 23, model mean validation loss 0.9486202597618103, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.1674407422542572, validation loss 0.9209531545639038\n",
      "Epoch 260, current patience 22, model mean validation loss 0.9303522706031799, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.5533804893493652, validation loss 0.8866214752197266\n",
      "Epoch 270, current patience 21, model mean validation loss 0.9306737184524536, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.32190459966659546, validation loss 0.970677375793457\n",
      "Epoch 280, current patience 20, model mean validation loss 0.9371668100357056, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.5855448246002197, validation loss 0.966962456703186\n",
      "Epoch 290, current patience 19, model mean validation loss 0.9376710653305054, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.5988904237747192, validation loss 0.9416214227676392\n",
      "Epoch 300, current patience 18, model mean validation loss 0.948704719543457, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.09854619204998016, validation loss 1.0289428234100342\n",
      "Epoch 310, current patience 17, model mean validation loss 0.9726923704147339, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7759997844696045, validation loss 1.1011879444122314\n",
      "Epoch 320, current patience 16, model mean validation loss 0.9713841080665588, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.23909161984920502, validation loss 0.9541061520576477\n",
      "Epoch 330, current patience 15, model mean validation loss 0.9934090375900269, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7583824396133423, validation loss 1.0971524715423584\n",
      "Epoch 340, current patience 14, model mean validation loss 1.0110090970993042, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.43620210886001587, validation loss 1.0274221897125244\n",
      "Epoch 350, current patience 13, model mean validation loss 1.0035309791564941, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.3861435651779175, validation loss 0.910852313041687\n",
      "Epoch 360, current patience 12, model mean validation loss 1.001596450805664, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.4250430166721344, validation loss 0.9514865279197693\n",
      "Epoch 370, current patience 11, model mean validation loss 1.0181496143341064, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.30822598934173584, validation loss 1.0740458965301514\n",
      "Epoch 380, current patience 10, model mean validation loss 1.0093680620193481, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.6268138885498047, validation loss 0.9586913585662842\n",
      "Epoch 390, current patience 9, model mean validation loss 1.0123748779296875, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.555981457233429, validation loss 1.125242829322815\n",
      "Epoch 400, current patience 8, model mean validation loss 1.0160284042358398, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.39649587869644165, validation loss 0.983333170413971\n",
      "Epoch 410, current patience 7, model mean validation loss 0.9949319362640381, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.7900800108909607, validation loss 0.928381085395813\n",
      "Epoch 420, current patience 6, model mean validation loss 1.0092549324035645, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.1663508117198944, validation loss 1.1420060396194458\n",
      "Epoch 430, current patience 5, model mean validation loss 1.0264416933059692, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.13115762174129486, validation loss 1.0483462810516357\n",
      "Epoch 440, current patience 4, model mean validation loss 1.040124535560608, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.2287343293428421, validation loss 1.0609490871429443\n",
      "Epoch 450, current patience 3, model mean validation loss 1.028096079826355, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.5255080461502075, validation loss 0.9778182506561279\n",
      "Epoch 460, current patience 2, model mean validation loss 1.029249906539917, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.3872992992401123, validation loss 0.9679219126701355\n",
      "Epoch 470, current patience 1, model mean validation loss 1.0300710201263428, embedding dim 1024, hidden size 2048, num layers 1, train loss 0.1431923359632492, validation loss 1.1318120956420898\n",
      "Epoch 0, current patience 30, model mean validation loss 1.172520637512207, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0901157855987549, validation loss 1.172520637512207\n",
      "Epoch 10, current patience 30, model mean validation loss 1.150403380393982, embedding dim 2048, hidden size 1, num layers 1, train loss 1.1752216815948486, validation loss 1.1282861232757568\n",
      "Epoch 20, current patience 30, model mean validation loss 1.1349552869796753, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0766240358352661, validation loss 1.1040592193603516\n",
      "Epoch 30, current patience 30, model mean validation loss 1.1268978118896484, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0897550582885742, validation loss 1.1027251482009888\n",
      "Epoch 40, current patience 30, model mean validation loss 1.1208078861236572, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0721770524978638, validation loss 1.0964479446411133\n",
      "Epoch 50, current patience 30, model mean validation loss 1.1169499158859253, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0942959785461426, validation loss 1.0976604223251343\n",
      "Epoch 60, current patience 30, model mean validation loss 1.1139241456985474, embedding dim 2048, hidden size 1, num layers 1, train loss 1.0929591655731201, validation loss 1.0957694053649902\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 9.68 GB, other allocations: 36.07 GB, max allowed: 45.90 GB). Tried to allocate 286.20 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[131]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     27\u001B[39m loss = loss_fn(prediction, y_batch.to(device))\n\u001B[32m     29\u001B[39m loss.backward()\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m model.zero_grad()\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m epoch % \u001B[32m10\u001B[39m == \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m epoch == number_of_epoches - \u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001B[39m, in \u001B[36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    488\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    489\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    490\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    491\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m493\u001B[39m out = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[38;5;28mself\u001B[39m._optimizer_step_code()\n\u001B[32m    496\u001B[39m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001B[39m, in \u001B[36m_use_grad_for_differentiable.<locals>._use_grad\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     89\u001B[39m     torch.set_grad_enabled(\u001B[38;5;28mself\u001B[39m.defaults[\u001B[33m\"\u001B[39m\u001B[33mdifferentiable\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     90\u001B[39m     torch._dynamo.graph_break()\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     93\u001B[39m     torch._dynamo.graph_break()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/adam.py:224\u001B[39m, in \u001B[36mAdam.step\u001B[39m\u001B[34m(self, closure)\u001B[39m\n\u001B[32m    212\u001B[39m     beta1, beta2 = group[\u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    214\u001B[39m     has_complex = \u001B[38;5;28mself\u001B[39m._init_group(\n\u001B[32m    215\u001B[39m         group,\n\u001B[32m    216\u001B[39m         params_with_grad,\n\u001B[32m   (...)\u001B[39m\u001B[32m    221\u001B[39m         state_steps,\n\u001B[32m    222\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m224\u001B[39m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    225\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    226\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    227\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    228\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    229\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    231\u001B[39m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mamsgrad\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    232\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    233\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    235\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    236\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweight_decay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meps\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmaximize\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mforeach\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    240\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcapturable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    241\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdifferentiable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfused\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    243\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgrad_scale\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfound_inf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    247\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001B[39m, in \u001B[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    152\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(*args, **kwargs)\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/adam.py:784\u001B[39m, in \u001B[36madam\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[39m\n\u001B[32m    781\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    782\u001B[39m     func = _single_tensor_adam\n\u001B[32m--> \u001B[39m\u001B[32m784\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    785\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    786\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    787\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    788\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    790\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    791\u001B[39m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    792\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    793\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    794\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    795\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    796\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    797\u001B[39m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    799\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    800\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    801\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    803\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/torch/optim/adam.py:430\u001B[39m, in \u001B[36m_single_tensor_adam\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[39m\n\u001B[32m    428\u001B[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001B[32m    429\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m430\u001B[39m         denom = (\u001B[43mexp_avg_sq\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m / bias_correction2_sqrt).add_(eps)\n\u001B[32m    432\u001B[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001B[32m    434\u001B[39m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: MPS backend out of memory (MPS allocated: 9.68 GB, other allocations: 36.07 GB, max allowed: 45.90 GB). Tried to allocate 286.20 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T09:19:56.232273Z",
     "start_time": "2025-07-06T09:19:56.180073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_model_name(model_name):\n",
    "    match = re.match(r'model_[^_]+_(\\d+)_(\\d+)_(\\d+)_\\d+\\.pt', model_name)\n",
    "    if not match:\n",
    "        raise ValueError('Incorrect model name format')\n",
    "    return int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "\n",
    "\n",
    "model_name = 'model_0.7129881978034973_32_32_1_530.pt'\n",
    "embedding_dim, hidden_size, num_layers = parse_model_name(model_name)\n",
    "model = Model(len(vocabulary), embedding_dim, hidden_size, num_layers).to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(os.getcwd(), \"models\", model_name), map_location=torch.device(device)))"
   ],
   "id": "993f5e36681145a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T09:20:32.878928Z",
     "start_time": "2025-07-06T09:20:08.402987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measuring the model performance\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for index in range(len(test_dataset)):\n",
    "    h0 = torch.zeros(num_layers, 1, hidden_size)\n",
    "    message = test_dataset['text'][index]\n",
    "    label = test_dataset['label'][index]\n",
    "    encoded_message = encode_x(token_to_index, test_tokenized_messages[index])\n",
    "    encoded_label = encode_y(label)\n",
    "    x_batch, y_batch = create_batch([encoded_message], [encoded_label], 1, len(vocabulary))\n",
    "    prediction, _ = model(x_batch.to(device), h0.to(device))\n",
    "    # https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#creating-the-network\n",
    "    _, top_i = torch.topk(prediction, k=1)\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "    if labels[label] == labels[top_i[0].item()]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    if index % 100 == 0:\n",
    "        print(f'Finished test {index}, accuracy is {correct / total}')\n",
    "\n",
    "print(correct, total)\n",
    "model.train()"
   ],
   "id": "8b99638d25231845",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished test 0, accuracy is 0.0\n",
      "Finished test 100, accuracy is 0.5148514851485149\n",
      "Finished test 200, accuracy is 0.6019900497512438\n",
      "Finished test 300, accuracy is 0.6312292358803987\n",
      "Finished test 400, accuracy is 0.6733167082294265\n",
      "Finished test 500, accuracy is 0.6866267465069861\n",
      "Finished test 600, accuracy is 0.7038269550748752\n",
      "Finished test 700, accuracy is 0.703281027104137\n",
      "Finished test 800, accuracy is 0.6991260923845194\n",
      "Finished test 900, accuracy is 0.6970033296337403\n",
      "Finished test 1000, accuracy is 0.6873126873126874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[151]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(test_dataset)):\n\u001B[32m      6\u001B[39m     h0 = torch.zeros(num_layers, \u001B[32m1\u001B[39m, hidden_size)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     message = \u001B[43mtest_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtext\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m[index]\n\u001B[32m      8\u001B[39m     label = test_dataset[\u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m][index]\n\u001B[32m      9\u001B[39m     encoded_message = encode_x(token_to_index, test_tokenized_messages[index])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/arrow_dataset.py:2777\u001B[39m, in \u001B[36mDataset.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   2775\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[32m   2776\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2777\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/arrow_dataset.py:2761\u001B[39m, in \u001B[36mDataset._getitem\u001B[39m\u001B[34m(self, key, **kwargs)\u001B[39m\n\u001B[32m   2759\u001B[39m format_kwargs = format_kwargs \u001B[38;5;28;01mif\u001B[39;00m format_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m   2760\u001B[39m formatter = get_formatter(format_type, features=\u001B[38;5;28mself\u001B[39m._info.features, **format_kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m2761\u001B[39m pa_subtable = \u001B[43mquery_table\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2762\u001B[39m formatted_output = format_table(\n\u001B[32m   2763\u001B[39m     pa_subtable, key, formatter=formatter, format_columns=format_columns, output_all_columns=output_all_columns\n\u001B[32m   2764\u001B[39m )\n\u001B[32m   2765\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/formatting/formatting.py:612\u001B[39m, in \u001B[36mquery_table\u001B[39m\u001B[34m(table, key, indices)\u001B[39m\n\u001B[32m    610\u001B[39m     pa_subtable = _query_table(table, key)\n\u001B[32m    611\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m612\u001B[39m     pa_subtable = \u001B[43m_query_table_with_indices_mapping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    613\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m pa_subtable\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/formatting/formatting.py:72\u001B[39m, in \u001B[36m_query_table_with_indices_mapping\u001B[39m\u001B[34m(table, key, indices)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m     71\u001B[39m     table = table.select([key])\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_query_table\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_pylist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Iterable):\n\u001B[32m     74\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _query_table(table, [indices.fast_slice(i, \u001B[32m1\u001B[39m).column(\u001B[32m0\u001B[39m)[\u001B[32m0\u001B[39m].as_py() \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m key])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/formatting/formatting.py:99\u001B[39m, in \u001B[36m_query_table\u001B[39m\u001B[34m(table, key)\u001B[39m\n\u001B[32m     97\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m table.table.slice(\u001B[32m0\u001B[39m, \u001B[32m0\u001B[39m)\n\u001B[32m     98\u001B[39m     \u001B[38;5;66;03m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfast_gather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m \u001B[49m\u001B[43m%\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    101\u001B[39m _raise_bad_key_type(key)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniconda/base/envs/sentiment-analysis/lib/python3.12/site-packages/datasets/table.py:124\u001B[39m, in \u001B[36mIndexedTableMixin.fast_gather\u001B[39m\u001B[34m(self, indices)\u001B[39m\n\u001B[32m    120\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mIndices must be non-empty\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    121\u001B[39m batch_indices = np.searchsorted(\u001B[38;5;28mself\u001B[39m._offsets, indices, side=\u001B[33m\"\u001B[39m\u001B[33mright\u001B[39m\u001B[33m\"\u001B[39m) - \u001B[32m1\u001B[39m\n\u001B[32m    122\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m pa.Table.from_batches(\n\u001B[32m    123\u001B[39m     [\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batches\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mslice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_offsets\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(batch_indices, indices)\n\u001B[32m    126\u001B[39m     ],\n\u001B[32m    127\u001B[39m     schema=\u001B[38;5;28mself\u001B[39m._schema,\n\u001B[32m    128\u001B[39m )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T11:06:36.342820Z",
     "start_time": "2025-07-06T11:06:36.298708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "h0 = torch.zeros(num_layers, 1, hidden_size)\n",
    "message = \"I'm sick of that\"  # \"I never hated you\", \"I do not hate you\"\n",
    "_, tokenized_messages = tokenize_messages([message])\n",
    "encoded_message = encode_x(token_to_index, tokenized_messages[0])\n",
    "x_batch, _ = create_batch([encoded_message], [torch.tensor([0, 0, 0])], 1, len(vocabulary))\n",
    "prediction, _ = model(x_batch.to(device), h0.to(device))\n",
    "print(prediction)\n",
    "_, top_i = torch.topk(prediction, k=1)\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "print(labels[top_i[0].item()])\n",
    "model.train()"
   ],
   "id": "db55682b7562318",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 162.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5146, -1.1322, -2.5265]], device='mps:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(36633, 32)\n",
       "  (rnn): GRU(32, 32, batch_first=True)\n",
       "  (linear): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "33a710c1218e59da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
