{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T06:11:46.857486Z",
     "start_time": "2025-06-30T06:11:44.973456Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T07:18:18.691560Z",
     "start_time": "2025-06-30T07:18:18.684881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See https://docs.pytorch.org/docs/stable/generated/torch.nn.GRU.html.\n",
    "# batch_size = 3\n",
    "# sequence_length = 5\n",
    "# input_size = 10\n",
    "# hidden_size = 20\n",
    "# num_layers = 2\n",
    "# rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "# input = torch.randn(batch_size, sequence_length, input_size)  # Should be (batch_size, sequence_length, input_size)\n",
    "# h0 = torch.randn(num_layers, batch_size, hidden_size)  # Should be (num_layers, batch_size, hidden_size)\n",
    "# output, hn = rnn(input, h0)\n",
    "# print(output.shape)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_dim, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocabulary_size)\n",
    "\n",
    "    def forward(self, sequence, hidden):\n",
    "        embedded = self.embedding(sequence)\n",
    "        prediction, hidden = self.rnn(embedded, hidden)\n",
    "        return self.linear(prediction), hidden\n",
    "\n",
    "batch_size = 1\n",
    "num_layers = 2\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "vocabulary_size = 4\n",
    "input = torch.tensor([\n",
    "    [0, 1, 2, 3, 0]\n",
    "])\n",
    "input2 = torch.tensor([\n",
    "    [0, 1, 2, 3, 0, 1]\n",
    "])\n",
    "model = Model(vocabulary_size, input_size, hidden_size)\n",
    "y1, h1 = model.forward(input, h0)\n",
    "y2, h2 = model.forward(input2, h1)\n",
    "print(y1.shape)\n",
    "print(h1.shape)\n",
    "print(y2.shape)\n",
    "print(h2.shape)"
   ],
   "id": "74d00197ac7e8079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4])\n",
      "torch.Size([2, 1, 20])\n",
      "torch.Size([1, 6, 4])\n",
      "torch.Size([2, 1, 20])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:08:27.540267Z",
     "start_time": "2025-06-29T20:08:27.534986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(messages):\n",
    "    tokens = set()\n",
    "    message_to_tokens = []\n",
    "    for message in messages:\n",
    "        doc = nlp(message)\n",
    "        message_tokens = {token.text.lower() for token in doc if\n",
    "                          token.pos_ in {'ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB'}}\n",
    "        tokens.update(message_tokens)\n",
    "        message_to_tokens.append(message_tokens)\n",
    "    return list(tokens), message_to_tokens"
   ],
   "id": "ab5d7274b7e5c02b",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:08:28.310515Z",
     "start_time": "2025-06-29T20:08:28.305752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_x(vocabulary, tokens):\n",
    "    vector = torch.zeros(len(vocabulary))\n",
    "    for token in tokens:\n",
    "        index = vocabulary[token]\n",
    "        vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def encode_y(label):\n",
    "    vector = torch.zeros(3)\n",
    "    vector[label] = 1\n",
    "    return vector"
   ],
   "id": "ccdbb77242fc8586",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:07.538105Z",
     "start_time": "2025-06-29T20:08:30.282665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "dataset = load_dataset('Sp1786/multiclass-sentiment-analysis-dataset')\n",
    "train_dataset: Dataset = dataset['train']\n",
    "validation_dataset: Dataset = dataset['validation']\n",
    "\n",
    "train_tokens, train_message_to_tokens = tokenize(train_dataset['text'])\n",
    "validation_tokens, validation_message_to_tokens = tokenize(validation_dataset['text'])\n",
    "\n",
    "# the full list of tokens is sorted to ensure that the encoding of the messages stays the same between the Jupiter Notebook reloads, so that the saved models could be loaded and used for inference\n",
    "tokens = sorted(set(train_tokens + validation_tokens))\n",
    "print(tokens[:20])\n",
    "\n",
    "vocabulary = {token: index for index, token in enumerate(tokens)}\n",
    "print(len(vocabulary))"
   ],
   "id": "a1f577bcdf2ff5f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"-', '#', '$', '%', '&', \"'\", \"'-cholla`s\", \"'back\", \"'calendar\", \"'gummed\", \"'not\", \"'peter\", \"'s\", '(:', '(=', '*', '****', '***kix', '*shuts']\n",
      "31839\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:13.495625Z",
     "start_time": "2025-06-29T20:10:09.997384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_xs = torch.stack([encode_x(vocabulary, tokens) for tokens in train_message_to_tokens])\n",
    "train_ys = torch.stack([encode_y(label) for label in train_dataset['label']])\n",
    "validation_xs = torch.stack([encode_x(vocabulary, tokens) for tokens in validation_message_to_tokens])\n",
    "validation_ys = torch.stack([encode_y(label) for label in validation_dataset['label']])\n",
    "print(train_xs.shape)\n",
    "print(train_ys.shape)\n",
    "print(validation_xs.shape)\n",
    "print(validation_ys.shape)"
   ],
   "id": "70e9afa4b858fc22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31232, 31839])\n",
      "torch.Size([31232, 3])\n",
      "torch.Size([5205, 31839])\n",
      "torch.Size([5205, 3])\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:16.171833Z",
     "start_time": "2025-06-29T20:10:16.166872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_batch(xs, ys, batch_size):\n",
    "    random_indices = np.random.choice(len(xs), batch_size)\n",
    "    return xs[random_indices], ys[random_indices]"
   ],
   "id": "18c5705daf5e4493",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:10:18.744226Z",
     "start_time": "2025-06-29T20:10:18.739412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "device = determine_device()\n",
    "print(f'Device is {device}')"
   ],
   "id": "8a688ed2982f2904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is mps\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:12.914952Z",
     "start_time": "2025-06-29T20:11:12.907530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_loss(model, iterations, validation_xs, validation_ys, batch_size):\n",
    "    model.eval()\n",
    "    loses = torch.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        validation_x_batch, validation_y_batch = create_batch(validation_xs, validation_ys, batch_size)\n",
    "        validation_prediction = model(validation_x_batch.to(device))\n",
    "        validation_loss = F.cross_entropy(validation_prediction, validation_y_batch.to(device), reduction='mean')\n",
    "        loses[i] = validation_loss.item()\n",
    "    model.train()\n",
    "    return loses.mean()"
   ],
   "id": "d3b92020a5546457",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:13.419613Z",
     "start_time": "2025-06-29T20:11:13.190819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.Softmax is not required (see the nn.CrossEntropyLoss docs why) and can be kept only in the inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocabulary), 256),\n",
    "    nn.Linear(256, 3)\n",
    ").to(device)"
   ],
   "id": "4b8c3318eccb5afb",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:17.749951Z",
     "start_time": "2025-06-29T20:11:14.834904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 512\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "number_of_epoches = 100\n",
    "min_validation_loss = float('inf')\n",
    "for epoch in range(number_of_epoches):\n",
    "    x_batch, y_batch = create_batch(train_xs, train_ys, batch_size)\n",
    "    prediction = model(x_batch.to(device))\n",
    "    loss = loss_fn(prediction, y_batch.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == number_of_epoches - 1:\n",
    "        mean_loss = estimate_loss(model, 10, validation_xs, validation_ys, batch_size)\n",
    "        print(f'Epoch {epoch}, trail loss {loss.item()}, validation loss {mean_loss.item()}')\n",
    "        if mean_loss < min_validation_loss:\n",
    "            model_file_name = os.path.join(model_dir, \"model_\" + str(epoch) + \".pt\")\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print(\"Model has been saved as\", model_file_name)\n",
    "            min_validation_loss = mean_loss"
   ],
   "id": "4f44062e1b42347d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, trail loss 1.102682113647461, validation loss 1.077303171157837\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_0.pt\n",
      "Epoch 10, trail loss 0.8979932069778442, validation loss 0.9276639819145203\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_10.pt\n",
      "Epoch 20, trail loss 0.7764990329742432, validation loss 0.8771727681159973\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_20.pt\n",
      "Epoch 30, trail loss 0.6884598135948181, validation loss 0.8671800494194031\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_30.pt\n",
      "Epoch 40, trail loss 0.7256267070770264, validation loss 0.9020015597343445\n",
      "Epoch 50, trail loss 0.6767445802688599, validation loss 0.8644858598709106\n",
      "Model has been saved as /Users/yaskovdev/dev/git_home/ai-sandbox/sentiment-analysis/models/model_50.pt\n",
      "Epoch 60, trail loss 0.6512887477874756, validation loss 0.8933747410774231\n",
      "Epoch 70, trail loss 0.48553532361984253, validation loss 0.8906658887863159\n",
      "Epoch 80, trail loss 0.6025042533874512, validation loss 0.9102509617805481\n",
      "Epoch 90, trail loss 0.4578779935836792, validation loss 0.9364584684371948\n",
      "Epoch 99, trail loss 0.5630014538764954, validation loss 0.9557567834854126\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:11:47.164068Z",
     "start_time": "2025-06-29T20:11:46.942965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(os.getcwd(), \"models\", 'model_50.pt'), map_location=torch.device(device)))"
   ],
   "id": "f4c30589c091f035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:12:48.113589Z",
     "start_time": "2025-06-29T20:12:48.060756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "message = \"You're the best\"\n",
    "test_tokens, _ = tokenize([message])\n",
    "x = encode_x(vocabulary, test_tokens)\n",
    "y = model(x.to(device))\n",
    "\n",
    "distribution = torch.nn.functional.softmax(y, dim=-1)\n",
    "print(distribution)\n",
    "answer = torch.argmax(distribution)\n",
    "print(['negative', 'neutral', 'positive'][answer])\n",
    "model.train()"
   ],
   "id": "6c7160e407faace2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0780, 0.2832, 0.6388], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=31839, out_features=256, bias=True)\n",
       "  (1): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T22:35:02.862627Z",
     "start_time": "2025-06-28T22:35:02.662960Z"
    }
   },
   "cell_type": "code",
   "source": "torch.onnx.export(model, (torch.tensor(x, dtype=torch.float32).to(device),), \"model.onnx\")",
   "id": "c630e4b125e46d91",
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
